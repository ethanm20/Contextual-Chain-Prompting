,Unnamed: 0,Access Gained,Attack Origin,Authentication Required,Availability,CVE ID,CVE Page,CWE ID,Complexity,Confidentiality,Integrity,Known Exploits,Publish Date,Score,Summary,Update Date,Vulnerability Classification,add_lines,codeLink,commit_id,commit_message,del_lines,file_name,files_changed,func_after,func_before,lang,lines_after,lines_before,parentID,patch,project,project_after,project_before,vul,vul_func_with_fix
2166,179902,,Local,Not required,Complete,CVE-2015-0274,https://www.cvedetails.com/cve/CVE-2015-0274/,CWE-19,Low,Complete,Complete,,2015-03-16,7.2,"The XFS implementation in the Linux kernel before 3.15 improperly uses an old size value during remote attribute replacement, which allows local users to cause a denial of service (transaction overrun and data corruption) or possibly gain privileges by leveraging XFS filesystem access.",2015-03-26,DoS +Priv ,1,https://github.com/torvalds/linux/commit/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,"xfs: remote attribute overwrite causes transaction overrun

Commit e461fcb (""xfs: remote attribute lookups require the value
length"") passes the remote attribute length in the xfs_da_args
structure on lookup so that CRC calculations and validity checking
can be performed correctly by related code. This, unfortunately has
the side effect of changing the args->valuelen parameter in cases
where it shouldn't.

That is, when we replace a remote attribute, the incoming
replacement stores the value and length in args->value and
args->valuelen, but then the lookup which finds the existing remote
attribute overwrites args->valuelen with the length of the remote
attribute being replaced. Hence when we go to create the new
attribute, we create it of the size of the existing remote
attribute, not the size it is supposed to be. When the new attribute
is much smaller than the old attribute, this results in a
transaction overrun and an ASSERT() failure on a debug kernel:

XFS: Assertion failed: tp->t_blk_res_used <= tp->t_blk_res, file: fs/xfs/xfs_trans.c, line: 331

Fix this by keeping the remote attribute value length separate to
the attribute value length in the xfs_da_args structure. The enables
us to pass the length of the remote attribute to be removed without
overwriting the new attribute's length.

Also, ensure that when we save remote block contexts for a later
rename we zero the original state variables so that we don't confuse
the state of the attribute to be removes with the state of the new
attribute that we just added. [Spotted by Brain Foster.]

Signed-off-by: Dave Chinner <dchinner@redhat.com>
Reviewed-by: Brian Foster <bfoster@redhat.com>
Signed-off-by: Dave Chinner <david@fromorbit.com>",1,fs/xfs/xfs_attr.c,"{""sha"": ""abda1124a70f66fbd1a79b28f8eaf5bf1916da1e"", ""filename"": ""fs/xfs/xfs_attr.c"", ""status"": ""modified"", ""additions"": 23, ""deletions"": 1, ""changes"": 24, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -213,7 +213,7 @@ xfs_attr_calc_size(\n \t\t * Out of line attribute, cannot double split, but\n \t\t * make room for the attribute value itself.\n \t\t */\n-\t\tuint\tdblocks = XFS_B_TO_FSB(mp, valuelen);\n+\t\tuint\tdblocks = xfs_attr3_rmt_blocks(mp, valuelen);\n \t\tnblks += dblocks;\n \t\tnblks += XFS_NEXTENTADD_SPACE_RES(mp, dblocks, XFS_ATTR_FORK);\n \t}\n@@ -698,11 +698,22 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)\n \n \t\ttrace_xfs_attr_leaf_replace(args);\n \n+\t\t/* save the attribute state for later removal*/\n \t\targs->op_flags |= XFS_DA_OP_RENAME;\t/* an atomic rename */\n \t\targs->blkno2 = args->blkno;\t\t/* set 2nd entry info*/\n \t\targs->index2 = args->index;\n \t\targs->rmtblkno2 = args->rmtblkno;\n \t\targs->rmtblkcnt2 = args->rmtblkcnt;\n+\t\targs->rmtvaluelen2 = args->rmtvaluelen;\n+\n+\t\t/*\n+\t\t * clear the remote attr state now that it is saved so that the\n+\t\t * values reflect the state of the attribute we are about to\n+\t\t * add, not the attribute we just found and will remove later.\n+\t\t */\n+\t\targs->rmtblkno = 0;\n+\t\targs->rmtblkcnt = 0;\n+\t\targs->rmtvaluelen = 0;\n \t}\n \n \t/*\n@@ -794,6 +805,7 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)\n \t\targs->blkno = args->blkno2;\n \t\targs->rmtblkno = args->rmtblkno2;\n \t\targs->rmtblkcnt = args->rmtblkcnt2;\n+\t\targs->rmtvaluelen = args->rmtvaluelen2;\n \t\tif (args->rmtblkno) {\n \t\t\terror = xfs_attr_rmtval_remove(args);\n \t\t\tif (error)\n@@ -999,13 +1011,22 @@ xfs_attr_node_addname(xfs_da_args_t *args)\n \n \t\ttrace_xfs_attr_node_replace(args);\n \n+\t\t/* save the attribute state for later removal*/\n \t\targs->op_flags |= XFS_DA_OP_RENAME;\t/* atomic rename op */\n \t\targs->blkno2 = args->blkno;\t\t/* set 2nd entry info*/\n \t\targs->index2 = args->index;\n \t\targs->rmtblkno2 = args->rmtblkno;\n \t\targs->rmtblkcnt2 = args->rmtblkcnt;\n+\t\targs->rmtvaluelen2 = args->rmtvaluelen;\n+\n+\t\t/*\n+\t\t * clear the remote attr state now that it is saved so that the\n+\t\t * values reflect the state of the attribute we are about to\n+\t\t * add, not the attribute we just found and will remove later.\n+\t\t */\n \t\targs->rmtblkno = 0;\n \t\targs->rmtblkcnt = 0;\n+\t\targs->rmtvaluelen = 0;\n \t}\n \n \tretval = xfs_attr3_leaf_add(blk->bp, state->args);\n@@ -1133,6 +1154,7 @@ xfs_attr_node_addname(xfs_da_args_t *args)\n \t\targs->blkno = args->blkno2;\n \t\targs->rmtblkno = args->rmtblkno2;\n \t\targs->rmtblkcnt = args->rmtblkcnt2;\n+\t\targs->rmtvaluelen = args->rmtvaluelen2;\n \t\tif (args->rmtblkno) {\n \t\t\terror = xfs_attr_rmtval_remove(args);\n \t\t\tif (error)""}<_**next**_>{""sha"": ""511c283459b19441d782114c4f832207860deab1"", ""filename"": ""fs/xfs/xfs_attr_leaf.c"", ""status"": ""modified"", ""additions"": 11, ""deletions"": 10, ""changes"": 21, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_leaf.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_leaf.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_leaf.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -1229,6 +1229,7 @@ xfs_attr3_leaf_add_work(\n \t\tname_rmt->valueblk = 0;\n \t\targs->rmtblkno = 1;\n \t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);\n+\t\targs->rmtvaluelen = args->valuelen;\n \t}\n \txfs_trans_log_buf(args->trans, bp,\n \t     XFS_DA_LOGRANGE(leaf, xfs_attr3_leaf_name(leaf, args->index),\n@@ -2167,11 +2168,11 @@ xfs_attr3_leaf_lookup_int(\n \t\t\tif (!xfs_attr_namesp_match(args->flags, entry->flags))\n \t\t\t\tcontinue;\n \t\t\targs->index = probe;\n-\t\t\targs->valuelen = be32_to_cpu(name_rmt->valuelen);\n+\t\t\targs->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);\n \t\t\targs->rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(\n \t\t\t\t\t\t\targs->dp->i_mount,\n-\t\t\t\t\t\t\targs->valuelen);\n+\t\t\t\t\t\t\targs->rmtvaluelen);\n \t\t\treturn XFS_ERROR(EEXIST);\n \t\t}\n \t}\n@@ -2220,19 +2221,19 @@ xfs_attr3_leaf_getvalue(\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);\n \t\tASSERT(name_rmt->namelen == args->namelen);\n \t\tASSERT(memcmp(args->name, name_rmt->name, args->namelen) == 0);\n-\t\tvaluelen = be32_to_cpu(name_rmt->valuelen);\n+\t\targs->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);\n \t\targs->rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(args->dp->i_mount,\n-\t\t\t\t\t\t       valuelen);\n+\t\t\t\t\t\t       args->rmtvaluelen);\n \t\tif (args->flags & ATTR_KERNOVAL) {\n-\t\t\targs->valuelen = valuelen;\n+\t\t\targs->valuelen = args->rmtvaluelen;\n \t\t\treturn 0;\n \t\t}\n-\t\tif (args->valuelen < valuelen) {\n-\t\t\targs->valuelen = valuelen;\n+\t\tif (args->valuelen < args->rmtvaluelen) {\n+\t\t\targs->valuelen = args->rmtvaluelen;\n \t\t\treturn XFS_ERROR(ERANGE);\n \t\t}\n-\t\targs->valuelen = valuelen;\n+\t\targs->valuelen = args->rmtvaluelen;\n \t}\n \treturn 0;\n }\n@@ -2519,7 +2520,7 @@ xfs_attr3_leaf_clearflag(\n \t\tASSERT((entry->flags & XFS_ATTR_LOCAL) == 0);\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);\n \t\tname_rmt->valueblk = cpu_to_be32(args->rmtblkno);\n-\t\tname_rmt->valuelen = cpu_to_be32(args->valuelen);\n+\t\tname_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);\n \t\txfs_trans_log_buf(args->trans, bp,\n \t\t\t XFS_DA_LOGRANGE(leaf, name_rmt, sizeof(*name_rmt)));\n \t}\n@@ -2677,7 +2678,7 @@ xfs_attr3_leaf_flipflags(\n \t\tASSERT((entry1->flags & XFS_ATTR_LOCAL) == 0);\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf1, args->index);\n \t\tname_rmt->valueblk = cpu_to_be32(args->rmtblkno);\n-\t\tname_rmt->valuelen = cpu_to_be32(args->valuelen);\n+\t\tname_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);\n \t\txfs_trans_log_buf(args->trans, bp1,\n \t\t\t XFS_DA_LOGRANGE(leaf1, name_rmt, sizeof(*name_rmt)));\n \t}""}<_**next**_>{""sha"": ""833fe5d98d806783ca6bb6cf2f4ecb83424bfdca"", ""filename"": ""fs/xfs/xfs_attr_list.c"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 0, ""changes"": 1, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_list.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_list.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_list.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -447,6 +447,7 @@ xfs_attr3_leaf_list_int(\n \t\t\t\targs.dp = context->dp;\n \t\t\t\targs.whichfork = XFS_ATTR_FORK;\n \t\t\t\targs.valuelen = valuelen;\n+\t\t\t\targs.rmtvaluelen = valuelen;\n \t\t\t\targs.value = kmem_alloc(valuelen, KM_SLEEP | KM_NOFS);\n \t\t\t\targs.rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\t\t\targs.rmtblkcnt = xfs_attr3_rmt_blocks(""}<_**next**_>{""sha"": ""d2e6e948cec7be3013b853033b6e1a64b365a682"", ""filename"": ""fs/xfs/xfs_attr_remote.c"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 3, ""changes"": 8, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_remote.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_remote.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_remote.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -337,7 +337,7 @@ xfs_attr_rmtval_get(\n \tstruct xfs_buf\t\t*bp;\n \txfs_dablk_t\t\tlblkno = args->rmtblkno;\n \t__uint8_t\t\t*dst = args->value;\n-\tint\t\t\tvaluelen = args->valuelen;\n+\tint\t\t\tvaluelen;\n \tint\t\t\tnmap;\n \tint\t\t\terror;\n \tint\t\t\tblkcnt = args->rmtblkcnt;\n@@ -347,7 +347,9 @@ xfs_attr_rmtval_get(\n \ttrace_xfs_attr_rmtval_get(args);\n \n \tASSERT(!(args->flags & ATTR_KERNOVAL));\n+\tASSERT(args->rmtvaluelen == args->valuelen);\n \n+\tvaluelen = args->rmtvaluelen;\n \twhile (valuelen > 0) {\n \t\tnmap = ATTR_RMTVALUE_MAPSIZE;\n \t\terror = xfs_bmapi_read(args->dp, (xfs_fileoff_t)lblkno,\n@@ -415,7 +417,7 @@ xfs_attr_rmtval_set(\n \t * attributes have headers, we can't just do a straight byte to FSB\n \t * conversion and have to take the header space into account.\n \t */\n-\tblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);\n+\tblkcnt = xfs_attr3_rmt_blocks(mp, args->rmtvaluelen);\n \terror = xfs_bmap_first_unused(args->trans, args->dp, blkcnt, &lfileoff,\n \t\t\t\t\t\t   XFS_ATTR_FORK);\n \tif (error)\n@@ -480,7 +482,7 @@ xfs_attr_rmtval_set(\n \t */\n \tlblkno = args->rmtblkno;\n \tblkcnt = args->rmtblkcnt;\n-\tvaluelen = args->valuelen;\n+\tvaluelen = args->rmtvaluelen;\n \twhile (valuelen > 0) {\n \t\tstruct xfs_buf\t*bp;\n \t\txfs_daddr_t\tdblkno;""}<_**next**_>{""sha"": ""201c6091d26abfa2e38dd17fd960e3efcb69bcd7"", ""filename"": ""fs/xfs/xfs_da_btree.h"", ""status"": ""modified"", ""additions"": 2, ""deletions"": 0, ""changes"": 2, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_da_btree.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_da_btree.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_da_btree.h?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -60,10 +60,12 @@ typedef struct xfs_da_args {\n \tint\t\tindex;\t\t/* index of attr of interest in blk */\n \txfs_dablk_t\trmtblkno;\t/* remote attr value starting blkno */\n \tint\t\trmtblkcnt;\t/* remote attr value block count */\n+\tint\t\trmtvaluelen;\t/* remote attr value length in bytes */\n \txfs_dablk_t\tblkno2;\t\t/* blkno of 2nd attr leaf of interest */\n \tint\t\tindex2;\t\t/* index of 2nd attr in blk */\n \txfs_dablk_t\trmtblkno2;\t/* remote attr value starting blkno */\n \tint\t\trmtblkcnt2;\t/* remote attr value block count */\n+\tint\t\trmtvaluelen2;\t/* remote attr value length in bytes */\n \tint\t\top_flags;\t/* operation flags */\n \tenum xfs_dacmp\tcmpresult;\t/* name compare result for lookups */\n } xfs_da_args_t;""}","xfs_attr_calc_size(
	struct xfs_inode 	*ip,
	int			namelen,
	int			valuelen,
	int			*local)
{
	struct xfs_mount 	*mp = ip->i_mount;
	int			size;
	int			nblks;

	/*
	 * Determine space new attribute will use, and if it would be
	 * ""local"" or ""remote"" (note: local != inline).
	 */
	size = xfs_attr_leaf_newentsize(namelen, valuelen,
					mp->m_sb.sb_blocksize, local);

	nblks = XFS_DAENTER_SPACE_RES(mp, XFS_ATTR_FORK);
	if (*local) {
		if (size > (mp->m_sb.sb_blocksize >> 1)) {
			/* Double split possible */
			nblks *= 2;
		}
	} else {
		/*
 		 * Out of line attribute, cannot double split, but
 		 * make room for the attribute value itself.
 		 */
		uint	dblocks = xfs_attr3_rmt_blocks(mp, valuelen);
 		nblks += dblocks;
 		nblks += XFS_NEXTENTADD_SPACE_RES(mp, dblocks, XFS_ATTR_FORK);
 	}

	return nblks;
}
","xfs_attr_calc_size(
	struct xfs_inode 	*ip,
	int			namelen,
	int			valuelen,
	int			*local)
{
	struct xfs_mount 	*mp = ip->i_mount;
	int			size;
	int			nblks;

	/*
	 * Determine space new attribute will use, and if it would be
	 * ""local"" or ""remote"" (note: local != inline).
	 */
	size = xfs_attr_leaf_newentsize(namelen, valuelen,
					mp->m_sb.sb_blocksize, local);

	nblks = XFS_DAENTER_SPACE_RES(mp, XFS_ATTR_FORK);
	if (*local) {
		if (size > (mp->m_sb.sb_blocksize >> 1)) {
			/* Double split possible */
			nblks *= 2;
		}
	} else {
		/*
 		 * Out of line attribute, cannot double split, but
 		 * make room for the attribute value itself.
 		 */
		uint	dblocks = XFS_B_TO_FSB(mp, valuelen);
 		nblks += dblocks;
 		nblks += XFS_NEXTENTADD_SPACE_RES(mp, dblocks, XFS_ATTR_FORK);
 	}

	return nblks;
}
",C,"		uint	dblocks = xfs_attr3_rmt_blocks(mp, valuelen);
","		uint	dblocks = XFS_B_TO_FSB(mp, valuelen);
",,"@@ -213,7 +213,7 @@ xfs_attr_calc_size(
 		 * Out of line attribute, cannot double split, but
 		 * make room for the attribute value itself.
 		 */
-		uint	dblocks = XFS_B_TO_FSB(mp, valuelen);
+		uint	dblocks = xfs_attr3_rmt_blocks(mp, valuelen);
 		nblks += dblocks;
 		nblks += XFS_NEXTENTADD_SPACE_RES(mp, dblocks, XFS_ATTR_FORK);
 	}
@@ -698,11 +698,22 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)
 
 		trace_xfs_attr_leaf_replace(args);
 
+		/* save the attribute state for later removal*/
 		args->op_flags |= XFS_DA_OP_RENAME;	/* an atomic rename */
 		args->blkno2 = args->blkno;		/* set 2nd entry info*/
 		args->index2 = args->index;
 		args->rmtblkno2 = args->rmtblkno;
 		args->rmtblkcnt2 = args->rmtblkcnt;
+		args->rmtvaluelen2 = args->rmtvaluelen;
+
+		/*
+		 * clear the remote attr state now that it is saved so that the
+		 * values reflect the state of the attribute we are about to
+		 * add, not the attribute we just found and will remove later.
+		 */
+		args->rmtblkno = 0;
+		args->rmtblkcnt = 0;
+		args->rmtvaluelen = 0;
 	}
 
 	/*
@@ -794,6 +805,7 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)
 		args->blkno = args->blkno2;
 		args->rmtblkno = args->rmtblkno2;
 		args->rmtblkcnt = args->rmtblkcnt2;
+		args->rmtvaluelen = args->rmtvaluelen2;
 		if (args->rmtblkno) {
 			error = xfs_attr_rmtval_remove(args);
 			if (error)
@@ -999,13 +1011,22 @@ xfs_attr_node_addname(xfs_da_args_t *args)
 
 		trace_xfs_attr_node_replace(args);
 
+		/* save the attribute state for later removal*/
 		args->op_flags |= XFS_DA_OP_RENAME;	/* atomic rename op */
 		args->blkno2 = args->blkno;		/* set 2nd entry info*/
 		args->index2 = args->index;
 		args->rmtblkno2 = args->rmtblkno;
 		args->rmtblkcnt2 = args->rmtblkcnt;
+		args->rmtvaluelen2 = args->rmtvaluelen;
+
+		/*
+		 * clear the remote attr state now that it is saved so that the
+		 * values reflect the state of the attribute we are about to
+		 * add, not the attribute we just found and will remove later.
+		 */
 		args->rmtblkno = 0;
 		args->rmtblkcnt = 0;
+		args->rmtvaluelen = 0;
 	}
 
 	retval = xfs_attr3_leaf_add(blk->bp, state->args);
@@ -1133,6 +1154,7 @@ xfs_attr_node_addname(xfs_da_args_t *args)
 		args->blkno = args->blkno2;
 		args->rmtblkno = args->rmtblkno2;
 		args->rmtblkcnt = args->rmtblkcnt2;
+		args->rmtvaluelen = args->rmtvaluelen2;
 		if (args->rmtblkno) {
 			error = xfs_attr_rmtval_remove(args);
 			if (error)",linux,8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,d540e43b0ab134b22f015f725ce6e070d12b0244,1,"xfs_attr_calc_size(
	struct xfs_inode 	*ip,
	int			namelen,
	int			valuelen,
	int			*local)
{
	struct xfs_mount 	*mp = ip->i_mount;
	int			size;
	int			nblks;

	/*
	 * Determine space new attribute will use, and if it would be
	 * ""local"" or ""remote"" (note: local != inline).
	 */
	size = xfs_attr_leaf_newentsize(namelen, valuelen,
					mp->m_sb.sb_blocksize, local);

	nblks = XFS_DAENTER_SPACE_RES(mp, XFS_ATTR_FORK);
	if (*local) {
		if (size > (mp->m_sb.sb_blocksize >> 1)) {
			/* Double split possible */
			nblks *= 2;
		}
	} else {
		/*
 		 * Out of line attribute, cannot double split, but
 		 * make room for the attribute value itself.
 		 */
//flaw_line_below:
		uint	dblocks = XFS_B_TO_FSB(mp, valuelen);
//fix_flaw_line_below:
//		uint	dblocks = xfs_attr3_rmt_blocks(mp, valuelen);
 		nblks += dblocks;
 		nblks += XFS_NEXTENTADD_SPACE_RES(mp, dblocks, XFS_ATTR_FORK);
 	}

	return nblks;
}
"
2167,179903,,Local,Not required,Complete,CVE-2015-0274,https://www.cvedetails.com/cve/CVE-2015-0274/,CWE-19,Low,Complete,Complete,,2015-03-16,7.2,"The XFS implementation in the Linux kernel before 3.15 improperly uses an old size value during remote attribute replacement, which allows local users to cause a denial of service (transaction overrun and data corruption) or possibly gain privileges by leveraging XFS filesystem access.",2015-03-26,DoS +Priv ,12,https://github.com/torvalds/linux/commit/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,"xfs: remote attribute overwrite causes transaction overrun

Commit e461fcb (""xfs: remote attribute lookups require the value
length"") passes the remote attribute length in the xfs_da_args
structure on lookup so that CRC calculations and validity checking
can be performed correctly by related code. This, unfortunately has
the side effect of changing the args->valuelen parameter in cases
where it shouldn't.

That is, when we replace a remote attribute, the incoming
replacement stores the value and length in args->value and
args->valuelen, but then the lookup which finds the existing remote
attribute overwrites args->valuelen with the length of the remote
attribute being replaced. Hence when we go to create the new
attribute, we create it of the size of the existing remote
attribute, not the size it is supposed to be. When the new attribute
is much smaller than the old attribute, this results in a
transaction overrun and an ASSERT() failure on a debug kernel:

XFS: Assertion failed: tp->t_blk_res_used <= tp->t_blk_res, file: fs/xfs/xfs_trans.c, line: 331

Fix this by keeping the remote attribute value length separate to
the attribute value length in the xfs_da_args structure. The enables
us to pass the length of the remote attribute to be removed without
overwriting the new attribute's length.

Also, ensure that when we save remote block contexts for a later
rename we zero the original state variables so that we don't confuse
the state of the attribute to be removes with the state of the new
attribute that we just added. [Spotted by Brain Foster.]

Signed-off-by: Dave Chinner <dchinner@redhat.com>
Reviewed-by: Brian Foster <bfoster@redhat.com>
Signed-off-by: Dave Chinner <david@fromorbit.com>",0,fs/xfs/xfs_attr.c,"{""sha"": ""abda1124a70f66fbd1a79b28f8eaf5bf1916da1e"", ""filename"": ""fs/xfs/xfs_attr.c"", ""status"": ""modified"", ""additions"": 23, ""deletions"": 1, ""changes"": 24, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -213,7 +213,7 @@ xfs_attr_calc_size(\n \t\t * Out of line attribute, cannot double split, but\n \t\t * make room for the attribute value itself.\n \t\t */\n-\t\tuint\tdblocks = XFS_B_TO_FSB(mp, valuelen);\n+\t\tuint\tdblocks = xfs_attr3_rmt_blocks(mp, valuelen);\n \t\tnblks += dblocks;\n \t\tnblks += XFS_NEXTENTADD_SPACE_RES(mp, dblocks, XFS_ATTR_FORK);\n \t}\n@@ -698,11 +698,22 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)\n \n \t\ttrace_xfs_attr_leaf_replace(args);\n \n+\t\t/* save the attribute state for later removal*/\n \t\targs->op_flags |= XFS_DA_OP_RENAME;\t/* an atomic rename */\n \t\targs->blkno2 = args->blkno;\t\t/* set 2nd entry info*/\n \t\targs->index2 = args->index;\n \t\targs->rmtblkno2 = args->rmtblkno;\n \t\targs->rmtblkcnt2 = args->rmtblkcnt;\n+\t\targs->rmtvaluelen2 = args->rmtvaluelen;\n+\n+\t\t/*\n+\t\t * clear the remote attr state now that it is saved so that the\n+\t\t * values reflect the state of the attribute we are about to\n+\t\t * add, not the attribute we just found and will remove later.\n+\t\t */\n+\t\targs->rmtblkno = 0;\n+\t\targs->rmtblkcnt = 0;\n+\t\targs->rmtvaluelen = 0;\n \t}\n \n \t/*\n@@ -794,6 +805,7 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)\n \t\targs->blkno = args->blkno2;\n \t\targs->rmtblkno = args->rmtblkno2;\n \t\targs->rmtblkcnt = args->rmtblkcnt2;\n+\t\targs->rmtvaluelen = args->rmtvaluelen2;\n \t\tif (args->rmtblkno) {\n \t\t\terror = xfs_attr_rmtval_remove(args);\n \t\t\tif (error)\n@@ -999,13 +1011,22 @@ xfs_attr_node_addname(xfs_da_args_t *args)\n \n \t\ttrace_xfs_attr_node_replace(args);\n \n+\t\t/* save the attribute state for later removal*/\n \t\targs->op_flags |= XFS_DA_OP_RENAME;\t/* atomic rename op */\n \t\targs->blkno2 = args->blkno;\t\t/* set 2nd entry info*/\n \t\targs->index2 = args->index;\n \t\targs->rmtblkno2 = args->rmtblkno;\n \t\targs->rmtblkcnt2 = args->rmtblkcnt;\n+\t\targs->rmtvaluelen2 = args->rmtvaluelen;\n+\n+\t\t/*\n+\t\t * clear the remote attr state now that it is saved so that the\n+\t\t * values reflect the state of the attribute we are about to\n+\t\t * add, not the attribute we just found and will remove later.\n+\t\t */\n \t\targs->rmtblkno = 0;\n \t\targs->rmtblkcnt = 0;\n+\t\targs->rmtvaluelen = 0;\n \t}\n \n \tretval = xfs_attr3_leaf_add(blk->bp, state->args);\n@@ -1133,6 +1154,7 @@ xfs_attr_node_addname(xfs_da_args_t *args)\n \t\targs->blkno = args->blkno2;\n \t\targs->rmtblkno = args->rmtblkno2;\n \t\targs->rmtblkcnt = args->rmtblkcnt2;\n+\t\targs->rmtvaluelen = args->rmtvaluelen2;\n \t\tif (args->rmtblkno) {\n \t\t\terror = xfs_attr_rmtval_remove(args);\n \t\t\tif (error)""}<_**next**_>{""sha"": ""511c283459b19441d782114c4f832207860deab1"", ""filename"": ""fs/xfs/xfs_attr_leaf.c"", ""status"": ""modified"", ""additions"": 11, ""deletions"": 10, ""changes"": 21, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_leaf.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_leaf.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_leaf.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -1229,6 +1229,7 @@ xfs_attr3_leaf_add_work(\n \t\tname_rmt->valueblk = 0;\n \t\targs->rmtblkno = 1;\n \t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);\n+\t\targs->rmtvaluelen = args->valuelen;\n \t}\n \txfs_trans_log_buf(args->trans, bp,\n \t     XFS_DA_LOGRANGE(leaf, xfs_attr3_leaf_name(leaf, args->index),\n@@ -2167,11 +2168,11 @@ xfs_attr3_leaf_lookup_int(\n \t\t\tif (!xfs_attr_namesp_match(args->flags, entry->flags))\n \t\t\t\tcontinue;\n \t\t\targs->index = probe;\n-\t\t\targs->valuelen = be32_to_cpu(name_rmt->valuelen);\n+\t\t\targs->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);\n \t\t\targs->rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(\n \t\t\t\t\t\t\targs->dp->i_mount,\n-\t\t\t\t\t\t\targs->valuelen);\n+\t\t\t\t\t\t\targs->rmtvaluelen);\n \t\t\treturn XFS_ERROR(EEXIST);\n \t\t}\n \t}\n@@ -2220,19 +2221,19 @@ xfs_attr3_leaf_getvalue(\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);\n \t\tASSERT(name_rmt->namelen == args->namelen);\n \t\tASSERT(memcmp(args->name, name_rmt->name, args->namelen) == 0);\n-\t\tvaluelen = be32_to_cpu(name_rmt->valuelen);\n+\t\targs->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);\n \t\targs->rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(args->dp->i_mount,\n-\t\t\t\t\t\t       valuelen);\n+\t\t\t\t\t\t       args->rmtvaluelen);\n \t\tif (args->flags & ATTR_KERNOVAL) {\n-\t\t\targs->valuelen = valuelen;\n+\t\t\targs->valuelen = args->rmtvaluelen;\n \t\t\treturn 0;\n \t\t}\n-\t\tif (args->valuelen < valuelen) {\n-\t\t\targs->valuelen = valuelen;\n+\t\tif (args->valuelen < args->rmtvaluelen) {\n+\t\t\targs->valuelen = args->rmtvaluelen;\n \t\t\treturn XFS_ERROR(ERANGE);\n \t\t}\n-\t\targs->valuelen = valuelen;\n+\t\targs->valuelen = args->rmtvaluelen;\n \t}\n \treturn 0;\n }\n@@ -2519,7 +2520,7 @@ xfs_attr3_leaf_clearflag(\n \t\tASSERT((entry->flags & XFS_ATTR_LOCAL) == 0);\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);\n \t\tname_rmt->valueblk = cpu_to_be32(args->rmtblkno);\n-\t\tname_rmt->valuelen = cpu_to_be32(args->valuelen);\n+\t\tname_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);\n \t\txfs_trans_log_buf(args->trans, bp,\n \t\t\t XFS_DA_LOGRANGE(leaf, name_rmt, sizeof(*name_rmt)));\n \t}\n@@ -2677,7 +2678,7 @@ xfs_attr3_leaf_flipflags(\n \t\tASSERT((entry1->flags & XFS_ATTR_LOCAL) == 0);\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf1, args->index);\n \t\tname_rmt->valueblk = cpu_to_be32(args->rmtblkno);\n-\t\tname_rmt->valuelen = cpu_to_be32(args->valuelen);\n+\t\tname_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);\n \t\txfs_trans_log_buf(args->trans, bp1,\n \t\t\t XFS_DA_LOGRANGE(leaf1, name_rmt, sizeof(*name_rmt)));\n \t}""}<_**next**_>{""sha"": ""833fe5d98d806783ca6bb6cf2f4ecb83424bfdca"", ""filename"": ""fs/xfs/xfs_attr_list.c"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 0, ""changes"": 1, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_list.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_list.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_list.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -447,6 +447,7 @@ xfs_attr3_leaf_list_int(\n \t\t\t\targs.dp = context->dp;\n \t\t\t\targs.whichfork = XFS_ATTR_FORK;\n \t\t\t\targs.valuelen = valuelen;\n+\t\t\t\targs.rmtvaluelen = valuelen;\n \t\t\t\targs.value = kmem_alloc(valuelen, KM_SLEEP | KM_NOFS);\n \t\t\t\targs.rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\t\t\targs.rmtblkcnt = xfs_attr3_rmt_blocks(""}<_**next**_>{""sha"": ""d2e6e948cec7be3013b853033b6e1a64b365a682"", ""filename"": ""fs/xfs/xfs_attr_remote.c"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 3, ""changes"": 8, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_remote.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_remote.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_remote.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -337,7 +337,7 @@ xfs_attr_rmtval_get(\n \tstruct xfs_buf\t\t*bp;\n \txfs_dablk_t\t\tlblkno = args->rmtblkno;\n \t__uint8_t\t\t*dst = args->value;\n-\tint\t\t\tvaluelen = args->valuelen;\n+\tint\t\t\tvaluelen;\n \tint\t\t\tnmap;\n \tint\t\t\terror;\n \tint\t\t\tblkcnt = args->rmtblkcnt;\n@@ -347,7 +347,9 @@ xfs_attr_rmtval_get(\n \ttrace_xfs_attr_rmtval_get(args);\n \n \tASSERT(!(args->flags & ATTR_KERNOVAL));\n+\tASSERT(args->rmtvaluelen == args->valuelen);\n \n+\tvaluelen = args->rmtvaluelen;\n \twhile (valuelen > 0) {\n \t\tnmap = ATTR_RMTVALUE_MAPSIZE;\n \t\terror = xfs_bmapi_read(args->dp, (xfs_fileoff_t)lblkno,\n@@ -415,7 +417,7 @@ xfs_attr_rmtval_set(\n \t * attributes have headers, we can't just do a straight byte to FSB\n \t * conversion and have to take the header space into account.\n \t */\n-\tblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);\n+\tblkcnt = xfs_attr3_rmt_blocks(mp, args->rmtvaluelen);\n \terror = xfs_bmap_first_unused(args->trans, args->dp, blkcnt, &lfileoff,\n \t\t\t\t\t\t   XFS_ATTR_FORK);\n \tif (error)\n@@ -480,7 +482,7 @@ xfs_attr_rmtval_set(\n \t */\n \tlblkno = args->rmtblkno;\n \tblkcnt = args->rmtblkcnt;\n-\tvaluelen = args->valuelen;\n+\tvaluelen = args->rmtvaluelen;\n \twhile (valuelen > 0) {\n \t\tstruct xfs_buf\t*bp;\n \t\txfs_daddr_t\tdblkno;""}<_**next**_>{""sha"": ""201c6091d26abfa2e38dd17fd960e3efcb69bcd7"", ""filename"": ""fs/xfs/xfs_da_btree.h"", ""status"": ""modified"", ""additions"": 2, ""deletions"": 0, ""changes"": 2, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_da_btree.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_da_btree.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_da_btree.h?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -60,10 +60,12 @@ typedef struct xfs_da_args {\n \tint\t\tindex;\t\t/* index of attr of interest in blk */\n \txfs_dablk_t\trmtblkno;\t/* remote attr value starting blkno */\n \tint\t\trmtblkcnt;\t/* remote attr value block count */\n+\tint\t\trmtvaluelen;\t/* remote attr value length in bytes */\n \txfs_dablk_t\tblkno2;\t\t/* blkno of 2nd attr leaf of interest */\n \tint\t\tindex2;\t\t/* index of 2nd attr in blk */\n \txfs_dablk_t\trmtblkno2;\t/* remote attr value starting blkno */\n \tint\t\trmtblkcnt2;\t/* remote attr value block count */\n+\tint\t\trmtvaluelen2;\t/* remote attr value length in bytes */\n \tint\t\top_flags;\t/* operation flags */\n \tenum xfs_dacmp\tcmpresult;\t/* name compare result for lookups */\n } xfs_da_args_t;""}","xfs_attr_leaf_addname(xfs_da_args_t *args)
{
	xfs_inode_t *dp;
	struct xfs_buf *bp;
	int retval, error, committed, forkoff;

	trace_xfs_attr_leaf_addname(args);

	/*
	 * Read the (only) block in the attribute list in.
	 */
	dp = args->dp;
	args->blkno = 0;
	error = xfs_attr3_leaf_read(args->trans, args->dp, args->blkno, -1, &bp);
	if (error)
		return error;

	/*
	 * Look up the given attribute in the leaf block.  Figure out if
	 * the given flags produce an error or call for an atomic rename.
	 */
	retval = xfs_attr3_leaf_lookup_int(bp, args);
	if ((args->flags & ATTR_REPLACE) && (retval == ENOATTR)) {
		xfs_trans_brelse(args->trans, bp);
		return retval;
	} else if (retval == EEXIST) {
		if (args->flags & ATTR_CREATE) {	/* pure create op */
			xfs_trans_brelse(args->trans, bp);
			return retval;
		}
 
 		trace_xfs_attr_leaf_replace(args);
 
		/* save the attribute state for later removal*/
 		args->op_flags |= XFS_DA_OP_RENAME;	/* an atomic rename */
 		args->blkno2 = args->blkno;		/* set 2nd entry info*/
 		args->index2 = args->index;
 		args->rmtblkno2 = args->rmtblkno;
 		args->rmtblkcnt2 = args->rmtblkcnt;
		args->rmtvaluelen2 = args->rmtvaluelen;

		/*
		 * clear the remote attr state now that it is saved so that the
		 * values reflect the state of the attribute we are about to
		 * add, not the attribute we just found and will remove later.
		 */
		args->rmtblkno = 0;
		args->rmtblkcnt = 0;
		args->rmtvaluelen = 0;
 	}
 
 	/*
	 * Add the attribute to the leaf block, transitioning to a Btree
	 * if required.
	 */
	retval = xfs_attr3_leaf_add(bp, args);
	if (retval == ENOSPC) {
		/*
		 * Promote the attribute list to the Btree format, then
		 * Commit that transaction so that the node_addname() call
		 * can manage its own transactions.
		 */
		xfs_bmap_init(args->flist, args->firstblock);
		error = xfs_attr3_leaf_to_node(args);
		if (!error) {
			error = xfs_bmap_finish(&args->trans, args->flist,
						&committed);
		}
		if (error) {
			ASSERT(committed);
			args->trans = NULL;
			xfs_bmap_cancel(args->flist);
			return(error);
		}

		/*
		 * bmap_finish() may have committed the last trans and started
		 * a new one.  We need the inode to be in all transactions.
		 */
		if (committed)
			xfs_trans_ijoin(args->trans, dp, 0);

		/*
		 * Commit the current trans (including the inode) and start
		 * a new one.
		 */
		error = xfs_trans_roll(&args->trans, dp);
		if (error)
			return (error);

		/*
		 * Fob the whole rest of the problem off on the Btree code.
		 */
		error = xfs_attr_node_addname(args);
		return(error);
	}

	/*
	 * Commit the transaction that added the attr name so that
	 * later routines can manage their own transactions.
	 */
	error = xfs_trans_roll(&args->trans, dp);
	if (error)
		return (error);

	/*
	 * If there was an out-of-line value, allocate the blocks we
	 * identified for its storage and copy the value.  This is done
	 * after we create the attribute so that we don't overflow the
	 * maximum size of a transaction and/or hit a deadlock.
	 */
	if (args->rmtblkno > 0) {
		error = xfs_attr_rmtval_set(args);
		if (error)
			return(error);
	}

	/*
	 * If this is an atomic rename operation, we must ""flip"" the
	 * incomplete flags on the ""new"" and ""old"" attribute/value pairs
	 * so that one disappears and one appears atomically.  Then we
	 * must remove the ""old"" attribute/value pair.
	 */
	if (args->op_flags & XFS_DA_OP_RENAME) {
		/*
		 * In a separate transaction, set the incomplete flag on the
		 * ""old"" attr and clear the incomplete flag on the ""new"" attr.
		 */
		error = xfs_attr3_leaf_flipflags(args);
		if (error)
			return(error);

		/*
		 * Dismantle the ""old"" attribute/value pair by removing
		 * a ""remote"" value (if it exists).
		 */
		args->index = args->index2;
 		args->blkno = args->blkno2;
 		args->rmtblkno = args->rmtblkno2;
 		args->rmtblkcnt = args->rmtblkcnt2;
		args->rmtvaluelen = args->rmtvaluelen2;
 		if (args->rmtblkno) {
 			error = xfs_attr_rmtval_remove(args);
 			if (error)
				return(error);
		}

		/*
		 * Read in the block containing the ""old"" attr, then
		 * remove the ""old"" attr from that block (neat, huh!)
		 */
		error = xfs_attr3_leaf_read(args->trans, args->dp, args->blkno,
					   -1, &bp);
		if (error)
			return error;

		xfs_attr3_leaf_remove(bp, args);

		/*
		 * If the result is small enough, shrink it all into the inode.
		 */
		if ((forkoff = xfs_attr_shortform_allfit(bp, dp))) {
			xfs_bmap_init(args->flist, args->firstblock);
			error = xfs_attr3_leaf_to_shortform(bp, args, forkoff);
			/* bp is gone due to xfs_da_shrink_inode */
			if (!error) {
				error = xfs_bmap_finish(&args->trans,
							args->flist,
							&committed);
			}
			if (error) {
				ASSERT(committed);
				args->trans = NULL;
				xfs_bmap_cancel(args->flist);
				return(error);
			}

			/*
			 * bmap_finish() may have committed the last trans
			 * and started a new one.  We need the inode to be
			 * in all transactions.
			 */
			if (committed)
				xfs_trans_ijoin(args->trans, dp, 0);
		}

		/*
		 * Commit the remove and start the next trans in series.
		 */
		error = xfs_trans_roll(&args->trans, dp);

	} else if (args->rmtblkno > 0) {
		/*
		 * Added a ""remote"" value, just clear the incomplete flag.
		 */
		error = xfs_attr3_leaf_clearflag(args);
	}
	return error;
}
","xfs_attr_leaf_addname(xfs_da_args_t *args)
{
	xfs_inode_t *dp;
	struct xfs_buf *bp;
	int retval, error, committed, forkoff;

	trace_xfs_attr_leaf_addname(args);

	/*
	 * Read the (only) block in the attribute list in.
	 */
	dp = args->dp;
	args->blkno = 0;
	error = xfs_attr3_leaf_read(args->trans, args->dp, args->blkno, -1, &bp);
	if (error)
		return error;

	/*
	 * Look up the given attribute in the leaf block.  Figure out if
	 * the given flags produce an error or call for an atomic rename.
	 */
	retval = xfs_attr3_leaf_lookup_int(bp, args);
	if ((args->flags & ATTR_REPLACE) && (retval == ENOATTR)) {
		xfs_trans_brelse(args->trans, bp);
		return retval;
	} else if (retval == EEXIST) {
		if (args->flags & ATTR_CREATE) {	/* pure create op */
			xfs_trans_brelse(args->trans, bp);
			return retval;
		}
 
 		trace_xfs_attr_leaf_replace(args);
 
 		args->op_flags |= XFS_DA_OP_RENAME;	/* an atomic rename */
 		args->blkno2 = args->blkno;		/* set 2nd entry info*/
 		args->index2 = args->index;
 		args->rmtblkno2 = args->rmtblkno;
 		args->rmtblkcnt2 = args->rmtblkcnt;
 	}
 
 	/*
	 * Add the attribute to the leaf block, transitioning to a Btree
	 * if required.
	 */
	retval = xfs_attr3_leaf_add(bp, args);
	if (retval == ENOSPC) {
		/*
		 * Promote the attribute list to the Btree format, then
		 * Commit that transaction so that the node_addname() call
		 * can manage its own transactions.
		 */
		xfs_bmap_init(args->flist, args->firstblock);
		error = xfs_attr3_leaf_to_node(args);
		if (!error) {
			error = xfs_bmap_finish(&args->trans, args->flist,
						&committed);
		}
		if (error) {
			ASSERT(committed);
			args->trans = NULL;
			xfs_bmap_cancel(args->flist);
			return(error);
		}

		/*
		 * bmap_finish() may have committed the last trans and started
		 * a new one.  We need the inode to be in all transactions.
		 */
		if (committed)
			xfs_trans_ijoin(args->trans, dp, 0);

		/*
		 * Commit the current trans (including the inode) and start
		 * a new one.
		 */
		error = xfs_trans_roll(&args->trans, dp);
		if (error)
			return (error);

		/*
		 * Fob the whole rest of the problem off on the Btree code.
		 */
		error = xfs_attr_node_addname(args);
		return(error);
	}

	/*
	 * Commit the transaction that added the attr name so that
	 * later routines can manage their own transactions.
	 */
	error = xfs_trans_roll(&args->trans, dp);
	if (error)
		return (error);

	/*
	 * If there was an out-of-line value, allocate the blocks we
	 * identified for its storage and copy the value.  This is done
	 * after we create the attribute so that we don't overflow the
	 * maximum size of a transaction and/or hit a deadlock.
	 */
	if (args->rmtblkno > 0) {
		error = xfs_attr_rmtval_set(args);
		if (error)
			return(error);
	}

	/*
	 * If this is an atomic rename operation, we must ""flip"" the
	 * incomplete flags on the ""new"" and ""old"" attribute/value pairs
	 * so that one disappears and one appears atomically.  Then we
	 * must remove the ""old"" attribute/value pair.
	 */
	if (args->op_flags & XFS_DA_OP_RENAME) {
		/*
		 * In a separate transaction, set the incomplete flag on the
		 * ""old"" attr and clear the incomplete flag on the ""new"" attr.
		 */
		error = xfs_attr3_leaf_flipflags(args);
		if (error)
			return(error);

		/*
		 * Dismantle the ""old"" attribute/value pair by removing
		 * a ""remote"" value (if it exists).
		 */
		args->index = args->index2;
 		args->blkno = args->blkno2;
 		args->rmtblkno = args->rmtblkno2;
 		args->rmtblkcnt = args->rmtblkcnt2;
 		if (args->rmtblkno) {
 			error = xfs_attr_rmtval_remove(args);
 			if (error)
				return(error);
		}

		/*
		 * Read in the block containing the ""old"" attr, then
		 * remove the ""old"" attr from that block (neat, huh!)
		 */
		error = xfs_attr3_leaf_read(args->trans, args->dp, args->blkno,
					   -1, &bp);
		if (error)
			return error;

		xfs_attr3_leaf_remove(bp, args);

		/*
		 * If the result is small enough, shrink it all into the inode.
		 */
		if ((forkoff = xfs_attr_shortform_allfit(bp, dp))) {
			xfs_bmap_init(args->flist, args->firstblock);
			error = xfs_attr3_leaf_to_shortform(bp, args, forkoff);
			/* bp is gone due to xfs_da_shrink_inode */
			if (!error) {
				error = xfs_bmap_finish(&args->trans,
							args->flist,
							&committed);
			}
			if (error) {
				ASSERT(committed);
				args->trans = NULL;
				xfs_bmap_cancel(args->flist);
				return(error);
			}

			/*
			 * bmap_finish() may have committed the last trans
			 * and started a new one.  We need the inode to be
			 * in all transactions.
			 */
			if (committed)
				xfs_trans_ijoin(args->trans, dp, 0);
		}

		/*
		 * Commit the remove and start the next trans in series.
		 */
		error = xfs_trans_roll(&args->trans, dp);

	} else if (args->rmtblkno > 0) {
		/*
		 * Added a ""remote"" value, just clear the incomplete flag.
		 */
		error = xfs_attr3_leaf_clearflag(args);
	}
	return error;
}
",C,"		/* save the attribute state for later removal*/
		args->rmtvaluelen2 = args->rmtvaluelen;

		/*
		 * clear the remote attr state now that it is saved so that the
		 * values reflect the state of the attribute we are about to
		 * add, not the attribute we just found and will remove later.
		 */
		args->rmtblkno = 0;
		args->rmtblkcnt = 0;
		args->rmtvaluelen = 0;
		args->rmtvaluelen = args->rmtvaluelen2;
",,,"@@ -213,7 +213,7 @@ xfs_attr_calc_size(
 		 * Out of line attribute, cannot double split, but
 		 * make room for the attribute value itself.
 		 */
-		uint	dblocks = XFS_B_TO_FSB(mp, valuelen);
+		uint	dblocks = xfs_attr3_rmt_blocks(mp, valuelen);
 		nblks += dblocks;
 		nblks += XFS_NEXTENTADD_SPACE_RES(mp, dblocks, XFS_ATTR_FORK);
 	}
@@ -698,11 +698,22 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)
 
 		trace_xfs_attr_leaf_replace(args);
 
+		/* save the attribute state for later removal*/
 		args->op_flags |= XFS_DA_OP_RENAME;	/* an atomic rename */
 		args->blkno2 = args->blkno;		/* set 2nd entry info*/
 		args->index2 = args->index;
 		args->rmtblkno2 = args->rmtblkno;
 		args->rmtblkcnt2 = args->rmtblkcnt;
+		args->rmtvaluelen2 = args->rmtvaluelen;
+
+		/*
+		 * clear the remote attr state now that it is saved so that the
+		 * values reflect the state of the attribute we are about to
+		 * add, not the attribute we just found and will remove later.
+		 */
+		args->rmtblkno = 0;
+		args->rmtblkcnt = 0;
+		args->rmtvaluelen = 0;
 	}
 
 	/*
@@ -794,6 +805,7 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)
 		args->blkno = args->blkno2;
 		args->rmtblkno = args->rmtblkno2;
 		args->rmtblkcnt = args->rmtblkcnt2;
+		args->rmtvaluelen = args->rmtvaluelen2;
 		if (args->rmtblkno) {
 			error = xfs_attr_rmtval_remove(args);
 			if (error)
@@ -999,13 +1011,22 @@ xfs_attr_node_addname(xfs_da_args_t *args)
 
 		trace_xfs_attr_node_replace(args);
 
+		/* save the attribute state for later removal*/
 		args->op_flags |= XFS_DA_OP_RENAME;	/* atomic rename op */
 		args->blkno2 = args->blkno;		/* set 2nd entry info*/
 		args->index2 = args->index;
 		args->rmtblkno2 = args->rmtblkno;
 		args->rmtblkcnt2 = args->rmtblkcnt;
+		args->rmtvaluelen2 = args->rmtvaluelen;
+
+		/*
+		 * clear the remote attr state now that it is saved so that the
+		 * values reflect the state of the attribute we are about to
+		 * add, not the attribute we just found and will remove later.
+		 */
 		args->rmtblkno = 0;
 		args->rmtblkcnt = 0;
+		args->rmtvaluelen = 0;
 	}
 
 	retval = xfs_attr3_leaf_add(blk->bp, state->args);
@@ -1133,6 +1154,7 @@ xfs_attr_node_addname(xfs_da_args_t *args)
 		args->blkno = args->blkno2;
 		args->rmtblkno = args->rmtblkno2;
 		args->rmtblkcnt = args->rmtblkcnt2;
+		args->rmtvaluelen = args->rmtvaluelen2;
 		if (args->rmtblkno) {
 			error = xfs_attr_rmtval_remove(args);
 			if (error)",linux,8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,d540e43b0ab134b22f015f725ce6e070d12b0244,1,"xfs_attr_leaf_addname(xfs_da_args_t *args)
{
	xfs_inode_t *dp;
	struct xfs_buf *bp;
	int retval, error, committed, forkoff;

	trace_xfs_attr_leaf_addname(args);

	/*
	 * Read the (only) block in the attribute list in.
	 */
	dp = args->dp;
	args->blkno = 0;
	error = xfs_attr3_leaf_read(args->trans, args->dp, args->blkno, -1, &bp);
	if (error)
		return error;

	/*
	 * Look up the given attribute in the leaf block.  Figure out if
	 * the given flags produce an error or call for an atomic rename.
	 */
	retval = xfs_attr3_leaf_lookup_int(bp, args);
	if ((args->flags & ATTR_REPLACE) && (retval == ENOATTR)) {
		xfs_trans_brelse(args->trans, bp);
		return retval;
	} else if (retval == EEXIST) {
		if (args->flags & ATTR_CREATE) {	/* pure create op */
			xfs_trans_brelse(args->trans, bp);
			return retval;
		}
 
 		trace_xfs_attr_leaf_replace(args);
 
//fix_flaw_line_below:
//		/* save the attribute state for later removal*/
 		args->op_flags |= XFS_DA_OP_RENAME;	/* an atomic rename */
 		args->blkno2 = args->blkno;		/* set 2nd entry info*/
 		args->index2 = args->index;
 		args->rmtblkno2 = args->rmtblkno;
 		args->rmtblkcnt2 = args->rmtblkcnt;
//fix_flaw_line_below:
//		args->rmtvaluelen2 = args->rmtvaluelen;
//fix_flaw_line_below:
//
//fix_flaw_line_below:
//		/*
//fix_flaw_line_below:
//		 * clear the remote attr state now that it is saved so that the
//fix_flaw_line_below:
//		 * values reflect the state of the attribute we are about to
//fix_flaw_line_below:
//		 * add, not the attribute we just found and will remove later.
//fix_flaw_line_below:
//		 */
//fix_flaw_line_below:
//		args->rmtblkno = 0;
//fix_flaw_line_below:
//		args->rmtblkcnt = 0;
//fix_flaw_line_below:
//		args->rmtvaluelen = 0;
 	}
 
 	/*
	 * Add the attribute to the leaf block, transitioning to a Btree
	 * if required.
	 */
	retval = xfs_attr3_leaf_add(bp, args);
	if (retval == ENOSPC) {
		/*
		 * Promote the attribute list to the Btree format, then
		 * Commit that transaction so that the node_addname() call
		 * can manage its own transactions.
		 */
		xfs_bmap_init(args->flist, args->firstblock);
		error = xfs_attr3_leaf_to_node(args);
		if (!error) {
			error = xfs_bmap_finish(&args->trans, args->flist,
						&committed);
		}
		if (error) {
			ASSERT(committed);
			args->trans = NULL;
			xfs_bmap_cancel(args->flist);
			return(error);
		}

		/*
		 * bmap_finish() may have committed the last trans and started
		 * a new one.  We need the inode to be in all transactions.
		 */
		if (committed)
			xfs_trans_ijoin(args->trans, dp, 0);

		/*
		 * Commit the current trans (including the inode) and start
		 * a new one.
		 */
		error = xfs_trans_roll(&args->trans, dp);
		if (error)
			return (error);

		/*
		 * Fob the whole rest of the problem off on the Btree code.
		 */
		error = xfs_attr_node_addname(args);
		return(error);
	}

	/*
	 * Commit the transaction that added the attr name so that
	 * later routines can manage their own transactions.
	 */
	error = xfs_trans_roll(&args->trans, dp);
	if (error)
		return (error);

	/*
	 * If there was an out-of-line value, allocate the blocks we
	 * identified for its storage and copy the value.  This is done
	 * after we create the attribute so that we don't overflow the
	 * maximum size of a transaction and/or hit a deadlock.
	 */
	if (args->rmtblkno > 0) {
		error = xfs_attr_rmtval_set(args);
		if (error)
			return(error);
	}

	/*
	 * If this is an atomic rename operation, we must ""flip"" the
	 * incomplete flags on the ""new"" and ""old"" attribute/value pairs
	 * so that one disappears and one appears atomically.  Then we
	 * must remove the ""old"" attribute/value pair.
	 */
	if (args->op_flags & XFS_DA_OP_RENAME) {
		/*
		 * In a separate transaction, set the incomplete flag on the
		 * ""old"" attr and clear the incomplete flag on the ""new"" attr.
		 */
		error = xfs_attr3_leaf_flipflags(args);
		if (error)
			return(error);

		/*
		 * Dismantle the ""old"" attribute/value pair by removing
		 * a ""remote"" value (if it exists).
		 */
		args->index = args->index2;
 		args->blkno = args->blkno2;
 		args->rmtblkno = args->rmtblkno2;
 		args->rmtblkcnt = args->rmtblkcnt2;
//fix_flaw_line_below:
//		args->rmtvaluelen = args->rmtvaluelen2;
 		if (args->rmtblkno) {
 			error = xfs_attr_rmtval_remove(args);
 			if (error)
				return(error);
		}

		/*
		 * Read in the block containing the ""old"" attr, then
		 * remove the ""old"" attr from that block (neat, huh!)
		 */
		error = xfs_attr3_leaf_read(args->trans, args->dp, args->blkno,
					   -1, &bp);
		if (error)
			return error;

		xfs_attr3_leaf_remove(bp, args);

		/*
		 * If the result is small enough, shrink it all into the inode.
		 */
		if ((forkoff = xfs_attr_shortform_allfit(bp, dp))) {
			xfs_bmap_init(args->flist, args->firstblock);
			error = xfs_attr3_leaf_to_shortform(bp, args, forkoff);
			/* bp is gone due to xfs_da_shrink_inode */
			if (!error) {
				error = xfs_bmap_finish(&args->trans,
							args->flist,
							&committed);
			}
			if (error) {
				ASSERT(committed);
				args->trans = NULL;
				xfs_bmap_cancel(args->flist);
				return(error);
			}

			/*
			 * bmap_finish() may have committed the last trans
			 * and started a new one.  We need the inode to be
			 * in all transactions.
			 */
			if (committed)
				xfs_trans_ijoin(args->trans, dp, 0);
		}

		/*
		 * Commit the remove and start the next trans in series.
		 */
		error = xfs_trans_roll(&args->trans, dp);

	} else if (args->rmtblkno > 0) {
		/*
		 * Added a ""remote"" value, just clear the incomplete flag.
		 */
		error = xfs_attr3_leaf_clearflag(args);
	}
	return error;
}
"
2168,179904,,Local,Not required,Complete,CVE-2015-0274,https://www.cvedetails.com/cve/CVE-2015-0274/,CWE-19,Low,Complete,Complete,,2015-03-16,7.2,"The XFS implementation in the Linux kernel before 3.15 improperly uses an old size value during remote attribute replacement, which allows local users to cause a denial of service (transaction overrun and data corruption) or possibly gain privileges by leveraging XFS filesystem access.",2015-03-26,DoS +Priv ,10,https://github.com/torvalds/linux/commit/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,"xfs: remote attribute overwrite causes transaction overrun

Commit e461fcb (""xfs: remote attribute lookups require the value
length"") passes the remote attribute length in the xfs_da_args
structure on lookup so that CRC calculations and validity checking
can be performed correctly by related code. This, unfortunately has
the side effect of changing the args->valuelen parameter in cases
where it shouldn't.

That is, when we replace a remote attribute, the incoming
replacement stores the value and length in args->value and
args->valuelen, but then the lookup which finds the existing remote
attribute overwrites args->valuelen with the length of the remote
attribute being replaced. Hence when we go to create the new
attribute, we create it of the size of the existing remote
attribute, not the size it is supposed to be. When the new attribute
is much smaller than the old attribute, this results in a
transaction overrun and an ASSERT() failure on a debug kernel:

XFS: Assertion failed: tp->t_blk_res_used <= tp->t_blk_res, file: fs/xfs/xfs_trans.c, line: 331

Fix this by keeping the remote attribute value length separate to
the attribute value length in the xfs_da_args structure. The enables
us to pass the length of the remote attribute to be removed without
overwriting the new attribute's length.

Also, ensure that when we save remote block contexts for a later
rename we zero the original state variables so that we don't confuse
the state of the attribute to be removes with the state of the new
attribute that we just added. [Spotted by Brain Foster.]

Signed-off-by: Dave Chinner <dchinner@redhat.com>
Reviewed-by: Brian Foster <bfoster@redhat.com>
Signed-off-by: Dave Chinner <david@fromorbit.com>",0,fs/xfs/xfs_attr.c,"{""sha"": ""abda1124a70f66fbd1a79b28f8eaf5bf1916da1e"", ""filename"": ""fs/xfs/xfs_attr.c"", ""status"": ""modified"", ""additions"": 23, ""deletions"": 1, ""changes"": 24, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -213,7 +213,7 @@ xfs_attr_calc_size(\n \t\t * Out of line attribute, cannot double split, but\n \t\t * make room for the attribute value itself.\n \t\t */\n-\t\tuint\tdblocks = XFS_B_TO_FSB(mp, valuelen);\n+\t\tuint\tdblocks = xfs_attr3_rmt_blocks(mp, valuelen);\n \t\tnblks += dblocks;\n \t\tnblks += XFS_NEXTENTADD_SPACE_RES(mp, dblocks, XFS_ATTR_FORK);\n \t}\n@@ -698,11 +698,22 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)\n \n \t\ttrace_xfs_attr_leaf_replace(args);\n \n+\t\t/* save the attribute state for later removal*/\n \t\targs->op_flags |= XFS_DA_OP_RENAME;\t/* an atomic rename */\n \t\targs->blkno2 = args->blkno;\t\t/* set 2nd entry info*/\n \t\targs->index2 = args->index;\n \t\targs->rmtblkno2 = args->rmtblkno;\n \t\targs->rmtblkcnt2 = args->rmtblkcnt;\n+\t\targs->rmtvaluelen2 = args->rmtvaluelen;\n+\n+\t\t/*\n+\t\t * clear the remote attr state now that it is saved so that the\n+\t\t * values reflect the state of the attribute we are about to\n+\t\t * add, not the attribute we just found and will remove later.\n+\t\t */\n+\t\targs->rmtblkno = 0;\n+\t\targs->rmtblkcnt = 0;\n+\t\targs->rmtvaluelen = 0;\n \t}\n \n \t/*\n@@ -794,6 +805,7 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)\n \t\targs->blkno = args->blkno2;\n \t\targs->rmtblkno = args->rmtblkno2;\n \t\targs->rmtblkcnt = args->rmtblkcnt2;\n+\t\targs->rmtvaluelen = args->rmtvaluelen2;\n \t\tif (args->rmtblkno) {\n \t\t\terror = xfs_attr_rmtval_remove(args);\n \t\t\tif (error)\n@@ -999,13 +1011,22 @@ xfs_attr_node_addname(xfs_da_args_t *args)\n \n \t\ttrace_xfs_attr_node_replace(args);\n \n+\t\t/* save the attribute state for later removal*/\n \t\targs->op_flags |= XFS_DA_OP_RENAME;\t/* atomic rename op */\n \t\targs->blkno2 = args->blkno;\t\t/* set 2nd entry info*/\n \t\targs->index2 = args->index;\n \t\targs->rmtblkno2 = args->rmtblkno;\n \t\targs->rmtblkcnt2 = args->rmtblkcnt;\n+\t\targs->rmtvaluelen2 = args->rmtvaluelen;\n+\n+\t\t/*\n+\t\t * clear the remote attr state now that it is saved so that the\n+\t\t * values reflect the state of the attribute we are about to\n+\t\t * add, not the attribute we just found and will remove later.\n+\t\t */\n \t\targs->rmtblkno = 0;\n \t\targs->rmtblkcnt = 0;\n+\t\targs->rmtvaluelen = 0;\n \t}\n \n \tretval = xfs_attr3_leaf_add(blk->bp, state->args);\n@@ -1133,6 +1154,7 @@ xfs_attr_node_addname(xfs_da_args_t *args)\n \t\targs->blkno = args->blkno2;\n \t\targs->rmtblkno = args->rmtblkno2;\n \t\targs->rmtblkcnt = args->rmtblkcnt2;\n+\t\targs->rmtvaluelen = args->rmtvaluelen2;\n \t\tif (args->rmtblkno) {\n \t\t\terror = xfs_attr_rmtval_remove(args);\n \t\t\tif (error)""}<_**next**_>{""sha"": ""511c283459b19441d782114c4f832207860deab1"", ""filename"": ""fs/xfs/xfs_attr_leaf.c"", ""status"": ""modified"", ""additions"": 11, ""deletions"": 10, ""changes"": 21, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_leaf.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_leaf.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_leaf.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -1229,6 +1229,7 @@ xfs_attr3_leaf_add_work(\n \t\tname_rmt->valueblk = 0;\n \t\targs->rmtblkno = 1;\n \t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);\n+\t\targs->rmtvaluelen = args->valuelen;\n \t}\n \txfs_trans_log_buf(args->trans, bp,\n \t     XFS_DA_LOGRANGE(leaf, xfs_attr3_leaf_name(leaf, args->index),\n@@ -2167,11 +2168,11 @@ xfs_attr3_leaf_lookup_int(\n \t\t\tif (!xfs_attr_namesp_match(args->flags, entry->flags))\n \t\t\t\tcontinue;\n \t\t\targs->index = probe;\n-\t\t\targs->valuelen = be32_to_cpu(name_rmt->valuelen);\n+\t\t\targs->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);\n \t\t\targs->rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(\n \t\t\t\t\t\t\targs->dp->i_mount,\n-\t\t\t\t\t\t\targs->valuelen);\n+\t\t\t\t\t\t\targs->rmtvaluelen);\n \t\t\treturn XFS_ERROR(EEXIST);\n \t\t}\n \t}\n@@ -2220,19 +2221,19 @@ xfs_attr3_leaf_getvalue(\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);\n \t\tASSERT(name_rmt->namelen == args->namelen);\n \t\tASSERT(memcmp(args->name, name_rmt->name, args->namelen) == 0);\n-\t\tvaluelen = be32_to_cpu(name_rmt->valuelen);\n+\t\targs->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);\n \t\targs->rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(args->dp->i_mount,\n-\t\t\t\t\t\t       valuelen);\n+\t\t\t\t\t\t       args->rmtvaluelen);\n \t\tif (args->flags & ATTR_KERNOVAL) {\n-\t\t\targs->valuelen = valuelen;\n+\t\t\targs->valuelen = args->rmtvaluelen;\n \t\t\treturn 0;\n \t\t}\n-\t\tif (args->valuelen < valuelen) {\n-\t\t\targs->valuelen = valuelen;\n+\t\tif (args->valuelen < args->rmtvaluelen) {\n+\t\t\targs->valuelen = args->rmtvaluelen;\n \t\t\treturn XFS_ERROR(ERANGE);\n \t\t}\n-\t\targs->valuelen = valuelen;\n+\t\targs->valuelen = args->rmtvaluelen;\n \t}\n \treturn 0;\n }\n@@ -2519,7 +2520,7 @@ xfs_attr3_leaf_clearflag(\n \t\tASSERT((entry->flags & XFS_ATTR_LOCAL) == 0);\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);\n \t\tname_rmt->valueblk = cpu_to_be32(args->rmtblkno);\n-\t\tname_rmt->valuelen = cpu_to_be32(args->valuelen);\n+\t\tname_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);\n \t\txfs_trans_log_buf(args->trans, bp,\n \t\t\t XFS_DA_LOGRANGE(leaf, name_rmt, sizeof(*name_rmt)));\n \t}\n@@ -2677,7 +2678,7 @@ xfs_attr3_leaf_flipflags(\n \t\tASSERT((entry1->flags & XFS_ATTR_LOCAL) == 0);\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf1, args->index);\n \t\tname_rmt->valueblk = cpu_to_be32(args->rmtblkno);\n-\t\tname_rmt->valuelen = cpu_to_be32(args->valuelen);\n+\t\tname_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);\n \t\txfs_trans_log_buf(args->trans, bp1,\n \t\t\t XFS_DA_LOGRANGE(leaf1, name_rmt, sizeof(*name_rmt)));\n \t}""}<_**next**_>{""sha"": ""833fe5d98d806783ca6bb6cf2f4ecb83424bfdca"", ""filename"": ""fs/xfs/xfs_attr_list.c"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 0, ""changes"": 1, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_list.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_list.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_list.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -447,6 +447,7 @@ xfs_attr3_leaf_list_int(\n \t\t\t\targs.dp = context->dp;\n \t\t\t\targs.whichfork = XFS_ATTR_FORK;\n \t\t\t\targs.valuelen = valuelen;\n+\t\t\t\targs.rmtvaluelen = valuelen;\n \t\t\t\targs.value = kmem_alloc(valuelen, KM_SLEEP | KM_NOFS);\n \t\t\t\targs.rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\t\t\targs.rmtblkcnt = xfs_attr3_rmt_blocks(""}<_**next**_>{""sha"": ""d2e6e948cec7be3013b853033b6e1a64b365a682"", ""filename"": ""fs/xfs/xfs_attr_remote.c"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 3, ""changes"": 8, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_remote.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_remote.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_remote.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -337,7 +337,7 @@ xfs_attr_rmtval_get(\n \tstruct xfs_buf\t\t*bp;\n \txfs_dablk_t\t\tlblkno = args->rmtblkno;\n \t__uint8_t\t\t*dst = args->value;\n-\tint\t\t\tvaluelen = args->valuelen;\n+\tint\t\t\tvaluelen;\n \tint\t\t\tnmap;\n \tint\t\t\terror;\n \tint\t\t\tblkcnt = args->rmtblkcnt;\n@@ -347,7 +347,9 @@ xfs_attr_rmtval_get(\n \ttrace_xfs_attr_rmtval_get(args);\n \n \tASSERT(!(args->flags & ATTR_KERNOVAL));\n+\tASSERT(args->rmtvaluelen == args->valuelen);\n \n+\tvaluelen = args->rmtvaluelen;\n \twhile (valuelen > 0) {\n \t\tnmap = ATTR_RMTVALUE_MAPSIZE;\n \t\terror = xfs_bmapi_read(args->dp, (xfs_fileoff_t)lblkno,\n@@ -415,7 +417,7 @@ xfs_attr_rmtval_set(\n \t * attributes have headers, we can't just do a straight byte to FSB\n \t * conversion and have to take the header space into account.\n \t */\n-\tblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);\n+\tblkcnt = xfs_attr3_rmt_blocks(mp, args->rmtvaluelen);\n \terror = xfs_bmap_first_unused(args->trans, args->dp, blkcnt, &lfileoff,\n \t\t\t\t\t\t   XFS_ATTR_FORK);\n \tif (error)\n@@ -480,7 +482,7 @@ xfs_attr_rmtval_set(\n \t */\n \tlblkno = args->rmtblkno;\n \tblkcnt = args->rmtblkcnt;\n-\tvaluelen = args->valuelen;\n+\tvaluelen = args->rmtvaluelen;\n \twhile (valuelen > 0) {\n \t\tstruct xfs_buf\t*bp;\n \t\txfs_daddr_t\tdblkno;""}<_**next**_>{""sha"": ""201c6091d26abfa2e38dd17fd960e3efcb69bcd7"", ""filename"": ""fs/xfs/xfs_da_btree.h"", ""status"": ""modified"", ""additions"": 2, ""deletions"": 0, ""changes"": 2, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_da_btree.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_da_btree.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_da_btree.h?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -60,10 +60,12 @@ typedef struct xfs_da_args {\n \tint\t\tindex;\t\t/* index of attr of interest in blk */\n \txfs_dablk_t\trmtblkno;\t/* remote attr value starting blkno */\n \tint\t\trmtblkcnt;\t/* remote attr value block count */\n+\tint\t\trmtvaluelen;\t/* remote attr value length in bytes */\n \txfs_dablk_t\tblkno2;\t\t/* blkno of 2nd attr leaf of interest */\n \tint\t\tindex2;\t\t/* index of 2nd attr in blk */\n \txfs_dablk_t\trmtblkno2;\t/* remote attr value starting blkno */\n \tint\t\trmtblkcnt2;\t/* remote attr value block count */\n+\tint\t\trmtvaluelen2;\t/* remote attr value length in bytes */\n \tint\t\top_flags;\t/* operation flags */\n \tenum xfs_dacmp\tcmpresult;\t/* name compare result for lookups */\n } xfs_da_args_t;""}","xfs_attr_node_addname(xfs_da_args_t *args)
{
	xfs_da_state_t *state;
	xfs_da_state_blk_t *blk;
	xfs_inode_t *dp;
	xfs_mount_t *mp;
	int committed, retval, error;

	trace_xfs_attr_node_addname(args);

	/*
	 * Fill in bucket of arguments/results/context to carry around.
	 */
	dp = args->dp;
	mp = dp->i_mount;
restart:
	state = xfs_da_state_alloc();
	state->args = args;
	state->mp = mp;
	state->blocksize = state->mp->m_sb.sb_blocksize;
	state->node_ents = state->mp->m_attr_node_ents;

	/*
	 * Search to see if name already exists, and get back a pointer
	 * to where it should go.
	 */
	error = xfs_da3_node_lookup_int(state, &retval);
	if (error)
		goto out;
	blk = &state->path.blk[ state->path.active-1 ];
	ASSERT(blk->magic == XFS_ATTR_LEAF_MAGIC);
	if ((args->flags & ATTR_REPLACE) && (retval == ENOATTR)) {
		goto out;
	} else if (retval == EEXIST) {
		if (args->flags & ATTR_CREATE)
			goto out;
 
 		trace_xfs_attr_node_replace(args);
 
		/* save the attribute state for later removal*/
 		args->op_flags |= XFS_DA_OP_RENAME;	/* atomic rename op */
 		args->blkno2 = args->blkno;		/* set 2nd entry info*/
 		args->index2 = args->index;
 		args->rmtblkno2 = args->rmtblkno;
 		args->rmtblkcnt2 = args->rmtblkcnt;
		args->rmtvaluelen2 = args->rmtvaluelen;

		/*
		 * clear the remote attr state now that it is saved so that the
		 * values reflect the state of the attribute we are about to
		 * add, not the attribute we just found and will remove later.
		 */
 		args->rmtblkno = 0;
 		args->rmtblkcnt = 0;
		args->rmtvaluelen = 0;
 	}
 
 	retval = xfs_attr3_leaf_add(blk->bp, state->args);
	if (retval == ENOSPC) {
		if (state->path.active == 1) {
			/*
			 * Its really a single leaf node, but it had
			 * out-of-line values so it looked like it *might*
			 * have been a b-tree.
			 */
			xfs_da_state_free(state);
			state = NULL;
			xfs_bmap_init(args->flist, args->firstblock);
			error = xfs_attr3_leaf_to_node(args);
			if (!error) {
				error = xfs_bmap_finish(&args->trans,
							args->flist,
							&committed);
			}
			if (error) {
				ASSERT(committed);
				args->trans = NULL;
				xfs_bmap_cancel(args->flist);
				goto out;
			}

			/*
			 * bmap_finish() may have committed the last trans
			 * and started a new one.  We need the inode to be
			 * in all transactions.
			 */
			if (committed)
				xfs_trans_ijoin(args->trans, dp, 0);

			/*
			 * Commit the node conversion and start the next
			 * trans in the chain.
			 */
			error = xfs_trans_roll(&args->trans, dp);
			if (error)
				goto out;

			goto restart;
		}

		/*
		 * Split as many Btree elements as required.
		 * This code tracks the new and old attr's location
		 * in the index/blkno/rmtblkno/rmtblkcnt fields and
		 * in the index2/blkno2/rmtblkno2/rmtblkcnt2 fields.
		 */
		xfs_bmap_init(args->flist, args->firstblock);
		error = xfs_da3_split(state);
		if (!error) {
			error = xfs_bmap_finish(&args->trans, args->flist,
						&committed);
		}
		if (error) {
			ASSERT(committed);
			args->trans = NULL;
			xfs_bmap_cancel(args->flist);
			goto out;
		}

		/*
		 * bmap_finish() may have committed the last trans and started
		 * a new one.  We need the inode to be in all transactions.
		 */
		if (committed)
			xfs_trans_ijoin(args->trans, dp, 0);
	} else {
		/*
		 * Addition succeeded, update Btree hashvals.
		 */
		xfs_da3_fixhashpath(state, &state->path);
	}

	/*
	 * Kill the state structure, we're done with it and need to
	 * allow the buffers to come back later.
	 */
	xfs_da_state_free(state);
	state = NULL;

	/*
	 * Commit the leaf addition or btree split and start the next
	 * trans in the chain.
	 */
	error = xfs_trans_roll(&args->trans, dp);
	if (error)
		goto out;

	/*
	 * If there was an out-of-line value, allocate the blocks we
	 * identified for its storage and copy the value.  This is done
	 * after we create the attribute so that we don't overflow the
	 * maximum size of a transaction and/or hit a deadlock.
	 */
	if (args->rmtblkno > 0) {
		error = xfs_attr_rmtval_set(args);
		if (error)
			return(error);
	}

	/*
	 * If this is an atomic rename operation, we must ""flip"" the
	 * incomplete flags on the ""new"" and ""old"" attribute/value pairs
	 * so that one disappears and one appears atomically.  Then we
	 * must remove the ""old"" attribute/value pair.
	 */
	if (args->op_flags & XFS_DA_OP_RENAME) {
		/*
		 * In a separate transaction, set the incomplete flag on the
		 * ""old"" attr and clear the incomplete flag on the ""new"" attr.
		 */
		error = xfs_attr3_leaf_flipflags(args);
		if (error)
			goto out;

		/*
		 * Dismantle the ""old"" attribute/value pair by removing
		 * a ""remote"" value (if it exists).
		 */
		args->index = args->index2;
 		args->blkno = args->blkno2;
 		args->rmtblkno = args->rmtblkno2;
 		args->rmtblkcnt = args->rmtblkcnt2;
		args->rmtvaluelen = args->rmtvaluelen2;
 		if (args->rmtblkno) {
 			error = xfs_attr_rmtval_remove(args);
 			if (error)
				return(error);
		}

		/*
		 * Re-find the ""old"" attribute entry after any split ops.
		 * The INCOMPLETE flag means that we will find the ""old""
		 * attr, not the ""new"" one.
		 */
		args->flags |= XFS_ATTR_INCOMPLETE;
		state = xfs_da_state_alloc();
		state->args = args;
		state->mp = mp;
		state->blocksize = state->mp->m_sb.sb_blocksize;
		state->node_ents = state->mp->m_attr_node_ents;
		state->inleaf = 0;
		error = xfs_da3_node_lookup_int(state, &retval);
		if (error)
			goto out;

		/*
		 * Remove the name and update the hashvals in the tree.
		 */
		blk = &state->path.blk[ state->path.active-1 ];
		ASSERT(blk->magic == XFS_ATTR_LEAF_MAGIC);
		error = xfs_attr3_leaf_remove(blk->bp, args);
		xfs_da3_fixhashpath(state, &state->path);

		/*
		 * Check to see if the tree needs to be collapsed.
		 */
		if (retval && (state->path.active > 1)) {
			xfs_bmap_init(args->flist, args->firstblock);
			error = xfs_da3_join(state);
			if (!error) {
				error = xfs_bmap_finish(&args->trans,
							args->flist,
							&committed);
			}
			if (error) {
				ASSERT(committed);
				args->trans = NULL;
				xfs_bmap_cancel(args->flist);
				goto out;
			}

			/*
			 * bmap_finish() may have committed the last trans
			 * and started a new one.  We need the inode to be
			 * in all transactions.
			 */
			if (committed)
				xfs_trans_ijoin(args->trans, dp, 0);
		}

		/*
		 * Commit and start the next trans in the chain.
		 */
		error = xfs_trans_roll(&args->trans, dp);
		if (error)
			goto out;

	} else if (args->rmtblkno > 0) {
		/*
		 * Added a ""remote"" value, just clear the incomplete flag.
		 */
		error = xfs_attr3_leaf_clearflag(args);
		if (error)
			goto out;
	}
	retval = error = 0;

out:
	if (state)
		xfs_da_state_free(state);
	if (error)
		return(error);
	return(retval);
}
","xfs_attr_node_addname(xfs_da_args_t *args)
{
	xfs_da_state_t *state;
	xfs_da_state_blk_t *blk;
	xfs_inode_t *dp;
	xfs_mount_t *mp;
	int committed, retval, error;

	trace_xfs_attr_node_addname(args);

	/*
	 * Fill in bucket of arguments/results/context to carry around.
	 */
	dp = args->dp;
	mp = dp->i_mount;
restart:
	state = xfs_da_state_alloc();
	state->args = args;
	state->mp = mp;
	state->blocksize = state->mp->m_sb.sb_blocksize;
	state->node_ents = state->mp->m_attr_node_ents;

	/*
	 * Search to see if name already exists, and get back a pointer
	 * to where it should go.
	 */
	error = xfs_da3_node_lookup_int(state, &retval);
	if (error)
		goto out;
	blk = &state->path.blk[ state->path.active-1 ];
	ASSERT(blk->magic == XFS_ATTR_LEAF_MAGIC);
	if ((args->flags & ATTR_REPLACE) && (retval == ENOATTR)) {
		goto out;
	} else if (retval == EEXIST) {
		if (args->flags & ATTR_CREATE)
			goto out;
 
 		trace_xfs_attr_node_replace(args);
 
 		args->op_flags |= XFS_DA_OP_RENAME;	/* atomic rename op */
 		args->blkno2 = args->blkno;		/* set 2nd entry info*/
 		args->index2 = args->index;
 		args->rmtblkno2 = args->rmtblkno;
 		args->rmtblkcnt2 = args->rmtblkcnt;
 		args->rmtblkno = 0;
 		args->rmtblkcnt = 0;
 	}
 
 	retval = xfs_attr3_leaf_add(blk->bp, state->args);
	if (retval == ENOSPC) {
		if (state->path.active == 1) {
			/*
			 * Its really a single leaf node, but it had
			 * out-of-line values so it looked like it *might*
			 * have been a b-tree.
			 */
			xfs_da_state_free(state);
			state = NULL;
			xfs_bmap_init(args->flist, args->firstblock);
			error = xfs_attr3_leaf_to_node(args);
			if (!error) {
				error = xfs_bmap_finish(&args->trans,
							args->flist,
							&committed);
			}
			if (error) {
				ASSERT(committed);
				args->trans = NULL;
				xfs_bmap_cancel(args->flist);
				goto out;
			}

			/*
			 * bmap_finish() may have committed the last trans
			 * and started a new one.  We need the inode to be
			 * in all transactions.
			 */
			if (committed)
				xfs_trans_ijoin(args->trans, dp, 0);

			/*
			 * Commit the node conversion and start the next
			 * trans in the chain.
			 */
			error = xfs_trans_roll(&args->trans, dp);
			if (error)
				goto out;

			goto restart;
		}

		/*
		 * Split as many Btree elements as required.
		 * This code tracks the new and old attr's location
		 * in the index/blkno/rmtblkno/rmtblkcnt fields and
		 * in the index2/blkno2/rmtblkno2/rmtblkcnt2 fields.
		 */
		xfs_bmap_init(args->flist, args->firstblock);
		error = xfs_da3_split(state);
		if (!error) {
			error = xfs_bmap_finish(&args->trans, args->flist,
						&committed);
		}
		if (error) {
			ASSERT(committed);
			args->trans = NULL;
			xfs_bmap_cancel(args->flist);
			goto out;
		}

		/*
		 * bmap_finish() may have committed the last trans and started
		 * a new one.  We need the inode to be in all transactions.
		 */
		if (committed)
			xfs_trans_ijoin(args->trans, dp, 0);
	} else {
		/*
		 * Addition succeeded, update Btree hashvals.
		 */
		xfs_da3_fixhashpath(state, &state->path);
	}

	/*
	 * Kill the state structure, we're done with it and need to
	 * allow the buffers to come back later.
	 */
	xfs_da_state_free(state);
	state = NULL;

	/*
	 * Commit the leaf addition or btree split and start the next
	 * trans in the chain.
	 */
	error = xfs_trans_roll(&args->trans, dp);
	if (error)
		goto out;

	/*
	 * If there was an out-of-line value, allocate the blocks we
	 * identified for its storage and copy the value.  This is done
	 * after we create the attribute so that we don't overflow the
	 * maximum size of a transaction and/or hit a deadlock.
	 */
	if (args->rmtblkno > 0) {
		error = xfs_attr_rmtval_set(args);
		if (error)
			return(error);
	}

	/*
	 * If this is an atomic rename operation, we must ""flip"" the
	 * incomplete flags on the ""new"" and ""old"" attribute/value pairs
	 * so that one disappears and one appears atomically.  Then we
	 * must remove the ""old"" attribute/value pair.
	 */
	if (args->op_flags & XFS_DA_OP_RENAME) {
		/*
		 * In a separate transaction, set the incomplete flag on the
		 * ""old"" attr and clear the incomplete flag on the ""new"" attr.
		 */
		error = xfs_attr3_leaf_flipflags(args);
		if (error)
			goto out;

		/*
		 * Dismantle the ""old"" attribute/value pair by removing
		 * a ""remote"" value (if it exists).
		 */
		args->index = args->index2;
 		args->blkno = args->blkno2;
 		args->rmtblkno = args->rmtblkno2;
 		args->rmtblkcnt = args->rmtblkcnt2;
 		if (args->rmtblkno) {
 			error = xfs_attr_rmtval_remove(args);
 			if (error)
				return(error);
		}

		/*
		 * Re-find the ""old"" attribute entry after any split ops.
		 * The INCOMPLETE flag means that we will find the ""old""
		 * attr, not the ""new"" one.
		 */
		args->flags |= XFS_ATTR_INCOMPLETE;
		state = xfs_da_state_alloc();
		state->args = args;
		state->mp = mp;
		state->blocksize = state->mp->m_sb.sb_blocksize;
		state->node_ents = state->mp->m_attr_node_ents;
		state->inleaf = 0;
		error = xfs_da3_node_lookup_int(state, &retval);
		if (error)
			goto out;

		/*
		 * Remove the name and update the hashvals in the tree.
		 */
		blk = &state->path.blk[ state->path.active-1 ];
		ASSERT(blk->magic == XFS_ATTR_LEAF_MAGIC);
		error = xfs_attr3_leaf_remove(blk->bp, args);
		xfs_da3_fixhashpath(state, &state->path);

		/*
		 * Check to see if the tree needs to be collapsed.
		 */
		if (retval && (state->path.active > 1)) {
			xfs_bmap_init(args->flist, args->firstblock);
			error = xfs_da3_join(state);
			if (!error) {
				error = xfs_bmap_finish(&args->trans,
							args->flist,
							&committed);
			}
			if (error) {
				ASSERT(committed);
				args->trans = NULL;
				xfs_bmap_cancel(args->flist);
				goto out;
			}

			/*
			 * bmap_finish() may have committed the last trans
			 * and started a new one.  We need the inode to be
			 * in all transactions.
			 */
			if (committed)
				xfs_trans_ijoin(args->trans, dp, 0);
		}

		/*
		 * Commit and start the next trans in the chain.
		 */
		error = xfs_trans_roll(&args->trans, dp);
		if (error)
			goto out;

	} else if (args->rmtblkno > 0) {
		/*
		 * Added a ""remote"" value, just clear the incomplete flag.
		 */
		error = xfs_attr3_leaf_clearflag(args);
		if (error)
			goto out;
	}
	retval = error = 0;

out:
	if (state)
		xfs_da_state_free(state);
	if (error)
		return(error);
	return(retval);
}
",C,"		/* save the attribute state for later removal*/
		args->rmtvaluelen2 = args->rmtvaluelen;

		/*
		 * clear the remote attr state now that it is saved so that the
		 * values reflect the state of the attribute we are about to
		 * add, not the attribute we just found and will remove later.
		 */
		args->rmtvaluelen = 0;
		args->rmtvaluelen = args->rmtvaluelen2;
",,,"@@ -213,7 +213,7 @@ xfs_attr_calc_size(
 		 * Out of line attribute, cannot double split, but
 		 * make room for the attribute value itself.
 		 */
-		uint	dblocks = XFS_B_TO_FSB(mp, valuelen);
+		uint	dblocks = xfs_attr3_rmt_blocks(mp, valuelen);
 		nblks += dblocks;
 		nblks += XFS_NEXTENTADD_SPACE_RES(mp, dblocks, XFS_ATTR_FORK);
 	}
@@ -698,11 +698,22 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)
 
 		trace_xfs_attr_leaf_replace(args);
 
+		/* save the attribute state for later removal*/
 		args->op_flags |= XFS_DA_OP_RENAME;	/* an atomic rename */
 		args->blkno2 = args->blkno;		/* set 2nd entry info*/
 		args->index2 = args->index;
 		args->rmtblkno2 = args->rmtblkno;
 		args->rmtblkcnt2 = args->rmtblkcnt;
+		args->rmtvaluelen2 = args->rmtvaluelen;
+
+		/*
+		 * clear the remote attr state now that it is saved so that the
+		 * values reflect the state of the attribute we are about to
+		 * add, not the attribute we just found and will remove later.
+		 */
+		args->rmtblkno = 0;
+		args->rmtblkcnt = 0;
+		args->rmtvaluelen = 0;
 	}
 
 	/*
@@ -794,6 +805,7 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)
 		args->blkno = args->blkno2;
 		args->rmtblkno = args->rmtblkno2;
 		args->rmtblkcnt = args->rmtblkcnt2;
+		args->rmtvaluelen = args->rmtvaluelen2;
 		if (args->rmtblkno) {
 			error = xfs_attr_rmtval_remove(args);
 			if (error)
@@ -999,13 +1011,22 @@ xfs_attr_node_addname(xfs_da_args_t *args)
 
 		trace_xfs_attr_node_replace(args);
 
+		/* save the attribute state for later removal*/
 		args->op_flags |= XFS_DA_OP_RENAME;	/* atomic rename op */
 		args->blkno2 = args->blkno;		/* set 2nd entry info*/
 		args->index2 = args->index;
 		args->rmtblkno2 = args->rmtblkno;
 		args->rmtblkcnt2 = args->rmtblkcnt;
+		args->rmtvaluelen2 = args->rmtvaluelen;
+
+		/*
+		 * clear the remote attr state now that it is saved so that the
+		 * values reflect the state of the attribute we are about to
+		 * add, not the attribute we just found and will remove later.
+		 */
 		args->rmtblkno = 0;
 		args->rmtblkcnt = 0;
+		args->rmtvaluelen = 0;
 	}
 
 	retval = xfs_attr3_leaf_add(blk->bp, state->args);
@@ -1133,6 +1154,7 @@ xfs_attr_node_addname(xfs_da_args_t *args)
 		args->blkno = args->blkno2;
 		args->rmtblkno = args->rmtblkno2;
 		args->rmtblkcnt = args->rmtblkcnt2;
+		args->rmtvaluelen = args->rmtvaluelen2;
 		if (args->rmtblkno) {
 			error = xfs_attr_rmtval_remove(args);
 			if (error)",linux,8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,d540e43b0ab134b22f015f725ce6e070d12b0244,1,"xfs_attr_node_addname(xfs_da_args_t *args)
{
	xfs_da_state_t *state;
	xfs_da_state_blk_t *blk;
	xfs_inode_t *dp;
	xfs_mount_t *mp;
	int committed, retval, error;

	trace_xfs_attr_node_addname(args);

	/*
	 * Fill in bucket of arguments/results/context to carry around.
	 */
	dp = args->dp;
	mp = dp->i_mount;
restart:
	state = xfs_da_state_alloc();
	state->args = args;
	state->mp = mp;
	state->blocksize = state->mp->m_sb.sb_blocksize;
	state->node_ents = state->mp->m_attr_node_ents;

	/*
	 * Search to see if name already exists, and get back a pointer
	 * to where it should go.
	 */
	error = xfs_da3_node_lookup_int(state, &retval);
	if (error)
		goto out;
	blk = &state->path.blk[ state->path.active-1 ];
	ASSERT(blk->magic == XFS_ATTR_LEAF_MAGIC);
	if ((args->flags & ATTR_REPLACE) && (retval == ENOATTR)) {
		goto out;
	} else if (retval == EEXIST) {
		if (args->flags & ATTR_CREATE)
			goto out;
 
 		trace_xfs_attr_node_replace(args);
 
//fix_flaw_line_below:
//		/* save the attribute state for later removal*/
 		args->op_flags |= XFS_DA_OP_RENAME;	/* atomic rename op */
 		args->blkno2 = args->blkno;		/* set 2nd entry info*/
 		args->index2 = args->index;
 		args->rmtblkno2 = args->rmtblkno;
 		args->rmtblkcnt2 = args->rmtblkcnt;
//fix_flaw_line_below:
//		args->rmtvaluelen2 = args->rmtvaluelen;
//fix_flaw_line_below:
//
//fix_flaw_line_below:
//		/*
//fix_flaw_line_below:
//		 * clear the remote attr state now that it is saved so that the
//fix_flaw_line_below:
//		 * values reflect the state of the attribute we are about to
//fix_flaw_line_below:
//		 * add, not the attribute we just found and will remove later.
//fix_flaw_line_below:
//		 */
 		args->rmtblkno = 0;
 		args->rmtblkcnt = 0;
//fix_flaw_line_below:
//		args->rmtvaluelen = 0;
 	}
 
 	retval = xfs_attr3_leaf_add(blk->bp, state->args);
	if (retval == ENOSPC) {
		if (state->path.active == 1) {
			/*
			 * Its really a single leaf node, but it had
			 * out-of-line values so it looked like it *might*
			 * have been a b-tree.
			 */
			xfs_da_state_free(state);
			state = NULL;
			xfs_bmap_init(args->flist, args->firstblock);
			error = xfs_attr3_leaf_to_node(args);
			if (!error) {
				error = xfs_bmap_finish(&args->trans,
							args->flist,
							&committed);
			}
			if (error) {
				ASSERT(committed);
				args->trans = NULL;
				xfs_bmap_cancel(args->flist);
				goto out;
			}

			/*
			 * bmap_finish() may have committed the last trans
			 * and started a new one.  We need the inode to be
			 * in all transactions.
			 */
			if (committed)
				xfs_trans_ijoin(args->trans, dp, 0);

			/*
			 * Commit the node conversion and start the next
			 * trans in the chain.
			 */
			error = xfs_trans_roll(&args->trans, dp);
			if (error)
				goto out;

			goto restart;
		}

		/*
		 * Split as many Btree elements as required.
		 * This code tracks the new and old attr's location
		 * in the index/blkno/rmtblkno/rmtblkcnt fields and
		 * in the index2/blkno2/rmtblkno2/rmtblkcnt2 fields.
		 */
		xfs_bmap_init(args->flist, args->firstblock);
		error = xfs_da3_split(state);
		if (!error) {
			error = xfs_bmap_finish(&args->trans, args->flist,
						&committed);
		}
		if (error) {
			ASSERT(committed);
			args->trans = NULL;
			xfs_bmap_cancel(args->flist);
			goto out;
		}

		/*
		 * bmap_finish() may have committed the last trans and started
		 * a new one.  We need the inode to be in all transactions.
		 */
		if (committed)
			xfs_trans_ijoin(args->trans, dp, 0);
	} else {
		/*
		 * Addition succeeded, update Btree hashvals.
		 */
		xfs_da3_fixhashpath(state, &state->path);
	}

	/*
	 * Kill the state structure, we're done with it and need to
	 * allow the buffers to come back later.
	 */
	xfs_da_state_free(state);
	state = NULL;

	/*
	 * Commit the leaf addition or btree split and start the next
	 * trans in the chain.
	 */
	error = xfs_trans_roll(&args->trans, dp);
	if (error)
		goto out;

	/*
	 * If there was an out-of-line value, allocate the blocks we
	 * identified for its storage and copy the value.  This is done
	 * after we create the attribute so that we don't overflow the
	 * maximum size of a transaction and/or hit a deadlock.
	 */
	if (args->rmtblkno > 0) {
		error = xfs_attr_rmtval_set(args);
		if (error)
			return(error);
	}

	/*
	 * If this is an atomic rename operation, we must ""flip"" the
	 * incomplete flags on the ""new"" and ""old"" attribute/value pairs
	 * so that one disappears and one appears atomically.  Then we
	 * must remove the ""old"" attribute/value pair.
	 */
	if (args->op_flags & XFS_DA_OP_RENAME) {
		/*
		 * In a separate transaction, set the incomplete flag on the
		 * ""old"" attr and clear the incomplete flag on the ""new"" attr.
		 */
		error = xfs_attr3_leaf_flipflags(args);
		if (error)
			goto out;

		/*
		 * Dismantle the ""old"" attribute/value pair by removing
		 * a ""remote"" value (if it exists).
		 */
		args->index = args->index2;
 		args->blkno = args->blkno2;
 		args->rmtblkno = args->rmtblkno2;
 		args->rmtblkcnt = args->rmtblkcnt2;
//fix_flaw_line_below:
//		args->rmtvaluelen = args->rmtvaluelen2;
 		if (args->rmtblkno) {
 			error = xfs_attr_rmtval_remove(args);
 			if (error)
				return(error);
		}

		/*
		 * Re-find the ""old"" attribute entry after any split ops.
		 * The INCOMPLETE flag means that we will find the ""old""
		 * attr, not the ""new"" one.
		 */
		args->flags |= XFS_ATTR_INCOMPLETE;
		state = xfs_da_state_alloc();
		state->args = args;
		state->mp = mp;
		state->blocksize = state->mp->m_sb.sb_blocksize;
		state->node_ents = state->mp->m_attr_node_ents;
		state->inleaf = 0;
		error = xfs_da3_node_lookup_int(state, &retval);
		if (error)
			goto out;

		/*
		 * Remove the name and update the hashvals in the tree.
		 */
		blk = &state->path.blk[ state->path.active-1 ];
		ASSERT(blk->magic == XFS_ATTR_LEAF_MAGIC);
		error = xfs_attr3_leaf_remove(blk->bp, args);
		xfs_da3_fixhashpath(state, &state->path);

		/*
		 * Check to see if the tree needs to be collapsed.
		 */
		if (retval && (state->path.active > 1)) {
			xfs_bmap_init(args->flist, args->firstblock);
			error = xfs_da3_join(state);
			if (!error) {
				error = xfs_bmap_finish(&args->trans,
							args->flist,
							&committed);
			}
			if (error) {
				ASSERT(committed);
				args->trans = NULL;
				xfs_bmap_cancel(args->flist);
				goto out;
			}

			/*
			 * bmap_finish() may have committed the last trans
			 * and started a new one.  We need the inode to be
			 * in all transactions.
			 */
			if (committed)
				xfs_trans_ijoin(args->trans, dp, 0);
		}

		/*
		 * Commit and start the next trans in the chain.
		 */
		error = xfs_trans_roll(&args->trans, dp);
		if (error)
			goto out;

	} else if (args->rmtblkno > 0) {
		/*
		 * Added a ""remote"" value, just clear the incomplete flag.
		 */
		error = xfs_attr3_leaf_clearflag(args);
		if (error)
			goto out;
	}
	retval = error = 0;

out:
	if (state)
		xfs_da_state_free(state);
	if (error)
		return(error);
	return(retval);
}
"
2169,179905,,Local,Not required,Complete,CVE-2015-0274,https://www.cvedetails.com/cve/CVE-2015-0274/,CWE-19,Low,Complete,Complete,,2015-03-16,7.2,"The XFS implementation in the Linux kernel before 3.15 improperly uses an old size value during remote attribute replacement, which allows local users to cause a denial of service (transaction overrun and data corruption) or possibly gain privileges by leveraging XFS filesystem access.",2015-03-26,DoS +Priv ,1,https://github.com/torvalds/linux/commit/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,"xfs: remote attribute overwrite causes transaction overrun

Commit e461fcb (""xfs: remote attribute lookups require the value
length"") passes the remote attribute length in the xfs_da_args
structure on lookup so that CRC calculations and validity checking
can be performed correctly by related code. This, unfortunately has
the side effect of changing the args->valuelen parameter in cases
where it shouldn't.

That is, when we replace a remote attribute, the incoming
replacement stores the value and length in args->value and
args->valuelen, but then the lookup which finds the existing remote
attribute overwrites args->valuelen with the length of the remote
attribute being replaced. Hence when we go to create the new
attribute, we create it of the size of the existing remote
attribute, not the size it is supposed to be. When the new attribute
is much smaller than the old attribute, this results in a
transaction overrun and an ASSERT() failure on a debug kernel:

XFS: Assertion failed: tp->t_blk_res_used <= tp->t_blk_res, file: fs/xfs/xfs_trans.c, line: 331

Fix this by keeping the remote attribute value length separate to
the attribute value length in the xfs_da_args structure. The enables
us to pass the length of the remote attribute to be removed without
overwriting the new attribute's length.

Also, ensure that when we save remote block contexts for a later
rename we zero the original state variables so that we don't confuse
the state of the attribute to be removes with the state of the new
attribute that we just added. [Spotted by Brain Foster.]

Signed-off-by: Dave Chinner <dchinner@redhat.com>
Reviewed-by: Brian Foster <bfoster@redhat.com>
Signed-off-by: Dave Chinner <david@fromorbit.com>",0,fs/xfs/xfs_attr_leaf.c,"{""sha"": ""abda1124a70f66fbd1a79b28f8eaf5bf1916da1e"", ""filename"": ""fs/xfs/xfs_attr.c"", ""status"": ""modified"", ""additions"": 23, ""deletions"": 1, ""changes"": 24, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -213,7 +213,7 @@ xfs_attr_calc_size(\n \t\t * Out of line attribute, cannot double split, but\n \t\t * make room for the attribute value itself.\n \t\t */\n-\t\tuint\tdblocks = XFS_B_TO_FSB(mp, valuelen);\n+\t\tuint\tdblocks = xfs_attr3_rmt_blocks(mp, valuelen);\n \t\tnblks += dblocks;\n \t\tnblks += XFS_NEXTENTADD_SPACE_RES(mp, dblocks, XFS_ATTR_FORK);\n \t}\n@@ -698,11 +698,22 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)\n \n \t\ttrace_xfs_attr_leaf_replace(args);\n \n+\t\t/* save the attribute state for later removal*/\n \t\targs->op_flags |= XFS_DA_OP_RENAME;\t/* an atomic rename */\n \t\targs->blkno2 = args->blkno;\t\t/* set 2nd entry info*/\n \t\targs->index2 = args->index;\n \t\targs->rmtblkno2 = args->rmtblkno;\n \t\targs->rmtblkcnt2 = args->rmtblkcnt;\n+\t\targs->rmtvaluelen2 = args->rmtvaluelen;\n+\n+\t\t/*\n+\t\t * clear the remote attr state now that it is saved so that the\n+\t\t * values reflect the state of the attribute we are about to\n+\t\t * add, not the attribute we just found and will remove later.\n+\t\t */\n+\t\targs->rmtblkno = 0;\n+\t\targs->rmtblkcnt = 0;\n+\t\targs->rmtvaluelen = 0;\n \t}\n \n \t/*\n@@ -794,6 +805,7 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)\n \t\targs->blkno = args->blkno2;\n \t\targs->rmtblkno = args->rmtblkno2;\n \t\targs->rmtblkcnt = args->rmtblkcnt2;\n+\t\targs->rmtvaluelen = args->rmtvaluelen2;\n \t\tif (args->rmtblkno) {\n \t\t\terror = xfs_attr_rmtval_remove(args);\n \t\t\tif (error)\n@@ -999,13 +1011,22 @@ xfs_attr_node_addname(xfs_da_args_t *args)\n \n \t\ttrace_xfs_attr_node_replace(args);\n \n+\t\t/* save the attribute state for later removal*/\n \t\targs->op_flags |= XFS_DA_OP_RENAME;\t/* atomic rename op */\n \t\targs->blkno2 = args->blkno;\t\t/* set 2nd entry info*/\n \t\targs->index2 = args->index;\n \t\targs->rmtblkno2 = args->rmtblkno;\n \t\targs->rmtblkcnt2 = args->rmtblkcnt;\n+\t\targs->rmtvaluelen2 = args->rmtvaluelen;\n+\n+\t\t/*\n+\t\t * clear the remote attr state now that it is saved so that the\n+\t\t * values reflect the state of the attribute we are about to\n+\t\t * add, not the attribute we just found and will remove later.\n+\t\t */\n \t\targs->rmtblkno = 0;\n \t\targs->rmtblkcnt = 0;\n+\t\targs->rmtvaluelen = 0;\n \t}\n \n \tretval = xfs_attr3_leaf_add(blk->bp, state->args);\n@@ -1133,6 +1154,7 @@ xfs_attr_node_addname(xfs_da_args_t *args)\n \t\targs->blkno = args->blkno2;\n \t\targs->rmtblkno = args->rmtblkno2;\n \t\targs->rmtblkcnt = args->rmtblkcnt2;\n+\t\targs->rmtvaluelen = args->rmtvaluelen2;\n \t\tif (args->rmtblkno) {\n \t\t\terror = xfs_attr_rmtval_remove(args);\n \t\t\tif (error)""}<_**next**_>{""sha"": ""511c283459b19441d782114c4f832207860deab1"", ""filename"": ""fs/xfs/xfs_attr_leaf.c"", ""status"": ""modified"", ""additions"": 11, ""deletions"": 10, ""changes"": 21, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_leaf.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_leaf.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_leaf.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -1229,6 +1229,7 @@ xfs_attr3_leaf_add_work(\n \t\tname_rmt->valueblk = 0;\n \t\targs->rmtblkno = 1;\n \t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);\n+\t\targs->rmtvaluelen = args->valuelen;\n \t}\n \txfs_trans_log_buf(args->trans, bp,\n \t     XFS_DA_LOGRANGE(leaf, xfs_attr3_leaf_name(leaf, args->index),\n@@ -2167,11 +2168,11 @@ xfs_attr3_leaf_lookup_int(\n \t\t\tif (!xfs_attr_namesp_match(args->flags, entry->flags))\n \t\t\t\tcontinue;\n \t\t\targs->index = probe;\n-\t\t\targs->valuelen = be32_to_cpu(name_rmt->valuelen);\n+\t\t\targs->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);\n \t\t\targs->rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(\n \t\t\t\t\t\t\targs->dp->i_mount,\n-\t\t\t\t\t\t\targs->valuelen);\n+\t\t\t\t\t\t\targs->rmtvaluelen);\n \t\t\treturn XFS_ERROR(EEXIST);\n \t\t}\n \t}\n@@ -2220,19 +2221,19 @@ xfs_attr3_leaf_getvalue(\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);\n \t\tASSERT(name_rmt->namelen == args->namelen);\n \t\tASSERT(memcmp(args->name, name_rmt->name, args->namelen) == 0);\n-\t\tvaluelen = be32_to_cpu(name_rmt->valuelen);\n+\t\targs->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);\n \t\targs->rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(args->dp->i_mount,\n-\t\t\t\t\t\t       valuelen);\n+\t\t\t\t\t\t       args->rmtvaluelen);\n \t\tif (args->flags & ATTR_KERNOVAL) {\n-\t\t\targs->valuelen = valuelen;\n+\t\t\targs->valuelen = args->rmtvaluelen;\n \t\t\treturn 0;\n \t\t}\n-\t\tif (args->valuelen < valuelen) {\n-\t\t\targs->valuelen = valuelen;\n+\t\tif (args->valuelen < args->rmtvaluelen) {\n+\t\t\targs->valuelen = args->rmtvaluelen;\n \t\t\treturn XFS_ERROR(ERANGE);\n \t\t}\n-\t\targs->valuelen = valuelen;\n+\t\targs->valuelen = args->rmtvaluelen;\n \t}\n \treturn 0;\n }\n@@ -2519,7 +2520,7 @@ xfs_attr3_leaf_clearflag(\n \t\tASSERT((entry->flags & XFS_ATTR_LOCAL) == 0);\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);\n \t\tname_rmt->valueblk = cpu_to_be32(args->rmtblkno);\n-\t\tname_rmt->valuelen = cpu_to_be32(args->valuelen);\n+\t\tname_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);\n \t\txfs_trans_log_buf(args->trans, bp,\n \t\t\t XFS_DA_LOGRANGE(leaf, name_rmt, sizeof(*name_rmt)));\n \t}\n@@ -2677,7 +2678,7 @@ xfs_attr3_leaf_flipflags(\n \t\tASSERT((entry1->flags & XFS_ATTR_LOCAL) == 0);\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf1, args->index);\n \t\tname_rmt->valueblk = cpu_to_be32(args->rmtblkno);\n-\t\tname_rmt->valuelen = cpu_to_be32(args->valuelen);\n+\t\tname_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);\n \t\txfs_trans_log_buf(args->trans, bp1,\n \t\t\t XFS_DA_LOGRANGE(leaf1, name_rmt, sizeof(*name_rmt)));\n \t}""}<_**next**_>{""sha"": ""833fe5d98d806783ca6bb6cf2f4ecb83424bfdca"", ""filename"": ""fs/xfs/xfs_attr_list.c"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 0, ""changes"": 1, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_list.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_list.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_list.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -447,6 +447,7 @@ xfs_attr3_leaf_list_int(\n \t\t\t\targs.dp = context->dp;\n \t\t\t\targs.whichfork = XFS_ATTR_FORK;\n \t\t\t\targs.valuelen = valuelen;\n+\t\t\t\targs.rmtvaluelen = valuelen;\n \t\t\t\targs.value = kmem_alloc(valuelen, KM_SLEEP | KM_NOFS);\n \t\t\t\targs.rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\t\t\targs.rmtblkcnt = xfs_attr3_rmt_blocks(""}<_**next**_>{""sha"": ""d2e6e948cec7be3013b853033b6e1a64b365a682"", ""filename"": ""fs/xfs/xfs_attr_remote.c"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 3, ""changes"": 8, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_remote.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_remote.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_remote.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -337,7 +337,7 @@ xfs_attr_rmtval_get(\n \tstruct xfs_buf\t\t*bp;\n \txfs_dablk_t\t\tlblkno = args->rmtblkno;\n \t__uint8_t\t\t*dst = args->value;\n-\tint\t\t\tvaluelen = args->valuelen;\n+\tint\t\t\tvaluelen;\n \tint\t\t\tnmap;\n \tint\t\t\terror;\n \tint\t\t\tblkcnt = args->rmtblkcnt;\n@@ -347,7 +347,9 @@ xfs_attr_rmtval_get(\n \ttrace_xfs_attr_rmtval_get(args);\n \n \tASSERT(!(args->flags & ATTR_KERNOVAL));\n+\tASSERT(args->rmtvaluelen == args->valuelen);\n \n+\tvaluelen = args->rmtvaluelen;\n \twhile (valuelen > 0) {\n \t\tnmap = ATTR_RMTVALUE_MAPSIZE;\n \t\terror = xfs_bmapi_read(args->dp, (xfs_fileoff_t)lblkno,\n@@ -415,7 +417,7 @@ xfs_attr_rmtval_set(\n \t * attributes have headers, we can't just do a straight byte to FSB\n \t * conversion and have to take the header space into account.\n \t */\n-\tblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);\n+\tblkcnt = xfs_attr3_rmt_blocks(mp, args->rmtvaluelen);\n \terror = xfs_bmap_first_unused(args->trans, args->dp, blkcnt, &lfileoff,\n \t\t\t\t\t\t   XFS_ATTR_FORK);\n \tif (error)\n@@ -480,7 +482,7 @@ xfs_attr_rmtval_set(\n \t */\n \tlblkno = args->rmtblkno;\n \tblkcnt = args->rmtblkcnt;\n-\tvaluelen = args->valuelen;\n+\tvaluelen = args->rmtvaluelen;\n \twhile (valuelen > 0) {\n \t\tstruct xfs_buf\t*bp;\n \t\txfs_daddr_t\tdblkno;""}<_**next**_>{""sha"": ""201c6091d26abfa2e38dd17fd960e3efcb69bcd7"", ""filename"": ""fs/xfs/xfs_da_btree.h"", ""status"": ""modified"", ""additions"": 2, ""deletions"": 0, ""changes"": 2, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_da_btree.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_da_btree.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_da_btree.h?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -60,10 +60,12 @@ typedef struct xfs_da_args {\n \tint\t\tindex;\t\t/* index of attr of interest in blk */\n \txfs_dablk_t\trmtblkno;\t/* remote attr value starting blkno */\n \tint\t\trmtblkcnt;\t/* remote attr value block count */\n+\tint\t\trmtvaluelen;\t/* remote attr value length in bytes */\n \txfs_dablk_t\tblkno2;\t\t/* blkno of 2nd attr leaf of interest */\n \tint\t\tindex2;\t\t/* index of 2nd attr in blk */\n \txfs_dablk_t\trmtblkno2;\t/* remote attr value starting blkno */\n \tint\t\trmtblkcnt2;\t/* remote attr value block count */\n+\tint\t\trmtvaluelen2;\t/* remote attr value length in bytes */\n \tint\t\top_flags;\t/* operation flags */\n \tenum xfs_dacmp\tcmpresult;\t/* name compare result for lookups */\n } xfs_da_args_t;""}","xfs_attr3_leaf_add_work(
	struct xfs_buf		*bp,
	struct xfs_attr3_icleaf_hdr *ichdr,
	struct xfs_da_args	*args,
	int			mapindex)
{
	struct xfs_attr_leafblock *leaf;
	struct xfs_attr_leaf_entry *entry;
	struct xfs_attr_leaf_name_local *name_loc;
	struct xfs_attr_leaf_name_remote *name_rmt;
	struct xfs_mount	*mp;
	int			tmp;
	int			i;

	trace_xfs_attr_leaf_add_work(args);

	leaf = bp->b_addr;
	ASSERT(mapindex >= 0 && mapindex < XFS_ATTR_LEAF_MAPSIZE);
	ASSERT(args->index >= 0 && args->index <= ichdr->count);

	/*
	 * Force open some space in the entry array and fill it in.
	 */
	entry = &xfs_attr3_leaf_entryp(leaf)[args->index];
	if (args->index < ichdr->count) {
		tmp  = ichdr->count - args->index;
		tmp *= sizeof(xfs_attr_leaf_entry_t);
		memmove(entry + 1, entry, tmp);
		xfs_trans_log_buf(args->trans, bp,
		    XFS_DA_LOGRANGE(leaf, entry, tmp + sizeof(*entry)));
	}
	ichdr->count++;

	/*
	 * Allocate space for the new string (at the end of the run).
	 */
	mp = args->trans->t_mountp;
	ASSERT(ichdr->freemap[mapindex].base < XFS_LBSIZE(mp));
	ASSERT((ichdr->freemap[mapindex].base & 0x3) == 0);
	ASSERT(ichdr->freemap[mapindex].size >=
		xfs_attr_leaf_newentsize(args->namelen, args->valuelen,
					 mp->m_sb.sb_blocksize, NULL));
	ASSERT(ichdr->freemap[mapindex].size < XFS_LBSIZE(mp));
	ASSERT((ichdr->freemap[mapindex].size & 0x3) == 0);

	ichdr->freemap[mapindex].size -=
			xfs_attr_leaf_newentsize(args->namelen, args->valuelen,
						 mp->m_sb.sb_blocksize, &tmp);

	entry->nameidx = cpu_to_be16(ichdr->freemap[mapindex].base +
				     ichdr->freemap[mapindex].size);
	entry->hashval = cpu_to_be32(args->hashval);
	entry->flags = tmp ? XFS_ATTR_LOCAL : 0;
	entry->flags |= XFS_ATTR_NSP_ARGS_TO_ONDISK(args->flags);
	if (args->op_flags & XFS_DA_OP_RENAME) {
		entry->flags |= XFS_ATTR_INCOMPLETE;
		if ((args->blkno2 == args->blkno) &&
		    (args->index2 <= args->index)) {
			args->index2++;
		}
	}
	xfs_trans_log_buf(args->trans, bp,
			  XFS_DA_LOGRANGE(leaf, entry, sizeof(*entry)));
	ASSERT((args->index == 0) ||
	       (be32_to_cpu(entry->hashval) >= be32_to_cpu((entry-1)->hashval)));
	ASSERT((args->index == ichdr->count - 1) ||
	       (be32_to_cpu(entry->hashval) <= be32_to_cpu((entry+1)->hashval)));

	/*
	 * For ""remote"" attribute values, simply note that we need to
	 * allocate space for the ""remote"" value.  We can't actually
	 * allocate the extents in this transaction, and we can't decide
	 * which blocks they should be as we might allocate more blocks
	 * as part of this transaction (a split operation for example).
	 */
	if (entry->flags & XFS_ATTR_LOCAL) {
		name_loc = xfs_attr3_leaf_name_local(leaf, args->index);
		name_loc->namelen = args->namelen;
		name_loc->valuelen = cpu_to_be16(args->valuelen);
		memcpy((char *)name_loc->nameval, args->name, args->namelen);
		memcpy((char *)&name_loc->nameval[args->namelen], args->value,
				   be16_to_cpu(name_loc->valuelen));
	} else {
		name_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);
		name_rmt->namelen = args->namelen;
		memcpy((char *)name_rmt->name, args->name, args->namelen);
		entry->flags |= XFS_ATTR_INCOMPLETE;
		/* just in case */
		name_rmt->valuelen = 0;
 		name_rmt->valueblk = 0;
 		args->rmtblkno = 1;
 		args->rmtblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);
		args->rmtvaluelen = args->valuelen;
 	}
 	xfs_trans_log_buf(args->trans, bp,
 	     XFS_DA_LOGRANGE(leaf, xfs_attr3_leaf_name(leaf, args->index),
				   xfs_attr_leaf_entsize(leaf, args->index)));

	/*
	 * Update the control info for this leaf node
	 */
	if (be16_to_cpu(entry->nameidx) < ichdr->firstused)
		ichdr->firstused = be16_to_cpu(entry->nameidx);

	ASSERT(ichdr->firstused >= ichdr->count * sizeof(xfs_attr_leaf_entry_t)
					+ xfs_attr3_leaf_hdr_size(leaf));
	tmp = (ichdr->count - 1) * sizeof(xfs_attr_leaf_entry_t)
					+ xfs_attr3_leaf_hdr_size(leaf);

	for (i = 0; i < XFS_ATTR_LEAF_MAPSIZE; i++) {
		if (ichdr->freemap[i].base == tmp) {
			ichdr->freemap[i].base += sizeof(xfs_attr_leaf_entry_t);
			ichdr->freemap[i].size -= sizeof(xfs_attr_leaf_entry_t);
		}
	}
	ichdr->usedbytes += xfs_attr_leaf_entsize(leaf, args->index);
	return 0;
}
","xfs_attr3_leaf_add_work(
	struct xfs_buf		*bp,
	struct xfs_attr3_icleaf_hdr *ichdr,
	struct xfs_da_args	*args,
	int			mapindex)
{
	struct xfs_attr_leafblock *leaf;
	struct xfs_attr_leaf_entry *entry;
	struct xfs_attr_leaf_name_local *name_loc;
	struct xfs_attr_leaf_name_remote *name_rmt;
	struct xfs_mount	*mp;
	int			tmp;
	int			i;

	trace_xfs_attr_leaf_add_work(args);

	leaf = bp->b_addr;
	ASSERT(mapindex >= 0 && mapindex < XFS_ATTR_LEAF_MAPSIZE);
	ASSERT(args->index >= 0 && args->index <= ichdr->count);

	/*
	 * Force open some space in the entry array and fill it in.
	 */
	entry = &xfs_attr3_leaf_entryp(leaf)[args->index];
	if (args->index < ichdr->count) {
		tmp  = ichdr->count - args->index;
		tmp *= sizeof(xfs_attr_leaf_entry_t);
		memmove(entry + 1, entry, tmp);
		xfs_trans_log_buf(args->trans, bp,
		    XFS_DA_LOGRANGE(leaf, entry, tmp + sizeof(*entry)));
	}
	ichdr->count++;

	/*
	 * Allocate space for the new string (at the end of the run).
	 */
	mp = args->trans->t_mountp;
	ASSERT(ichdr->freemap[mapindex].base < XFS_LBSIZE(mp));
	ASSERT((ichdr->freemap[mapindex].base & 0x3) == 0);
	ASSERT(ichdr->freemap[mapindex].size >=
		xfs_attr_leaf_newentsize(args->namelen, args->valuelen,
					 mp->m_sb.sb_blocksize, NULL));
	ASSERT(ichdr->freemap[mapindex].size < XFS_LBSIZE(mp));
	ASSERT((ichdr->freemap[mapindex].size & 0x3) == 0);

	ichdr->freemap[mapindex].size -=
			xfs_attr_leaf_newentsize(args->namelen, args->valuelen,
						 mp->m_sb.sb_blocksize, &tmp);

	entry->nameidx = cpu_to_be16(ichdr->freemap[mapindex].base +
				     ichdr->freemap[mapindex].size);
	entry->hashval = cpu_to_be32(args->hashval);
	entry->flags = tmp ? XFS_ATTR_LOCAL : 0;
	entry->flags |= XFS_ATTR_NSP_ARGS_TO_ONDISK(args->flags);
	if (args->op_flags & XFS_DA_OP_RENAME) {
		entry->flags |= XFS_ATTR_INCOMPLETE;
		if ((args->blkno2 == args->blkno) &&
		    (args->index2 <= args->index)) {
			args->index2++;
		}
	}
	xfs_trans_log_buf(args->trans, bp,
			  XFS_DA_LOGRANGE(leaf, entry, sizeof(*entry)));
	ASSERT((args->index == 0) ||
	       (be32_to_cpu(entry->hashval) >= be32_to_cpu((entry-1)->hashval)));
	ASSERT((args->index == ichdr->count - 1) ||
	       (be32_to_cpu(entry->hashval) <= be32_to_cpu((entry+1)->hashval)));

	/*
	 * For ""remote"" attribute values, simply note that we need to
	 * allocate space for the ""remote"" value.  We can't actually
	 * allocate the extents in this transaction, and we can't decide
	 * which blocks they should be as we might allocate more blocks
	 * as part of this transaction (a split operation for example).
	 */
	if (entry->flags & XFS_ATTR_LOCAL) {
		name_loc = xfs_attr3_leaf_name_local(leaf, args->index);
		name_loc->namelen = args->namelen;
		name_loc->valuelen = cpu_to_be16(args->valuelen);
		memcpy((char *)name_loc->nameval, args->name, args->namelen);
		memcpy((char *)&name_loc->nameval[args->namelen], args->value,
				   be16_to_cpu(name_loc->valuelen));
	} else {
		name_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);
		name_rmt->namelen = args->namelen;
		memcpy((char *)name_rmt->name, args->name, args->namelen);
		entry->flags |= XFS_ATTR_INCOMPLETE;
		/* just in case */
		name_rmt->valuelen = 0;
 		name_rmt->valueblk = 0;
 		args->rmtblkno = 1;
 		args->rmtblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);
 	}
 	xfs_trans_log_buf(args->trans, bp,
 	     XFS_DA_LOGRANGE(leaf, xfs_attr3_leaf_name(leaf, args->index),
				   xfs_attr_leaf_entsize(leaf, args->index)));

	/*
	 * Update the control info for this leaf node
	 */
	if (be16_to_cpu(entry->nameidx) < ichdr->firstused)
		ichdr->firstused = be16_to_cpu(entry->nameidx);

	ASSERT(ichdr->firstused >= ichdr->count * sizeof(xfs_attr_leaf_entry_t)
					+ xfs_attr3_leaf_hdr_size(leaf));
	tmp = (ichdr->count - 1) * sizeof(xfs_attr_leaf_entry_t)
					+ xfs_attr3_leaf_hdr_size(leaf);

	for (i = 0; i < XFS_ATTR_LEAF_MAPSIZE; i++) {
		if (ichdr->freemap[i].base == tmp) {
			ichdr->freemap[i].base += sizeof(xfs_attr_leaf_entry_t);
			ichdr->freemap[i].size -= sizeof(xfs_attr_leaf_entry_t);
		}
	}
	ichdr->usedbytes += xfs_attr_leaf_entsize(leaf, args->index);
	return 0;
}
",C,"		args->rmtvaluelen = args->valuelen;
",,,"@@ -1229,6 +1229,7 @@ xfs_attr3_leaf_add_work(
 		name_rmt->valueblk = 0;
 		args->rmtblkno = 1;
 		args->rmtblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);
+		args->rmtvaluelen = args->valuelen;
 	}
 	xfs_trans_log_buf(args->trans, bp,
 	     XFS_DA_LOGRANGE(leaf, xfs_attr3_leaf_name(leaf, args->index),
@@ -2167,11 +2168,11 @@ xfs_attr3_leaf_lookup_int(
 			if (!xfs_attr_namesp_match(args->flags, entry->flags))
 				continue;
 			args->index = probe;
-			args->valuelen = be32_to_cpu(name_rmt->valuelen);
+			args->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);
 			args->rmtblkno = be32_to_cpu(name_rmt->valueblk);
 			args->rmtblkcnt = xfs_attr3_rmt_blocks(
 							args->dp->i_mount,
-							args->valuelen);
+							args->rmtvaluelen);
 			return XFS_ERROR(EEXIST);
 		}
 	}
@@ -2220,19 +2221,19 @@ xfs_attr3_leaf_getvalue(
 		name_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);
 		ASSERT(name_rmt->namelen == args->namelen);
 		ASSERT(memcmp(args->name, name_rmt->name, args->namelen) == 0);
-		valuelen = be32_to_cpu(name_rmt->valuelen);
+		args->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);
 		args->rmtblkno = be32_to_cpu(name_rmt->valueblk);
 		args->rmtblkcnt = xfs_attr3_rmt_blocks(args->dp->i_mount,
-						       valuelen);
+						       args->rmtvaluelen);
 		if (args->flags & ATTR_KERNOVAL) {
-			args->valuelen = valuelen;
+			args->valuelen = args->rmtvaluelen;
 			return 0;
 		}
-		if (args->valuelen < valuelen) {
-			args->valuelen = valuelen;
+		if (args->valuelen < args->rmtvaluelen) {
+			args->valuelen = args->rmtvaluelen;
 			return XFS_ERROR(ERANGE);
 		}
-		args->valuelen = valuelen;
+		args->valuelen = args->rmtvaluelen;
 	}
 	return 0;
 }
@@ -2519,7 +2520,7 @@ xfs_attr3_leaf_clearflag(
 		ASSERT((entry->flags & XFS_ATTR_LOCAL) == 0);
 		name_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);
 		name_rmt->valueblk = cpu_to_be32(args->rmtblkno);
-		name_rmt->valuelen = cpu_to_be32(args->valuelen);
+		name_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);
 		xfs_trans_log_buf(args->trans, bp,
 			 XFS_DA_LOGRANGE(leaf, name_rmt, sizeof(*name_rmt)));
 	}
@@ -2677,7 +2678,7 @@ xfs_attr3_leaf_flipflags(
 		ASSERT((entry1->flags & XFS_ATTR_LOCAL) == 0);
 		name_rmt = xfs_attr3_leaf_name_remote(leaf1, args->index);
 		name_rmt->valueblk = cpu_to_be32(args->rmtblkno);
-		name_rmt->valuelen = cpu_to_be32(args->valuelen);
+		name_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);
 		xfs_trans_log_buf(args->trans, bp1,
 			 XFS_DA_LOGRANGE(leaf1, name_rmt, sizeof(*name_rmt)));
 	}",linux,8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,d540e43b0ab134b22f015f725ce6e070d12b0244,1,"xfs_attr3_leaf_add_work(
	struct xfs_buf		*bp,
	struct xfs_attr3_icleaf_hdr *ichdr,
	struct xfs_da_args	*args,
	int			mapindex)
{
	struct xfs_attr_leafblock *leaf;
	struct xfs_attr_leaf_entry *entry;
	struct xfs_attr_leaf_name_local *name_loc;
	struct xfs_attr_leaf_name_remote *name_rmt;
	struct xfs_mount	*mp;
	int			tmp;
	int			i;

	trace_xfs_attr_leaf_add_work(args);

	leaf = bp->b_addr;
	ASSERT(mapindex >= 0 && mapindex < XFS_ATTR_LEAF_MAPSIZE);
	ASSERT(args->index >= 0 && args->index <= ichdr->count);

	/*
	 * Force open some space in the entry array and fill it in.
	 */
	entry = &xfs_attr3_leaf_entryp(leaf)[args->index];
	if (args->index < ichdr->count) {
		tmp  = ichdr->count - args->index;
		tmp *= sizeof(xfs_attr_leaf_entry_t);
		memmove(entry + 1, entry, tmp);
		xfs_trans_log_buf(args->trans, bp,
		    XFS_DA_LOGRANGE(leaf, entry, tmp + sizeof(*entry)));
	}
	ichdr->count++;

	/*
	 * Allocate space for the new string (at the end of the run).
	 */
	mp = args->trans->t_mountp;
	ASSERT(ichdr->freemap[mapindex].base < XFS_LBSIZE(mp));
	ASSERT((ichdr->freemap[mapindex].base & 0x3) == 0);
	ASSERT(ichdr->freemap[mapindex].size >=
		xfs_attr_leaf_newentsize(args->namelen, args->valuelen,
					 mp->m_sb.sb_blocksize, NULL));
	ASSERT(ichdr->freemap[mapindex].size < XFS_LBSIZE(mp));
	ASSERT((ichdr->freemap[mapindex].size & 0x3) == 0);

	ichdr->freemap[mapindex].size -=
			xfs_attr_leaf_newentsize(args->namelen, args->valuelen,
						 mp->m_sb.sb_blocksize, &tmp);

	entry->nameidx = cpu_to_be16(ichdr->freemap[mapindex].base +
				     ichdr->freemap[mapindex].size);
	entry->hashval = cpu_to_be32(args->hashval);
	entry->flags = tmp ? XFS_ATTR_LOCAL : 0;
	entry->flags |= XFS_ATTR_NSP_ARGS_TO_ONDISK(args->flags);
	if (args->op_flags & XFS_DA_OP_RENAME) {
		entry->flags |= XFS_ATTR_INCOMPLETE;
		if ((args->blkno2 == args->blkno) &&
		    (args->index2 <= args->index)) {
			args->index2++;
		}
	}
	xfs_trans_log_buf(args->trans, bp,
			  XFS_DA_LOGRANGE(leaf, entry, sizeof(*entry)));
	ASSERT((args->index == 0) ||
	       (be32_to_cpu(entry->hashval) >= be32_to_cpu((entry-1)->hashval)));
	ASSERT((args->index == ichdr->count - 1) ||
	       (be32_to_cpu(entry->hashval) <= be32_to_cpu((entry+1)->hashval)));

	/*
	 * For ""remote"" attribute values, simply note that we need to
	 * allocate space for the ""remote"" value.  We can't actually
	 * allocate the extents in this transaction, and we can't decide
	 * which blocks they should be as we might allocate more blocks
	 * as part of this transaction (a split operation for example).
	 */
	if (entry->flags & XFS_ATTR_LOCAL) {
		name_loc = xfs_attr3_leaf_name_local(leaf, args->index);
		name_loc->namelen = args->namelen;
		name_loc->valuelen = cpu_to_be16(args->valuelen);
		memcpy((char *)name_loc->nameval, args->name, args->namelen);
		memcpy((char *)&name_loc->nameval[args->namelen], args->value,
				   be16_to_cpu(name_loc->valuelen));
	} else {
		name_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);
		name_rmt->namelen = args->namelen;
		memcpy((char *)name_rmt->name, args->name, args->namelen);
		entry->flags |= XFS_ATTR_INCOMPLETE;
		/* just in case */
		name_rmt->valuelen = 0;
 		name_rmt->valueblk = 0;
 		args->rmtblkno = 1;
 		args->rmtblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);
//fix_flaw_line_below:
//		args->rmtvaluelen = args->valuelen;
 	}
 	xfs_trans_log_buf(args->trans, bp,
 	     XFS_DA_LOGRANGE(leaf, xfs_attr3_leaf_name(leaf, args->index),
				   xfs_attr_leaf_entsize(leaf, args->index)));

	/*
	 * Update the control info for this leaf node
	 */
	if (be16_to_cpu(entry->nameidx) < ichdr->firstused)
		ichdr->firstused = be16_to_cpu(entry->nameidx);

	ASSERT(ichdr->firstused >= ichdr->count * sizeof(xfs_attr_leaf_entry_t)
					+ xfs_attr3_leaf_hdr_size(leaf));
	tmp = (ichdr->count - 1) * sizeof(xfs_attr_leaf_entry_t)
					+ xfs_attr3_leaf_hdr_size(leaf);

	for (i = 0; i < XFS_ATTR_LEAF_MAPSIZE; i++) {
		if (ichdr->freemap[i].base == tmp) {
			ichdr->freemap[i].base += sizeof(xfs_attr_leaf_entry_t);
			ichdr->freemap[i].size -= sizeof(xfs_attr_leaf_entry_t);
		}
	}
	ichdr->usedbytes += xfs_attr_leaf_entsize(leaf, args->index);
	return 0;
}
"
2170,179906,,Local,Not required,Complete,CVE-2015-0274,https://www.cvedetails.com/cve/CVE-2015-0274/,CWE-19,Low,Complete,Complete,,2015-03-16,7.2,"The XFS implementation in the Linux kernel before 3.15 improperly uses an old size value during remote attribute replacement, which allows local users to cause a denial of service (transaction overrun and data corruption) or possibly gain privileges by leveraging XFS filesystem access.",2015-03-26,DoS +Priv ,1,https://github.com/torvalds/linux/commit/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,"xfs: remote attribute overwrite causes transaction overrun

Commit e461fcb (""xfs: remote attribute lookups require the value
length"") passes the remote attribute length in the xfs_da_args
structure on lookup so that CRC calculations and validity checking
can be performed correctly by related code. This, unfortunately has
the side effect of changing the args->valuelen parameter in cases
where it shouldn't.

That is, when we replace a remote attribute, the incoming
replacement stores the value and length in args->value and
args->valuelen, but then the lookup which finds the existing remote
attribute overwrites args->valuelen with the length of the remote
attribute being replaced. Hence when we go to create the new
attribute, we create it of the size of the existing remote
attribute, not the size it is supposed to be. When the new attribute
is much smaller than the old attribute, this results in a
transaction overrun and an ASSERT() failure on a debug kernel:

XFS: Assertion failed: tp->t_blk_res_used <= tp->t_blk_res, file: fs/xfs/xfs_trans.c, line: 331

Fix this by keeping the remote attribute value length separate to
the attribute value length in the xfs_da_args structure. The enables
us to pass the length of the remote attribute to be removed without
overwriting the new attribute's length.

Also, ensure that when we save remote block contexts for a later
rename we zero the original state variables so that we don't confuse
the state of the attribute to be removes with the state of the new
attribute that we just added. [Spotted by Brain Foster.]

Signed-off-by: Dave Chinner <dchinner@redhat.com>
Reviewed-by: Brian Foster <bfoster@redhat.com>
Signed-off-by: Dave Chinner <david@fromorbit.com>",1,fs/xfs/xfs_attr_leaf.c,"{""sha"": ""abda1124a70f66fbd1a79b28f8eaf5bf1916da1e"", ""filename"": ""fs/xfs/xfs_attr.c"", ""status"": ""modified"", ""additions"": 23, ""deletions"": 1, ""changes"": 24, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -213,7 +213,7 @@ xfs_attr_calc_size(\n \t\t * Out of line attribute, cannot double split, but\n \t\t * make room for the attribute value itself.\n \t\t */\n-\t\tuint\tdblocks = XFS_B_TO_FSB(mp, valuelen);\n+\t\tuint\tdblocks = xfs_attr3_rmt_blocks(mp, valuelen);\n \t\tnblks += dblocks;\n \t\tnblks += XFS_NEXTENTADD_SPACE_RES(mp, dblocks, XFS_ATTR_FORK);\n \t}\n@@ -698,11 +698,22 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)\n \n \t\ttrace_xfs_attr_leaf_replace(args);\n \n+\t\t/* save the attribute state for later removal*/\n \t\targs->op_flags |= XFS_DA_OP_RENAME;\t/* an atomic rename */\n \t\targs->blkno2 = args->blkno;\t\t/* set 2nd entry info*/\n \t\targs->index2 = args->index;\n \t\targs->rmtblkno2 = args->rmtblkno;\n \t\targs->rmtblkcnt2 = args->rmtblkcnt;\n+\t\targs->rmtvaluelen2 = args->rmtvaluelen;\n+\n+\t\t/*\n+\t\t * clear the remote attr state now that it is saved so that the\n+\t\t * values reflect the state of the attribute we are about to\n+\t\t * add, not the attribute we just found and will remove later.\n+\t\t */\n+\t\targs->rmtblkno = 0;\n+\t\targs->rmtblkcnt = 0;\n+\t\targs->rmtvaluelen = 0;\n \t}\n \n \t/*\n@@ -794,6 +805,7 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)\n \t\targs->blkno = args->blkno2;\n \t\targs->rmtblkno = args->rmtblkno2;\n \t\targs->rmtblkcnt = args->rmtblkcnt2;\n+\t\targs->rmtvaluelen = args->rmtvaluelen2;\n \t\tif (args->rmtblkno) {\n \t\t\terror = xfs_attr_rmtval_remove(args);\n \t\t\tif (error)\n@@ -999,13 +1011,22 @@ xfs_attr_node_addname(xfs_da_args_t *args)\n \n \t\ttrace_xfs_attr_node_replace(args);\n \n+\t\t/* save the attribute state for later removal*/\n \t\targs->op_flags |= XFS_DA_OP_RENAME;\t/* atomic rename op */\n \t\targs->blkno2 = args->blkno;\t\t/* set 2nd entry info*/\n \t\targs->index2 = args->index;\n \t\targs->rmtblkno2 = args->rmtblkno;\n \t\targs->rmtblkcnt2 = args->rmtblkcnt;\n+\t\targs->rmtvaluelen2 = args->rmtvaluelen;\n+\n+\t\t/*\n+\t\t * clear the remote attr state now that it is saved so that the\n+\t\t * values reflect the state of the attribute we are about to\n+\t\t * add, not the attribute we just found and will remove later.\n+\t\t */\n \t\targs->rmtblkno = 0;\n \t\targs->rmtblkcnt = 0;\n+\t\targs->rmtvaluelen = 0;\n \t}\n \n \tretval = xfs_attr3_leaf_add(blk->bp, state->args);\n@@ -1133,6 +1154,7 @@ xfs_attr_node_addname(xfs_da_args_t *args)\n \t\targs->blkno = args->blkno2;\n \t\targs->rmtblkno = args->rmtblkno2;\n \t\targs->rmtblkcnt = args->rmtblkcnt2;\n+\t\targs->rmtvaluelen = args->rmtvaluelen2;\n \t\tif (args->rmtblkno) {\n \t\t\terror = xfs_attr_rmtval_remove(args);\n \t\t\tif (error)""}<_**next**_>{""sha"": ""511c283459b19441d782114c4f832207860deab1"", ""filename"": ""fs/xfs/xfs_attr_leaf.c"", ""status"": ""modified"", ""additions"": 11, ""deletions"": 10, ""changes"": 21, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_leaf.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_leaf.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_leaf.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -1229,6 +1229,7 @@ xfs_attr3_leaf_add_work(\n \t\tname_rmt->valueblk = 0;\n \t\targs->rmtblkno = 1;\n \t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);\n+\t\targs->rmtvaluelen = args->valuelen;\n \t}\n \txfs_trans_log_buf(args->trans, bp,\n \t     XFS_DA_LOGRANGE(leaf, xfs_attr3_leaf_name(leaf, args->index),\n@@ -2167,11 +2168,11 @@ xfs_attr3_leaf_lookup_int(\n \t\t\tif (!xfs_attr_namesp_match(args->flags, entry->flags))\n \t\t\t\tcontinue;\n \t\t\targs->index = probe;\n-\t\t\targs->valuelen = be32_to_cpu(name_rmt->valuelen);\n+\t\t\targs->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);\n \t\t\targs->rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(\n \t\t\t\t\t\t\targs->dp->i_mount,\n-\t\t\t\t\t\t\targs->valuelen);\n+\t\t\t\t\t\t\targs->rmtvaluelen);\n \t\t\treturn XFS_ERROR(EEXIST);\n \t\t}\n \t}\n@@ -2220,19 +2221,19 @@ xfs_attr3_leaf_getvalue(\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);\n \t\tASSERT(name_rmt->namelen == args->namelen);\n \t\tASSERT(memcmp(args->name, name_rmt->name, args->namelen) == 0);\n-\t\tvaluelen = be32_to_cpu(name_rmt->valuelen);\n+\t\targs->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);\n \t\targs->rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(args->dp->i_mount,\n-\t\t\t\t\t\t       valuelen);\n+\t\t\t\t\t\t       args->rmtvaluelen);\n \t\tif (args->flags & ATTR_KERNOVAL) {\n-\t\t\targs->valuelen = valuelen;\n+\t\t\targs->valuelen = args->rmtvaluelen;\n \t\t\treturn 0;\n \t\t}\n-\t\tif (args->valuelen < valuelen) {\n-\t\t\targs->valuelen = valuelen;\n+\t\tif (args->valuelen < args->rmtvaluelen) {\n+\t\t\targs->valuelen = args->rmtvaluelen;\n \t\t\treturn XFS_ERROR(ERANGE);\n \t\t}\n-\t\targs->valuelen = valuelen;\n+\t\targs->valuelen = args->rmtvaluelen;\n \t}\n \treturn 0;\n }\n@@ -2519,7 +2520,7 @@ xfs_attr3_leaf_clearflag(\n \t\tASSERT((entry->flags & XFS_ATTR_LOCAL) == 0);\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);\n \t\tname_rmt->valueblk = cpu_to_be32(args->rmtblkno);\n-\t\tname_rmt->valuelen = cpu_to_be32(args->valuelen);\n+\t\tname_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);\n \t\txfs_trans_log_buf(args->trans, bp,\n \t\t\t XFS_DA_LOGRANGE(leaf, name_rmt, sizeof(*name_rmt)));\n \t}\n@@ -2677,7 +2678,7 @@ xfs_attr3_leaf_flipflags(\n \t\tASSERT((entry1->flags & XFS_ATTR_LOCAL) == 0);\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf1, args->index);\n \t\tname_rmt->valueblk = cpu_to_be32(args->rmtblkno);\n-\t\tname_rmt->valuelen = cpu_to_be32(args->valuelen);\n+\t\tname_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);\n \t\txfs_trans_log_buf(args->trans, bp1,\n \t\t\t XFS_DA_LOGRANGE(leaf1, name_rmt, sizeof(*name_rmt)));\n \t}""}<_**next**_>{""sha"": ""833fe5d98d806783ca6bb6cf2f4ecb83424bfdca"", ""filename"": ""fs/xfs/xfs_attr_list.c"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 0, ""changes"": 1, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_list.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_list.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_list.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -447,6 +447,7 @@ xfs_attr3_leaf_list_int(\n \t\t\t\targs.dp = context->dp;\n \t\t\t\targs.whichfork = XFS_ATTR_FORK;\n \t\t\t\targs.valuelen = valuelen;\n+\t\t\t\targs.rmtvaluelen = valuelen;\n \t\t\t\targs.value = kmem_alloc(valuelen, KM_SLEEP | KM_NOFS);\n \t\t\t\targs.rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\t\t\targs.rmtblkcnt = xfs_attr3_rmt_blocks(""}<_**next**_>{""sha"": ""d2e6e948cec7be3013b853033b6e1a64b365a682"", ""filename"": ""fs/xfs/xfs_attr_remote.c"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 3, ""changes"": 8, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_remote.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_remote.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_remote.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -337,7 +337,7 @@ xfs_attr_rmtval_get(\n \tstruct xfs_buf\t\t*bp;\n \txfs_dablk_t\t\tlblkno = args->rmtblkno;\n \t__uint8_t\t\t*dst = args->value;\n-\tint\t\t\tvaluelen = args->valuelen;\n+\tint\t\t\tvaluelen;\n \tint\t\t\tnmap;\n \tint\t\t\terror;\n \tint\t\t\tblkcnt = args->rmtblkcnt;\n@@ -347,7 +347,9 @@ xfs_attr_rmtval_get(\n \ttrace_xfs_attr_rmtval_get(args);\n \n \tASSERT(!(args->flags & ATTR_KERNOVAL));\n+\tASSERT(args->rmtvaluelen == args->valuelen);\n \n+\tvaluelen = args->rmtvaluelen;\n \twhile (valuelen > 0) {\n \t\tnmap = ATTR_RMTVALUE_MAPSIZE;\n \t\terror = xfs_bmapi_read(args->dp, (xfs_fileoff_t)lblkno,\n@@ -415,7 +417,7 @@ xfs_attr_rmtval_set(\n \t * attributes have headers, we can't just do a straight byte to FSB\n \t * conversion and have to take the header space into account.\n \t */\n-\tblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);\n+\tblkcnt = xfs_attr3_rmt_blocks(mp, args->rmtvaluelen);\n \terror = xfs_bmap_first_unused(args->trans, args->dp, blkcnt, &lfileoff,\n \t\t\t\t\t\t   XFS_ATTR_FORK);\n \tif (error)\n@@ -480,7 +482,7 @@ xfs_attr_rmtval_set(\n \t */\n \tlblkno = args->rmtblkno;\n \tblkcnt = args->rmtblkcnt;\n-\tvaluelen = args->valuelen;\n+\tvaluelen = args->rmtvaluelen;\n \twhile (valuelen > 0) {\n \t\tstruct xfs_buf\t*bp;\n \t\txfs_daddr_t\tdblkno;""}<_**next**_>{""sha"": ""201c6091d26abfa2e38dd17fd960e3efcb69bcd7"", ""filename"": ""fs/xfs/xfs_da_btree.h"", ""status"": ""modified"", ""additions"": 2, ""deletions"": 0, ""changes"": 2, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_da_btree.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_da_btree.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_da_btree.h?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -60,10 +60,12 @@ typedef struct xfs_da_args {\n \tint\t\tindex;\t\t/* index of attr of interest in blk */\n \txfs_dablk_t\trmtblkno;\t/* remote attr value starting blkno */\n \tint\t\trmtblkcnt;\t/* remote attr value block count */\n+\tint\t\trmtvaluelen;\t/* remote attr value length in bytes */\n \txfs_dablk_t\tblkno2;\t\t/* blkno of 2nd attr leaf of interest */\n \tint\t\tindex2;\t\t/* index of 2nd attr in blk */\n \txfs_dablk_t\trmtblkno2;\t/* remote attr value starting blkno */\n \tint\t\trmtblkcnt2;\t/* remote attr value block count */\n+\tint\t\trmtvaluelen2;\t/* remote attr value length in bytes */\n \tint\t\top_flags;\t/* operation flags */\n \tenum xfs_dacmp\tcmpresult;\t/* name compare result for lookups */\n } xfs_da_args_t;""}","xfs_attr3_leaf_clearflag(
	struct xfs_da_args	*args)
{
	struct xfs_attr_leafblock *leaf;
	struct xfs_attr_leaf_entry *entry;
	struct xfs_attr_leaf_name_remote *name_rmt;
	struct xfs_buf		*bp;
	int			error;
#ifdef DEBUG
	struct xfs_attr3_icleaf_hdr ichdr;
	xfs_attr_leaf_name_local_t *name_loc;
	int namelen;
	char *name;
#endif /* DEBUG */

	trace_xfs_attr_leaf_clearflag(args);
	/*
	 * Set up the operation.
	 */
	error = xfs_attr3_leaf_read(args->trans, args->dp, args->blkno, -1, &bp);
	if (error)
		return(error);

	leaf = bp->b_addr;
	entry = &xfs_attr3_leaf_entryp(leaf)[args->index];
	ASSERT(entry->flags & XFS_ATTR_INCOMPLETE);

#ifdef DEBUG
	xfs_attr3_leaf_hdr_from_disk(&ichdr, leaf);
	ASSERT(args->index < ichdr.count);
	ASSERT(args->index >= 0);

	if (entry->flags & XFS_ATTR_LOCAL) {
		name_loc = xfs_attr3_leaf_name_local(leaf, args->index);
		namelen = name_loc->namelen;
		name = (char *)name_loc->nameval;
	} else {
		name_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);
		namelen = name_rmt->namelen;
		name = (char *)name_rmt->name;
	}
	ASSERT(be32_to_cpu(entry->hashval) == args->hashval);
	ASSERT(namelen == args->namelen);
	ASSERT(memcmp(name, args->name, namelen) == 0);
#endif /* DEBUG */

	entry->flags &= ~XFS_ATTR_INCOMPLETE;
	xfs_trans_log_buf(args->trans, bp,
			 XFS_DA_LOGRANGE(leaf, entry, sizeof(*entry)));

	if (args->rmtblkno) {
 		ASSERT((entry->flags & XFS_ATTR_LOCAL) == 0);
 		name_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);
 		name_rmt->valueblk = cpu_to_be32(args->rmtblkno);
		name_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);
 		xfs_trans_log_buf(args->trans, bp,
 			 XFS_DA_LOGRANGE(leaf, name_rmt, sizeof(*name_rmt)));
 	}

	/*
	 * Commit the flag value change and start the next trans in series.
	 */
	return xfs_trans_roll(&args->trans, args->dp);
}
","xfs_attr3_leaf_clearflag(
	struct xfs_da_args	*args)
{
	struct xfs_attr_leafblock *leaf;
	struct xfs_attr_leaf_entry *entry;
	struct xfs_attr_leaf_name_remote *name_rmt;
	struct xfs_buf		*bp;
	int			error;
#ifdef DEBUG
	struct xfs_attr3_icleaf_hdr ichdr;
	xfs_attr_leaf_name_local_t *name_loc;
	int namelen;
	char *name;
#endif /* DEBUG */

	trace_xfs_attr_leaf_clearflag(args);
	/*
	 * Set up the operation.
	 */
	error = xfs_attr3_leaf_read(args->trans, args->dp, args->blkno, -1, &bp);
	if (error)
		return(error);

	leaf = bp->b_addr;
	entry = &xfs_attr3_leaf_entryp(leaf)[args->index];
	ASSERT(entry->flags & XFS_ATTR_INCOMPLETE);

#ifdef DEBUG
	xfs_attr3_leaf_hdr_from_disk(&ichdr, leaf);
	ASSERT(args->index < ichdr.count);
	ASSERT(args->index >= 0);

	if (entry->flags & XFS_ATTR_LOCAL) {
		name_loc = xfs_attr3_leaf_name_local(leaf, args->index);
		namelen = name_loc->namelen;
		name = (char *)name_loc->nameval;
	} else {
		name_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);
		namelen = name_rmt->namelen;
		name = (char *)name_rmt->name;
	}
	ASSERT(be32_to_cpu(entry->hashval) == args->hashval);
	ASSERT(namelen == args->namelen);
	ASSERT(memcmp(name, args->name, namelen) == 0);
#endif /* DEBUG */

	entry->flags &= ~XFS_ATTR_INCOMPLETE;
	xfs_trans_log_buf(args->trans, bp,
			 XFS_DA_LOGRANGE(leaf, entry, sizeof(*entry)));

	if (args->rmtblkno) {
 		ASSERT((entry->flags & XFS_ATTR_LOCAL) == 0);
 		name_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);
 		name_rmt->valueblk = cpu_to_be32(args->rmtblkno);
		name_rmt->valuelen = cpu_to_be32(args->valuelen);
 		xfs_trans_log_buf(args->trans, bp,
 			 XFS_DA_LOGRANGE(leaf, name_rmt, sizeof(*name_rmt)));
 	}

	/*
	 * Commit the flag value change and start the next trans in series.
	 */
	return xfs_trans_roll(&args->trans, args->dp);
}
",C,"		name_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);
","		name_rmt->valuelen = cpu_to_be32(args->valuelen);
",,"@@ -1229,6 +1229,7 @@ xfs_attr3_leaf_add_work(
 		name_rmt->valueblk = 0;
 		args->rmtblkno = 1;
 		args->rmtblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);
+		args->rmtvaluelen = args->valuelen;
 	}
 	xfs_trans_log_buf(args->trans, bp,
 	     XFS_DA_LOGRANGE(leaf, xfs_attr3_leaf_name(leaf, args->index),
@@ -2167,11 +2168,11 @@ xfs_attr3_leaf_lookup_int(
 			if (!xfs_attr_namesp_match(args->flags, entry->flags))
 				continue;
 			args->index = probe;
-			args->valuelen = be32_to_cpu(name_rmt->valuelen);
+			args->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);
 			args->rmtblkno = be32_to_cpu(name_rmt->valueblk);
 			args->rmtblkcnt = xfs_attr3_rmt_blocks(
 							args->dp->i_mount,
-							args->valuelen);
+							args->rmtvaluelen);
 			return XFS_ERROR(EEXIST);
 		}
 	}
@@ -2220,19 +2221,19 @@ xfs_attr3_leaf_getvalue(
 		name_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);
 		ASSERT(name_rmt->namelen == args->namelen);
 		ASSERT(memcmp(args->name, name_rmt->name, args->namelen) == 0);
-		valuelen = be32_to_cpu(name_rmt->valuelen);
+		args->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);
 		args->rmtblkno = be32_to_cpu(name_rmt->valueblk);
 		args->rmtblkcnt = xfs_attr3_rmt_blocks(args->dp->i_mount,
-						       valuelen);
+						       args->rmtvaluelen);
 		if (args->flags & ATTR_KERNOVAL) {
-			args->valuelen = valuelen;
+			args->valuelen = args->rmtvaluelen;
 			return 0;
 		}
-		if (args->valuelen < valuelen) {
-			args->valuelen = valuelen;
+		if (args->valuelen < args->rmtvaluelen) {
+			args->valuelen = args->rmtvaluelen;
 			return XFS_ERROR(ERANGE);
 		}
-		args->valuelen = valuelen;
+		args->valuelen = args->rmtvaluelen;
 	}
 	return 0;
 }
@@ -2519,7 +2520,7 @@ xfs_attr3_leaf_clearflag(
 		ASSERT((entry->flags & XFS_ATTR_LOCAL) == 0);
 		name_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);
 		name_rmt->valueblk = cpu_to_be32(args->rmtblkno);
-		name_rmt->valuelen = cpu_to_be32(args->valuelen);
+		name_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);
 		xfs_trans_log_buf(args->trans, bp,
 			 XFS_DA_LOGRANGE(leaf, name_rmt, sizeof(*name_rmt)));
 	}
@@ -2677,7 +2678,7 @@ xfs_attr3_leaf_flipflags(
 		ASSERT((entry1->flags & XFS_ATTR_LOCAL) == 0);
 		name_rmt = xfs_attr3_leaf_name_remote(leaf1, args->index);
 		name_rmt->valueblk = cpu_to_be32(args->rmtblkno);
-		name_rmt->valuelen = cpu_to_be32(args->valuelen);
+		name_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);
 		xfs_trans_log_buf(args->trans, bp1,
 			 XFS_DA_LOGRANGE(leaf1, name_rmt, sizeof(*name_rmt)));
 	}",linux,8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,d540e43b0ab134b22f015f725ce6e070d12b0244,1,"xfs_attr3_leaf_clearflag(
	struct xfs_da_args	*args)
{
	struct xfs_attr_leafblock *leaf;
	struct xfs_attr_leaf_entry *entry;
	struct xfs_attr_leaf_name_remote *name_rmt;
	struct xfs_buf		*bp;
	int			error;
#ifdef DEBUG
	struct xfs_attr3_icleaf_hdr ichdr;
	xfs_attr_leaf_name_local_t *name_loc;
	int namelen;
	char *name;
#endif /* DEBUG */

	trace_xfs_attr_leaf_clearflag(args);
	/*
	 * Set up the operation.
	 */
	error = xfs_attr3_leaf_read(args->trans, args->dp, args->blkno, -1, &bp);
	if (error)
		return(error);

	leaf = bp->b_addr;
	entry = &xfs_attr3_leaf_entryp(leaf)[args->index];
	ASSERT(entry->flags & XFS_ATTR_INCOMPLETE);

#ifdef DEBUG
	xfs_attr3_leaf_hdr_from_disk(&ichdr, leaf);
	ASSERT(args->index < ichdr.count);
	ASSERT(args->index >= 0);

	if (entry->flags & XFS_ATTR_LOCAL) {
		name_loc = xfs_attr3_leaf_name_local(leaf, args->index);
		namelen = name_loc->namelen;
		name = (char *)name_loc->nameval;
	} else {
		name_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);
		namelen = name_rmt->namelen;
		name = (char *)name_rmt->name;
	}
	ASSERT(be32_to_cpu(entry->hashval) == args->hashval);
	ASSERT(namelen == args->namelen);
	ASSERT(memcmp(name, args->name, namelen) == 0);
#endif /* DEBUG */

	entry->flags &= ~XFS_ATTR_INCOMPLETE;
	xfs_trans_log_buf(args->trans, bp,
			 XFS_DA_LOGRANGE(leaf, entry, sizeof(*entry)));

	if (args->rmtblkno) {
 		ASSERT((entry->flags & XFS_ATTR_LOCAL) == 0);
 		name_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);
 		name_rmt->valueblk = cpu_to_be32(args->rmtblkno);
//flaw_line_below:
		name_rmt->valuelen = cpu_to_be32(args->valuelen);
//fix_flaw_line_below:
//		name_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);
 		xfs_trans_log_buf(args->trans, bp,
 			 XFS_DA_LOGRANGE(leaf, name_rmt, sizeof(*name_rmt)));
 	}

	/*
	 * Commit the flag value change and start the next trans in series.
	 */
	return xfs_trans_roll(&args->trans, args->dp);
}
"
2171,179907,,Local,Not required,Complete,CVE-2015-0274,https://www.cvedetails.com/cve/CVE-2015-0274/,CWE-19,Low,Complete,Complete,,2015-03-16,7.2,"The XFS implementation in the Linux kernel before 3.15 improperly uses an old size value during remote attribute replacement, which allows local users to cause a denial of service (transaction overrun and data corruption) or possibly gain privileges by leveraging XFS filesystem access.",2015-03-26,DoS +Priv ,1,https://github.com/torvalds/linux/commit/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,"xfs: remote attribute overwrite causes transaction overrun

Commit e461fcb (""xfs: remote attribute lookups require the value
length"") passes the remote attribute length in the xfs_da_args
structure on lookup so that CRC calculations and validity checking
can be performed correctly by related code. This, unfortunately has
the side effect of changing the args->valuelen parameter in cases
where it shouldn't.

That is, when we replace a remote attribute, the incoming
replacement stores the value and length in args->value and
args->valuelen, but then the lookup which finds the existing remote
attribute overwrites args->valuelen with the length of the remote
attribute being replaced. Hence when we go to create the new
attribute, we create it of the size of the existing remote
attribute, not the size it is supposed to be. When the new attribute
is much smaller than the old attribute, this results in a
transaction overrun and an ASSERT() failure on a debug kernel:

XFS: Assertion failed: tp->t_blk_res_used <= tp->t_blk_res, file: fs/xfs/xfs_trans.c, line: 331

Fix this by keeping the remote attribute value length separate to
the attribute value length in the xfs_da_args structure. The enables
us to pass the length of the remote attribute to be removed without
overwriting the new attribute's length.

Also, ensure that when we save remote block contexts for a later
rename we zero the original state variables so that we don't confuse
the state of the attribute to be removes with the state of the new
attribute that we just added. [Spotted by Brain Foster.]

Signed-off-by: Dave Chinner <dchinner@redhat.com>
Reviewed-by: Brian Foster <bfoster@redhat.com>
Signed-off-by: Dave Chinner <david@fromorbit.com>",1,fs/xfs/xfs_attr_leaf.c,"{""sha"": ""abda1124a70f66fbd1a79b28f8eaf5bf1916da1e"", ""filename"": ""fs/xfs/xfs_attr.c"", ""status"": ""modified"", ""additions"": 23, ""deletions"": 1, ""changes"": 24, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -213,7 +213,7 @@ xfs_attr_calc_size(\n \t\t * Out of line attribute, cannot double split, but\n \t\t * make room for the attribute value itself.\n \t\t */\n-\t\tuint\tdblocks = XFS_B_TO_FSB(mp, valuelen);\n+\t\tuint\tdblocks = xfs_attr3_rmt_blocks(mp, valuelen);\n \t\tnblks += dblocks;\n \t\tnblks += XFS_NEXTENTADD_SPACE_RES(mp, dblocks, XFS_ATTR_FORK);\n \t}\n@@ -698,11 +698,22 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)\n \n \t\ttrace_xfs_attr_leaf_replace(args);\n \n+\t\t/* save the attribute state for later removal*/\n \t\targs->op_flags |= XFS_DA_OP_RENAME;\t/* an atomic rename */\n \t\targs->blkno2 = args->blkno;\t\t/* set 2nd entry info*/\n \t\targs->index2 = args->index;\n \t\targs->rmtblkno2 = args->rmtblkno;\n \t\targs->rmtblkcnt2 = args->rmtblkcnt;\n+\t\targs->rmtvaluelen2 = args->rmtvaluelen;\n+\n+\t\t/*\n+\t\t * clear the remote attr state now that it is saved so that the\n+\t\t * values reflect the state of the attribute we are about to\n+\t\t * add, not the attribute we just found and will remove later.\n+\t\t */\n+\t\targs->rmtblkno = 0;\n+\t\targs->rmtblkcnt = 0;\n+\t\targs->rmtvaluelen = 0;\n \t}\n \n \t/*\n@@ -794,6 +805,7 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)\n \t\targs->blkno = args->blkno2;\n \t\targs->rmtblkno = args->rmtblkno2;\n \t\targs->rmtblkcnt = args->rmtblkcnt2;\n+\t\targs->rmtvaluelen = args->rmtvaluelen2;\n \t\tif (args->rmtblkno) {\n \t\t\terror = xfs_attr_rmtval_remove(args);\n \t\t\tif (error)\n@@ -999,13 +1011,22 @@ xfs_attr_node_addname(xfs_da_args_t *args)\n \n \t\ttrace_xfs_attr_node_replace(args);\n \n+\t\t/* save the attribute state for later removal*/\n \t\targs->op_flags |= XFS_DA_OP_RENAME;\t/* atomic rename op */\n \t\targs->blkno2 = args->blkno;\t\t/* set 2nd entry info*/\n \t\targs->index2 = args->index;\n \t\targs->rmtblkno2 = args->rmtblkno;\n \t\targs->rmtblkcnt2 = args->rmtblkcnt;\n+\t\targs->rmtvaluelen2 = args->rmtvaluelen;\n+\n+\t\t/*\n+\t\t * clear the remote attr state now that it is saved so that the\n+\t\t * values reflect the state of the attribute we are about to\n+\t\t * add, not the attribute we just found and will remove later.\n+\t\t */\n \t\targs->rmtblkno = 0;\n \t\targs->rmtblkcnt = 0;\n+\t\targs->rmtvaluelen = 0;\n \t}\n \n \tretval = xfs_attr3_leaf_add(blk->bp, state->args);\n@@ -1133,6 +1154,7 @@ xfs_attr_node_addname(xfs_da_args_t *args)\n \t\targs->blkno = args->blkno2;\n \t\targs->rmtblkno = args->rmtblkno2;\n \t\targs->rmtblkcnt = args->rmtblkcnt2;\n+\t\targs->rmtvaluelen = args->rmtvaluelen2;\n \t\tif (args->rmtblkno) {\n \t\t\terror = xfs_attr_rmtval_remove(args);\n \t\t\tif (error)""}<_**next**_>{""sha"": ""511c283459b19441d782114c4f832207860deab1"", ""filename"": ""fs/xfs/xfs_attr_leaf.c"", ""status"": ""modified"", ""additions"": 11, ""deletions"": 10, ""changes"": 21, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_leaf.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_leaf.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_leaf.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -1229,6 +1229,7 @@ xfs_attr3_leaf_add_work(\n \t\tname_rmt->valueblk = 0;\n \t\targs->rmtblkno = 1;\n \t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);\n+\t\targs->rmtvaluelen = args->valuelen;\n \t}\n \txfs_trans_log_buf(args->trans, bp,\n \t     XFS_DA_LOGRANGE(leaf, xfs_attr3_leaf_name(leaf, args->index),\n@@ -2167,11 +2168,11 @@ xfs_attr3_leaf_lookup_int(\n \t\t\tif (!xfs_attr_namesp_match(args->flags, entry->flags))\n \t\t\t\tcontinue;\n \t\t\targs->index = probe;\n-\t\t\targs->valuelen = be32_to_cpu(name_rmt->valuelen);\n+\t\t\targs->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);\n \t\t\targs->rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(\n \t\t\t\t\t\t\targs->dp->i_mount,\n-\t\t\t\t\t\t\targs->valuelen);\n+\t\t\t\t\t\t\targs->rmtvaluelen);\n \t\t\treturn XFS_ERROR(EEXIST);\n \t\t}\n \t}\n@@ -2220,19 +2221,19 @@ xfs_attr3_leaf_getvalue(\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);\n \t\tASSERT(name_rmt->namelen == args->namelen);\n \t\tASSERT(memcmp(args->name, name_rmt->name, args->namelen) == 0);\n-\t\tvaluelen = be32_to_cpu(name_rmt->valuelen);\n+\t\targs->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);\n \t\targs->rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(args->dp->i_mount,\n-\t\t\t\t\t\t       valuelen);\n+\t\t\t\t\t\t       args->rmtvaluelen);\n \t\tif (args->flags & ATTR_KERNOVAL) {\n-\t\t\targs->valuelen = valuelen;\n+\t\t\targs->valuelen = args->rmtvaluelen;\n \t\t\treturn 0;\n \t\t}\n-\t\tif (args->valuelen < valuelen) {\n-\t\t\targs->valuelen = valuelen;\n+\t\tif (args->valuelen < args->rmtvaluelen) {\n+\t\t\targs->valuelen = args->rmtvaluelen;\n \t\t\treturn XFS_ERROR(ERANGE);\n \t\t}\n-\t\targs->valuelen = valuelen;\n+\t\targs->valuelen = args->rmtvaluelen;\n \t}\n \treturn 0;\n }\n@@ -2519,7 +2520,7 @@ xfs_attr3_leaf_clearflag(\n \t\tASSERT((entry->flags & XFS_ATTR_LOCAL) == 0);\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);\n \t\tname_rmt->valueblk = cpu_to_be32(args->rmtblkno);\n-\t\tname_rmt->valuelen = cpu_to_be32(args->valuelen);\n+\t\tname_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);\n \t\txfs_trans_log_buf(args->trans, bp,\n \t\t\t XFS_DA_LOGRANGE(leaf, name_rmt, sizeof(*name_rmt)));\n \t}\n@@ -2677,7 +2678,7 @@ xfs_attr3_leaf_flipflags(\n \t\tASSERT((entry1->flags & XFS_ATTR_LOCAL) == 0);\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf1, args->index);\n \t\tname_rmt->valueblk = cpu_to_be32(args->rmtblkno);\n-\t\tname_rmt->valuelen = cpu_to_be32(args->valuelen);\n+\t\tname_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);\n \t\txfs_trans_log_buf(args->trans, bp1,\n \t\t\t XFS_DA_LOGRANGE(leaf1, name_rmt, sizeof(*name_rmt)));\n \t}""}<_**next**_>{""sha"": ""833fe5d98d806783ca6bb6cf2f4ecb83424bfdca"", ""filename"": ""fs/xfs/xfs_attr_list.c"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 0, ""changes"": 1, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_list.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_list.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_list.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -447,6 +447,7 @@ xfs_attr3_leaf_list_int(\n \t\t\t\targs.dp = context->dp;\n \t\t\t\targs.whichfork = XFS_ATTR_FORK;\n \t\t\t\targs.valuelen = valuelen;\n+\t\t\t\targs.rmtvaluelen = valuelen;\n \t\t\t\targs.value = kmem_alloc(valuelen, KM_SLEEP | KM_NOFS);\n \t\t\t\targs.rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\t\t\targs.rmtblkcnt = xfs_attr3_rmt_blocks(""}<_**next**_>{""sha"": ""d2e6e948cec7be3013b853033b6e1a64b365a682"", ""filename"": ""fs/xfs/xfs_attr_remote.c"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 3, ""changes"": 8, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_remote.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_remote.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_remote.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -337,7 +337,7 @@ xfs_attr_rmtval_get(\n \tstruct xfs_buf\t\t*bp;\n \txfs_dablk_t\t\tlblkno = args->rmtblkno;\n \t__uint8_t\t\t*dst = args->value;\n-\tint\t\t\tvaluelen = args->valuelen;\n+\tint\t\t\tvaluelen;\n \tint\t\t\tnmap;\n \tint\t\t\terror;\n \tint\t\t\tblkcnt = args->rmtblkcnt;\n@@ -347,7 +347,9 @@ xfs_attr_rmtval_get(\n \ttrace_xfs_attr_rmtval_get(args);\n \n \tASSERT(!(args->flags & ATTR_KERNOVAL));\n+\tASSERT(args->rmtvaluelen == args->valuelen);\n \n+\tvaluelen = args->rmtvaluelen;\n \twhile (valuelen > 0) {\n \t\tnmap = ATTR_RMTVALUE_MAPSIZE;\n \t\terror = xfs_bmapi_read(args->dp, (xfs_fileoff_t)lblkno,\n@@ -415,7 +417,7 @@ xfs_attr_rmtval_set(\n \t * attributes have headers, we can't just do a straight byte to FSB\n \t * conversion and have to take the header space into account.\n \t */\n-\tblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);\n+\tblkcnt = xfs_attr3_rmt_blocks(mp, args->rmtvaluelen);\n \terror = xfs_bmap_first_unused(args->trans, args->dp, blkcnt, &lfileoff,\n \t\t\t\t\t\t   XFS_ATTR_FORK);\n \tif (error)\n@@ -480,7 +482,7 @@ xfs_attr_rmtval_set(\n \t */\n \tlblkno = args->rmtblkno;\n \tblkcnt = args->rmtblkcnt;\n-\tvaluelen = args->valuelen;\n+\tvaluelen = args->rmtvaluelen;\n \twhile (valuelen > 0) {\n \t\tstruct xfs_buf\t*bp;\n \t\txfs_daddr_t\tdblkno;""}<_**next**_>{""sha"": ""201c6091d26abfa2e38dd17fd960e3efcb69bcd7"", ""filename"": ""fs/xfs/xfs_da_btree.h"", ""status"": ""modified"", ""additions"": 2, ""deletions"": 0, ""changes"": 2, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_da_btree.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_da_btree.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_da_btree.h?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -60,10 +60,12 @@ typedef struct xfs_da_args {\n \tint\t\tindex;\t\t/* index of attr of interest in blk */\n \txfs_dablk_t\trmtblkno;\t/* remote attr value starting blkno */\n \tint\t\trmtblkcnt;\t/* remote attr value block count */\n+\tint\t\trmtvaluelen;\t/* remote attr value length in bytes */\n \txfs_dablk_t\tblkno2;\t\t/* blkno of 2nd attr leaf of interest */\n \tint\t\tindex2;\t\t/* index of 2nd attr in blk */\n \txfs_dablk_t\trmtblkno2;\t/* remote attr value starting blkno */\n \tint\t\trmtblkcnt2;\t/* remote attr value block count */\n+\tint\t\trmtvaluelen2;\t/* remote attr value length in bytes */\n \tint\t\top_flags;\t/* operation flags */\n \tenum xfs_dacmp\tcmpresult;\t/* name compare result for lookups */\n } xfs_da_args_t;""}","xfs_attr3_leaf_flipflags(
	struct xfs_da_args	*args)
{
	struct xfs_attr_leafblock *leaf1;
	struct xfs_attr_leafblock *leaf2;
	struct xfs_attr_leaf_entry *entry1;
	struct xfs_attr_leaf_entry *entry2;
	struct xfs_attr_leaf_name_remote *name_rmt;
	struct xfs_buf		*bp1;
	struct xfs_buf		*bp2;
	int error;
#ifdef DEBUG
	struct xfs_attr3_icleaf_hdr ichdr1;
	struct xfs_attr3_icleaf_hdr ichdr2;
	xfs_attr_leaf_name_local_t *name_loc;
	int namelen1, namelen2;
	char *name1, *name2;
#endif /* DEBUG */

	trace_xfs_attr_leaf_flipflags(args);

	/*
	 * Read the block containing the ""old"" attr
	 */
	error = xfs_attr3_leaf_read(args->trans, args->dp, args->blkno, -1, &bp1);
	if (error)
		return error;

	/*
	 * Read the block containing the ""new"" attr, if it is different
	 */
	if (args->blkno2 != args->blkno) {
		error = xfs_attr3_leaf_read(args->trans, args->dp, args->blkno2,
					   -1, &bp2);
		if (error)
			return error;
	} else {
		bp2 = bp1;
	}

	leaf1 = bp1->b_addr;
	entry1 = &xfs_attr3_leaf_entryp(leaf1)[args->index];

	leaf2 = bp2->b_addr;
	entry2 = &xfs_attr3_leaf_entryp(leaf2)[args->index2];

#ifdef DEBUG
	xfs_attr3_leaf_hdr_from_disk(&ichdr1, leaf1);
	ASSERT(args->index < ichdr1.count);
	ASSERT(args->index >= 0);

	xfs_attr3_leaf_hdr_from_disk(&ichdr2, leaf2);
	ASSERT(args->index2 < ichdr2.count);
	ASSERT(args->index2 >= 0);

	if (entry1->flags & XFS_ATTR_LOCAL) {
		name_loc = xfs_attr3_leaf_name_local(leaf1, args->index);
		namelen1 = name_loc->namelen;
		name1 = (char *)name_loc->nameval;
	} else {
		name_rmt = xfs_attr3_leaf_name_remote(leaf1, args->index);
		namelen1 = name_rmt->namelen;
		name1 = (char *)name_rmt->name;
	}
	if (entry2->flags & XFS_ATTR_LOCAL) {
		name_loc = xfs_attr3_leaf_name_local(leaf2, args->index2);
		namelen2 = name_loc->namelen;
		name2 = (char *)name_loc->nameval;
	} else {
		name_rmt = xfs_attr3_leaf_name_remote(leaf2, args->index2);
		namelen2 = name_rmt->namelen;
		name2 = (char *)name_rmt->name;
	}
	ASSERT(be32_to_cpu(entry1->hashval) == be32_to_cpu(entry2->hashval));
	ASSERT(namelen1 == namelen2);
	ASSERT(memcmp(name1, name2, namelen1) == 0);
#endif /* DEBUG */

	ASSERT(entry1->flags & XFS_ATTR_INCOMPLETE);
	ASSERT((entry2->flags & XFS_ATTR_INCOMPLETE) == 0);

	entry1->flags &= ~XFS_ATTR_INCOMPLETE;
	xfs_trans_log_buf(args->trans, bp1,
			  XFS_DA_LOGRANGE(leaf1, entry1, sizeof(*entry1)));
	if (args->rmtblkno) {
 		ASSERT((entry1->flags & XFS_ATTR_LOCAL) == 0);
 		name_rmt = xfs_attr3_leaf_name_remote(leaf1, args->index);
 		name_rmt->valueblk = cpu_to_be32(args->rmtblkno);
		name_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);
 		xfs_trans_log_buf(args->trans, bp1,
 			 XFS_DA_LOGRANGE(leaf1, name_rmt, sizeof(*name_rmt)));
 	}

	entry2->flags |= XFS_ATTR_INCOMPLETE;
	xfs_trans_log_buf(args->trans, bp2,
			  XFS_DA_LOGRANGE(leaf2, entry2, sizeof(*entry2)));
	if ((entry2->flags & XFS_ATTR_LOCAL) == 0) {
		name_rmt = xfs_attr3_leaf_name_remote(leaf2, args->index2);
		name_rmt->valueblk = 0;
		name_rmt->valuelen = 0;
		xfs_trans_log_buf(args->trans, bp2,
			 XFS_DA_LOGRANGE(leaf2, name_rmt, sizeof(*name_rmt)));
	}

	/*
	 * Commit the flag value change and start the next trans in series.
	 */
	error = xfs_trans_roll(&args->trans, args->dp);

	return error;
}
","xfs_attr3_leaf_flipflags(
	struct xfs_da_args	*args)
{
	struct xfs_attr_leafblock *leaf1;
	struct xfs_attr_leafblock *leaf2;
	struct xfs_attr_leaf_entry *entry1;
	struct xfs_attr_leaf_entry *entry2;
	struct xfs_attr_leaf_name_remote *name_rmt;
	struct xfs_buf		*bp1;
	struct xfs_buf		*bp2;
	int error;
#ifdef DEBUG
	struct xfs_attr3_icleaf_hdr ichdr1;
	struct xfs_attr3_icleaf_hdr ichdr2;
	xfs_attr_leaf_name_local_t *name_loc;
	int namelen1, namelen2;
	char *name1, *name2;
#endif /* DEBUG */

	trace_xfs_attr_leaf_flipflags(args);

	/*
	 * Read the block containing the ""old"" attr
	 */
	error = xfs_attr3_leaf_read(args->trans, args->dp, args->blkno, -1, &bp1);
	if (error)
		return error;

	/*
	 * Read the block containing the ""new"" attr, if it is different
	 */
	if (args->blkno2 != args->blkno) {
		error = xfs_attr3_leaf_read(args->trans, args->dp, args->blkno2,
					   -1, &bp2);
		if (error)
			return error;
	} else {
		bp2 = bp1;
	}

	leaf1 = bp1->b_addr;
	entry1 = &xfs_attr3_leaf_entryp(leaf1)[args->index];

	leaf2 = bp2->b_addr;
	entry2 = &xfs_attr3_leaf_entryp(leaf2)[args->index2];

#ifdef DEBUG
	xfs_attr3_leaf_hdr_from_disk(&ichdr1, leaf1);
	ASSERT(args->index < ichdr1.count);
	ASSERT(args->index >= 0);

	xfs_attr3_leaf_hdr_from_disk(&ichdr2, leaf2);
	ASSERT(args->index2 < ichdr2.count);
	ASSERT(args->index2 >= 0);

	if (entry1->flags & XFS_ATTR_LOCAL) {
		name_loc = xfs_attr3_leaf_name_local(leaf1, args->index);
		namelen1 = name_loc->namelen;
		name1 = (char *)name_loc->nameval;
	} else {
		name_rmt = xfs_attr3_leaf_name_remote(leaf1, args->index);
		namelen1 = name_rmt->namelen;
		name1 = (char *)name_rmt->name;
	}
	if (entry2->flags & XFS_ATTR_LOCAL) {
		name_loc = xfs_attr3_leaf_name_local(leaf2, args->index2);
		namelen2 = name_loc->namelen;
		name2 = (char *)name_loc->nameval;
	} else {
		name_rmt = xfs_attr3_leaf_name_remote(leaf2, args->index2);
		namelen2 = name_rmt->namelen;
		name2 = (char *)name_rmt->name;
	}
	ASSERT(be32_to_cpu(entry1->hashval) == be32_to_cpu(entry2->hashval));
	ASSERT(namelen1 == namelen2);
	ASSERT(memcmp(name1, name2, namelen1) == 0);
#endif /* DEBUG */

	ASSERT(entry1->flags & XFS_ATTR_INCOMPLETE);
	ASSERT((entry2->flags & XFS_ATTR_INCOMPLETE) == 0);

	entry1->flags &= ~XFS_ATTR_INCOMPLETE;
	xfs_trans_log_buf(args->trans, bp1,
			  XFS_DA_LOGRANGE(leaf1, entry1, sizeof(*entry1)));
	if (args->rmtblkno) {
 		ASSERT((entry1->flags & XFS_ATTR_LOCAL) == 0);
 		name_rmt = xfs_attr3_leaf_name_remote(leaf1, args->index);
 		name_rmt->valueblk = cpu_to_be32(args->rmtblkno);
		name_rmt->valuelen = cpu_to_be32(args->valuelen);
 		xfs_trans_log_buf(args->trans, bp1,
 			 XFS_DA_LOGRANGE(leaf1, name_rmt, sizeof(*name_rmt)));
 	}

	entry2->flags |= XFS_ATTR_INCOMPLETE;
	xfs_trans_log_buf(args->trans, bp2,
			  XFS_DA_LOGRANGE(leaf2, entry2, sizeof(*entry2)));
	if ((entry2->flags & XFS_ATTR_LOCAL) == 0) {
		name_rmt = xfs_attr3_leaf_name_remote(leaf2, args->index2);
		name_rmt->valueblk = 0;
		name_rmt->valuelen = 0;
		xfs_trans_log_buf(args->trans, bp2,
			 XFS_DA_LOGRANGE(leaf2, name_rmt, sizeof(*name_rmt)));
	}

	/*
	 * Commit the flag value change and start the next trans in series.
	 */
	error = xfs_trans_roll(&args->trans, args->dp);

	return error;
}
",C,"		name_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);
","		name_rmt->valuelen = cpu_to_be32(args->valuelen);
",,"@@ -1229,6 +1229,7 @@ xfs_attr3_leaf_add_work(
 		name_rmt->valueblk = 0;
 		args->rmtblkno = 1;
 		args->rmtblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);
+		args->rmtvaluelen = args->valuelen;
 	}
 	xfs_trans_log_buf(args->trans, bp,
 	     XFS_DA_LOGRANGE(leaf, xfs_attr3_leaf_name(leaf, args->index),
@@ -2167,11 +2168,11 @@ xfs_attr3_leaf_lookup_int(
 			if (!xfs_attr_namesp_match(args->flags, entry->flags))
 				continue;
 			args->index = probe;
-			args->valuelen = be32_to_cpu(name_rmt->valuelen);
+			args->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);
 			args->rmtblkno = be32_to_cpu(name_rmt->valueblk);
 			args->rmtblkcnt = xfs_attr3_rmt_blocks(
 							args->dp->i_mount,
-							args->valuelen);
+							args->rmtvaluelen);
 			return XFS_ERROR(EEXIST);
 		}
 	}
@@ -2220,19 +2221,19 @@ xfs_attr3_leaf_getvalue(
 		name_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);
 		ASSERT(name_rmt->namelen == args->namelen);
 		ASSERT(memcmp(args->name, name_rmt->name, args->namelen) == 0);
-		valuelen = be32_to_cpu(name_rmt->valuelen);
+		args->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);
 		args->rmtblkno = be32_to_cpu(name_rmt->valueblk);
 		args->rmtblkcnt = xfs_attr3_rmt_blocks(args->dp->i_mount,
-						       valuelen);
+						       args->rmtvaluelen);
 		if (args->flags & ATTR_KERNOVAL) {
-			args->valuelen = valuelen;
+			args->valuelen = args->rmtvaluelen;
 			return 0;
 		}
-		if (args->valuelen < valuelen) {
-			args->valuelen = valuelen;
+		if (args->valuelen < args->rmtvaluelen) {
+			args->valuelen = args->rmtvaluelen;
 			return XFS_ERROR(ERANGE);
 		}
-		args->valuelen = valuelen;
+		args->valuelen = args->rmtvaluelen;
 	}
 	return 0;
 }
@@ -2519,7 +2520,7 @@ xfs_attr3_leaf_clearflag(
 		ASSERT((entry->flags & XFS_ATTR_LOCAL) == 0);
 		name_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);
 		name_rmt->valueblk = cpu_to_be32(args->rmtblkno);
-		name_rmt->valuelen = cpu_to_be32(args->valuelen);
+		name_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);
 		xfs_trans_log_buf(args->trans, bp,
 			 XFS_DA_LOGRANGE(leaf, name_rmt, sizeof(*name_rmt)));
 	}
@@ -2677,7 +2678,7 @@ xfs_attr3_leaf_flipflags(
 		ASSERT((entry1->flags & XFS_ATTR_LOCAL) == 0);
 		name_rmt = xfs_attr3_leaf_name_remote(leaf1, args->index);
 		name_rmt->valueblk = cpu_to_be32(args->rmtblkno);
-		name_rmt->valuelen = cpu_to_be32(args->valuelen);
+		name_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);
 		xfs_trans_log_buf(args->trans, bp1,
 			 XFS_DA_LOGRANGE(leaf1, name_rmt, sizeof(*name_rmt)));
 	}",linux,8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,d540e43b0ab134b22f015f725ce6e070d12b0244,1,"xfs_attr3_leaf_flipflags(
	struct xfs_da_args	*args)
{
	struct xfs_attr_leafblock *leaf1;
	struct xfs_attr_leafblock *leaf2;
	struct xfs_attr_leaf_entry *entry1;
	struct xfs_attr_leaf_entry *entry2;
	struct xfs_attr_leaf_name_remote *name_rmt;
	struct xfs_buf		*bp1;
	struct xfs_buf		*bp2;
	int error;
#ifdef DEBUG
	struct xfs_attr3_icleaf_hdr ichdr1;
	struct xfs_attr3_icleaf_hdr ichdr2;
	xfs_attr_leaf_name_local_t *name_loc;
	int namelen1, namelen2;
	char *name1, *name2;
#endif /* DEBUG */

	trace_xfs_attr_leaf_flipflags(args);

	/*
	 * Read the block containing the ""old"" attr
	 */
	error = xfs_attr3_leaf_read(args->trans, args->dp, args->blkno, -1, &bp1);
	if (error)
		return error;

	/*
	 * Read the block containing the ""new"" attr, if it is different
	 */
	if (args->blkno2 != args->blkno) {
		error = xfs_attr3_leaf_read(args->trans, args->dp, args->blkno2,
					   -1, &bp2);
		if (error)
			return error;
	} else {
		bp2 = bp1;
	}

	leaf1 = bp1->b_addr;
	entry1 = &xfs_attr3_leaf_entryp(leaf1)[args->index];

	leaf2 = bp2->b_addr;
	entry2 = &xfs_attr3_leaf_entryp(leaf2)[args->index2];

#ifdef DEBUG
	xfs_attr3_leaf_hdr_from_disk(&ichdr1, leaf1);
	ASSERT(args->index < ichdr1.count);
	ASSERT(args->index >= 0);

	xfs_attr3_leaf_hdr_from_disk(&ichdr2, leaf2);
	ASSERT(args->index2 < ichdr2.count);
	ASSERT(args->index2 >= 0);

	if (entry1->flags & XFS_ATTR_LOCAL) {
		name_loc = xfs_attr3_leaf_name_local(leaf1, args->index);
		namelen1 = name_loc->namelen;
		name1 = (char *)name_loc->nameval;
	} else {
		name_rmt = xfs_attr3_leaf_name_remote(leaf1, args->index);
		namelen1 = name_rmt->namelen;
		name1 = (char *)name_rmt->name;
	}
	if (entry2->flags & XFS_ATTR_LOCAL) {
		name_loc = xfs_attr3_leaf_name_local(leaf2, args->index2);
		namelen2 = name_loc->namelen;
		name2 = (char *)name_loc->nameval;
	} else {
		name_rmt = xfs_attr3_leaf_name_remote(leaf2, args->index2);
		namelen2 = name_rmt->namelen;
		name2 = (char *)name_rmt->name;
	}
	ASSERT(be32_to_cpu(entry1->hashval) == be32_to_cpu(entry2->hashval));
	ASSERT(namelen1 == namelen2);
	ASSERT(memcmp(name1, name2, namelen1) == 0);
#endif /* DEBUG */

	ASSERT(entry1->flags & XFS_ATTR_INCOMPLETE);
	ASSERT((entry2->flags & XFS_ATTR_INCOMPLETE) == 0);

	entry1->flags &= ~XFS_ATTR_INCOMPLETE;
	xfs_trans_log_buf(args->trans, bp1,
			  XFS_DA_LOGRANGE(leaf1, entry1, sizeof(*entry1)));
	if (args->rmtblkno) {
 		ASSERT((entry1->flags & XFS_ATTR_LOCAL) == 0);
 		name_rmt = xfs_attr3_leaf_name_remote(leaf1, args->index);
 		name_rmt->valueblk = cpu_to_be32(args->rmtblkno);
//flaw_line_below:
		name_rmt->valuelen = cpu_to_be32(args->valuelen);
//fix_flaw_line_below:
//		name_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);
 		xfs_trans_log_buf(args->trans, bp1,
 			 XFS_DA_LOGRANGE(leaf1, name_rmt, sizeof(*name_rmt)));
 	}

	entry2->flags |= XFS_ATTR_INCOMPLETE;
	xfs_trans_log_buf(args->trans, bp2,
			  XFS_DA_LOGRANGE(leaf2, entry2, sizeof(*entry2)));
	if ((entry2->flags & XFS_ATTR_LOCAL) == 0) {
		name_rmt = xfs_attr3_leaf_name_remote(leaf2, args->index2);
		name_rmt->valueblk = 0;
		name_rmt->valuelen = 0;
		xfs_trans_log_buf(args->trans, bp2,
			 XFS_DA_LOGRANGE(leaf2, name_rmt, sizeof(*name_rmt)));
	}

	/*
	 * Commit the flag value change and start the next trans in series.
	 */
	error = xfs_trans_roll(&args->trans, args->dp);

	return error;
}
"
2172,179908,,Local,Not required,Complete,CVE-2015-0274,https://www.cvedetails.com/cve/CVE-2015-0274/,CWE-19,Low,Complete,Complete,,2015-03-16,7.2,"The XFS implementation in the Linux kernel before 3.15 improperly uses an old size value during remote attribute replacement, which allows local users to cause a denial of service (transaction overrun and data corruption) or possibly gain privileges by leveraging XFS filesystem access.",2015-03-26,DoS +Priv ,6,https://github.com/torvalds/linux/commit/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,"xfs: remote attribute overwrite causes transaction overrun

Commit e461fcb (""xfs: remote attribute lookups require the value
length"") passes the remote attribute length in the xfs_da_args
structure on lookup so that CRC calculations and validity checking
can be performed correctly by related code. This, unfortunately has
the side effect of changing the args->valuelen parameter in cases
where it shouldn't.

That is, when we replace a remote attribute, the incoming
replacement stores the value and length in args->value and
args->valuelen, but then the lookup which finds the existing remote
attribute overwrites args->valuelen with the length of the remote
attribute being replaced. Hence when we go to create the new
attribute, we create it of the size of the existing remote
attribute, not the size it is supposed to be. When the new attribute
is much smaller than the old attribute, this results in a
transaction overrun and an ASSERT() failure on a debug kernel:

XFS: Assertion failed: tp->t_blk_res_used <= tp->t_blk_res, file: fs/xfs/xfs_trans.c, line: 331

Fix this by keeping the remote attribute value length separate to
the attribute value length in the xfs_da_args structure. The enables
us to pass the length of the remote attribute to be removed without
overwriting the new attribute's length.

Also, ensure that when we save remote block contexts for a later
rename we zero the original state variables so that we don't confuse
the state of the attribute to be removes with the state of the new
attribute that we just added. [Spotted by Brain Foster.]

Signed-off-by: Dave Chinner <dchinner@redhat.com>
Reviewed-by: Brian Foster <bfoster@redhat.com>
Signed-off-by: Dave Chinner <david@fromorbit.com>",6,fs/xfs/xfs_attr_leaf.c,"{""sha"": ""abda1124a70f66fbd1a79b28f8eaf5bf1916da1e"", ""filename"": ""fs/xfs/xfs_attr.c"", ""status"": ""modified"", ""additions"": 23, ""deletions"": 1, ""changes"": 24, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -213,7 +213,7 @@ xfs_attr_calc_size(\n \t\t * Out of line attribute, cannot double split, but\n \t\t * make room for the attribute value itself.\n \t\t */\n-\t\tuint\tdblocks = XFS_B_TO_FSB(mp, valuelen);\n+\t\tuint\tdblocks = xfs_attr3_rmt_blocks(mp, valuelen);\n \t\tnblks += dblocks;\n \t\tnblks += XFS_NEXTENTADD_SPACE_RES(mp, dblocks, XFS_ATTR_FORK);\n \t}\n@@ -698,11 +698,22 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)\n \n \t\ttrace_xfs_attr_leaf_replace(args);\n \n+\t\t/* save the attribute state for later removal*/\n \t\targs->op_flags |= XFS_DA_OP_RENAME;\t/* an atomic rename */\n \t\targs->blkno2 = args->blkno;\t\t/* set 2nd entry info*/\n \t\targs->index2 = args->index;\n \t\targs->rmtblkno2 = args->rmtblkno;\n \t\targs->rmtblkcnt2 = args->rmtblkcnt;\n+\t\targs->rmtvaluelen2 = args->rmtvaluelen;\n+\n+\t\t/*\n+\t\t * clear the remote attr state now that it is saved so that the\n+\t\t * values reflect the state of the attribute we are about to\n+\t\t * add, not the attribute we just found and will remove later.\n+\t\t */\n+\t\targs->rmtblkno = 0;\n+\t\targs->rmtblkcnt = 0;\n+\t\targs->rmtvaluelen = 0;\n \t}\n \n \t/*\n@@ -794,6 +805,7 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)\n \t\targs->blkno = args->blkno2;\n \t\targs->rmtblkno = args->rmtblkno2;\n \t\targs->rmtblkcnt = args->rmtblkcnt2;\n+\t\targs->rmtvaluelen = args->rmtvaluelen2;\n \t\tif (args->rmtblkno) {\n \t\t\terror = xfs_attr_rmtval_remove(args);\n \t\t\tif (error)\n@@ -999,13 +1011,22 @@ xfs_attr_node_addname(xfs_da_args_t *args)\n \n \t\ttrace_xfs_attr_node_replace(args);\n \n+\t\t/* save the attribute state for later removal*/\n \t\targs->op_flags |= XFS_DA_OP_RENAME;\t/* atomic rename op */\n \t\targs->blkno2 = args->blkno;\t\t/* set 2nd entry info*/\n \t\targs->index2 = args->index;\n \t\targs->rmtblkno2 = args->rmtblkno;\n \t\targs->rmtblkcnt2 = args->rmtblkcnt;\n+\t\targs->rmtvaluelen2 = args->rmtvaluelen;\n+\n+\t\t/*\n+\t\t * clear the remote attr state now that it is saved so that the\n+\t\t * values reflect the state of the attribute we are about to\n+\t\t * add, not the attribute we just found and will remove later.\n+\t\t */\n \t\targs->rmtblkno = 0;\n \t\targs->rmtblkcnt = 0;\n+\t\targs->rmtvaluelen = 0;\n \t}\n \n \tretval = xfs_attr3_leaf_add(blk->bp, state->args);\n@@ -1133,6 +1154,7 @@ xfs_attr_node_addname(xfs_da_args_t *args)\n \t\targs->blkno = args->blkno2;\n \t\targs->rmtblkno = args->rmtblkno2;\n \t\targs->rmtblkcnt = args->rmtblkcnt2;\n+\t\targs->rmtvaluelen = args->rmtvaluelen2;\n \t\tif (args->rmtblkno) {\n \t\t\terror = xfs_attr_rmtval_remove(args);\n \t\t\tif (error)""}<_**next**_>{""sha"": ""511c283459b19441d782114c4f832207860deab1"", ""filename"": ""fs/xfs/xfs_attr_leaf.c"", ""status"": ""modified"", ""additions"": 11, ""deletions"": 10, ""changes"": 21, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_leaf.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_leaf.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_leaf.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -1229,6 +1229,7 @@ xfs_attr3_leaf_add_work(\n \t\tname_rmt->valueblk = 0;\n \t\targs->rmtblkno = 1;\n \t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);\n+\t\targs->rmtvaluelen = args->valuelen;\n \t}\n \txfs_trans_log_buf(args->trans, bp,\n \t     XFS_DA_LOGRANGE(leaf, xfs_attr3_leaf_name(leaf, args->index),\n@@ -2167,11 +2168,11 @@ xfs_attr3_leaf_lookup_int(\n \t\t\tif (!xfs_attr_namesp_match(args->flags, entry->flags))\n \t\t\t\tcontinue;\n \t\t\targs->index = probe;\n-\t\t\targs->valuelen = be32_to_cpu(name_rmt->valuelen);\n+\t\t\targs->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);\n \t\t\targs->rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(\n \t\t\t\t\t\t\targs->dp->i_mount,\n-\t\t\t\t\t\t\targs->valuelen);\n+\t\t\t\t\t\t\targs->rmtvaluelen);\n \t\t\treturn XFS_ERROR(EEXIST);\n \t\t}\n \t}\n@@ -2220,19 +2221,19 @@ xfs_attr3_leaf_getvalue(\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);\n \t\tASSERT(name_rmt->namelen == args->namelen);\n \t\tASSERT(memcmp(args->name, name_rmt->name, args->namelen) == 0);\n-\t\tvaluelen = be32_to_cpu(name_rmt->valuelen);\n+\t\targs->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);\n \t\targs->rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(args->dp->i_mount,\n-\t\t\t\t\t\t       valuelen);\n+\t\t\t\t\t\t       args->rmtvaluelen);\n \t\tif (args->flags & ATTR_KERNOVAL) {\n-\t\t\targs->valuelen = valuelen;\n+\t\t\targs->valuelen = args->rmtvaluelen;\n \t\t\treturn 0;\n \t\t}\n-\t\tif (args->valuelen < valuelen) {\n-\t\t\targs->valuelen = valuelen;\n+\t\tif (args->valuelen < args->rmtvaluelen) {\n+\t\t\targs->valuelen = args->rmtvaluelen;\n \t\t\treturn XFS_ERROR(ERANGE);\n \t\t}\n-\t\targs->valuelen = valuelen;\n+\t\targs->valuelen = args->rmtvaluelen;\n \t}\n \treturn 0;\n }\n@@ -2519,7 +2520,7 @@ xfs_attr3_leaf_clearflag(\n \t\tASSERT((entry->flags & XFS_ATTR_LOCAL) == 0);\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);\n \t\tname_rmt->valueblk = cpu_to_be32(args->rmtblkno);\n-\t\tname_rmt->valuelen = cpu_to_be32(args->valuelen);\n+\t\tname_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);\n \t\txfs_trans_log_buf(args->trans, bp,\n \t\t\t XFS_DA_LOGRANGE(leaf, name_rmt, sizeof(*name_rmt)));\n \t}\n@@ -2677,7 +2678,7 @@ xfs_attr3_leaf_flipflags(\n \t\tASSERT((entry1->flags & XFS_ATTR_LOCAL) == 0);\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf1, args->index);\n \t\tname_rmt->valueblk = cpu_to_be32(args->rmtblkno);\n-\t\tname_rmt->valuelen = cpu_to_be32(args->valuelen);\n+\t\tname_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);\n \t\txfs_trans_log_buf(args->trans, bp1,\n \t\t\t XFS_DA_LOGRANGE(leaf1, name_rmt, sizeof(*name_rmt)));\n \t}""}<_**next**_>{""sha"": ""833fe5d98d806783ca6bb6cf2f4ecb83424bfdca"", ""filename"": ""fs/xfs/xfs_attr_list.c"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 0, ""changes"": 1, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_list.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_list.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_list.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -447,6 +447,7 @@ xfs_attr3_leaf_list_int(\n \t\t\t\targs.dp = context->dp;\n \t\t\t\targs.whichfork = XFS_ATTR_FORK;\n \t\t\t\targs.valuelen = valuelen;\n+\t\t\t\targs.rmtvaluelen = valuelen;\n \t\t\t\targs.value = kmem_alloc(valuelen, KM_SLEEP | KM_NOFS);\n \t\t\t\targs.rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\t\t\targs.rmtblkcnt = xfs_attr3_rmt_blocks(""}<_**next**_>{""sha"": ""d2e6e948cec7be3013b853033b6e1a64b365a682"", ""filename"": ""fs/xfs/xfs_attr_remote.c"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 3, ""changes"": 8, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_remote.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_remote.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_remote.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -337,7 +337,7 @@ xfs_attr_rmtval_get(\n \tstruct xfs_buf\t\t*bp;\n \txfs_dablk_t\t\tlblkno = args->rmtblkno;\n \t__uint8_t\t\t*dst = args->value;\n-\tint\t\t\tvaluelen = args->valuelen;\n+\tint\t\t\tvaluelen;\n \tint\t\t\tnmap;\n \tint\t\t\terror;\n \tint\t\t\tblkcnt = args->rmtblkcnt;\n@@ -347,7 +347,9 @@ xfs_attr_rmtval_get(\n \ttrace_xfs_attr_rmtval_get(args);\n \n \tASSERT(!(args->flags & ATTR_KERNOVAL));\n+\tASSERT(args->rmtvaluelen == args->valuelen);\n \n+\tvaluelen = args->rmtvaluelen;\n \twhile (valuelen > 0) {\n \t\tnmap = ATTR_RMTVALUE_MAPSIZE;\n \t\terror = xfs_bmapi_read(args->dp, (xfs_fileoff_t)lblkno,\n@@ -415,7 +417,7 @@ xfs_attr_rmtval_set(\n \t * attributes have headers, we can't just do a straight byte to FSB\n \t * conversion and have to take the header space into account.\n \t */\n-\tblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);\n+\tblkcnt = xfs_attr3_rmt_blocks(mp, args->rmtvaluelen);\n \terror = xfs_bmap_first_unused(args->trans, args->dp, blkcnt, &lfileoff,\n \t\t\t\t\t\t   XFS_ATTR_FORK);\n \tif (error)\n@@ -480,7 +482,7 @@ xfs_attr_rmtval_set(\n \t */\n \tlblkno = args->rmtblkno;\n \tblkcnt = args->rmtblkcnt;\n-\tvaluelen = args->valuelen;\n+\tvaluelen = args->rmtvaluelen;\n \twhile (valuelen > 0) {\n \t\tstruct xfs_buf\t*bp;\n \t\txfs_daddr_t\tdblkno;""}<_**next**_>{""sha"": ""201c6091d26abfa2e38dd17fd960e3efcb69bcd7"", ""filename"": ""fs/xfs/xfs_da_btree.h"", ""status"": ""modified"", ""additions"": 2, ""deletions"": 0, ""changes"": 2, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_da_btree.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_da_btree.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_da_btree.h?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -60,10 +60,12 @@ typedef struct xfs_da_args {\n \tint\t\tindex;\t\t/* index of attr of interest in blk */\n \txfs_dablk_t\trmtblkno;\t/* remote attr value starting blkno */\n \tint\t\trmtblkcnt;\t/* remote attr value block count */\n+\tint\t\trmtvaluelen;\t/* remote attr value length in bytes */\n \txfs_dablk_t\tblkno2;\t\t/* blkno of 2nd attr leaf of interest */\n \tint\t\tindex2;\t\t/* index of 2nd attr in blk */\n \txfs_dablk_t\trmtblkno2;\t/* remote attr value starting blkno */\n \tint\t\trmtblkcnt2;\t/* remote attr value block count */\n+\tint\t\trmtvaluelen2;\t/* remote attr value length in bytes */\n \tint\t\top_flags;\t/* operation flags */\n \tenum xfs_dacmp\tcmpresult;\t/* name compare result for lookups */\n } xfs_da_args_t;""}","xfs_attr3_leaf_getvalue(
	struct xfs_buf		*bp,
	struct xfs_da_args	*args)
{
	struct xfs_attr_leafblock *leaf;
	struct xfs_attr3_icleaf_hdr ichdr;
	struct xfs_attr_leaf_entry *entry;
	struct xfs_attr_leaf_name_local *name_loc;
	struct xfs_attr_leaf_name_remote *name_rmt;
	int			valuelen;

	leaf = bp->b_addr;
	xfs_attr3_leaf_hdr_from_disk(&ichdr, leaf);
	ASSERT(ichdr.count < XFS_LBSIZE(args->dp->i_mount) / 8);
	ASSERT(args->index < ichdr.count);

	entry = &xfs_attr3_leaf_entryp(leaf)[args->index];
	if (entry->flags & XFS_ATTR_LOCAL) {
		name_loc = xfs_attr3_leaf_name_local(leaf, args->index);
		ASSERT(name_loc->namelen == args->namelen);
		ASSERT(memcmp(args->name, name_loc->nameval, args->namelen) == 0);
		valuelen = be16_to_cpu(name_loc->valuelen);
		if (args->flags & ATTR_KERNOVAL) {
			args->valuelen = valuelen;
			return 0;
		}
		if (args->valuelen < valuelen) {
			args->valuelen = valuelen;
			return XFS_ERROR(ERANGE);
		}
		args->valuelen = valuelen;
		memcpy(args->value, &name_loc->nameval[args->namelen], valuelen);
	} else {
 		name_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);
 		ASSERT(name_rmt->namelen == args->namelen);
 		ASSERT(memcmp(args->name, name_rmt->name, args->namelen) == 0);
		args->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);
 		args->rmtblkno = be32_to_cpu(name_rmt->valueblk);
 		args->rmtblkcnt = xfs_attr3_rmt_blocks(args->dp->i_mount,
						       args->rmtvaluelen);
 		if (args->flags & ATTR_KERNOVAL) {
			args->valuelen = args->rmtvaluelen;
 			return 0;
 		}
		if (args->valuelen < args->rmtvaluelen) {
			args->valuelen = args->rmtvaluelen;
 			return XFS_ERROR(ERANGE);
 		}
		args->valuelen = args->rmtvaluelen;
 	}
 	return 0;
 }
","xfs_attr3_leaf_getvalue(
	struct xfs_buf		*bp,
	struct xfs_da_args	*args)
{
	struct xfs_attr_leafblock *leaf;
	struct xfs_attr3_icleaf_hdr ichdr;
	struct xfs_attr_leaf_entry *entry;
	struct xfs_attr_leaf_name_local *name_loc;
	struct xfs_attr_leaf_name_remote *name_rmt;
	int			valuelen;

	leaf = bp->b_addr;
	xfs_attr3_leaf_hdr_from_disk(&ichdr, leaf);
	ASSERT(ichdr.count < XFS_LBSIZE(args->dp->i_mount) / 8);
	ASSERT(args->index < ichdr.count);

	entry = &xfs_attr3_leaf_entryp(leaf)[args->index];
	if (entry->flags & XFS_ATTR_LOCAL) {
		name_loc = xfs_attr3_leaf_name_local(leaf, args->index);
		ASSERT(name_loc->namelen == args->namelen);
		ASSERT(memcmp(args->name, name_loc->nameval, args->namelen) == 0);
		valuelen = be16_to_cpu(name_loc->valuelen);
		if (args->flags & ATTR_KERNOVAL) {
			args->valuelen = valuelen;
			return 0;
		}
		if (args->valuelen < valuelen) {
			args->valuelen = valuelen;
			return XFS_ERROR(ERANGE);
		}
		args->valuelen = valuelen;
		memcpy(args->value, &name_loc->nameval[args->namelen], valuelen);
	} else {
 		name_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);
 		ASSERT(name_rmt->namelen == args->namelen);
 		ASSERT(memcmp(args->name, name_rmt->name, args->namelen) == 0);
		valuelen = be32_to_cpu(name_rmt->valuelen);
 		args->rmtblkno = be32_to_cpu(name_rmt->valueblk);
 		args->rmtblkcnt = xfs_attr3_rmt_blocks(args->dp->i_mount,
						       valuelen);
 		if (args->flags & ATTR_KERNOVAL) {
			args->valuelen = valuelen;
 			return 0;
 		}
		if (args->valuelen < valuelen) {
			args->valuelen = valuelen;
 			return XFS_ERROR(ERANGE);
 		}
		args->valuelen = valuelen;
 	}
 	return 0;
 }
",C,"		args->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);
						       args->rmtvaluelen);
			args->valuelen = args->rmtvaluelen;
		if (args->valuelen < args->rmtvaluelen) {
			args->valuelen = args->rmtvaluelen;
		args->valuelen = args->rmtvaluelen;
","		valuelen = be32_to_cpu(name_rmt->valuelen);
						       valuelen);
			args->valuelen = valuelen;
		if (args->valuelen < valuelen) {
			args->valuelen = valuelen;
		args->valuelen = valuelen;
",,"@@ -1229,6 +1229,7 @@ xfs_attr3_leaf_add_work(
 		name_rmt->valueblk = 0;
 		args->rmtblkno = 1;
 		args->rmtblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);
+		args->rmtvaluelen = args->valuelen;
 	}
 	xfs_trans_log_buf(args->trans, bp,
 	     XFS_DA_LOGRANGE(leaf, xfs_attr3_leaf_name(leaf, args->index),
@@ -2167,11 +2168,11 @@ xfs_attr3_leaf_lookup_int(
 			if (!xfs_attr_namesp_match(args->flags, entry->flags))
 				continue;
 			args->index = probe;
-			args->valuelen = be32_to_cpu(name_rmt->valuelen);
+			args->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);
 			args->rmtblkno = be32_to_cpu(name_rmt->valueblk);
 			args->rmtblkcnt = xfs_attr3_rmt_blocks(
 							args->dp->i_mount,
-							args->valuelen);
+							args->rmtvaluelen);
 			return XFS_ERROR(EEXIST);
 		}
 	}
@@ -2220,19 +2221,19 @@ xfs_attr3_leaf_getvalue(
 		name_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);
 		ASSERT(name_rmt->namelen == args->namelen);
 		ASSERT(memcmp(args->name, name_rmt->name, args->namelen) == 0);
-		valuelen = be32_to_cpu(name_rmt->valuelen);
+		args->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);
 		args->rmtblkno = be32_to_cpu(name_rmt->valueblk);
 		args->rmtblkcnt = xfs_attr3_rmt_blocks(args->dp->i_mount,
-						       valuelen);
+						       args->rmtvaluelen);
 		if (args->flags & ATTR_KERNOVAL) {
-			args->valuelen = valuelen;
+			args->valuelen = args->rmtvaluelen;
 			return 0;
 		}
-		if (args->valuelen < valuelen) {
-			args->valuelen = valuelen;
+		if (args->valuelen < args->rmtvaluelen) {
+			args->valuelen = args->rmtvaluelen;
 			return XFS_ERROR(ERANGE);
 		}
-		args->valuelen = valuelen;
+		args->valuelen = args->rmtvaluelen;
 	}
 	return 0;
 }
@@ -2519,7 +2520,7 @@ xfs_attr3_leaf_clearflag(
 		ASSERT((entry->flags & XFS_ATTR_LOCAL) == 0);
 		name_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);
 		name_rmt->valueblk = cpu_to_be32(args->rmtblkno);
-		name_rmt->valuelen = cpu_to_be32(args->valuelen);
+		name_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);
 		xfs_trans_log_buf(args->trans, bp,
 			 XFS_DA_LOGRANGE(leaf, name_rmt, sizeof(*name_rmt)));
 	}
@@ -2677,7 +2678,7 @@ xfs_attr3_leaf_flipflags(
 		ASSERT((entry1->flags & XFS_ATTR_LOCAL) == 0);
 		name_rmt = xfs_attr3_leaf_name_remote(leaf1, args->index);
 		name_rmt->valueblk = cpu_to_be32(args->rmtblkno);
-		name_rmt->valuelen = cpu_to_be32(args->valuelen);
+		name_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);
 		xfs_trans_log_buf(args->trans, bp1,
 			 XFS_DA_LOGRANGE(leaf1, name_rmt, sizeof(*name_rmt)));
 	}",linux,8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,d540e43b0ab134b22f015f725ce6e070d12b0244,1,"xfs_attr3_leaf_getvalue(
	struct xfs_buf		*bp,
	struct xfs_da_args	*args)
{
	struct xfs_attr_leafblock *leaf;
	struct xfs_attr3_icleaf_hdr ichdr;
	struct xfs_attr_leaf_entry *entry;
	struct xfs_attr_leaf_name_local *name_loc;
	struct xfs_attr_leaf_name_remote *name_rmt;
	int			valuelen;

	leaf = bp->b_addr;
	xfs_attr3_leaf_hdr_from_disk(&ichdr, leaf);
	ASSERT(ichdr.count < XFS_LBSIZE(args->dp->i_mount) / 8);
	ASSERT(args->index < ichdr.count);

	entry = &xfs_attr3_leaf_entryp(leaf)[args->index];
	if (entry->flags & XFS_ATTR_LOCAL) {
		name_loc = xfs_attr3_leaf_name_local(leaf, args->index);
		ASSERT(name_loc->namelen == args->namelen);
		ASSERT(memcmp(args->name, name_loc->nameval, args->namelen) == 0);
		valuelen = be16_to_cpu(name_loc->valuelen);
		if (args->flags & ATTR_KERNOVAL) {
			args->valuelen = valuelen;
			return 0;
		}
		if (args->valuelen < valuelen) {
			args->valuelen = valuelen;
			return XFS_ERROR(ERANGE);
		}
		args->valuelen = valuelen;
		memcpy(args->value, &name_loc->nameval[args->namelen], valuelen);
	} else {
 		name_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);
 		ASSERT(name_rmt->namelen == args->namelen);
 		ASSERT(memcmp(args->name, name_rmt->name, args->namelen) == 0);
//flaw_line_below:
		valuelen = be32_to_cpu(name_rmt->valuelen);
//fix_flaw_line_below:
//		args->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);
 		args->rmtblkno = be32_to_cpu(name_rmt->valueblk);
 		args->rmtblkcnt = xfs_attr3_rmt_blocks(args->dp->i_mount,
//flaw_line_below:
						       valuelen);
//fix_flaw_line_below:
//						       args->rmtvaluelen);
 		if (args->flags & ATTR_KERNOVAL) {
//flaw_line_below:
			args->valuelen = valuelen;
//fix_flaw_line_below:
//			args->valuelen = args->rmtvaluelen;
 			return 0;
 		}
//flaw_line_below:
		if (args->valuelen < valuelen) {
//flaw_line_below:
			args->valuelen = valuelen;
//fix_flaw_line_below:
//		if (args->valuelen < args->rmtvaluelen) {
//fix_flaw_line_below:
//			args->valuelen = args->rmtvaluelen;
 			return XFS_ERROR(ERANGE);
 		}
//flaw_line_below:
		args->valuelen = valuelen;
//fix_flaw_line_below:
//		args->valuelen = args->rmtvaluelen;
 	}
 	return 0;
 }
"
2173,179909,,Local,Not required,Complete,CVE-2015-0274,https://www.cvedetails.com/cve/CVE-2015-0274/,CWE-19,Low,Complete,Complete,,2015-03-16,7.2,"The XFS implementation in the Linux kernel before 3.15 improperly uses an old size value during remote attribute replacement, which allows local users to cause a denial of service (transaction overrun and data corruption) or possibly gain privileges by leveraging XFS filesystem access.",2015-03-26,DoS +Priv ,2,https://github.com/torvalds/linux/commit/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,"xfs: remote attribute overwrite causes transaction overrun

Commit e461fcb (""xfs: remote attribute lookups require the value
length"") passes the remote attribute length in the xfs_da_args
structure on lookup so that CRC calculations and validity checking
can be performed correctly by related code. This, unfortunately has
the side effect of changing the args->valuelen parameter in cases
where it shouldn't.

That is, when we replace a remote attribute, the incoming
replacement stores the value and length in args->value and
args->valuelen, but then the lookup which finds the existing remote
attribute overwrites args->valuelen with the length of the remote
attribute being replaced. Hence when we go to create the new
attribute, we create it of the size of the existing remote
attribute, not the size it is supposed to be. When the new attribute
is much smaller than the old attribute, this results in a
transaction overrun and an ASSERT() failure on a debug kernel:

XFS: Assertion failed: tp->t_blk_res_used <= tp->t_blk_res, file: fs/xfs/xfs_trans.c, line: 331

Fix this by keeping the remote attribute value length separate to
the attribute value length in the xfs_da_args structure. The enables
us to pass the length of the remote attribute to be removed without
overwriting the new attribute's length.

Also, ensure that when we save remote block contexts for a later
rename we zero the original state variables so that we don't confuse
the state of the attribute to be removes with the state of the new
attribute that we just added. [Spotted by Brain Foster.]

Signed-off-by: Dave Chinner <dchinner@redhat.com>
Reviewed-by: Brian Foster <bfoster@redhat.com>
Signed-off-by: Dave Chinner <david@fromorbit.com>",2,fs/xfs/xfs_attr_leaf.c,"{""sha"": ""abda1124a70f66fbd1a79b28f8eaf5bf1916da1e"", ""filename"": ""fs/xfs/xfs_attr.c"", ""status"": ""modified"", ""additions"": 23, ""deletions"": 1, ""changes"": 24, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -213,7 +213,7 @@ xfs_attr_calc_size(\n \t\t * Out of line attribute, cannot double split, but\n \t\t * make room for the attribute value itself.\n \t\t */\n-\t\tuint\tdblocks = XFS_B_TO_FSB(mp, valuelen);\n+\t\tuint\tdblocks = xfs_attr3_rmt_blocks(mp, valuelen);\n \t\tnblks += dblocks;\n \t\tnblks += XFS_NEXTENTADD_SPACE_RES(mp, dblocks, XFS_ATTR_FORK);\n \t}\n@@ -698,11 +698,22 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)\n \n \t\ttrace_xfs_attr_leaf_replace(args);\n \n+\t\t/* save the attribute state for later removal*/\n \t\targs->op_flags |= XFS_DA_OP_RENAME;\t/* an atomic rename */\n \t\targs->blkno2 = args->blkno;\t\t/* set 2nd entry info*/\n \t\targs->index2 = args->index;\n \t\targs->rmtblkno2 = args->rmtblkno;\n \t\targs->rmtblkcnt2 = args->rmtblkcnt;\n+\t\targs->rmtvaluelen2 = args->rmtvaluelen;\n+\n+\t\t/*\n+\t\t * clear the remote attr state now that it is saved so that the\n+\t\t * values reflect the state of the attribute we are about to\n+\t\t * add, not the attribute we just found and will remove later.\n+\t\t */\n+\t\targs->rmtblkno = 0;\n+\t\targs->rmtblkcnt = 0;\n+\t\targs->rmtvaluelen = 0;\n \t}\n \n \t/*\n@@ -794,6 +805,7 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)\n \t\targs->blkno = args->blkno2;\n \t\targs->rmtblkno = args->rmtblkno2;\n \t\targs->rmtblkcnt = args->rmtblkcnt2;\n+\t\targs->rmtvaluelen = args->rmtvaluelen2;\n \t\tif (args->rmtblkno) {\n \t\t\terror = xfs_attr_rmtval_remove(args);\n \t\t\tif (error)\n@@ -999,13 +1011,22 @@ xfs_attr_node_addname(xfs_da_args_t *args)\n \n \t\ttrace_xfs_attr_node_replace(args);\n \n+\t\t/* save the attribute state for later removal*/\n \t\targs->op_flags |= XFS_DA_OP_RENAME;\t/* atomic rename op */\n \t\targs->blkno2 = args->blkno;\t\t/* set 2nd entry info*/\n \t\targs->index2 = args->index;\n \t\targs->rmtblkno2 = args->rmtblkno;\n \t\targs->rmtblkcnt2 = args->rmtblkcnt;\n+\t\targs->rmtvaluelen2 = args->rmtvaluelen;\n+\n+\t\t/*\n+\t\t * clear the remote attr state now that it is saved so that the\n+\t\t * values reflect the state of the attribute we are about to\n+\t\t * add, not the attribute we just found and will remove later.\n+\t\t */\n \t\targs->rmtblkno = 0;\n \t\targs->rmtblkcnt = 0;\n+\t\targs->rmtvaluelen = 0;\n \t}\n \n \tretval = xfs_attr3_leaf_add(blk->bp, state->args);\n@@ -1133,6 +1154,7 @@ xfs_attr_node_addname(xfs_da_args_t *args)\n \t\targs->blkno = args->blkno2;\n \t\targs->rmtblkno = args->rmtblkno2;\n \t\targs->rmtblkcnt = args->rmtblkcnt2;\n+\t\targs->rmtvaluelen = args->rmtvaluelen2;\n \t\tif (args->rmtblkno) {\n \t\t\terror = xfs_attr_rmtval_remove(args);\n \t\t\tif (error)""}<_**next**_>{""sha"": ""511c283459b19441d782114c4f832207860deab1"", ""filename"": ""fs/xfs/xfs_attr_leaf.c"", ""status"": ""modified"", ""additions"": 11, ""deletions"": 10, ""changes"": 21, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_leaf.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_leaf.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_leaf.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -1229,6 +1229,7 @@ xfs_attr3_leaf_add_work(\n \t\tname_rmt->valueblk = 0;\n \t\targs->rmtblkno = 1;\n \t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);\n+\t\targs->rmtvaluelen = args->valuelen;\n \t}\n \txfs_trans_log_buf(args->trans, bp,\n \t     XFS_DA_LOGRANGE(leaf, xfs_attr3_leaf_name(leaf, args->index),\n@@ -2167,11 +2168,11 @@ xfs_attr3_leaf_lookup_int(\n \t\t\tif (!xfs_attr_namesp_match(args->flags, entry->flags))\n \t\t\t\tcontinue;\n \t\t\targs->index = probe;\n-\t\t\targs->valuelen = be32_to_cpu(name_rmt->valuelen);\n+\t\t\targs->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);\n \t\t\targs->rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(\n \t\t\t\t\t\t\targs->dp->i_mount,\n-\t\t\t\t\t\t\targs->valuelen);\n+\t\t\t\t\t\t\targs->rmtvaluelen);\n \t\t\treturn XFS_ERROR(EEXIST);\n \t\t}\n \t}\n@@ -2220,19 +2221,19 @@ xfs_attr3_leaf_getvalue(\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);\n \t\tASSERT(name_rmt->namelen == args->namelen);\n \t\tASSERT(memcmp(args->name, name_rmt->name, args->namelen) == 0);\n-\t\tvaluelen = be32_to_cpu(name_rmt->valuelen);\n+\t\targs->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);\n \t\targs->rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(args->dp->i_mount,\n-\t\t\t\t\t\t       valuelen);\n+\t\t\t\t\t\t       args->rmtvaluelen);\n \t\tif (args->flags & ATTR_KERNOVAL) {\n-\t\t\targs->valuelen = valuelen;\n+\t\t\targs->valuelen = args->rmtvaluelen;\n \t\t\treturn 0;\n \t\t}\n-\t\tif (args->valuelen < valuelen) {\n-\t\t\targs->valuelen = valuelen;\n+\t\tif (args->valuelen < args->rmtvaluelen) {\n+\t\t\targs->valuelen = args->rmtvaluelen;\n \t\t\treturn XFS_ERROR(ERANGE);\n \t\t}\n-\t\targs->valuelen = valuelen;\n+\t\targs->valuelen = args->rmtvaluelen;\n \t}\n \treturn 0;\n }\n@@ -2519,7 +2520,7 @@ xfs_attr3_leaf_clearflag(\n \t\tASSERT((entry->flags & XFS_ATTR_LOCAL) == 0);\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);\n \t\tname_rmt->valueblk = cpu_to_be32(args->rmtblkno);\n-\t\tname_rmt->valuelen = cpu_to_be32(args->valuelen);\n+\t\tname_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);\n \t\txfs_trans_log_buf(args->trans, bp,\n \t\t\t XFS_DA_LOGRANGE(leaf, name_rmt, sizeof(*name_rmt)));\n \t}\n@@ -2677,7 +2678,7 @@ xfs_attr3_leaf_flipflags(\n \t\tASSERT((entry1->flags & XFS_ATTR_LOCAL) == 0);\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf1, args->index);\n \t\tname_rmt->valueblk = cpu_to_be32(args->rmtblkno);\n-\t\tname_rmt->valuelen = cpu_to_be32(args->valuelen);\n+\t\tname_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);\n \t\txfs_trans_log_buf(args->trans, bp1,\n \t\t\t XFS_DA_LOGRANGE(leaf1, name_rmt, sizeof(*name_rmt)));\n \t}""}<_**next**_>{""sha"": ""833fe5d98d806783ca6bb6cf2f4ecb83424bfdca"", ""filename"": ""fs/xfs/xfs_attr_list.c"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 0, ""changes"": 1, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_list.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_list.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_list.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -447,6 +447,7 @@ xfs_attr3_leaf_list_int(\n \t\t\t\targs.dp = context->dp;\n \t\t\t\targs.whichfork = XFS_ATTR_FORK;\n \t\t\t\targs.valuelen = valuelen;\n+\t\t\t\targs.rmtvaluelen = valuelen;\n \t\t\t\targs.value = kmem_alloc(valuelen, KM_SLEEP | KM_NOFS);\n \t\t\t\targs.rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\t\t\targs.rmtblkcnt = xfs_attr3_rmt_blocks(""}<_**next**_>{""sha"": ""d2e6e948cec7be3013b853033b6e1a64b365a682"", ""filename"": ""fs/xfs/xfs_attr_remote.c"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 3, ""changes"": 8, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_remote.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_remote.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_remote.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -337,7 +337,7 @@ xfs_attr_rmtval_get(\n \tstruct xfs_buf\t\t*bp;\n \txfs_dablk_t\t\tlblkno = args->rmtblkno;\n \t__uint8_t\t\t*dst = args->value;\n-\tint\t\t\tvaluelen = args->valuelen;\n+\tint\t\t\tvaluelen;\n \tint\t\t\tnmap;\n \tint\t\t\terror;\n \tint\t\t\tblkcnt = args->rmtblkcnt;\n@@ -347,7 +347,9 @@ xfs_attr_rmtval_get(\n \ttrace_xfs_attr_rmtval_get(args);\n \n \tASSERT(!(args->flags & ATTR_KERNOVAL));\n+\tASSERT(args->rmtvaluelen == args->valuelen);\n \n+\tvaluelen = args->rmtvaluelen;\n \twhile (valuelen > 0) {\n \t\tnmap = ATTR_RMTVALUE_MAPSIZE;\n \t\terror = xfs_bmapi_read(args->dp, (xfs_fileoff_t)lblkno,\n@@ -415,7 +417,7 @@ xfs_attr_rmtval_set(\n \t * attributes have headers, we can't just do a straight byte to FSB\n \t * conversion and have to take the header space into account.\n \t */\n-\tblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);\n+\tblkcnt = xfs_attr3_rmt_blocks(mp, args->rmtvaluelen);\n \terror = xfs_bmap_first_unused(args->trans, args->dp, blkcnt, &lfileoff,\n \t\t\t\t\t\t   XFS_ATTR_FORK);\n \tif (error)\n@@ -480,7 +482,7 @@ xfs_attr_rmtval_set(\n \t */\n \tlblkno = args->rmtblkno;\n \tblkcnt = args->rmtblkcnt;\n-\tvaluelen = args->valuelen;\n+\tvaluelen = args->rmtvaluelen;\n \twhile (valuelen > 0) {\n \t\tstruct xfs_buf\t*bp;\n \t\txfs_daddr_t\tdblkno;""}<_**next**_>{""sha"": ""201c6091d26abfa2e38dd17fd960e3efcb69bcd7"", ""filename"": ""fs/xfs/xfs_da_btree.h"", ""status"": ""modified"", ""additions"": 2, ""deletions"": 0, ""changes"": 2, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_da_btree.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_da_btree.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_da_btree.h?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -60,10 +60,12 @@ typedef struct xfs_da_args {\n \tint\t\tindex;\t\t/* index of attr of interest in blk */\n \txfs_dablk_t\trmtblkno;\t/* remote attr value starting blkno */\n \tint\t\trmtblkcnt;\t/* remote attr value block count */\n+\tint\t\trmtvaluelen;\t/* remote attr value length in bytes */\n \txfs_dablk_t\tblkno2;\t\t/* blkno of 2nd attr leaf of interest */\n \tint\t\tindex2;\t\t/* index of 2nd attr in blk */\n \txfs_dablk_t\trmtblkno2;\t/* remote attr value starting blkno */\n \tint\t\trmtblkcnt2;\t/* remote attr value block count */\n+\tint\t\trmtvaluelen2;\t/* remote attr value length in bytes */\n \tint\t\top_flags;\t/* operation flags */\n \tenum xfs_dacmp\tcmpresult;\t/* name compare result for lookups */\n } xfs_da_args_t;""}","xfs_attr3_leaf_lookup_int(
	struct xfs_buf		*bp,
	struct xfs_da_args	*args)
{
	struct xfs_attr_leafblock *leaf;
	struct xfs_attr3_icleaf_hdr ichdr;
	struct xfs_attr_leaf_entry *entry;
	struct xfs_attr_leaf_entry *entries;
	struct xfs_attr_leaf_name_local *name_loc;
	struct xfs_attr_leaf_name_remote *name_rmt;
	xfs_dahash_t		hashval;
	int			probe;
	int			span;

	trace_xfs_attr_leaf_lookup(args);

	leaf = bp->b_addr;
	xfs_attr3_leaf_hdr_from_disk(&ichdr, leaf);
	entries = xfs_attr3_leaf_entryp(leaf);
	ASSERT(ichdr.count < XFS_LBSIZE(args->dp->i_mount) / 8);

	/*
	 * Binary search.  (note: small blocks will skip this loop)
	 */
	hashval = args->hashval;
	probe = span = ichdr.count / 2;
	for (entry = &entries[probe]; span > 4; entry = &entries[probe]) {
		span /= 2;
		if (be32_to_cpu(entry->hashval) < hashval)
			probe += span;
		else if (be32_to_cpu(entry->hashval) > hashval)
			probe -= span;
		else
			break;
	}
	ASSERT(probe >= 0 && (!ichdr.count || probe < ichdr.count));
	ASSERT(span <= 4 || be32_to_cpu(entry->hashval) == hashval);

	/*
	 * Since we may have duplicate hashval's, find the first matching
	 * hashval in the leaf.
	 */
	while (probe > 0 && be32_to_cpu(entry->hashval) >= hashval) {
		entry--;
		probe--;
	}
	while (probe < ichdr.count &&
	       be32_to_cpu(entry->hashval) < hashval) {
		entry++;
		probe++;
	}
	if (probe == ichdr.count || be32_to_cpu(entry->hashval) != hashval) {
		args->index = probe;
		return XFS_ERROR(ENOATTR);
	}

	/*
	 * Duplicate keys may be present, so search all of them for a match.
	 */
	for (; probe < ichdr.count && (be32_to_cpu(entry->hashval) == hashval);
			entry++, probe++) {
/*
 * GROT: Add code to remove incomplete entries.
 */
		/*
		 * If we are looking for INCOMPLETE entries, show only those.
		 * If we are looking for complete entries, show only those.
		 */
		if ((args->flags & XFS_ATTR_INCOMPLETE) !=
		    (entry->flags & XFS_ATTR_INCOMPLETE)) {
			continue;
		}
		if (entry->flags & XFS_ATTR_LOCAL) {
			name_loc = xfs_attr3_leaf_name_local(leaf, probe);
			if (name_loc->namelen != args->namelen)
				continue;
			if (memcmp(args->name, name_loc->nameval,
							args->namelen) != 0)
				continue;
			if (!xfs_attr_namesp_match(args->flags, entry->flags))
				continue;
			args->index = probe;
			return XFS_ERROR(EEXIST);
		} else {
			name_rmt = xfs_attr3_leaf_name_remote(leaf, probe);
			if (name_rmt->namelen != args->namelen)
				continue;
			if (memcmp(args->name, name_rmt->name,
							args->namelen) != 0)
				continue;
 			if (!xfs_attr_namesp_match(args->flags, entry->flags))
 				continue;
 			args->index = probe;
			args->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);
 			args->rmtblkno = be32_to_cpu(name_rmt->valueblk);
 			args->rmtblkcnt = xfs_attr3_rmt_blocks(
 							args->dp->i_mount,
							args->rmtvaluelen);
 			return XFS_ERROR(EEXIST);
 		}
 	}
	args->index = probe;
	return XFS_ERROR(ENOATTR);
}
","xfs_attr3_leaf_lookup_int(
	struct xfs_buf		*bp,
	struct xfs_da_args	*args)
{
	struct xfs_attr_leafblock *leaf;
	struct xfs_attr3_icleaf_hdr ichdr;
	struct xfs_attr_leaf_entry *entry;
	struct xfs_attr_leaf_entry *entries;
	struct xfs_attr_leaf_name_local *name_loc;
	struct xfs_attr_leaf_name_remote *name_rmt;
	xfs_dahash_t		hashval;
	int			probe;
	int			span;

	trace_xfs_attr_leaf_lookup(args);

	leaf = bp->b_addr;
	xfs_attr3_leaf_hdr_from_disk(&ichdr, leaf);
	entries = xfs_attr3_leaf_entryp(leaf);
	ASSERT(ichdr.count < XFS_LBSIZE(args->dp->i_mount) / 8);

	/*
	 * Binary search.  (note: small blocks will skip this loop)
	 */
	hashval = args->hashval;
	probe = span = ichdr.count / 2;
	for (entry = &entries[probe]; span > 4; entry = &entries[probe]) {
		span /= 2;
		if (be32_to_cpu(entry->hashval) < hashval)
			probe += span;
		else if (be32_to_cpu(entry->hashval) > hashval)
			probe -= span;
		else
			break;
	}
	ASSERT(probe >= 0 && (!ichdr.count || probe < ichdr.count));
	ASSERT(span <= 4 || be32_to_cpu(entry->hashval) == hashval);

	/*
	 * Since we may have duplicate hashval's, find the first matching
	 * hashval in the leaf.
	 */
	while (probe > 0 && be32_to_cpu(entry->hashval) >= hashval) {
		entry--;
		probe--;
	}
	while (probe < ichdr.count &&
	       be32_to_cpu(entry->hashval) < hashval) {
		entry++;
		probe++;
	}
	if (probe == ichdr.count || be32_to_cpu(entry->hashval) != hashval) {
		args->index = probe;
		return XFS_ERROR(ENOATTR);
	}

	/*
	 * Duplicate keys may be present, so search all of them for a match.
	 */
	for (; probe < ichdr.count && (be32_to_cpu(entry->hashval) == hashval);
			entry++, probe++) {
/*
 * GROT: Add code to remove incomplete entries.
 */
		/*
		 * If we are looking for INCOMPLETE entries, show only those.
		 * If we are looking for complete entries, show only those.
		 */
		if ((args->flags & XFS_ATTR_INCOMPLETE) !=
		    (entry->flags & XFS_ATTR_INCOMPLETE)) {
			continue;
		}
		if (entry->flags & XFS_ATTR_LOCAL) {
			name_loc = xfs_attr3_leaf_name_local(leaf, probe);
			if (name_loc->namelen != args->namelen)
				continue;
			if (memcmp(args->name, name_loc->nameval,
							args->namelen) != 0)
				continue;
			if (!xfs_attr_namesp_match(args->flags, entry->flags))
				continue;
			args->index = probe;
			return XFS_ERROR(EEXIST);
		} else {
			name_rmt = xfs_attr3_leaf_name_remote(leaf, probe);
			if (name_rmt->namelen != args->namelen)
				continue;
			if (memcmp(args->name, name_rmt->name,
							args->namelen) != 0)
				continue;
 			if (!xfs_attr_namesp_match(args->flags, entry->flags))
 				continue;
 			args->index = probe;
			args->valuelen = be32_to_cpu(name_rmt->valuelen);
 			args->rmtblkno = be32_to_cpu(name_rmt->valueblk);
 			args->rmtblkcnt = xfs_attr3_rmt_blocks(
 							args->dp->i_mount,
							args->valuelen);
 			return XFS_ERROR(EEXIST);
 		}
 	}
	args->index = probe;
	return XFS_ERROR(ENOATTR);
}
",C,"			args->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);
							args->rmtvaluelen);
","			args->valuelen = be32_to_cpu(name_rmt->valuelen);
							args->valuelen);
",,"@@ -1229,6 +1229,7 @@ xfs_attr3_leaf_add_work(
 		name_rmt->valueblk = 0;
 		args->rmtblkno = 1;
 		args->rmtblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);
+		args->rmtvaluelen = args->valuelen;
 	}
 	xfs_trans_log_buf(args->trans, bp,
 	     XFS_DA_LOGRANGE(leaf, xfs_attr3_leaf_name(leaf, args->index),
@@ -2167,11 +2168,11 @@ xfs_attr3_leaf_lookup_int(
 			if (!xfs_attr_namesp_match(args->flags, entry->flags))
 				continue;
 			args->index = probe;
-			args->valuelen = be32_to_cpu(name_rmt->valuelen);
+			args->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);
 			args->rmtblkno = be32_to_cpu(name_rmt->valueblk);
 			args->rmtblkcnt = xfs_attr3_rmt_blocks(
 							args->dp->i_mount,
-							args->valuelen);
+							args->rmtvaluelen);
 			return XFS_ERROR(EEXIST);
 		}
 	}
@@ -2220,19 +2221,19 @@ xfs_attr3_leaf_getvalue(
 		name_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);
 		ASSERT(name_rmt->namelen == args->namelen);
 		ASSERT(memcmp(args->name, name_rmt->name, args->namelen) == 0);
-		valuelen = be32_to_cpu(name_rmt->valuelen);
+		args->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);
 		args->rmtblkno = be32_to_cpu(name_rmt->valueblk);
 		args->rmtblkcnt = xfs_attr3_rmt_blocks(args->dp->i_mount,
-						       valuelen);
+						       args->rmtvaluelen);
 		if (args->flags & ATTR_KERNOVAL) {
-			args->valuelen = valuelen;
+			args->valuelen = args->rmtvaluelen;
 			return 0;
 		}
-		if (args->valuelen < valuelen) {
-			args->valuelen = valuelen;
+		if (args->valuelen < args->rmtvaluelen) {
+			args->valuelen = args->rmtvaluelen;
 			return XFS_ERROR(ERANGE);
 		}
-		args->valuelen = valuelen;
+		args->valuelen = args->rmtvaluelen;
 	}
 	return 0;
 }
@@ -2519,7 +2520,7 @@ xfs_attr3_leaf_clearflag(
 		ASSERT((entry->flags & XFS_ATTR_LOCAL) == 0);
 		name_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);
 		name_rmt->valueblk = cpu_to_be32(args->rmtblkno);
-		name_rmt->valuelen = cpu_to_be32(args->valuelen);
+		name_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);
 		xfs_trans_log_buf(args->trans, bp,
 			 XFS_DA_LOGRANGE(leaf, name_rmt, sizeof(*name_rmt)));
 	}
@@ -2677,7 +2678,7 @@ xfs_attr3_leaf_flipflags(
 		ASSERT((entry1->flags & XFS_ATTR_LOCAL) == 0);
 		name_rmt = xfs_attr3_leaf_name_remote(leaf1, args->index);
 		name_rmt->valueblk = cpu_to_be32(args->rmtblkno);
-		name_rmt->valuelen = cpu_to_be32(args->valuelen);
+		name_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);
 		xfs_trans_log_buf(args->trans, bp1,
 			 XFS_DA_LOGRANGE(leaf1, name_rmt, sizeof(*name_rmt)));
 	}",linux,8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,d540e43b0ab134b22f015f725ce6e070d12b0244,1,"xfs_attr3_leaf_lookup_int(
	struct xfs_buf		*bp,
	struct xfs_da_args	*args)
{
	struct xfs_attr_leafblock *leaf;
	struct xfs_attr3_icleaf_hdr ichdr;
	struct xfs_attr_leaf_entry *entry;
	struct xfs_attr_leaf_entry *entries;
	struct xfs_attr_leaf_name_local *name_loc;
	struct xfs_attr_leaf_name_remote *name_rmt;
	xfs_dahash_t		hashval;
	int			probe;
	int			span;

	trace_xfs_attr_leaf_lookup(args);

	leaf = bp->b_addr;
	xfs_attr3_leaf_hdr_from_disk(&ichdr, leaf);
	entries = xfs_attr3_leaf_entryp(leaf);
	ASSERT(ichdr.count < XFS_LBSIZE(args->dp->i_mount) / 8);

	/*
	 * Binary search.  (note: small blocks will skip this loop)
	 */
	hashval = args->hashval;
	probe = span = ichdr.count / 2;
	for (entry = &entries[probe]; span > 4; entry = &entries[probe]) {
		span /= 2;
		if (be32_to_cpu(entry->hashval) < hashval)
			probe += span;
		else if (be32_to_cpu(entry->hashval) > hashval)
			probe -= span;
		else
			break;
	}
	ASSERT(probe >= 0 && (!ichdr.count || probe < ichdr.count));
	ASSERT(span <= 4 || be32_to_cpu(entry->hashval) == hashval);

	/*
	 * Since we may have duplicate hashval's, find the first matching
	 * hashval in the leaf.
	 */
	while (probe > 0 && be32_to_cpu(entry->hashval) >= hashval) {
		entry--;
		probe--;
	}
	while (probe < ichdr.count &&
	       be32_to_cpu(entry->hashval) < hashval) {
		entry++;
		probe++;
	}
	if (probe == ichdr.count || be32_to_cpu(entry->hashval) != hashval) {
		args->index = probe;
		return XFS_ERROR(ENOATTR);
	}

	/*
	 * Duplicate keys may be present, so search all of them for a match.
	 */
	for (; probe < ichdr.count && (be32_to_cpu(entry->hashval) == hashval);
			entry++, probe++) {
/*
 * GROT: Add code to remove incomplete entries.
 */
		/*
		 * If we are looking for INCOMPLETE entries, show only those.
		 * If we are looking for complete entries, show only those.
		 */
		if ((args->flags & XFS_ATTR_INCOMPLETE) !=
		    (entry->flags & XFS_ATTR_INCOMPLETE)) {
			continue;
		}
		if (entry->flags & XFS_ATTR_LOCAL) {
			name_loc = xfs_attr3_leaf_name_local(leaf, probe);
			if (name_loc->namelen != args->namelen)
				continue;
			if (memcmp(args->name, name_loc->nameval,
							args->namelen) != 0)
				continue;
			if (!xfs_attr_namesp_match(args->flags, entry->flags))
				continue;
			args->index = probe;
			return XFS_ERROR(EEXIST);
		} else {
			name_rmt = xfs_attr3_leaf_name_remote(leaf, probe);
			if (name_rmt->namelen != args->namelen)
				continue;
			if (memcmp(args->name, name_rmt->name,
							args->namelen) != 0)
				continue;
 			if (!xfs_attr_namesp_match(args->flags, entry->flags))
 				continue;
 			args->index = probe;
//flaw_line_below:
			args->valuelen = be32_to_cpu(name_rmt->valuelen);
//fix_flaw_line_below:
//			args->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);
 			args->rmtblkno = be32_to_cpu(name_rmt->valueblk);
 			args->rmtblkcnt = xfs_attr3_rmt_blocks(
 							args->dp->i_mount,
//flaw_line_below:
							args->valuelen);
//fix_flaw_line_below:
//							args->rmtvaluelen);
 			return XFS_ERROR(EEXIST);
 		}
 	}
	args->index = probe;
	return XFS_ERROR(ENOATTR);
}
"
2174,179910,,Local,Not required,Complete,CVE-2015-0274,https://www.cvedetails.com/cve/CVE-2015-0274/,CWE-19,Low,Complete,Complete,,2015-03-16,7.2,"The XFS implementation in the Linux kernel before 3.15 improperly uses an old size value during remote attribute replacement, which allows local users to cause a denial of service (transaction overrun and data corruption) or possibly gain privileges by leveraging XFS filesystem access.",2015-03-26,DoS +Priv ,1,https://github.com/torvalds/linux/commit/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,"xfs: remote attribute overwrite causes transaction overrun

Commit e461fcb (""xfs: remote attribute lookups require the value
length"") passes the remote attribute length in the xfs_da_args
structure on lookup so that CRC calculations and validity checking
can be performed correctly by related code. This, unfortunately has
the side effect of changing the args->valuelen parameter in cases
where it shouldn't.

That is, when we replace a remote attribute, the incoming
replacement stores the value and length in args->value and
args->valuelen, but then the lookup which finds the existing remote
attribute overwrites args->valuelen with the length of the remote
attribute being replaced. Hence when we go to create the new
attribute, we create it of the size of the existing remote
attribute, not the size it is supposed to be. When the new attribute
is much smaller than the old attribute, this results in a
transaction overrun and an ASSERT() failure on a debug kernel:

XFS: Assertion failed: tp->t_blk_res_used <= tp->t_blk_res, file: fs/xfs/xfs_trans.c, line: 331

Fix this by keeping the remote attribute value length separate to
the attribute value length in the xfs_da_args structure. The enables
us to pass the length of the remote attribute to be removed without
overwriting the new attribute's length.

Also, ensure that when we save remote block contexts for a later
rename we zero the original state variables so that we don't confuse
the state of the attribute to be removes with the state of the new
attribute that we just added. [Spotted by Brain Foster.]

Signed-off-by: Dave Chinner <dchinner@redhat.com>
Reviewed-by: Brian Foster <bfoster@redhat.com>
Signed-off-by: Dave Chinner <david@fromorbit.com>",0,fs/xfs/xfs_attr_list.c,"{""sha"": ""abda1124a70f66fbd1a79b28f8eaf5bf1916da1e"", ""filename"": ""fs/xfs/xfs_attr.c"", ""status"": ""modified"", ""additions"": 23, ""deletions"": 1, ""changes"": 24, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -213,7 +213,7 @@ xfs_attr_calc_size(\n \t\t * Out of line attribute, cannot double split, but\n \t\t * make room for the attribute value itself.\n \t\t */\n-\t\tuint\tdblocks = XFS_B_TO_FSB(mp, valuelen);\n+\t\tuint\tdblocks = xfs_attr3_rmt_blocks(mp, valuelen);\n \t\tnblks += dblocks;\n \t\tnblks += XFS_NEXTENTADD_SPACE_RES(mp, dblocks, XFS_ATTR_FORK);\n \t}\n@@ -698,11 +698,22 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)\n \n \t\ttrace_xfs_attr_leaf_replace(args);\n \n+\t\t/* save the attribute state for later removal*/\n \t\targs->op_flags |= XFS_DA_OP_RENAME;\t/* an atomic rename */\n \t\targs->blkno2 = args->blkno;\t\t/* set 2nd entry info*/\n \t\targs->index2 = args->index;\n \t\targs->rmtblkno2 = args->rmtblkno;\n \t\targs->rmtblkcnt2 = args->rmtblkcnt;\n+\t\targs->rmtvaluelen2 = args->rmtvaluelen;\n+\n+\t\t/*\n+\t\t * clear the remote attr state now that it is saved so that the\n+\t\t * values reflect the state of the attribute we are about to\n+\t\t * add, not the attribute we just found and will remove later.\n+\t\t */\n+\t\targs->rmtblkno = 0;\n+\t\targs->rmtblkcnt = 0;\n+\t\targs->rmtvaluelen = 0;\n \t}\n \n \t/*\n@@ -794,6 +805,7 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)\n \t\targs->blkno = args->blkno2;\n \t\targs->rmtblkno = args->rmtblkno2;\n \t\targs->rmtblkcnt = args->rmtblkcnt2;\n+\t\targs->rmtvaluelen = args->rmtvaluelen2;\n \t\tif (args->rmtblkno) {\n \t\t\terror = xfs_attr_rmtval_remove(args);\n \t\t\tif (error)\n@@ -999,13 +1011,22 @@ xfs_attr_node_addname(xfs_da_args_t *args)\n \n \t\ttrace_xfs_attr_node_replace(args);\n \n+\t\t/* save the attribute state for later removal*/\n \t\targs->op_flags |= XFS_DA_OP_RENAME;\t/* atomic rename op */\n \t\targs->blkno2 = args->blkno;\t\t/* set 2nd entry info*/\n \t\targs->index2 = args->index;\n \t\targs->rmtblkno2 = args->rmtblkno;\n \t\targs->rmtblkcnt2 = args->rmtblkcnt;\n+\t\targs->rmtvaluelen2 = args->rmtvaluelen;\n+\n+\t\t/*\n+\t\t * clear the remote attr state now that it is saved so that the\n+\t\t * values reflect the state of the attribute we are about to\n+\t\t * add, not the attribute we just found and will remove later.\n+\t\t */\n \t\targs->rmtblkno = 0;\n \t\targs->rmtblkcnt = 0;\n+\t\targs->rmtvaluelen = 0;\n \t}\n \n \tretval = xfs_attr3_leaf_add(blk->bp, state->args);\n@@ -1133,6 +1154,7 @@ xfs_attr_node_addname(xfs_da_args_t *args)\n \t\targs->blkno = args->blkno2;\n \t\targs->rmtblkno = args->rmtblkno2;\n \t\targs->rmtblkcnt = args->rmtblkcnt2;\n+\t\targs->rmtvaluelen = args->rmtvaluelen2;\n \t\tif (args->rmtblkno) {\n \t\t\terror = xfs_attr_rmtval_remove(args);\n \t\t\tif (error)""}<_**next**_>{""sha"": ""511c283459b19441d782114c4f832207860deab1"", ""filename"": ""fs/xfs/xfs_attr_leaf.c"", ""status"": ""modified"", ""additions"": 11, ""deletions"": 10, ""changes"": 21, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_leaf.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_leaf.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_leaf.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -1229,6 +1229,7 @@ xfs_attr3_leaf_add_work(\n \t\tname_rmt->valueblk = 0;\n \t\targs->rmtblkno = 1;\n \t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);\n+\t\targs->rmtvaluelen = args->valuelen;\n \t}\n \txfs_trans_log_buf(args->trans, bp,\n \t     XFS_DA_LOGRANGE(leaf, xfs_attr3_leaf_name(leaf, args->index),\n@@ -2167,11 +2168,11 @@ xfs_attr3_leaf_lookup_int(\n \t\t\tif (!xfs_attr_namesp_match(args->flags, entry->flags))\n \t\t\t\tcontinue;\n \t\t\targs->index = probe;\n-\t\t\targs->valuelen = be32_to_cpu(name_rmt->valuelen);\n+\t\t\targs->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);\n \t\t\targs->rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(\n \t\t\t\t\t\t\targs->dp->i_mount,\n-\t\t\t\t\t\t\targs->valuelen);\n+\t\t\t\t\t\t\targs->rmtvaluelen);\n \t\t\treturn XFS_ERROR(EEXIST);\n \t\t}\n \t}\n@@ -2220,19 +2221,19 @@ xfs_attr3_leaf_getvalue(\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);\n \t\tASSERT(name_rmt->namelen == args->namelen);\n \t\tASSERT(memcmp(args->name, name_rmt->name, args->namelen) == 0);\n-\t\tvaluelen = be32_to_cpu(name_rmt->valuelen);\n+\t\targs->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);\n \t\targs->rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(args->dp->i_mount,\n-\t\t\t\t\t\t       valuelen);\n+\t\t\t\t\t\t       args->rmtvaluelen);\n \t\tif (args->flags & ATTR_KERNOVAL) {\n-\t\t\targs->valuelen = valuelen;\n+\t\t\targs->valuelen = args->rmtvaluelen;\n \t\t\treturn 0;\n \t\t}\n-\t\tif (args->valuelen < valuelen) {\n-\t\t\targs->valuelen = valuelen;\n+\t\tif (args->valuelen < args->rmtvaluelen) {\n+\t\t\targs->valuelen = args->rmtvaluelen;\n \t\t\treturn XFS_ERROR(ERANGE);\n \t\t}\n-\t\targs->valuelen = valuelen;\n+\t\targs->valuelen = args->rmtvaluelen;\n \t}\n \treturn 0;\n }\n@@ -2519,7 +2520,7 @@ xfs_attr3_leaf_clearflag(\n \t\tASSERT((entry->flags & XFS_ATTR_LOCAL) == 0);\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);\n \t\tname_rmt->valueblk = cpu_to_be32(args->rmtblkno);\n-\t\tname_rmt->valuelen = cpu_to_be32(args->valuelen);\n+\t\tname_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);\n \t\txfs_trans_log_buf(args->trans, bp,\n \t\t\t XFS_DA_LOGRANGE(leaf, name_rmt, sizeof(*name_rmt)));\n \t}\n@@ -2677,7 +2678,7 @@ xfs_attr3_leaf_flipflags(\n \t\tASSERT((entry1->flags & XFS_ATTR_LOCAL) == 0);\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf1, args->index);\n \t\tname_rmt->valueblk = cpu_to_be32(args->rmtblkno);\n-\t\tname_rmt->valuelen = cpu_to_be32(args->valuelen);\n+\t\tname_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);\n \t\txfs_trans_log_buf(args->trans, bp1,\n \t\t\t XFS_DA_LOGRANGE(leaf1, name_rmt, sizeof(*name_rmt)));\n \t}""}<_**next**_>{""sha"": ""833fe5d98d806783ca6bb6cf2f4ecb83424bfdca"", ""filename"": ""fs/xfs/xfs_attr_list.c"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 0, ""changes"": 1, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_list.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_list.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_list.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -447,6 +447,7 @@ xfs_attr3_leaf_list_int(\n \t\t\t\targs.dp = context->dp;\n \t\t\t\targs.whichfork = XFS_ATTR_FORK;\n \t\t\t\targs.valuelen = valuelen;\n+\t\t\t\targs.rmtvaluelen = valuelen;\n \t\t\t\targs.value = kmem_alloc(valuelen, KM_SLEEP | KM_NOFS);\n \t\t\t\targs.rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\t\t\targs.rmtblkcnt = xfs_attr3_rmt_blocks(""}<_**next**_>{""sha"": ""d2e6e948cec7be3013b853033b6e1a64b365a682"", ""filename"": ""fs/xfs/xfs_attr_remote.c"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 3, ""changes"": 8, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_remote.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_remote.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_remote.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -337,7 +337,7 @@ xfs_attr_rmtval_get(\n \tstruct xfs_buf\t\t*bp;\n \txfs_dablk_t\t\tlblkno = args->rmtblkno;\n \t__uint8_t\t\t*dst = args->value;\n-\tint\t\t\tvaluelen = args->valuelen;\n+\tint\t\t\tvaluelen;\n \tint\t\t\tnmap;\n \tint\t\t\terror;\n \tint\t\t\tblkcnt = args->rmtblkcnt;\n@@ -347,7 +347,9 @@ xfs_attr_rmtval_get(\n \ttrace_xfs_attr_rmtval_get(args);\n \n \tASSERT(!(args->flags & ATTR_KERNOVAL));\n+\tASSERT(args->rmtvaluelen == args->valuelen);\n \n+\tvaluelen = args->rmtvaluelen;\n \twhile (valuelen > 0) {\n \t\tnmap = ATTR_RMTVALUE_MAPSIZE;\n \t\terror = xfs_bmapi_read(args->dp, (xfs_fileoff_t)lblkno,\n@@ -415,7 +417,7 @@ xfs_attr_rmtval_set(\n \t * attributes have headers, we can't just do a straight byte to FSB\n \t * conversion and have to take the header space into account.\n \t */\n-\tblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);\n+\tblkcnt = xfs_attr3_rmt_blocks(mp, args->rmtvaluelen);\n \terror = xfs_bmap_first_unused(args->trans, args->dp, blkcnt, &lfileoff,\n \t\t\t\t\t\t   XFS_ATTR_FORK);\n \tif (error)\n@@ -480,7 +482,7 @@ xfs_attr_rmtval_set(\n \t */\n \tlblkno = args->rmtblkno;\n \tblkcnt = args->rmtblkcnt;\n-\tvaluelen = args->valuelen;\n+\tvaluelen = args->rmtvaluelen;\n \twhile (valuelen > 0) {\n \t\tstruct xfs_buf\t*bp;\n \t\txfs_daddr_t\tdblkno;""}<_**next**_>{""sha"": ""201c6091d26abfa2e38dd17fd960e3efcb69bcd7"", ""filename"": ""fs/xfs/xfs_da_btree.h"", ""status"": ""modified"", ""additions"": 2, ""deletions"": 0, ""changes"": 2, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_da_btree.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_da_btree.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_da_btree.h?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -60,10 +60,12 @@ typedef struct xfs_da_args {\n \tint\t\tindex;\t\t/* index of attr of interest in blk */\n \txfs_dablk_t\trmtblkno;\t/* remote attr value starting blkno */\n \tint\t\trmtblkcnt;\t/* remote attr value block count */\n+\tint\t\trmtvaluelen;\t/* remote attr value length in bytes */\n \txfs_dablk_t\tblkno2;\t\t/* blkno of 2nd attr leaf of interest */\n \tint\t\tindex2;\t\t/* index of 2nd attr in blk */\n \txfs_dablk_t\trmtblkno2;\t/* remote attr value starting blkno */\n \tint\t\trmtblkcnt2;\t/* remote attr value block count */\n+\tint\t\trmtvaluelen2;\t/* remote attr value length in bytes */\n \tint\t\top_flags;\t/* operation flags */\n \tenum xfs_dacmp\tcmpresult;\t/* name compare result for lookups */\n } xfs_da_args_t;""}","xfs_attr3_leaf_list_int(
	struct xfs_buf			*bp,
	struct xfs_attr_list_context	*context)
{
	struct attrlist_cursor_kern	*cursor;
	struct xfs_attr_leafblock	*leaf;
	struct xfs_attr3_icleaf_hdr	ichdr;
	struct xfs_attr_leaf_entry	*entries;
	struct xfs_attr_leaf_entry	*entry;
	int				retval;
	int				i;

	trace_xfs_attr_list_leaf(context);

	leaf = bp->b_addr;
	xfs_attr3_leaf_hdr_from_disk(&ichdr, leaf);
	entries = xfs_attr3_leaf_entryp(leaf);

	cursor = context->cursor;
	cursor->initted = 1;

	/*
	 * Re-find our place in the leaf block if this is a new syscall.
	 */
	if (context->resynch) {
		entry = &entries[0];
		for (i = 0; i < ichdr.count; entry++, i++) {
			if (be32_to_cpu(entry->hashval) == cursor->hashval) {
				if (cursor->offset == context->dupcnt) {
					context->dupcnt = 0;
					break;
				}
				context->dupcnt++;
			} else if (be32_to_cpu(entry->hashval) >
					cursor->hashval) {
				context->dupcnt = 0;
				break;
			}
		}
		if (i == ichdr.count) {
			trace_xfs_attr_list_notfound(context);
			return 0;
		}
	} else {
		entry = &entries[0];
		i = 0;
	}
	context->resynch = 0;

	/*
	 * We have found our place, start copying out the new attributes.
	 */
	retval = 0;
	for (; i < ichdr.count; entry++, i++) {
		if (be32_to_cpu(entry->hashval) != cursor->hashval) {
			cursor->hashval = be32_to_cpu(entry->hashval);
			cursor->offset = 0;
		}

		if (entry->flags & XFS_ATTR_INCOMPLETE)
			continue;		/* skip incomplete entries */

		if (entry->flags & XFS_ATTR_LOCAL) {
			xfs_attr_leaf_name_local_t *name_loc =
				xfs_attr3_leaf_name_local(leaf, i);

			retval = context->put_listent(context,
						entry->flags,
						name_loc->nameval,
						(int)name_loc->namelen,
						be16_to_cpu(name_loc->valuelen),
						&name_loc->nameval[name_loc->namelen]);
			if (retval)
				return retval;
		} else {
			xfs_attr_leaf_name_remote_t *name_rmt =
				xfs_attr3_leaf_name_remote(leaf, i);

			int valuelen = be32_to_cpu(name_rmt->valuelen);

			if (context->put_value) {
				xfs_da_args_t args;

				memset((char *)&args, 0, sizeof(args));
 				args.dp = context->dp;
 				args.whichfork = XFS_ATTR_FORK;
 				args.valuelen = valuelen;
				args.rmtvaluelen = valuelen;
 				args.value = kmem_alloc(valuelen, KM_SLEEP | KM_NOFS);
 				args.rmtblkno = be32_to_cpu(name_rmt->valueblk);
 				args.rmtblkcnt = xfs_attr3_rmt_blocks(
							args.dp->i_mount, valuelen);
				retval = xfs_attr_rmtval_get(&args);
				if (retval)
					return retval;
				retval = context->put_listent(context,
						entry->flags,
						name_rmt->name,
						(int)name_rmt->namelen,
						valuelen,
						args.value);
				kmem_free(args.value);
			} else {
				retval = context->put_listent(context,
						entry->flags,
						name_rmt->name,
						(int)name_rmt->namelen,
						valuelen,
						NULL);
			}
			if (retval)
				return retval;
		}
		if (context->seen_enough)
			break;
		cursor->offset++;
	}
	trace_xfs_attr_list_leaf_end(context);
	return retval;
}
","xfs_attr3_leaf_list_int(
	struct xfs_buf			*bp,
	struct xfs_attr_list_context	*context)
{
	struct attrlist_cursor_kern	*cursor;
	struct xfs_attr_leafblock	*leaf;
	struct xfs_attr3_icleaf_hdr	ichdr;
	struct xfs_attr_leaf_entry	*entries;
	struct xfs_attr_leaf_entry	*entry;
	int				retval;
	int				i;

	trace_xfs_attr_list_leaf(context);

	leaf = bp->b_addr;
	xfs_attr3_leaf_hdr_from_disk(&ichdr, leaf);
	entries = xfs_attr3_leaf_entryp(leaf);

	cursor = context->cursor;
	cursor->initted = 1;

	/*
	 * Re-find our place in the leaf block if this is a new syscall.
	 */
	if (context->resynch) {
		entry = &entries[0];
		for (i = 0; i < ichdr.count; entry++, i++) {
			if (be32_to_cpu(entry->hashval) == cursor->hashval) {
				if (cursor->offset == context->dupcnt) {
					context->dupcnt = 0;
					break;
				}
				context->dupcnt++;
			} else if (be32_to_cpu(entry->hashval) >
					cursor->hashval) {
				context->dupcnt = 0;
				break;
			}
		}
		if (i == ichdr.count) {
			trace_xfs_attr_list_notfound(context);
			return 0;
		}
	} else {
		entry = &entries[0];
		i = 0;
	}
	context->resynch = 0;

	/*
	 * We have found our place, start copying out the new attributes.
	 */
	retval = 0;
	for (; i < ichdr.count; entry++, i++) {
		if (be32_to_cpu(entry->hashval) != cursor->hashval) {
			cursor->hashval = be32_to_cpu(entry->hashval);
			cursor->offset = 0;
		}

		if (entry->flags & XFS_ATTR_INCOMPLETE)
			continue;		/* skip incomplete entries */

		if (entry->flags & XFS_ATTR_LOCAL) {
			xfs_attr_leaf_name_local_t *name_loc =
				xfs_attr3_leaf_name_local(leaf, i);

			retval = context->put_listent(context,
						entry->flags,
						name_loc->nameval,
						(int)name_loc->namelen,
						be16_to_cpu(name_loc->valuelen),
						&name_loc->nameval[name_loc->namelen]);
			if (retval)
				return retval;
		} else {
			xfs_attr_leaf_name_remote_t *name_rmt =
				xfs_attr3_leaf_name_remote(leaf, i);

			int valuelen = be32_to_cpu(name_rmt->valuelen);

			if (context->put_value) {
				xfs_da_args_t args;

				memset((char *)&args, 0, sizeof(args));
 				args.dp = context->dp;
 				args.whichfork = XFS_ATTR_FORK;
 				args.valuelen = valuelen;
 				args.value = kmem_alloc(valuelen, KM_SLEEP | KM_NOFS);
 				args.rmtblkno = be32_to_cpu(name_rmt->valueblk);
 				args.rmtblkcnt = xfs_attr3_rmt_blocks(
							args.dp->i_mount, valuelen);
				retval = xfs_attr_rmtval_get(&args);
				if (retval)
					return retval;
				retval = context->put_listent(context,
						entry->flags,
						name_rmt->name,
						(int)name_rmt->namelen,
						valuelen,
						args.value);
				kmem_free(args.value);
			} else {
				retval = context->put_listent(context,
						entry->flags,
						name_rmt->name,
						(int)name_rmt->namelen,
						valuelen,
						NULL);
			}
			if (retval)
				return retval;
		}
		if (context->seen_enough)
			break;
		cursor->offset++;
	}
	trace_xfs_attr_list_leaf_end(context);
	return retval;
}
",C,"				args.rmtvaluelen = valuelen;
",,,"@@ -447,6 +447,7 @@ xfs_attr3_leaf_list_int(
 				args.dp = context->dp;
 				args.whichfork = XFS_ATTR_FORK;
 				args.valuelen = valuelen;
+				args.rmtvaluelen = valuelen;
 				args.value = kmem_alloc(valuelen, KM_SLEEP | KM_NOFS);
 				args.rmtblkno = be32_to_cpu(name_rmt->valueblk);
 				args.rmtblkcnt = xfs_attr3_rmt_blocks(",linux,8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,d540e43b0ab134b22f015f725ce6e070d12b0244,1,"xfs_attr3_leaf_list_int(
	struct xfs_buf			*bp,
	struct xfs_attr_list_context	*context)
{
	struct attrlist_cursor_kern	*cursor;
	struct xfs_attr_leafblock	*leaf;
	struct xfs_attr3_icleaf_hdr	ichdr;
	struct xfs_attr_leaf_entry	*entries;
	struct xfs_attr_leaf_entry	*entry;
	int				retval;
	int				i;

	trace_xfs_attr_list_leaf(context);

	leaf = bp->b_addr;
	xfs_attr3_leaf_hdr_from_disk(&ichdr, leaf);
	entries = xfs_attr3_leaf_entryp(leaf);

	cursor = context->cursor;
	cursor->initted = 1;

	/*
	 * Re-find our place in the leaf block if this is a new syscall.
	 */
	if (context->resynch) {
		entry = &entries[0];
		for (i = 0; i < ichdr.count; entry++, i++) {
			if (be32_to_cpu(entry->hashval) == cursor->hashval) {
				if (cursor->offset == context->dupcnt) {
					context->dupcnt = 0;
					break;
				}
				context->dupcnt++;
			} else if (be32_to_cpu(entry->hashval) >
					cursor->hashval) {
				context->dupcnt = 0;
				break;
			}
		}
		if (i == ichdr.count) {
			trace_xfs_attr_list_notfound(context);
			return 0;
		}
	} else {
		entry = &entries[0];
		i = 0;
	}
	context->resynch = 0;

	/*
	 * We have found our place, start copying out the new attributes.
	 */
	retval = 0;
	for (; i < ichdr.count; entry++, i++) {
		if (be32_to_cpu(entry->hashval) != cursor->hashval) {
			cursor->hashval = be32_to_cpu(entry->hashval);
			cursor->offset = 0;
		}

		if (entry->flags & XFS_ATTR_INCOMPLETE)
			continue;		/* skip incomplete entries */

		if (entry->flags & XFS_ATTR_LOCAL) {
			xfs_attr_leaf_name_local_t *name_loc =
				xfs_attr3_leaf_name_local(leaf, i);

			retval = context->put_listent(context,
						entry->flags,
						name_loc->nameval,
						(int)name_loc->namelen,
						be16_to_cpu(name_loc->valuelen),
						&name_loc->nameval[name_loc->namelen]);
			if (retval)
				return retval;
		} else {
			xfs_attr_leaf_name_remote_t *name_rmt =
				xfs_attr3_leaf_name_remote(leaf, i);

			int valuelen = be32_to_cpu(name_rmt->valuelen);

			if (context->put_value) {
				xfs_da_args_t args;

				memset((char *)&args, 0, sizeof(args));
 				args.dp = context->dp;
 				args.whichfork = XFS_ATTR_FORK;
 				args.valuelen = valuelen;
//fix_flaw_line_below:
//				args.rmtvaluelen = valuelen;
 				args.value = kmem_alloc(valuelen, KM_SLEEP | KM_NOFS);
 				args.rmtblkno = be32_to_cpu(name_rmt->valueblk);
 				args.rmtblkcnt = xfs_attr3_rmt_blocks(
							args.dp->i_mount, valuelen);
				retval = xfs_attr_rmtval_get(&args);
				if (retval)
					return retval;
				retval = context->put_listent(context,
						entry->flags,
						name_rmt->name,
						(int)name_rmt->namelen,
						valuelen,
						args.value);
				kmem_free(args.value);
			} else {
				retval = context->put_listent(context,
						entry->flags,
						name_rmt->name,
						(int)name_rmt->namelen,
						valuelen,
						NULL);
			}
			if (retval)
				return retval;
		}
		if (context->seen_enough)
			break;
		cursor->offset++;
	}
	trace_xfs_attr_list_leaf_end(context);
	return retval;
}
"
2175,179911,,Local,Not required,Complete,CVE-2015-0274,https://www.cvedetails.com/cve/CVE-2015-0274/,CWE-19,Low,Complete,Complete,,2015-03-16,7.2,"The XFS implementation in the Linux kernel before 3.15 improperly uses an old size value during remote attribute replacement, which allows local users to cause a denial of service (transaction overrun and data corruption) or possibly gain privileges by leveraging XFS filesystem access.",2015-03-26,DoS +Priv ,3,https://github.com/torvalds/linux/commit/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,"xfs: remote attribute overwrite causes transaction overrun

Commit e461fcb (""xfs: remote attribute lookups require the value
length"") passes the remote attribute length in the xfs_da_args
structure on lookup so that CRC calculations and validity checking
can be performed correctly by related code. This, unfortunately has
the side effect of changing the args->valuelen parameter in cases
where it shouldn't.

That is, when we replace a remote attribute, the incoming
replacement stores the value and length in args->value and
args->valuelen, but then the lookup which finds the existing remote
attribute overwrites args->valuelen with the length of the remote
attribute being replaced. Hence when we go to create the new
attribute, we create it of the size of the existing remote
attribute, not the size it is supposed to be. When the new attribute
is much smaller than the old attribute, this results in a
transaction overrun and an ASSERT() failure on a debug kernel:

XFS: Assertion failed: tp->t_blk_res_used <= tp->t_blk_res, file: fs/xfs/xfs_trans.c, line: 331

Fix this by keeping the remote attribute value length separate to
the attribute value length in the xfs_da_args structure. The enables
us to pass the length of the remote attribute to be removed without
overwriting the new attribute's length.

Also, ensure that when we save remote block contexts for a later
rename we zero the original state variables so that we don't confuse
the state of the attribute to be removes with the state of the new
attribute that we just added. [Spotted by Brain Foster.]

Signed-off-by: Dave Chinner <dchinner@redhat.com>
Reviewed-by: Brian Foster <bfoster@redhat.com>
Signed-off-by: Dave Chinner <david@fromorbit.com>",1,fs/xfs/xfs_attr_remote.c,"{""sha"": ""abda1124a70f66fbd1a79b28f8eaf5bf1916da1e"", ""filename"": ""fs/xfs/xfs_attr.c"", ""status"": ""modified"", ""additions"": 23, ""deletions"": 1, ""changes"": 24, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -213,7 +213,7 @@ xfs_attr_calc_size(\n \t\t * Out of line attribute, cannot double split, but\n \t\t * make room for the attribute value itself.\n \t\t */\n-\t\tuint\tdblocks = XFS_B_TO_FSB(mp, valuelen);\n+\t\tuint\tdblocks = xfs_attr3_rmt_blocks(mp, valuelen);\n \t\tnblks += dblocks;\n \t\tnblks += XFS_NEXTENTADD_SPACE_RES(mp, dblocks, XFS_ATTR_FORK);\n \t}\n@@ -698,11 +698,22 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)\n \n \t\ttrace_xfs_attr_leaf_replace(args);\n \n+\t\t/* save the attribute state for later removal*/\n \t\targs->op_flags |= XFS_DA_OP_RENAME;\t/* an atomic rename */\n \t\targs->blkno2 = args->blkno;\t\t/* set 2nd entry info*/\n \t\targs->index2 = args->index;\n \t\targs->rmtblkno2 = args->rmtblkno;\n \t\targs->rmtblkcnt2 = args->rmtblkcnt;\n+\t\targs->rmtvaluelen2 = args->rmtvaluelen;\n+\n+\t\t/*\n+\t\t * clear the remote attr state now that it is saved so that the\n+\t\t * values reflect the state of the attribute we are about to\n+\t\t * add, not the attribute we just found and will remove later.\n+\t\t */\n+\t\targs->rmtblkno = 0;\n+\t\targs->rmtblkcnt = 0;\n+\t\targs->rmtvaluelen = 0;\n \t}\n \n \t/*\n@@ -794,6 +805,7 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)\n \t\targs->blkno = args->blkno2;\n \t\targs->rmtblkno = args->rmtblkno2;\n \t\targs->rmtblkcnt = args->rmtblkcnt2;\n+\t\targs->rmtvaluelen = args->rmtvaluelen2;\n \t\tif (args->rmtblkno) {\n \t\t\terror = xfs_attr_rmtval_remove(args);\n \t\t\tif (error)\n@@ -999,13 +1011,22 @@ xfs_attr_node_addname(xfs_da_args_t *args)\n \n \t\ttrace_xfs_attr_node_replace(args);\n \n+\t\t/* save the attribute state for later removal*/\n \t\targs->op_flags |= XFS_DA_OP_RENAME;\t/* atomic rename op */\n \t\targs->blkno2 = args->blkno;\t\t/* set 2nd entry info*/\n \t\targs->index2 = args->index;\n \t\targs->rmtblkno2 = args->rmtblkno;\n \t\targs->rmtblkcnt2 = args->rmtblkcnt;\n+\t\targs->rmtvaluelen2 = args->rmtvaluelen;\n+\n+\t\t/*\n+\t\t * clear the remote attr state now that it is saved so that the\n+\t\t * values reflect the state of the attribute we are about to\n+\t\t * add, not the attribute we just found and will remove later.\n+\t\t */\n \t\targs->rmtblkno = 0;\n \t\targs->rmtblkcnt = 0;\n+\t\targs->rmtvaluelen = 0;\n \t}\n \n \tretval = xfs_attr3_leaf_add(blk->bp, state->args);\n@@ -1133,6 +1154,7 @@ xfs_attr_node_addname(xfs_da_args_t *args)\n \t\targs->blkno = args->blkno2;\n \t\targs->rmtblkno = args->rmtblkno2;\n \t\targs->rmtblkcnt = args->rmtblkcnt2;\n+\t\targs->rmtvaluelen = args->rmtvaluelen2;\n \t\tif (args->rmtblkno) {\n \t\t\terror = xfs_attr_rmtval_remove(args);\n \t\t\tif (error)""}<_**next**_>{""sha"": ""511c283459b19441d782114c4f832207860deab1"", ""filename"": ""fs/xfs/xfs_attr_leaf.c"", ""status"": ""modified"", ""additions"": 11, ""deletions"": 10, ""changes"": 21, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_leaf.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_leaf.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_leaf.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -1229,6 +1229,7 @@ xfs_attr3_leaf_add_work(\n \t\tname_rmt->valueblk = 0;\n \t\targs->rmtblkno = 1;\n \t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);\n+\t\targs->rmtvaluelen = args->valuelen;\n \t}\n \txfs_trans_log_buf(args->trans, bp,\n \t     XFS_DA_LOGRANGE(leaf, xfs_attr3_leaf_name(leaf, args->index),\n@@ -2167,11 +2168,11 @@ xfs_attr3_leaf_lookup_int(\n \t\t\tif (!xfs_attr_namesp_match(args->flags, entry->flags))\n \t\t\t\tcontinue;\n \t\t\targs->index = probe;\n-\t\t\targs->valuelen = be32_to_cpu(name_rmt->valuelen);\n+\t\t\targs->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);\n \t\t\targs->rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(\n \t\t\t\t\t\t\targs->dp->i_mount,\n-\t\t\t\t\t\t\targs->valuelen);\n+\t\t\t\t\t\t\targs->rmtvaluelen);\n \t\t\treturn XFS_ERROR(EEXIST);\n \t\t}\n \t}\n@@ -2220,19 +2221,19 @@ xfs_attr3_leaf_getvalue(\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);\n \t\tASSERT(name_rmt->namelen == args->namelen);\n \t\tASSERT(memcmp(args->name, name_rmt->name, args->namelen) == 0);\n-\t\tvaluelen = be32_to_cpu(name_rmt->valuelen);\n+\t\targs->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);\n \t\targs->rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(args->dp->i_mount,\n-\t\t\t\t\t\t       valuelen);\n+\t\t\t\t\t\t       args->rmtvaluelen);\n \t\tif (args->flags & ATTR_KERNOVAL) {\n-\t\t\targs->valuelen = valuelen;\n+\t\t\targs->valuelen = args->rmtvaluelen;\n \t\t\treturn 0;\n \t\t}\n-\t\tif (args->valuelen < valuelen) {\n-\t\t\targs->valuelen = valuelen;\n+\t\tif (args->valuelen < args->rmtvaluelen) {\n+\t\t\targs->valuelen = args->rmtvaluelen;\n \t\t\treturn XFS_ERROR(ERANGE);\n \t\t}\n-\t\targs->valuelen = valuelen;\n+\t\targs->valuelen = args->rmtvaluelen;\n \t}\n \treturn 0;\n }\n@@ -2519,7 +2520,7 @@ xfs_attr3_leaf_clearflag(\n \t\tASSERT((entry->flags & XFS_ATTR_LOCAL) == 0);\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);\n \t\tname_rmt->valueblk = cpu_to_be32(args->rmtblkno);\n-\t\tname_rmt->valuelen = cpu_to_be32(args->valuelen);\n+\t\tname_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);\n \t\txfs_trans_log_buf(args->trans, bp,\n \t\t\t XFS_DA_LOGRANGE(leaf, name_rmt, sizeof(*name_rmt)));\n \t}\n@@ -2677,7 +2678,7 @@ xfs_attr3_leaf_flipflags(\n \t\tASSERT((entry1->flags & XFS_ATTR_LOCAL) == 0);\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf1, args->index);\n \t\tname_rmt->valueblk = cpu_to_be32(args->rmtblkno);\n-\t\tname_rmt->valuelen = cpu_to_be32(args->valuelen);\n+\t\tname_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);\n \t\txfs_trans_log_buf(args->trans, bp1,\n \t\t\t XFS_DA_LOGRANGE(leaf1, name_rmt, sizeof(*name_rmt)));\n \t}""}<_**next**_>{""sha"": ""833fe5d98d806783ca6bb6cf2f4ecb83424bfdca"", ""filename"": ""fs/xfs/xfs_attr_list.c"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 0, ""changes"": 1, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_list.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_list.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_list.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -447,6 +447,7 @@ xfs_attr3_leaf_list_int(\n \t\t\t\targs.dp = context->dp;\n \t\t\t\targs.whichfork = XFS_ATTR_FORK;\n \t\t\t\targs.valuelen = valuelen;\n+\t\t\t\targs.rmtvaluelen = valuelen;\n \t\t\t\targs.value = kmem_alloc(valuelen, KM_SLEEP | KM_NOFS);\n \t\t\t\targs.rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\t\t\targs.rmtblkcnt = xfs_attr3_rmt_blocks(""}<_**next**_>{""sha"": ""d2e6e948cec7be3013b853033b6e1a64b365a682"", ""filename"": ""fs/xfs/xfs_attr_remote.c"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 3, ""changes"": 8, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_remote.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_remote.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_remote.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -337,7 +337,7 @@ xfs_attr_rmtval_get(\n \tstruct xfs_buf\t\t*bp;\n \txfs_dablk_t\t\tlblkno = args->rmtblkno;\n \t__uint8_t\t\t*dst = args->value;\n-\tint\t\t\tvaluelen = args->valuelen;\n+\tint\t\t\tvaluelen;\n \tint\t\t\tnmap;\n \tint\t\t\terror;\n \tint\t\t\tblkcnt = args->rmtblkcnt;\n@@ -347,7 +347,9 @@ xfs_attr_rmtval_get(\n \ttrace_xfs_attr_rmtval_get(args);\n \n \tASSERT(!(args->flags & ATTR_KERNOVAL));\n+\tASSERT(args->rmtvaluelen == args->valuelen);\n \n+\tvaluelen = args->rmtvaluelen;\n \twhile (valuelen > 0) {\n \t\tnmap = ATTR_RMTVALUE_MAPSIZE;\n \t\terror = xfs_bmapi_read(args->dp, (xfs_fileoff_t)lblkno,\n@@ -415,7 +417,7 @@ xfs_attr_rmtval_set(\n \t * attributes have headers, we can't just do a straight byte to FSB\n \t * conversion and have to take the header space into account.\n \t */\n-\tblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);\n+\tblkcnt = xfs_attr3_rmt_blocks(mp, args->rmtvaluelen);\n \terror = xfs_bmap_first_unused(args->trans, args->dp, blkcnt, &lfileoff,\n \t\t\t\t\t\t   XFS_ATTR_FORK);\n \tif (error)\n@@ -480,7 +482,7 @@ xfs_attr_rmtval_set(\n \t */\n \tlblkno = args->rmtblkno;\n \tblkcnt = args->rmtblkcnt;\n-\tvaluelen = args->valuelen;\n+\tvaluelen = args->rmtvaluelen;\n \twhile (valuelen > 0) {\n \t\tstruct xfs_buf\t*bp;\n \t\txfs_daddr_t\tdblkno;""}<_**next**_>{""sha"": ""201c6091d26abfa2e38dd17fd960e3efcb69bcd7"", ""filename"": ""fs/xfs/xfs_da_btree.h"", ""status"": ""modified"", ""additions"": 2, ""deletions"": 0, ""changes"": 2, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_da_btree.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_da_btree.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_da_btree.h?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -60,10 +60,12 @@ typedef struct xfs_da_args {\n \tint\t\tindex;\t\t/* index of attr of interest in blk */\n \txfs_dablk_t\trmtblkno;\t/* remote attr value starting blkno */\n \tint\t\trmtblkcnt;\t/* remote attr value block count */\n+\tint\t\trmtvaluelen;\t/* remote attr value length in bytes */\n \txfs_dablk_t\tblkno2;\t\t/* blkno of 2nd attr leaf of interest */\n \tint\t\tindex2;\t\t/* index of 2nd attr in blk */\n \txfs_dablk_t\trmtblkno2;\t/* remote attr value starting blkno */\n \tint\t\trmtblkcnt2;\t/* remote attr value block count */\n+\tint\t\trmtvaluelen2;\t/* remote attr value length in bytes */\n \tint\t\top_flags;\t/* operation flags */\n \tenum xfs_dacmp\tcmpresult;\t/* name compare result for lookups */\n } xfs_da_args_t;""}","xfs_attr_rmtval_get(
	struct xfs_da_args	*args)
{
	struct xfs_bmbt_irec	map[ATTR_RMTVALUE_MAPSIZE];
	struct xfs_mount	*mp = args->dp->i_mount;
 	struct xfs_buf		*bp;
 	xfs_dablk_t		lblkno = args->rmtblkno;
 	__uint8_t		*dst = args->value;
	int			valuelen;
 	int			nmap;
 	int			error;
 	int			blkcnt = args->rmtblkcnt;
	int			i;
	int			offset = 0;

 	trace_xfs_attr_rmtval_get(args);
 
 	ASSERT(!(args->flags & ATTR_KERNOVAL));
	ASSERT(args->rmtvaluelen == args->valuelen);
 
	valuelen = args->rmtvaluelen;
 	while (valuelen > 0) {
 		nmap = ATTR_RMTVALUE_MAPSIZE;
 		error = xfs_bmapi_read(args->dp, (xfs_fileoff_t)lblkno,
				       blkcnt, map, &nmap,
				       XFS_BMAPI_ATTRFORK);
		if (error)
			return error;
		ASSERT(nmap >= 1);

		for (i = 0; (i < nmap) && (valuelen > 0); i++) {
			xfs_daddr_t	dblkno;
			int		dblkcnt;

			ASSERT((map[i].br_startblock != DELAYSTARTBLOCK) &&
			       (map[i].br_startblock != HOLESTARTBLOCK));
			dblkno = XFS_FSB_TO_DADDR(mp, map[i].br_startblock);
			dblkcnt = XFS_FSB_TO_BB(mp, map[i].br_blockcount);
			error = xfs_trans_read_buf(mp, NULL, mp->m_ddev_targp,
						   dblkno, dblkcnt, 0, &bp,
						   &xfs_attr3_rmt_buf_ops);
			if (error)
				return error;

			error = xfs_attr_rmtval_copyout(mp, bp, args->dp->i_ino,
							&offset, &valuelen,
							&dst);
			xfs_buf_relse(bp);
			if (error)
				return error;

			/* roll attribute extent map forwards */
			lblkno += map[i].br_blockcount;
			blkcnt -= map[i].br_blockcount;
		}
	}
	ASSERT(valuelen == 0);
	return 0;
}
","xfs_attr_rmtval_get(
	struct xfs_da_args	*args)
{
	struct xfs_bmbt_irec	map[ATTR_RMTVALUE_MAPSIZE];
	struct xfs_mount	*mp = args->dp->i_mount;
 	struct xfs_buf		*bp;
 	xfs_dablk_t		lblkno = args->rmtblkno;
 	__uint8_t		*dst = args->value;
	int			valuelen = args->valuelen;
 	int			nmap;
 	int			error;
 	int			blkcnt = args->rmtblkcnt;
	int			i;
	int			offset = 0;

 	trace_xfs_attr_rmtval_get(args);
 
 	ASSERT(!(args->flags & ATTR_KERNOVAL));
 
 	while (valuelen > 0) {
 		nmap = ATTR_RMTVALUE_MAPSIZE;
 		error = xfs_bmapi_read(args->dp, (xfs_fileoff_t)lblkno,
				       blkcnt, map, &nmap,
				       XFS_BMAPI_ATTRFORK);
		if (error)
			return error;
		ASSERT(nmap >= 1);

		for (i = 0; (i < nmap) && (valuelen > 0); i++) {
			xfs_daddr_t	dblkno;
			int		dblkcnt;

			ASSERT((map[i].br_startblock != DELAYSTARTBLOCK) &&
			       (map[i].br_startblock != HOLESTARTBLOCK));
			dblkno = XFS_FSB_TO_DADDR(mp, map[i].br_startblock);
			dblkcnt = XFS_FSB_TO_BB(mp, map[i].br_blockcount);
			error = xfs_trans_read_buf(mp, NULL, mp->m_ddev_targp,
						   dblkno, dblkcnt, 0, &bp,
						   &xfs_attr3_rmt_buf_ops);
			if (error)
				return error;

			error = xfs_attr_rmtval_copyout(mp, bp, args->dp->i_ino,
							&offset, &valuelen,
							&dst);
			xfs_buf_relse(bp);
			if (error)
				return error;

			/* roll attribute extent map forwards */
			lblkno += map[i].br_blockcount;
			blkcnt -= map[i].br_blockcount;
		}
	}
	ASSERT(valuelen == 0);
	return 0;
}
",C,"	int			valuelen;
	ASSERT(args->rmtvaluelen == args->valuelen);
	valuelen = args->rmtvaluelen;
","	int			valuelen = args->valuelen;
",,"@@ -337,7 +337,7 @@ xfs_attr_rmtval_get(
 	struct xfs_buf		*bp;
 	xfs_dablk_t		lblkno = args->rmtblkno;
 	__uint8_t		*dst = args->value;
-	int			valuelen = args->valuelen;
+	int			valuelen;
 	int			nmap;
 	int			error;
 	int			blkcnt = args->rmtblkcnt;
@@ -347,7 +347,9 @@ xfs_attr_rmtval_get(
 	trace_xfs_attr_rmtval_get(args);
 
 	ASSERT(!(args->flags & ATTR_KERNOVAL));
+	ASSERT(args->rmtvaluelen == args->valuelen);
 
+	valuelen = args->rmtvaluelen;
 	while (valuelen > 0) {
 		nmap = ATTR_RMTVALUE_MAPSIZE;
 		error = xfs_bmapi_read(args->dp, (xfs_fileoff_t)lblkno,
@@ -415,7 +417,7 @@ xfs_attr_rmtval_set(
 	 * attributes have headers, we can't just do a straight byte to FSB
 	 * conversion and have to take the header space into account.
 	 */
-	blkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);
+	blkcnt = xfs_attr3_rmt_blocks(mp, args->rmtvaluelen);
 	error = xfs_bmap_first_unused(args->trans, args->dp, blkcnt, &lfileoff,
 						   XFS_ATTR_FORK);
 	if (error)
@@ -480,7 +482,7 @@ xfs_attr_rmtval_set(
 	 */
 	lblkno = args->rmtblkno;
 	blkcnt = args->rmtblkcnt;
-	valuelen = args->valuelen;
+	valuelen = args->rmtvaluelen;
 	while (valuelen > 0) {
 		struct xfs_buf	*bp;
 		xfs_daddr_t	dblkno;",linux,8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,d540e43b0ab134b22f015f725ce6e070d12b0244,1,"xfs_attr_rmtval_get(
	struct xfs_da_args	*args)
{
	struct xfs_bmbt_irec	map[ATTR_RMTVALUE_MAPSIZE];
	struct xfs_mount	*mp = args->dp->i_mount;
 	struct xfs_buf		*bp;
 	xfs_dablk_t		lblkno = args->rmtblkno;
 	__uint8_t		*dst = args->value;
//flaw_line_below:
	int			valuelen = args->valuelen;
//fix_flaw_line_below:
//	int			valuelen;
 	int			nmap;
 	int			error;
 	int			blkcnt = args->rmtblkcnt;
	int			i;
	int			offset = 0;

 	trace_xfs_attr_rmtval_get(args);
 
 	ASSERT(!(args->flags & ATTR_KERNOVAL));
//fix_flaw_line_below:
//	ASSERT(args->rmtvaluelen == args->valuelen);
 
//fix_flaw_line_below:
//	valuelen = args->rmtvaluelen;
 	while (valuelen > 0) {
 		nmap = ATTR_RMTVALUE_MAPSIZE;
 		error = xfs_bmapi_read(args->dp, (xfs_fileoff_t)lblkno,
				       blkcnt, map, &nmap,
				       XFS_BMAPI_ATTRFORK);
		if (error)
			return error;
		ASSERT(nmap >= 1);

		for (i = 0; (i < nmap) && (valuelen > 0); i++) {
			xfs_daddr_t	dblkno;
			int		dblkcnt;

			ASSERT((map[i].br_startblock != DELAYSTARTBLOCK) &&
			       (map[i].br_startblock != HOLESTARTBLOCK));
			dblkno = XFS_FSB_TO_DADDR(mp, map[i].br_startblock);
			dblkcnt = XFS_FSB_TO_BB(mp, map[i].br_blockcount);
			error = xfs_trans_read_buf(mp, NULL, mp->m_ddev_targp,
						   dblkno, dblkcnt, 0, &bp,
						   &xfs_attr3_rmt_buf_ops);
			if (error)
				return error;

			error = xfs_attr_rmtval_copyout(mp, bp, args->dp->i_ino,
							&offset, &valuelen,
							&dst);
			xfs_buf_relse(bp);
			if (error)
				return error;

			/* roll attribute extent map forwards */
			lblkno += map[i].br_blockcount;
			blkcnt -= map[i].br_blockcount;
		}
	}
	ASSERT(valuelen == 0);
	return 0;
}
"
2176,179912,,Local,Not required,Complete,CVE-2015-0274,https://www.cvedetails.com/cve/CVE-2015-0274/,CWE-19,Low,Complete,Complete,,2015-03-16,7.2,"The XFS implementation in the Linux kernel before 3.15 improperly uses an old size value during remote attribute replacement, which allows local users to cause a denial of service (transaction overrun and data corruption) or possibly gain privileges by leveraging XFS filesystem access.",2015-03-26,DoS +Priv ,2,https://github.com/torvalds/linux/commit/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,"xfs: remote attribute overwrite causes transaction overrun

Commit e461fcb (""xfs: remote attribute lookups require the value
length"") passes the remote attribute length in the xfs_da_args
structure on lookup so that CRC calculations and validity checking
can be performed correctly by related code. This, unfortunately has
the side effect of changing the args->valuelen parameter in cases
where it shouldn't.

That is, when we replace a remote attribute, the incoming
replacement stores the value and length in args->value and
args->valuelen, but then the lookup which finds the existing remote
attribute overwrites args->valuelen with the length of the remote
attribute being replaced. Hence when we go to create the new
attribute, we create it of the size of the existing remote
attribute, not the size it is supposed to be. When the new attribute
is much smaller than the old attribute, this results in a
transaction overrun and an ASSERT() failure on a debug kernel:

XFS: Assertion failed: tp->t_blk_res_used <= tp->t_blk_res, file: fs/xfs/xfs_trans.c, line: 331

Fix this by keeping the remote attribute value length separate to
the attribute value length in the xfs_da_args structure. The enables
us to pass the length of the remote attribute to be removed without
overwriting the new attribute's length.

Also, ensure that when we save remote block contexts for a later
rename we zero the original state variables so that we don't confuse
the state of the attribute to be removes with the state of the new
attribute that we just added. [Spotted by Brain Foster.]

Signed-off-by: Dave Chinner <dchinner@redhat.com>
Reviewed-by: Brian Foster <bfoster@redhat.com>
Signed-off-by: Dave Chinner <david@fromorbit.com>",2,fs/xfs/xfs_attr_remote.c,"{""sha"": ""abda1124a70f66fbd1a79b28f8eaf5bf1916da1e"", ""filename"": ""fs/xfs/xfs_attr.c"", ""status"": ""modified"", ""additions"": 23, ""deletions"": 1, ""changes"": 24, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -213,7 +213,7 @@ xfs_attr_calc_size(\n \t\t * Out of line attribute, cannot double split, but\n \t\t * make room for the attribute value itself.\n \t\t */\n-\t\tuint\tdblocks = XFS_B_TO_FSB(mp, valuelen);\n+\t\tuint\tdblocks = xfs_attr3_rmt_blocks(mp, valuelen);\n \t\tnblks += dblocks;\n \t\tnblks += XFS_NEXTENTADD_SPACE_RES(mp, dblocks, XFS_ATTR_FORK);\n \t}\n@@ -698,11 +698,22 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)\n \n \t\ttrace_xfs_attr_leaf_replace(args);\n \n+\t\t/* save the attribute state for later removal*/\n \t\targs->op_flags |= XFS_DA_OP_RENAME;\t/* an atomic rename */\n \t\targs->blkno2 = args->blkno;\t\t/* set 2nd entry info*/\n \t\targs->index2 = args->index;\n \t\targs->rmtblkno2 = args->rmtblkno;\n \t\targs->rmtblkcnt2 = args->rmtblkcnt;\n+\t\targs->rmtvaluelen2 = args->rmtvaluelen;\n+\n+\t\t/*\n+\t\t * clear the remote attr state now that it is saved so that the\n+\t\t * values reflect the state of the attribute we are about to\n+\t\t * add, not the attribute we just found and will remove later.\n+\t\t */\n+\t\targs->rmtblkno = 0;\n+\t\targs->rmtblkcnt = 0;\n+\t\targs->rmtvaluelen = 0;\n \t}\n \n \t/*\n@@ -794,6 +805,7 @@ xfs_attr_leaf_addname(xfs_da_args_t *args)\n \t\targs->blkno = args->blkno2;\n \t\targs->rmtblkno = args->rmtblkno2;\n \t\targs->rmtblkcnt = args->rmtblkcnt2;\n+\t\targs->rmtvaluelen = args->rmtvaluelen2;\n \t\tif (args->rmtblkno) {\n \t\t\terror = xfs_attr_rmtval_remove(args);\n \t\t\tif (error)\n@@ -999,13 +1011,22 @@ xfs_attr_node_addname(xfs_da_args_t *args)\n \n \t\ttrace_xfs_attr_node_replace(args);\n \n+\t\t/* save the attribute state for later removal*/\n \t\targs->op_flags |= XFS_DA_OP_RENAME;\t/* atomic rename op */\n \t\targs->blkno2 = args->blkno;\t\t/* set 2nd entry info*/\n \t\targs->index2 = args->index;\n \t\targs->rmtblkno2 = args->rmtblkno;\n \t\targs->rmtblkcnt2 = args->rmtblkcnt;\n+\t\targs->rmtvaluelen2 = args->rmtvaluelen;\n+\n+\t\t/*\n+\t\t * clear the remote attr state now that it is saved so that the\n+\t\t * values reflect the state of the attribute we are about to\n+\t\t * add, not the attribute we just found and will remove later.\n+\t\t */\n \t\targs->rmtblkno = 0;\n \t\targs->rmtblkcnt = 0;\n+\t\targs->rmtvaluelen = 0;\n \t}\n \n \tretval = xfs_attr3_leaf_add(blk->bp, state->args);\n@@ -1133,6 +1154,7 @@ xfs_attr_node_addname(xfs_da_args_t *args)\n \t\targs->blkno = args->blkno2;\n \t\targs->rmtblkno = args->rmtblkno2;\n \t\targs->rmtblkcnt = args->rmtblkcnt2;\n+\t\targs->rmtvaluelen = args->rmtvaluelen2;\n \t\tif (args->rmtblkno) {\n \t\t\terror = xfs_attr_rmtval_remove(args);\n \t\t\tif (error)""}<_**next**_>{""sha"": ""511c283459b19441d782114c4f832207860deab1"", ""filename"": ""fs/xfs/xfs_attr_leaf.c"", ""status"": ""modified"", ""additions"": 11, ""deletions"": 10, ""changes"": 21, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_leaf.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_leaf.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_leaf.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -1229,6 +1229,7 @@ xfs_attr3_leaf_add_work(\n \t\tname_rmt->valueblk = 0;\n \t\targs->rmtblkno = 1;\n \t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);\n+\t\targs->rmtvaluelen = args->valuelen;\n \t}\n \txfs_trans_log_buf(args->trans, bp,\n \t     XFS_DA_LOGRANGE(leaf, xfs_attr3_leaf_name(leaf, args->index),\n@@ -2167,11 +2168,11 @@ xfs_attr3_leaf_lookup_int(\n \t\t\tif (!xfs_attr_namesp_match(args->flags, entry->flags))\n \t\t\t\tcontinue;\n \t\t\targs->index = probe;\n-\t\t\targs->valuelen = be32_to_cpu(name_rmt->valuelen);\n+\t\t\targs->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);\n \t\t\targs->rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(\n \t\t\t\t\t\t\targs->dp->i_mount,\n-\t\t\t\t\t\t\targs->valuelen);\n+\t\t\t\t\t\t\targs->rmtvaluelen);\n \t\t\treturn XFS_ERROR(EEXIST);\n \t\t}\n \t}\n@@ -2220,19 +2221,19 @@ xfs_attr3_leaf_getvalue(\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);\n \t\tASSERT(name_rmt->namelen == args->namelen);\n \t\tASSERT(memcmp(args->name, name_rmt->name, args->namelen) == 0);\n-\t\tvaluelen = be32_to_cpu(name_rmt->valuelen);\n+\t\targs->rmtvaluelen = be32_to_cpu(name_rmt->valuelen);\n \t\targs->rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\targs->rmtblkcnt = xfs_attr3_rmt_blocks(args->dp->i_mount,\n-\t\t\t\t\t\t       valuelen);\n+\t\t\t\t\t\t       args->rmtvaluelen);\n \t\tif (args->flags & ATTR_KERNOVAL) {\n-\t\t\targs->valuelen = valuelen;\n+\t\t\targs->valuelen = args->rmtvaluelen;\n \t\t\treturn 0;\n \t\t}\n-\t\tif (args->valuelen < valuelen) {\n-\t\t\targs->valuelen = valuelen;\n+\t\tif (args->valuelen < args->rmtvaluelen) {\n+\t\t\targs->valuelen = args->rmtvaluelen;\n \t\t\treturn XFS_ERROR(ERANGE);\n \t\t}\n-\t\targs->valuelen = valuelen;\n+\t\targs->valuelen = args->rmtvaluelen;\n \t}\n \treturn 0;\n }\n@@ -2519,7 +2520,7 @@ xfs_attr3_leaf_clearflag(\n \t\tASSERT((entry->flags & XFS_ATTR_LOCAL) == 0);\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);\n \t\tname_rmt->valueblk = cpu_to_be32(args->rmtblkno);\n-\t\tname_rmt->valuelen = cpu_to_be32(args->valuelen);\n+\t\tname_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);\n \t\txfs_trans_log_buf(args->trans, bp,\n \t\t\t XFS_DA_LOGRANGE(leaf, name_rmt, sizeof(*name_rmt)));\n \t}\n@@ -2677,7 +2678,7 @@ xfs_attr3_leaf_flipflags(\n \t\tASSERT((entry1->flags & XFS_ATTR_LOCAL) == 0);\n \t\tname_rmt = xfs_attr3_leaf_name_remote(leaf1, args->index);\n \t\tname_rmt->valueblk = cpu_to_be32(args->rmtblkno);\n-\t\tname_rmt->valuelen = cpu_to_be32(args->valuelen);\n+\t\tname_rmt->valuelen = cpu_to_be32(args->rmtvaluelen);\n \t\txfs_trans_log_buf(args->trans, bp1,\n \t\t\t XFS_DA_LOGRANGE(leaf1, name_rmt, sizeof(*name_rmt)));\n \t}""}<_**next**_>{""sha"": ""833fe5d98d806783ca6bb6cf2f4ecb83424bfdca"", ""filename"": ""fs/xfs/xfs_attr_list.c"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 0, ""changes"": 1, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_list.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_list.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_list.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -447,6 +447,7 @@ xfs_attr3_leaf_list_int(\n \t\t\t\targs.dp = context->dp;\n \t\t\t\targs.whichfork = XFS_ATTR_FORK;\n \t\t\t\targs.valuelen = valuelen;\n+\t\t\t\targs.rmtvaluelen = valuelen;\n \t\t\t\targs.value = kmem_alloc(valuelen, KM_SLEEP | KM_NOFS);\n \t\t\t\targs.rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\t\t\targs.rmtblkcnt = xfs_attr3_rmt_blocks(""}<_**next**_>{""sha"": ""d2e6e948cec7be3013b853033b6e1a64b365a682"", ""filename"": ""fs/xfs/xfs_attr_remote.c"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 3, ""changes"": 8, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_remote.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_attr_remote.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_attr_remote.c?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -337,7 +337,7 @@ xfs_attr_rmtval_get(\n \tstruct xfs_buf\t\t*bp;\n \txfs_dablk_t\t\tlblkno = args->rmtblkno;\n \t__uint8_t\t\t*dst = args->value;\n-\tint\t\t\tvaluelen = args->valuelen;\n+\tint\t\t\tvaluelen;\n \tint\t\t\tnmap;\n \tint\t\t\terror;\n \tint\t\t\tblkcnt = args->rmtblkcnt;\n@@ -347,7 +347,9 @@ xfs_attr_rmtval_get(\n \ttrace_xfs_attr_rmtval_get(args);\n \n \tASSERT(!(args->flags & ATTR_KERNOVAL));\n+\tASSERT(args->rmtvaluelen == args->valuelen);\n \n+\tvaluelen = args->rmtvaluelen;\n \twhile (valuelen > 0) {\n \t\tnmap = ATTR_RMTVALUE_MAPSIZE;\n \t\terror = xfs_bmapi_read(args->dp, (xfs_fileoff_t)lblkno,\n@@ -415,7 +417,7 @@ xfs_attr_rmtval_set(\n \t * attributes have headers, we can't just do a straight byte to FSB\n \t * conversion and have to take the header space into account.\n \t */\n-\tblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);\n+\tblkcnt = xfs_attr3_rmt_blocks(mp, args->rmtvaluelen);\n \terror = xfs_bmap_first_unused(args->trans, args->dp, blkcnt, &lfileoff,\n \t\t\t\t\t\t   XFS_ATTR_FORK);\n \tif (error)\n@@ -480,7 +482,7 @@ xfs_attr_rmtval_set(\n \t */\n \tlblkno = args->rmtblkno;\n \tblkcnt = args->rmtblkcnt;\n-\tvaluelen = args->valuelen;\n+\tvaluelen = args->rmtvaluelen;\n \twhile (valuelen > 0) {\n \t\tstruct xfs_buf\t*bp;\n \t\txfs_daddr_t\tdblkno;""}<_**next**_>{""sha"": ""201c6091d26abfa2e38dd17fd960e3efcb69bcd7"", ""filename"": ""fs/xfs/xfs_da_btree.h"", ""status"": ""modified"", ""additions"": 2, ""deletions"": 0, ""changes"": 2, ""blob_url"": ""https://github.com/torvalds/linux/blob/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_da_btree.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59/fs/xfs/xfs_da_btree.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/xfs/xfs_da_btree.h?ref=8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59"", ""patch"": ""@@ -60,10 +60,12 @@ typedef struct xfs_da_args {\n \tint\t\tindex;\t\t/* index of attr of interest in blk */\n \txfs_dablk_t\trmtblkno;\t/* remote attr value starting blkno */\n \tint\t\trmtblkcnt;\t/* remote attr value block count */\n+\tint\t\trmtvaluelen;\t/* remote attr value length in bytes */\n \txfs_dablk_t\tblkno2;\t\t/* blkno of 2nd attr leaf of interest */\n \tint\t\tindex2;\t\t/* index of 2nd attr in blk */\n \txfs_dablk_t\trmtblkno2;\t/* remote attr value starting blkno */\n \tint\t\trmtblkcnt2;\t/* remote attr value block count */\n+\tint\t\trmtvaluelen2;\t/* remote attr value length in bytes */\n \tint\t\top_flags;\t/* operation flags */\n \tenum xfs_dacmp\tcmpresult;\t/* name compare result for lookups */\n } xfs_da_args_t;""}","xfs_attr_rmtval_set(
	struct xfs_da_args	*args)
{
	struct xfs_inode	*dp = args->dp;
	struct xfs_mount	*mp = dp->i_mount;
	struct xfs_bmbt_irec	map;
	xfs_dablk_t		lblkno;
	xfs_fileoff_t		lfileoff = 0;
	__uint8_t		*src = args->value;
	int			blkcnt;
	int			valuelen;
	int			nmap;
	int			error;
	int			offset = 0;

	trace_xfs_attr_rmtval_set(args);

	/*
	 * Find a ""hole"" in the attribute address space large enough for
	 * us to drop the new attribute's value into. Because CRC enable
 	 * attributes have headers, we can't just do a straight byte to FSB
 	 * conversion and have to take the header space into account.
 	 */
	blkcnt = xfs_attr3_rmt_blocks(mp, args->rmtvaluelen);
 	error = xfs_bmap_first_unused(args->trans, args->dp, blkcnt, &lfileoff,
 						   XFS_ATTR_FORK);
 	if (error)
		return error;

	args->rmtblkno = lblkno = (xfs_dablk_t)lfileoff;
	args->rmtblkcnt = blkcnt;

	/*
	 * Roll through the ""value"", allocating blocks on disk as required.
	 */
	while (blkcnt > 0) {
		int	committed;

		/*
		 * Allocate a single extent, up to the size of the value.
		 */
		xfs_bmap_init(args->flist, args->firstblock);
		nmap = 1;
		error = xfs_bmapi_write(args->trans, dp, (xfs_fileoff_t)lblkno,
				  blkcnt,
				  XFS_BMAPI_ATTRFORK | XFS_BMAPI_METADATA,
				  args->firstblock, args->total, &map, &nmap,
				  args->flist);
		if (!error) {
			error = xfs_bmap_finish(&args->trans, args->flist,
						&committed);
		}
		if (error) {
			ASSERT(committed);
			args->trans = NULL;
			xfs_bmap_cancel(args->flist);
			return(error);
		}

		/*
		 * bmap_finish() may have committed the last trans and started
		 * a new one.  We need the inode to be in all transactions.
		 */
		if (committed)
			xfs_trans_ijoin(args->trans, dp, 0);

		ASSERT(nmap == 1);
		ASSERT((map.br_startblock != DELAYSTARTBLOCK) &&
		       (map.br_startblock != HOLESTARTBLOCK));
		lblkno += map.br_blockcount;
		blkcnt -= map.br_blockcount;

		/*
		 * Start the next trans in the chain.
		 */
		error = xfs_trans_roll(&args->trans, dp);
		if (error)
			return (error);
	}

	/*
	 * Roll through the ""value"", copying the attribute value to the
	 * already-allocated blocks.  Blocks are written synchronously
	 * so that we can know they are all on disk before we turn off
	 * the INCOMPLETE flag.
 	 */
 	lblkno = args->rmtblkno;
 	blkcnt = args->rmtblkcnt;
	valuelen = args->rmtvaluelen;
 	while (valuelen > 0) {
 		struct xfs_buf	*bp;
 		xfs_daddr_t	dblkno;
		int		dblkcnt;

		ASSERT(blkcnt > 0);

		xfs_bmap_init(args->flist, args->firstblock);
		nmap = 1;
		error = xfs_bmapi_read(dp, (xfs_fileoff_t)lblkno,
				       blkcnt, &map, &nmap,
				       XFS_BMAPI_ATTRFORK);
		if (error)
			return(error);
		ASSERT(nmap == 1);
		ASSERT((map.br_startblock != DELAYSTARTBLOCK) &&
		       (map.br_startblock != HOLESTARTBLOCK));

		dblkno = XFS_FSB_TO_DADDR(mp, map.br_startblock),
		dblkcnt = XFS_FSB_TO_BB(mp, map.br_blockcount);

		bp = xfs_buf_get(mp->m_ddev_targp, dblkno, dblkcnt, 0);
		if (!bp)
			return ENOMEM;
		bp->b_ops = &xfs_attr3_rmt_buf_ops;

		xfs_attr_rmtval_copyin(mp, bp, args->dp->i_ino, &offset,
				       &valuelen, &src);

		error = xfs_bwrite(bp);	/* GROT: NOTE: synchronous write */
		xfs_buf_relse(bp);
		if (error)
			return error;


		/* roll attribute extent map forwards */
		lblkno += map.br_blockcount;
		blkcnt -= map.br_blockcount;
	}
	ASSERT(valuelen == 0);
	return 0;
}
","xfs_attr_rmtval_set(
	struct xfs_da_args	*args)
{
	struct xfs_inode	*dp = args->dp;
	struct xfs_mount	*mp = dp->i_mount;
	struct xfs_bmbt_irec	map;
	xfs_dablk_t		lblkno;
	xfs_fileoff_t		lfileoff = 0;
	__uint8_t		*src = args->value;
	int			blkcnt;
	int			valuelen;
	int			nmap;
	int			error;
	int			offset = 0;

	trace_xfs_attr_rmtval_set(args);

	/*
	 * Find a ""hole"" in the attribute address space large enough for
	 * us to drop the new attribute's value into. Because CRC enable
 	 * attributes have headers, we can't just do a straight byte to FSB
 	 * conversion and have to take the header space into account.
 	 */
	blkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);
 	error = xfs_bmap_first_unused(args->trans, args->dp, blkcnt, &lfileoff,
 						   XFS_ATTR_FORK);
 	if (error)
		return error;

	args->rmtblkno = lblkno = (xfs_dablk_t)lfileoff;
	args->rmtblkcnt = blkcnt;

	/*
	 * Roll through the ""value"", allocating blocks on disk as required.
	 */
	while (blkcnt > 0) {
		int	committed;

		/*
		 * Allocate a single extent, up to the size of the value.
		 */
		xfs_bmap_init(args->flist, args->firstblock);
		nmap = 1;
		error = xfs_bmapi_write(args->trans, dp, (xfs_fileoff_t)lblkno,
				  blkcnt,
				  XFS_BMAPI_ATTRFORK | XFS_BMAPI_METADATA,
				  args->firstblock, args->total, &map, &nmap,
				  args->flist);
		if (!error) {
			error = xfs_bmap_finish(&args->trans, args->flist,
						&committed);
		}
		if (error) {
			ASSERT(committed);
			args->trans = NULL;
			xfs_bmap_cancel(args->flist);
			return(error);
		}

		/*
		 * bmap_finish() may have committed the last trans and started
		 * a new one.  We need the inode to be in all transactions.
		 */
		if (committed)
			xfs_trans_ijoin(args->trans, dp, 0);

		ASSERT(nmap == 1);
		ASSERT((map.br_startblock != DELAYSTARTBLOCK) &&
		       (map.br_startblock != HOLESTARTBLOCK));
		lblkno += map.br_blockcount;
		blkcnt -= map.br_blockcount;

		/*
		 * Start the next trans in the chain.
		 */
		error = xfs_trans_roll(&args->trans, dp);
		if (error)
			return (error);
	}

	/*
	 * Roll through the ""value"", copying the attribute value to the
	 * already-allocated blocks.  Blocks are written synchronously
	 * so that we can know they are all on disk before we turn off
	 * the INCOMPLETE flag.
 	 */
 	lblkno = args->rmtblkno;
 	blkcnt = args->rmtblkcnt;
	valuelen = args->valuelen;
 	while (valuelen > 0) {
 		struct xfs_buf	*bp;
 		xfs_daddr_t	dblkno;
		int		dblkcnt;

		ASSERT(blkcnt > 0);

		xfs_bmap_init(args->flist, args->firstblock);
		nmap = 1;
		error = xfs_bmapi_read(dp, (xfs_fileoff_t)lblkno,
				       blkcnt, &map, &nmap,
				       XFS_BMAPI_ATTRFORK);
		if (error)
			return(error);
		ASSERT(nmap == 1);
		ASSERT((map.br_startblock != DELAYSTARTBLOCK) &&
		       (map.br_startblock != HOLESTARTBLOCK));

		dblkno = XFS_FSB_TO_DADDR(mp, map.br_startblock),
		dblkcnt = XFS_FSB_TO_BB(mp, map.br_blockcount);

		bp = xfs_buf_get(mp->m_ddev_targp, dblkno, dblkcnt, 0);
		if (!bp)
			return ENOMEM;
		bp->b_ops = &xfs_attr3_rmt_buf_ops;

		xfs_attr_rmtval_copyin(mp, bp, args->dp->i_ino, &offset,
				       &valuelen, &src);

		error = xfs_bwrite(bp);	/* GROT: NOTE: synchronous write */
		xfs_buf_relse(bp);
		if (error)
			return error;


		/* roll attribute extent map forwards */
		lblkno += map.br_blockcount;
		blkcnt -= map.br_blockcount;
	}
	ASSERT(valuelen == 0);
	return 0;
}
",C,"	blkcnt = xfs_attr3_rmt_blocks(mp, args->rmtvaluelen);
	valuelen = args->rmtvaluelen;
","	blkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);
	valuelen = args->valuelen;
",,"@@ -337,7 +337,7 @@ xfs_attr_rmtval_get(
 	struct xfs_buf		*bp;
 	xfs_dablk_t		lblkno = args->rmtblkno;
 	__uint8_t		*dst = args->value;
-	int			valuelen = args->valuelen;
+	int			valuelen;
 	int			nmap;
 	int			error;
 	int			blkcnt = args->rmtblkcnt;
@@ -347,7 +347,9 @@ xfs_attr_rmtval_get(
 	trace_xfs_attr_rmtval_get(args);
 
 	ASSERT(!(args->flags & ATTR_KERNOVAL));
+	ASSERT(args->rmtvaluelen == args->valuelen);
 
+	valuelen = args->rmtvaluelen;
 	while (valuelen > 0) {
 		nmap = ATTR_RMTVALUE_MAPSIZE;
 		error = xfs_bmapi_read(args->dp, (xfs_fileoff_t)lblkno,
@@ -415,7 +417,7 @@ xfs_attr_rmtval_set(
 	 * attributes have headers, we can't just do a straight byte to FSB
 	 * conversion and have to take the header space into account.
 	 */
-	blkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);
+	blkcnt = xfs_attr3_rmt_blocks(mp, args->rmtvaluelen);
 	error = xfs_bmap_first_unused(args->trans, args->dp, blkcnt, &lfileoff,
 						   XFS_ATTR_FORK);
 	if (error)
@@ -480,7 +482,7 @@ xfs_attr_rmtval_set(
 	 */
 	lblkno = args->rmtblkno;
 	blkcnt = args->rmtblkcnt;
-	valuelen = args->valuelen;
+	valuelen = args->rmtvaluelen;
 	while (valuelen > 0) {
 		struct xfs_buf	*bp;
 		xfs_daddr_t	dblkno;",linux,8275cdd0e7ac550dcce2b3ef6d2fb3b808c1ae59,d540e43b0ab134b22f015f725ce6e070d12b0244,1,"xfs_attr_rmtval_set(
	struct xfs_da_args	*args)
{
	struct xfs_inode	*dp = args->dp;
	struct xfs_mount	*mp = dp->i_mount;
	struct xfs_bmbt_irec	map;
	xfs_dablk_t		lblkno;
	xfs_fileoff_t		lfileoff = 0;
	__uint8_t		*src = args->value;
	int			blkcnt;
	int			valuelen;
	int			nmap;
	int			error;
	int			offset = 0;

	trace_xfs_attr_rmtval_set(args);

	/*
	 * Find a ""hole"" in the attribute address space large enough for
	 * us to drop the new attribute's value into. Because CRC enable
 	 * attributes have headers, we can't just do a straight byte to FSB
 	 * conversion and have to take the header space into account.
 	 */
//flaw_line_below:
	blkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);
//fix_flaw_line_below:
//	blkcnt = xfs_attr3_rmt_blocks(mp, args->rmtvaluelen);
 	error = xfs_bmap_first_unused(args->trans, args->dp, blkcnt, &lfileoff,
 						   XFS_ATTR_FORK);
 	if (error)
		return error;

	args->rmtblkno = lblkno = (xfs_dablk_t)lfileoff;
	args->rmtblkcnt = blkcnt;

	/*
	 * Roll through the ""value"", allocating blocks on disk as required.
	 */
	while (blkcnt > 0) {
		int	committed;

		/*
		 * Allocate a single extent, up to the size of the value.
		 */
		xfs_bmap_init(args->flist, args->firstblock);
		nmap = 1;
		error = xfs_bmapi_write(args->trans, dp, (xfs_fileoff_t)lblkno,
				  blkcnt,
				  XFS_BMAPI_ATTRFORK | XFS_BMAPI_METADATA,
				  args->firstblock, args->total, &map, &nmap,
				  args->flist);
		if (!error) {
			error = xfs_bmap_finish(&args->trans, args->flist,
						&committed);
		}
		if (error) {
			ASSERT(committed);
			args->trans = NULL;
			xfs_bmap_cancel(args->flist);
			return(error);
		}

		/*
		 * bmap_finish() may have committed the last trans and started
		 * a new one.  We need the inode to be in all transactions.
		 */
		if (committed)
			xfs_trans_ijoin(args->trans, dp, 0);

		ASSERT(nmap == 1);
		ASSERT((map.br_startblock != DELAYSTARTBLOCK) &&
		       (map.br_startblock != HOLESTARTBLOCK));
		lblkno += map.br_blockcount;
		blkcnt -= map.br_blockcount;

		/*
		 * Start the next trans in the chain.
		 */
		error = xfs_trans_roll(&args->trans, dp);
		if (error)
			return (error);
	}

	/*
	 * Roll through the ""value"", copying the attribute value to the
	 * already-allocated blocks.  Blocks are written synchronously
	 * so that we can know they are all on disk before we turn off
	 * the INCOMPLETE flag.
 	 */
 	lblkno = args->rmtblkno;
 	blkcnt = args->rmtblkcnt;
//flaw_line_below:
	valuelen = args->valuelen;
//fix_flaw_line_below:
//	valuelen = args->rmtvaluelen;
 	while (valuelen > 0) {
 		struct xfs_buf	*bp;
 		xfs_daddr_t	dblkno;
		int		dblkcnt;

		ASSERT(blkcnt > 0);

		xfs_bmap_init(args->flist, args->firstblock);
		nmap = 1;
		error = xfs_bmapi_read(dp, (xfs_fileoff_t)lblkno,
				       blkcnt, &map, &nmap,
				       XFS_BMAPI_ATTRFORK);
		if (error)
			return(error);
		ASSERT(nmap == 1);
		ASSERT((map.br_startblock != DELAYSTARTBLOCK) &&
		       (map.br_startblock != HOLESTARTBLOCK));

		dblkno = XFS_FSB_TO_DADDR(mp, map.br_startblock),
		dblkcnt = XFS_FSB_TO_BB(mp, map.br_blockcount);

		bp = xfs_buf_get(mp->m_ddev_targp, dblkno, dblkcnt, 0);
		if (!bp)
			return ENOMEM;
		bp->b_ops = &xfs_attr3_rmt_buf_ops;

		xfs_attr_rmtval_copyin(mp, bp, args->dp->i_ino, &offset,
				       &valuelen, &src);

		error = xfs_bwrite(bp);	/* GROT: NOTE: synchronous write */
		xfs_buf_relse(bp);
		if (error)
			return error;


		/* roll attribute extent map forwards */
		lblkno += map.br_blockcount;
		blkcnt -= map.br_blockcount;
	}
	ASSERT(valuelen == 0);
	return 0;
}
"
2397,180133,,Remote,Not required,Complete,CVE-2016-7117,https://www.cvedetails.com/cve/CVE-2016-7117/,CWE-19,Low,Complete,Complete,,2016-10-10,10.0,Use-after-free vulnerability in the __sys_recvmmsg function in net/socket.c in the Linux kernel before 4.5.2 allows remote attackers to execute arbitrary code via vectors involving a recvmmsg system call that is mishandled during error processing.,2018-01-04,Exec Code ,19,https://github.com/torvalds/linux/commit/34b88a68f26a75e4fded796f1a49c40f82234b7d,34b88a68f26a75e4fded796f1a49c40f82234b7d,"net: Fix use after free in the recvmmsg exit path

The syzkaller fuzzer hit the following use-after-free:

  Call Trace:
   [<ffffffff8175ea0e>] __asan_report_load8_noabort+0x3e/0x40 mm/kasan/report.c:295
   [<ffffffff851cc31a>] __sys_recvmmsg+0x6fa/0x7f0 net/socket.c:2261
   [<     inline     >] SYSC_recvmmsg net/socket.c:2281
   [<ffffffff851cc57f>] SyS_recvmmsg+0x16f/0x180 net/socket.c:2270
   [<ffffffff86332bb6>] entry_SYSCALL_64_fastpath+0x16/0x7a
  arch/x86/entry/entry_64.S:185

And, as Dmitry rightly assessed, that is because we can drop the
reference and then touch it when the underlying recvmsg calls return
some packets and then hit an error, which will make recvmmsg to set
sock->sk->sk_err, oops, fix it.

Reported-and-Tested-by: Dmitry Vyukov <dvyukov@google.com>
Cc: Alexander Potapenko <glider@google.com>
Cc: Eric Dumazet <edumazet@google.com>
Cc: Kostya Serebryany <kcc@google.com>
Cc: Sasha Levin <sasha.levin@oracle.com>
Fixes: a2e2725541fa (""net: Introduce recvmmsg socket syscall"")
http://lkml.kernel.org/r/20160122211644.GC2470@redhat.com
Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
Signed-off-by: David S. Miller <davem@davemloft.net>",17,net/socket.c,"{""sha"": ""5f77a8e93830bd30cef60e68354bda683c9acc43"", ""filename"": ""net/socket.c"", ""status"": ""modified"", ""additions"": 19, ""deletions"": 19, ""changes"": 38, ""blob_url"": ""https://github.com/torvalds/linux/blob/34b88a68f26a75e4fded796f1a49c40f82234b7d/net/socket.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/34b88a68f26a75e4fded796f1a49c40f82234b7d/net/socket.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/net/socket.c?ref=34b88a68f26a75e4fded796f1a49c40f82234b7d"", ""patch"": ""@@ -2244,31 +2244,31 @@ int __sys_recvmmsg(int fd, struct mmsghdr __user *mmsg, unsigned int vlen,\n \t\tcond_resched();\n \t}\n \n-out_put:\n-\tfput_light(sock->file, fput_needed);\n-\n \tif (err == 0)\n-\t\treturn datagrams;\n+\t\tgoto out_put;\n \n-\tif (datagrams != 0) {\n+\tif (datagrams == 0) {\n+\t\tdatagrams = err;\n+\t\tgoto out_put;\n+\t}\n+\n+\t/*\n+\t * We may return less entries than requested (vlen) if the\n+\t * sock is non block and there aren't enough datagrams...\n+\t */\n+\tif (err != -EAGAIN) {\n \t\t/*\n-\t\t * We may return less entries than requested (vlen) if the\n-\t\t * sock is non block and there aren't enough datagrams...\n+\t\t * ... or  if recvmsg returns an error after we\n+\t\t * received some datagrams, where we record the\n+\t\t * error to return on the next call or if the\n+\t\t * app asks about it using getsockopt(SO_ERROR).\n \t\t */\n-\t\tif (err != -EAGAIN) {\n-\t\t\t/*\n-\t\t\t * ... or  if recvmsg returns an error after we\n-\t\t\t * received some datagrams, where we record the\n-\t\t\t * error to return on the next call or if the\n-\t\t\t * app asks about it using getsockopt(SO_ERROR).\n-\t\t\t */\n-\t\t\tsock->sk->sk_err = -err;\n-\t\t}\n-\n-\t\treturn datagrams;\n+\t\tsock->sk->sk_err = -err;\n \t}\n+out_put:\n+\tfput_light(sock->file, fput_needed);\n \n-\treturn err;\n+\treturn datagrams;\n }\n \n SYSCALL_DEFINE5(recvmmsg, int, fd, struct mmsghdr __user *, mmsg,""}","int __sys_recvmmsg(int fd, struct mmsghdr __user *mmsg, unsigned int vlen,
		   unsigned int flags, struct timespec *timeout)
{
	int fput_needed, err, datagrams;
	struct socket *sock;
	struct mmsghdr __user *entry;
	struct compat_mmsghdr __user *compat_entry;
	struct msghdr msg_sys;
	struct timespec end_time;

	if (timeout &&
	    poll_select_set_timeout(&end_time, timeout->tv_sec,
				    timeout->tv_nsec))
		return -EINVAL;

	datagrams = 0;

	sock = sockfd_lookup_light(fd, &err, &fput_needed);
	if (!sock)
		return err;

	err = sock_error(sock->sk);
	if (err)
		goto out_put;

	entry = mmsg;
	compat_entry = (struct compat_mmsghdr __user *)mmsg;

	while (datagrams < vlen) {
		/*
		 * No need to ask LSM for more than the first datagram.
		 */
		if (MSG_CMSG_COMPAT & flags) {
			err = ___sys_recvmsg(sock, (struct user_msghdr __user *)compat_entry,
					     &msg_sys, flags & ~MSG_WAITFORONE,
					     datagrams);
			if (err < 0)
				break;
			err = __put_user(err, &compat_entry->msg_len);
			++compat_entry;
		} else {
			err = ___sys_recvmsg(sock,
					     (struct user_msghdr __user *)entry,
					     &msg_sys, flags & ~MSG_WAITFORONE,
					     datagrams);
			if (err < 0)
				break;
			err = put_user(err, &entry->msg_len);
			++entry;
		}

		if (err)
			break;
		++datagrams;

		/* MSG_WAITFORONE turns on MSG_DONTWAIT after one packet */
		if (flags & MSG_WAITFORONE)
			flags |= MSG_DONTWAIT;

		if (timeout) {
			ktime_get_ts(timeout);
			*timeout = timespec_sub(end_time, *timeout);
			if (timeout->tv_sec < 0) {
				timeout->tv_sec = timeout->tv_nsec = 0;
				break;
			}

			/* Timeout, return less than vlen datagrams */
			if (timeout->tv_nsec == 0 && timeout->tv_sec == 0)
				break;
		}

		/* Out of band data, return right away */
		if (msg_sys.msg_flags & MSG_OOB)
			break;
 		cond_resched();
 	}
 
 	if (err == 0)
		goto out_put;
 
	if (datagrams == 0) {
		datagrams = err;
		goto out_put;
	}

	/*
	 * We may return less entries than requested (vlen) if the
	 * sock is non block and there aren't enough datagrams...
	 */
	if (err != -EAGAIN) {
 		/*
		 * ... or  if recvmsg returns an error after we
		 * received some datagrams, where we record the
		 * error to return on the next call or if the
		 * app asks about it using getsockopt(SO_ERROR).
 		 */
		sock->sk->sk_err = -err;
 	}
out_put:
	fput_light(sock->file, fput_needed);
 
	return datagrams;
 }
","int __sys_recvmmsg(int fd, struct mmsghdr __user *mmsg, unsigned int vlen,
		   unsigned int flags, struct timespec *timeout)
{
	int fput_needed, err, datagrams;
	struct socket *sock;
	struct mmsghdr __user *entry;
	struct compat_mmsghdr __user *compat_entry;
	struct msghdr msg_sys;
	struct timespec end_time;

	if (timeout &&
	    poll_select_set_timeout(&end_time, timeout->tv_sec,
				    timeout->tv_nsec))
		return -EINVAL;

	datagrams = 0;

	sock = sockfd_lookup_light(fd, &err, &fput_needed);
	if (!sock)
		return err;

	err = sock_error(sock->sk);
	if (err)
		goto out_put;

	entry = mmsg;
	compat_entry = (struct compat_mmsghdr __user *)mmsg;

	while (datagrams < vlen) {
		/*
		 * No need to ask LSM for more than the first datagram.
		 */
		if (MSG_CMSG_COMPAT & flags) {
			err = ___sys_recvmsg(sock, (struct user_msghdr __user *)compat_entry,
					     &msg_sys, flags & ~MSG_WAITFORONE,
					     datagrams);
			if (err < 0)
				break;
			err = __put_user(err, &compat_entry->msg_len);
			++compat_entry;
		} else {
			err = ___sys_recvmsg(sock,
					     (struct user_msghdr __user *)entry,
					     &msg_sys, flags & ~MSG_WAITFORONE,
					     datagrams);
			if (err < 0)
				break;
			err = put_user(err, &entry->msg_len);
			++entry;
		}

		if (err)
			break;
		++datagrams;

		/* MSG_WAITFORONE turns on MSG_DONTWAIT after one packet */
		if (flags & MSG_WAITFORONE)
			flags |= MSG_DONTWAIT;

		if (timeout) {
			ktime_get_ts(timeout);
			*timeout = timespec_sub(end_time, *timeout);
			if (timeout->tv_sec < 0) {
				timeout->tv_sec = timeout->tv_nsec = 0;
				break;
			}

			/* Timeout, return less than vlen datagrams */
			if (timeout->tv_nsec == 0 && timeout->tv_sec == 0)
				break;
		}

		/* Out of band data, return right away */
		if (msg_sys.msg_flags & MSG_OOB)
			break;
 		cond_resched();
 	}
 
out_put:
	fput_light(sock->file, fput_needed);
 	if (err == 0)
		return datagrams;
 
	if (datagrams != 0) {
 		/*
		 * We may return less entries than requested (vlen) if the
		 * sock is non block and there aren't enough datagrams...
 		 */
		if (err != -EAGAIN) {
			/*
			 * ... or  if recvmsg returns an error after we
			 * received some datagrams, where we record the
			 * error to return on the next call or if the
			 * app asks about it using getsockopt(SO_ERROR).
			 */
			sock->sk->sk_err = -err;
		}
		return datagrams;
 	}
 
	return err;
 }
",C,"		goto out_put;
	if (datagrams == 0) {
		datagrams = err;
		goto out_put;
	}

	/*
	 * We may return less entries than requested (vlen) if the
	 * sock is non block and there aren't enough datagrams...
	 */
	if (err != -EAGAIN) {
		 * ... or  if recvmsg returns an error after we
		 * received some datagrams, where we record the
		 * error to return on the next call or if the
		 * app asks about it using getsockopt(SO_ERROR).
		sock->sk->sk_err = -err;
out_put:
	fput_light(sock->file, fput_needed);
	return datagrams;
","out_put:
	fput_light(sock->file, fput_needed);
		return datagrams;
	if (datagrams != 0) {
		 * We may return less entries than requested (vlen) if the
		 * sock is non block and there aren't enough datagrams...
		if (err != -EAGAIN) {
			/*
			 * ... or  if recvmsg returns an error after we
			 * received some datagrams, where we record the
			 * error to return on the next call or if the
			 * app asks about it using getsockopt(SO_ERROR).
			 */
			sock->sk->sk_err = -err;
		}
		return datagrams;
	return err;
",,"@@ -2244,31 +2244,31 @@ int __sys_recvmmsg(int fd, struct mmsghdr __user *mmsg, unsigned int vlen,
 		cond_resched();
 	}
 
-out_put:
-	fput_light(sock->file, fput_needed);
-
 	if (err == 0)
-		return datagrams;
+		goto out_put;
 
-	if (datagrams != 0) {
+	if (datagrams == 0) {
+		datagrams = err;
+		goto out_put;
+	}
+
+	/*
+	 * We may return less entries than requested (vlen) if the
+	 * sock is non block and there aren't enough datagrams...
+	 */
+	if (err != -EAGAIN) {
 		/*
-		 * We may return less entries than requested (vlen) if the
-		 * sock is non block and there aren't enough datagrams...
+		 * ... or  if recvmsg returns an error after we
+		 * received some datagrams, where we record the
+		 * error to return on the next call or if the
+		 * app asks about it using getsockopt(SO_ERROR).
 		 */
-		if (err != -EAGAIN) {
-			/*
-			 * ... or  if recvmsg returns an error after we
-			 * received some datagrams, where we record the
-			 * error to return on the next call or if the
-			 * app asks about it using getsockopt(SO_ERROR).
-			 */
-			sock->sk->sk_err = -err;
-		}
-
-		return datagrams;
+		sock->sk->sk_err = -err;
 	}
+out_put:
+	fput_light(sock->file, fput_needed);
 
-	return err;
+	return datagrams;
 }
 
 SYSCALL_DEFINE5(recvmmsg, int, fd, struct mmsghdr __user *, mmsg,",linux,34b88a68f26a75e4fded796f1a49c40f82234b7d,b6e4038262bc933f2ef5427b6bcd2607d02ba4bb,1,"int __sys_recvmmsg(int fd, struct mmsghdr __user *mmsg, unsigned int vlen,
		   unsigned int flags, struct timespec *timeout)
{
	int fput_needed, err, datagrams;
	struct socket *sock;
	struct mmsghdr __user *entry;
	struct compat_mmsghdr __user *compat_entry;
	struct msghdr msg_sys;
	struct timespec end_time;

	if (timeout &&
	    poll_select_set_timeout(&end_time, timeout->tv_sec,
				    timeout->tv_nsec))
		return -EINVAL;

	datagrams = 0;

	sock = sockfd_lookup_light(fd, &err, &fput_needed);
	if (!sock)
		return err;

	err = sock_error(sock->sk);
	if (err)
		goto out_put;

	entry = mmsg;
	compat_entry = (struct compat_mmsghdr __user *)mmsg;

	while (datagrams < vlen) {
		/*
		 * No need to ask LSM for more than the first datagram.
		 */
		if (MSG_CMSG_COMPAT & flags) {
			err = ___sys_recvmsg(sock, (struct user_msghdr __user *)compat_entry,
					     &msg_sys, flags & ~MSG_WAITFORONE,
					     datagrams);
			if (err < 0)
				break;
			err = __put_user(err, &compat_entry->msg_len);
			++compat_entry;
		} else {
			err = ___sys_recvmsg(sock,
					     (struct user_msghdr __user *)entry,
					     &msg_sys, flags & ~MSG_WAITFORONE,
					     datagrams);
			if (err < 0)
				break;
			err = put_user(err, &entry->msg_len);
			++entry;
		}

		if (err)
			break;
		++datagrams;

		/* MSG_WAITFORONE turns on MSG_DONTWAIT after one packet */
		if (flags & MSG_WAITFORONE)
			flags |= MSG_DONTWAIT;

		if (timeout) {
			ktime_get_ts(timeout);
			*timeout = timespec_sub(end_time, *timeout);
			if (timeout->tv_sec < 0) {
				timeout->tv_sec = timeout->tv_nsec = 0;
				break;
			}

			/* Timeout, return less than vlen datagrams */
			if (timeout->tv_nsec == 0 && timeout->tv_sec == 0)
				break;
		}

		/* Out of band data, return right away */
		if (msg_sys.msg_flags & MSG_OOB)
			break;
 		cond_resched();
 	}
 
//flaw_line_below:
out_put:
//flaw_line_below:
	fput_light(sock->file, fput_needed);
//flaw_line_below:

 	if (err == 0)
//flaw_line_below:
		return datagrams;
//fix_flaw_line_below:
//		goto out_put;
 
//flaw_line_below:
	if (datagrams != 0) {
//fix_flaw_line_below:
//	if (datagrams == 0) {
//fix_flaw_line_below:
//		datagrams = err;
//fix_flaw_line_below:
//		goto out_put;
//fix_flaw_line_below:
//	}
//fix_flaw_line_below:
//
//fix_flaw_line_below:
//	/*
//fix_flaw_line_below:
//	 * We may return less entries than requested (vlen) if the
//fix_flaw_line_below:
//	 * sock is non block and there aren't enough datagrams...
//fix_flaw_line_below:
//	 */
//fix_flaw_line_below:
//	if (err != -EAGAIN) {
 		/*
//flaw_line_below:
		 * We may return less entries than requested (vlen) if the
//flaw_line_below:
		 * sock is non block and there aren't enough datagrams...
//fix_flaw_line_below:
//		 * ... or  if recvmsg returns an error after we
//fix_flaw_line_below:
//		 * received some datagrams, where we record the
//fix_flaw_line_below:
//		 * error to return on the next call or if the
//fix_flaw_line_below:
//		 * app asks about it using getsockopt(SO_ERROR).
 		 */
//flaw_line_below:
		if (err != -EAGAIN) {
//flaw_line_below:
			/*
//flaw_line_below:
			 * ... or  if recvmsg returns an error after we
//flaw_line_below:
			 * received some datagrams, where we record the
//flaw_line_below:
			 * error to return on the next call or if the
//flaw_line_below:
			 * app asks about it using getsockopt(SO_ERROR).
//flaw_line_below:
			 */
//flaw_line_below:
			sock->sk->sk_err = -err;
//flaw_line_below:
		}
//flaw_line_below:

//flaw_line_below:
		return datagrams;
//fix_flaw_line_below:
//		sock->sk->sk_err = -err;
 	}
//fix_flaw_line_below:
//out_put:
//fix_flaw_line_below:
//	fput_light(sock->file, fput_needed);
 
//flaw_line_below:
	return err;
//fix_flaw_line_below:
//	return datagrams;
 }
"
2873,180609,,Local,Not required,,CVE-2016-2085,https://www.cvedetails.com/cve/CVE-2016-2085/,CWE-19,Low,,Partial,,2016-04-27,2.1,"The evm_verify_hmac function in security/integrity/evm/evm_main.c in the Linux kernel before 4.5 does not properly copy data, which makes it easier for local users to forge MAC values via a timing side-channel attack.",2016-12-02,,1,https://github.com/torvalds/linux/commit/613317bd212c585c20796c10afe5daaa95d4b0a1,613317bd212c585c20796c10afe5daaa95d4b0a1,"EVM: Use crypto_memneq() for digest comparisons

This patch fixes vulnerability CVE-2016-2085.  The problem exists
because the vm_verify_hmac() function includes a use of memcmp().
Unfortunately, this allows timing side channel attacks; specifically
a MAC forgery complexity drop from 2^128 to 2^12.  This patch changes
the memcmp() to the cryptographically safe crypto_memneq().

Reported-by: Xiaofei Rex Guo <xiaofei.rex.guo@intel.com>
Signed-off-by: Ryan Ware <ware@linux.intel.com>
Cc: stable@vger.kernel.org
Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>
Signed-off-by: James Morris <james.l.morris@oracle.com>",1,security/integrity/evm/evm_main.c,"{""sha"": ""e6ea9d4b1de91a8d58e3ccab0fd3cef222ea6fcd"", ""filename"": ""security/integrity/evm/evm_main.c"", ""status"": ""modified"", ""additions"": 2, ""deletions"": 1, ""changes"": 3, ""blob_url"": ""https://github.com/torvalds/linux/blob/613317bd212c585c20796c10afe5daaa95d4b0a1/security/integrity/evm/evm_main.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/613317bd212c585c20796c10afe5daaa95d4b0a1/security/integrity/evm/evm_main.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/security/integrity/evm/evm_main.c?ref=613317bd212c585c20796c10afe5daaa95d4b0a1"", ""patch"": ""@@ -23,6 +23,7 @@\n #include <linux/integrity.h>\n #include <linux/evm.h>\n #include <crypto/hash.h>\n+#include <crypto/algapi.h>\n #include \""evm.h\""\n \n int evm_initialized;\n@@ -148,7 +149,7 @@ static enum integrity_status evm_verify_hmac(struct dentry *dentry,\n \t\t\t\t   xattr_value_len, calc.digest);\n \t\tif (rc)\n \t\t\tbreak;\n-\t\trc = memcmp(xattr_data->digest, calc.digest,\n+\t\trc = crypto_memneq(xattr_data->digest, calc.digest,\n \t\t\t    sizeof(calc.digest));\n \t\tif (rc)\n \t\t\trc = -EINVAL;""}","static enum integrity_status evm_verify_hmac(struct dentry *dentry,
					     const char *xattr_name,
					     char *xattr_value,
					     size_t xattr_value_len,
					     struct integrity_iint_cache *iint)
{
	struct evm_ima_xattr_data *xattr_data = NULL;
	struct evm_ima_xattr_data calc;
	enum integrity_status evm_status = INTEGRITY_PASS;
	int rc, xattr_len;

	if (iint && iint->evm_status == INTEGRITY_PASS)
		return iint->evm_status;

	/* if status is not PASS, try to check again - against -ENOMEM */

	/* first need to know the sig type */
	rc = vfs_getxattr_alloc(dentry, XATTR_NAME_EVM, (char **)&xattr_data, 0,
				GFP_NOFS);
	if (rc <= 0) {
		evm_status = INTEGRITY_FAIL;
		if (rc == -ENODATA) {
			rc = evm_find_protected_xattrs(dentry);
			if (rc > 0)
				evm_status = INTEGRITY_NOLABEL;
			else if (rc == 0)
				evm_status = INTEGRITY_NOXATTRS; /* new file */
		} else if (rc == -EOPNOTSUPP) {
			evm_status = INTEGRITY_UNKNOWN;
		}
		goto out;
	}

	xattr_len = rc;

	/* check value type */
	switch (xattr_data->type) {
	case EVM_XATTR_HMAC:
		rc = evm_calc_hmac(dentry, xattr_name, xattr_value,
 				   xattr_value_len, calc.digest);
 		if (rc)
 			break;
		rc = crypto_memneq(xattr_data->digest, calc.digest,
 			    sizeof(calc.digest));
 		if (rc)
 			rc = -EINVAL;
		break;
	case EVM_IMA_XATTR_DIGSIG:
		rc = evm_calc_hash(dentry, xattr_name, xattr_value,
				xattr_value_len, calc.digest);
		if (rc)
			break;
		rc = integrity_digsig_verify(INTEGRITY_KEYRING_EVM,
					(const char *)xattr_data, xattr_len,
					calc.digest, sizeof(calc.digest));
		if (!rc) {
			/* Replace RSA with HMAC if not mounted readonly and
			 * not immutable
			 */
			if (!IS_RDONLY(d_backing_inode(dentry)) &&
			    !IS_IMMUTABLE(d_backing_inode(dentry)))
				evm_update_evmxattr(dentry, xattr_name,
						    xattr_value,
						    xattr_value_len);
		}
		break;
	default:
		rc = -EINVAL;
		break;
	}

	if (rc)
		evm_status = (rc == -ENODATA) ?
				INTEGRITY_NOXATTRS : INTEGRITY_FAIL;
out:
	if (iint)
		iint->evm_status = evm_status;
	kfree(xattr_data);
	return evm_status;
}
","static enum integrity_status evm_verify_hmac(struct dentry *dentry,
					     const char *xattr_name,
					     char *xattr_value,
					     size_t xattr_value_len,
					     struct integrity_iint_cache *iint)
{
	struct evm_ima_xattr_data *xattr_data = NULL;
	struct evm_ima_xattr_data calc;
	enum integrity_status evm_status = INTEGRITY_PASS;
	int rc, xattr_len;

	if (iint && iint->evm_status == INTEGRITY_PASS)
		return iint->evm_status;

	/* if status is not PASS, try to check again - against -ENOMEM */

	/* first need to know the sig type */
	rc = vfs_getxattr_alloc(dentry, XATTR_NAME_EVM, (char **)&xattr_data, 0,
				GFP_NOFS);
	if (rc <= 0) {
		evm_status = INTEGRITY_FAIL;
		if (rc == -ENODATA) {
			rc = evm_find_protected_xattrs(dentry);
			if (rc > 0)
				evm_status = INTEGRITY_NOLABEL;
			else if (rc == 0)
				evm_status = INTEGRITY_NOXATTRS; /* new file */
		} else if (rc == -EOPNOTSUPP) {
			evm_status = INTEGRITY_UNKNOWN;
		}
		goto out;
	}

	xattr_len = rc;

	/* check value type */
	switch (xattr_data->type) {
	case EVM_XATTR_HMAC:
		rc = evm_calc_hmac(dentry, xattr_name, xattr_value,
 				   xattr_value_len, calc.digest);
 		if (rc)
 			break;
		rc = memcmp(xattr_data->digest, calc.digest,
 			    sizeof(calc.digest));
 		if (rc)
 			rc = -EINVAL;
		break;
	case EVM_IMA_XATTR_DIGSIG:
		rc = evm_calc_hash(dentry, xattr_name, xattr_value,
				xattr_value_len, calc.digest);
		if (rc)
			break;
		rc = integrity_digsig_verify(INTEGRITY_KEYRING_EVM,
					(const char *)xattr_data, xattr_len,
					calc.digest, sizeof(calc.digest));
		if (!rc) {
			/* Replace RSA with HMAC if not mounted readonly and
			 * not immutable
			 */
			if (!IS_RDONLY(d_backing_inode(dentry)) &&
			    !IS_IMMUTABLE(d_backing_inode(dentry)))
				evm_update_evmxattr(dentry, xattr_name,
						    xattr_value,
						    xattr_value_len);
		}
		break;
	default:
		rc = -EINVAL;
		break;
	}

	if (rc)
		evm_status = (rc == -ENODATA) ?
				INTEGRITY_NOXATTRS : INTEGRITY_FAIL;
out:
	if (iint)
		iint->evm_status = evm_status;
	kfree(xattr_data);
	return evm_status;
}
",C,"		rc = crypto_memneq(xattr_data->digest, calc.digest,
","		rc = memcmp(xattr_data->digest, calc.digest,
",,"@@ -23,6 +23,7 @@
 #include <linux/integrity.h>
 #include <linux/evm.h>
 #include <crypto/hash.h>
+#include <crypto/algapi.h>
 #include ""evm.h""
 
 int evm_initialized;
@@ -148,7 +149,7 @@ static enum integrity_status evm_verify_hmac(struct dentry *dentry,
 				   xattr_value_len, calc.digest);
 		if (rc)
 			break;
-		rc = memcmp(xattr_data->digest, calc.digest,
+		rc = crypto_memneq(xattr_data->digest, calc.digest,
 			    sizeof(calc.digest));
 		if (rc)
 			rc = -EINVAL;",linux,613317bd212c585c20796c10afe5daaa95d4b0a1,c05235d50f681bf685e7290cae05ab3b4fa493f3,1,"static enum integrity_status evm_verify_hmac(struct dentry *dentry,
					     const char *xattr_name,
					     char *xattr_value,
					     size_t xattr_value_len,
					     struct integrity_iint_cache *iint)
{
	struct evm_ima_xattr_data *xattr_data = NULL;
	struct evm_ima_xattr_data calc;
	enum integrity_status evm_status = INTEGRITY_PASS;
	int rc, xattr_len;

	if (iint && iint->evm_status == INTEGRITY_PASS)
		return iint->evm_status;

	/* if status is not PASS, try to check again - against -ENOMEM */

	/* first need to know the sig type */
	rc = vfs_getxattr_alloc(dentry, XATTR_NAME_EVM, (char **)&xattr_data, 0,
				GFP_NOFS);
	if (rc <= 0) {
		evm_status = INTEGRITY_FAIL;
		if (rc == -ENODATA) {
			rc = evm_find_protected_xattrs(dentry);
			if (rc > 0)
				evm_status = INTEGRITY_NOLABEL;
			else if (rc == 0)
				evm_status = INTEGRITY_NOXATTRS; /* new file */
		} else if (rc == -EOPNOTSUPP) {
			evm_status = INTEGRITY_UNKNOWN;
		}
		goto out;
	}

	xattr_len = rc;

	/* check value type */
	switch (xattr_data->type) {
	case EVM_XATTR_HMAC:
		rc = evm_calc_hmac(dentry, xattr_name, xattr_value,
 				   xattr_value_len, calc.digest);
 		if (rc)
 			break;
//flaw_line_below:
		rc = memcmp(xattr_data->digest, calc.digest,
//fix_flaw_line_below:
//		rc = crypto_memneq(xattr_data->digest, calc.digest,
 			    sizeof(calc.digest));
 		if (rc)
 			rc = -EINVAL;
		break;
	case EVM_IMA_XATTR_DIGSIG:
		rc = evm_calc_hash(dentry, xattr_name, xattr_value,
				xattr_value_len, calc.digest);
		if (rc)
			break;
		rc = integrity_digsig_verify(INTEGRITY_KEYRING_EVM,
					(const char *)xattr_data, xattr_len,
					calc.digest, sizeof(calc.digest));
		if (!rc) {
			/* Replace RSA with HMAC if not mounted readonly and
			 * not immutable
			 */
			if (!IS_RDONLY(d_backing_inode(dentry)) &&
			    !IS_IMMUTABLE(d_backing_inode(dentry)))
				evm_update_evmxattr(dentry, xattr_name,
						    xattr_value,
						    xattr_value_len);
		}
		break;
	default:
		rc = -EINVAL;
		break;
	}

	if (rc)
		evm_status = (rc == -ENODATA) ?
				INTEGRITY_NOXATTRS : INTEGRITY_FAIL;
out:
	if (iint)
		iint->evm_status = evm_status;
	kfree(xattr_data);
	return evm_status;
}
"
3008,180744,,Local,Not required,Complete,CVE-2015-1573,https://www.cvedetails.com/cve/CVE-2015-1573/,CWE-19,Low,,,,2016-05-02,4.9,"The nft_flush_table function in net/netfilter/nf_tables_api.c in the Linux kernel before 3.18.5 mishandles the interaction between cross-chain jumps and ruleset flushes, which allows local users to cause a denial of service (panic) by leveraging the CAP_NET_ADMIN capability.",2018-01-04,DoS ,9,https://github.com/torvalds/linux/commit/a2f18db0c68fec96631c10cad9384c196e9008ac,a2f18db0c68fec96631c10cad9384c196e9008ac,"netfilter: nf_tables: fix flush ruleset chain dependencies

Jumping between chains doesn't mix well with flush ruleset. Rules
from a different chain and set elements may still refer to us.

[  353.373791] ------------[ cut here ]------------
[  353.373845] kernel BUG at net/netfilter/nf_tables_api.c:1159!
[  353.373896] invalid opcode: 0000 [#1] SMP
[  353.373942] Modules linked in: intel_powerclamp uas iwldvm iwlwifi
[  353.374017] CPU: 0 PID: 6445 Comm: 31c3.nft Not tainted 3.18.0 #98
[  353.374069] Hardware name: LENOVO 5129CTO/5129CTO, BIOS 6QET47WW (1.17 ) 07/14/2010
[...]
[  353.375018] Call Trace:
[  353.375046]  [<ffffffff81964c31>] ? nf_tables_commit+0x381/0x540
[  353.375101]  [<ffffffff81949118>] nfnetlink_rcv+0x3d8/0x4b0
[  353.375150]  [<ffffffff81943fc5>] netlink_unicast+0x105/0x1a0
[  353.375200]  [<ffffffff8194438e>] netlink_sendmsg+0x32e/0x790
[  353.375253]  [<ffffffff818f398e>] sock_sendmsg+0x8e/0xc0
[  353.375300]  [<ffffffff818f36b9>] ? move_addr_to_kernel.part.20+0x19/0x70
[  353.375357]  [<ffffffff818f44f9>] ? move_addr_to_kernel+0x19/0x30
[  353.375410]  [<ffffffff819016d2>] ? verify_iovec+0x42/0xd0
[  353.375459]  [<ffffffff818f3e10>] ___sys_sendmsg+0x3f0/0x400
[  353.375510]  [<ffffffff810615fa>] ? native_sched_clock+0x2a/0x90
[  353.375563]  [<ffffffff81176697>] ? acct_account_cputime+0x17/0x20
[  353.375616]  [<ffffffff8110dc78>] ? account_user_time+0x88/0xa0
[  353.375667]  [<ffffffff818f4bbd>] __sys_sendmsg+0x3d/0x80
[  353.375719]  [<ffffffff81b184f4>] ? int_check_syscall_exit_work+0x34/0x3d
[  353.375776]  [<ffffffff818f4c0d>] SyS_sendmsg+0xd/0x20
[  353.375823]  [<ffffffff81b1826d>] system_call_fastpath+0x16/0x1b

Release objects in this order: rules -> sets -> chains -> tables, to
make sure no references to chains are held anymore.

Reported-by: Asbjoern Sloth Toennesen <asbjorn@asbjorn.biz>
Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>",4,net/netfilter/nf_tables_api.c,"{""sha"": ""3b3ddb4fb9ee122a5b6d3a39450be38a64d6f614"", ""filename"": ""net/netfilter/nf_tables_api.c"", ""status"": ""modified"", ""additions"": 9, ""deletions"": 5, ""changes"": 14, ""blob_url"": ""https://github.com/torvalds/linux/blob/a2f18db0c68fec96631c10cad9384c196e9008ac/net/netfilter/nf_tables_api.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/a2f18db0c68fec96631c10cad9384c196e9008ac/net/netfilter/nf_tables_api.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/net/netfilter/nf_tables_api.c?ref=a2f18db0c68fec96631c10cad9384c196e9008ac"", ""patch"": ""@@ -713,16 +713,12 @@ static int nft_flush_table(struct nft_ctx *ctx)\n \tstruct nft_chain *chain, *nc;\n \tstruct nft_set *set, *ns;\n \n-\tlist_for_each_entry_safe(chain, nc, &ctx->table->chains, list) {\n+\tlist_for_each_entry(chain, &ctx->table->chains, list) {\n \t\tctx->chain = chain;\n \n \t\terr = nft_delrule_by_chain(ctx);\n \t\tif (err < 0)\n \t\t\tgoto out;\n-\n-\t\terr = nft_delchain(ctx);\n-\t\tif (err < 0)\n-\t\t\tgoto out;\n \t}\n \n \tlist_for_each_entry_safe(set, ns, &ctx->table->sets, list) {\n@@ -735,6 +731,14 @@ static int nft_flush_table(struct nft_ctx *ctx)\n \t\t\tgoto out;\n \t}\n \n+\tlist_for_each_entry_safe(chain, nc, &ctx->table->chains, list) {\n+\t\tctx->chain = chain;\n+\n+\t\terr = nft_delchain(ctx);\n+\t\tif (err < 0)\n+\t\t\tgoto out;\n+\t}\n+\n \terr = nft_deltable(ctx);\n out:\n \treturn err;""}","static int nft_flush_table(struct nft_ctx *ctx)
{
	int err;
 	struct nft_chain *chain, *nc;
 	struct nft_set *set, *ns;
 
	list_for_each_entry(chain, &ctx->table->chains, list) {
 		ctx->chain = chain;
 
 		err = nft_delrule_by_chain(ctx);
 		if (err < 0)
 			goto out;
 	}
 
 	list_for_each_entry_safe(set, ns, &ctx->table->sets, list) {
		if (set->flags & NFT_SET_ANONYMOUS &&
		    !list_empty(&set->bindings))
			continue;

		err = nft_delset(ctx, set);
		if (err < 0)
 			goto out;
 	}
 
	list_for_each_entry_safe(chain, nc, &ctx->table->chains, list) {
		ctx->chain = chain;

		err = nft_delchain(ctx);
		if (err < 0)
			goto out;
	}

 	err = nft_deltable(ctx);
 out:
 	return err;
}
","static int nft_flush_table(struct nft_ctx *ctx)
{
	int err;
 	struct nft_chain *chain, *nc;
 	struct nft_set *set, *ns;
 
	list_for_each_entry_safe(chain, nc, &ctx->table->chains, list) {
 		ctx->chain = chain;
 
 		err = nft_delrule_by_chain(ctx);
 		if (err < 0)
 			goto out;
		err = nft_delchain(ctx);
		if (err < 0)
			goto out;
 	}
 
 	list_for_each_entry_safe(set, ns, &ctx->table->sets, list) {
		if (set->flags & NFT_SET_ANONYMOUS &&
		    !list_empty(&set->bindings))
			continue;

		err = nft_delset(ctx, set);
		if (err < 0)
 			goto out;
 	}
 
 	err = nft_deltable(ctx);
 out:
 	return err;
}
",C,"	list_for_each_entry(chain, &ctx->table->chains, list) {
	list_for_each_entry_safe(chain, nc, &ctx->table->chains, list) {
		ctx->chain = chain;

		err = nft_delchain(ctx);
		if (err < 0)
			goto out;
	}

","	list_for_each_entry_safe(chain, nc, &ctx->table->chains, list) {
		err = nft_delchain(ctx);
		if (err < 0)
			goto out;
",,"@@ -713,16 +713,12 @@ static int nft_flush_table(struct nft_ctx *ctx)
 	struct nft_chain *chain, *nc;
 	struct nft_set *set, *ns;
 
-	list_for_each_entry_safe(chain, nc, &ctx->table->chains, list) {
+	list_for_each_entry(chain, &ctx->table->chains, list) {
 		ctx->chain = chain;
 
 		err = nft_delrule_by_chain(ctx);
 		if (err < 0)
 			goto out;
-
-		err = nft_delchain(ctx);
-		if (err < 0)
-			goto out;
 	}
 
 	list_for_each_entry_safe(set, ns, &ctx->table->sets, list) {
@@ -735,6 +731,14 @@ static int nft_flush_table(struct nft_ctx *ctx)
 			goto out;
 	}
 
+	list_for_each_entry_safe(chain, nc, &ctx->table->chains, list) {
+		ctx->chain = chain;
+
+		err = nft_delchain(ctx);
+		if (err < 0)
+			goto out;
+	}
+
 	err = nft_deltable(ctx);
 out:
 	return err;",linux,a2f18db0c68fec96631c10cad9384c196e9008ac,62924af247e95de7041a6d6f2d06cdd05152e2dc,1,"static int nft_flush_table(struct nft_ctx *ctx)
{
	int err;
 	struct nft_chain *chain, *nc;
 	struct nft_set *set, *ns;
 
//flaw_line_below:
	list_for_each_entry_safe(chain, nc, &ctx->table->chains, list) {
//fix_flaw_line_below:
//	list_for_each_entry(chain, &ctx->table->chains, list) {
 		ctx->chain = chain;
 
 		err = nft_delrule_by_chain(ctx);
 		if (err < 0)
 			goto out;
//flaw_line_below:

//flaw_line_below:
		err = nft_delchain(ctx);
//flaw_line_below:
		if (err < 0)
//flaw_line_below:
			goto out;
 	}
 
 	list_for_each_entry_safe(set, ns, &ctx->table->sets, list) {
		if (set->flags & NFT_SET_ANONYMOUS &&
		    !list_empty(&set->bindings))
			continue;

		err = nft_delset(ctx, set);
		if (err < 0)
 			goto out;
 	}
 
//fix_flaw_line_below:
//	list_for_each_entry_safe(chain, nc, &ctx->table->chains, list) {
//fix_flaw_line_below:
//		ctx->chain = chain;
//fix_flaw_line_below:
//
//fix_flaw_line_below:
//		err = nft_delchain(ctx);
//fix_flaw_line_below:
//		if (err < 0)
//fix_flaw_line_below:
//			goto out;
//fix_flaw_line_below:
//	}
//fix_flaw_line_below:
//
 	err = nft_deltable(ctx);
 out:
 	return err;
}
"
3019,180755,,Remote,Not required,Complete,CVE-2014-9803,https://www.cvedetails.com/cve/CVE-2014-9803/,CWE-19,Medium,Complete,Complete,,2016-07-10,9.3,"arch/arm64/include/asm/pgtable.h in the Linux kernel before 3.15-rc5-next-20140519, as used in Android before 2016-07-05 on Nexus 5X and 6P devices, mishandles execute-only pages, which allows attackers to gain privileges via a crafted application, aka Android internal bug 28557020.",2016-07-12,+Priv ,2,https://github.com/torvalds/linux/commit/5a0fdfada3a2aa50d7b947a2e958bf00cbe0d830,5a0fdfada3a2aa50d7b947a2e958bf00cbe0d830,"Revert ""arm64: Introduce execute-only page access permissions""

This reverts commit bc07c2c6e9ed125d362af0214b6313dca180cb08.

While the aim is increased security for --x memory maps, it does not
protect against kernel level reads. Until SECCOMP is implemented for
arm64, revert this patch to avoid giving a false idea of execute-only
mappings.

Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>",1,arch/arm64/mm/fault.c,"{""sha"": ""aa150ed99f222e5eff7ba51aee46ebf7e22d79c1"", ""filename"": ""arch/arm64/include/asm/pgtable.h"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 6, ""changes"": 11, ""blob_url"": ""https://github.com/torvalds/linux/blob/5a0fdfada3a2aa50d7b947a2e958bf00cbe0d830/arch/arm64/include/asm/pgtable.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/5a0fdfada3a2aa50d7b947a2e958bf00cbe0d830/arch/arm64/include/asm/pgtable.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/arch/arm64/include/asm/pgtable.h?ref=5a0fdfada3a2aa50d7b947a2e958bf00cbe0d830"", ""patch"": ""@@ -86,13 +86,12 @@ extern void __pgd_error(const char *file, int line, unsigned long val);\n #define PAGE_COPY_EXEC\t\t__pgprot(_PAGE_DEFAULT | PTE_USER | PTE_NG | PTE_PXN)\n #define PAGE_READONLY\t\t__pgprot(_PAGE_DEFAULT | PTE_USER | PTE_NG | PTE_PXN | PTE_UXN)\n #define PAGE_READONLY_EXEC\t__pgprot(_PAGE_DEFAULT | PTE_USER | PTE_NG | PTE_PXN)\n-#define PAGE_EXECONLY\t\t__pgprot(_PAGE_DEFAULT | PTE_NG | PTE_PXN)\n \n #define __P000  PAGE_NONE\n #define __P001  PAGE_READONLY\n #define __P010  PAGE_COPY\n #define __P011  PAGE_COPY\n-#define __P100  PAGE_EXECONLY\n+#define __P100  PAGE_READONLY_EXEC\n #define __P101  PAGE_READONLY_EXEC\n #define __P110  PAGE_COPY_EXEC\n #define __P111  PAGE_COPY_EXEC\n@@ -101,7 +100,7 @@ extern void __pgd_error(const char *file, int line, unsigned long val);\n #define __S001  PAGE_READONLY\n #define __S010  PAGE_SHARED\n #define __S011  PAGE_SHARED\n-#define __S100  PAGE_EXECONLY\n+#define __S100  PAGE_READONLY_EXEC\n #define __S101  PAGE_READONLY_EXEC\n #define __S110  PAGE_SHARED_EXEC\n #define __S111  PAGE_SHARED_EXEC\n@@ -137,8 +136,8 @@ extern struct page *empty_zero_page;\n #define pte_write(pte)\t\t(!!(pte_val(pte) & PTE_WRITE))\n #define pte_exec(pte)\t\t(!(pte_val(pte) & PTE_UXN))\n \n-#define pte_valid_ng(pte) \\\n-\t((pte_val(pte) & (PTE_VALID | PTE_NG)) == (PTE_VALID | PTE_NG))\n+#define pte_valid_user(pte) \\\n+\t((pte_val(pte) & (PTE_VALID | PTE_USER)) == (PTE_VALID | PTE_USER))\n \n static inline pte_t pte_wrprotect(pte_t pte)\n {\n@@ -192,7 +191,7 @@ extern void __sync_icache_dcache(pte_t pteval, unsigned long addr);\n static inline void set_pte_at(struct mm_struct *mm, unsigned long addr,\n \t\t\t      pte_t *ptep, pte_t pte)\n {\n-\tif (pte_valid_ng(pte)) {\n+\tif (pte_valid_user(pte)) {\n \t\tif (!pte_special(pte) && pte_exec(pte))\n \t\t\t__sync_icache_dcache(pte, addr);\n \t\tif (pte_dirty(pte) && pte_write(pte))""}<_**next**_>{""sha"": ""bcc965e2cce1fefca8d0791c2792973d6ab3832b"", ""filename"": ""arch/arm64/mm/fault.c"", ""status"": ""modified"", ""additions"": 3, ""deletions"": 2, ""changes"": 5, ""blob_url"": ""https://github.com/torvalds/linux/blob/5a0fdfada3a2aa50d7b947a2e958bf00cbe0d830/arch/arm64/mm/fault.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/5a0fdfada3a2aa50d7b947a2e958bf00cbe0d830/arch/arm64/mm/fault.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/arch/arm64/mm/fault.c?ref=5a0fdfada3a2aa50d7b947a2e958bf00cbe0d830"", ""patch"": ""@@ -173,7 +173,8 @@ static int __do_page_fault(struct mm_struct *mm, unsigned long addr,\n good_area:\n \t/*\n \t * Check that the permissions on the VMA allow for the fault which\n-\t * occurred.\n+\t * occurred. If we encountered a write or exec fault, we must have\n+\t * appropriate permissions, otherwise we allow any permission.\n \t */\n \tif (!(vma->vm_flags & vm_flags)) {\n \t\tfault = VM_FAULT_BADACCESS;\n@@ -195,7 +196,7 @@ static int __kprobes do_page_fault(unsigned long addr, unsigned int esr,\n \tstruct task_struct *tsk;\n \tstruct mm_struct *mm;\n \tint fault, sig, code;\n-\tunsigned long vm_flags = VM_READ | VM_WRITE;\n+\tunsigned long vm_flags = VM_READ | VM_WRITE | VM_EXEC;\n \tunsigned int mm_flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;\n \n \ttsk = current;""}","static int __do_page_fault(struct mm_struct *mm, unsigned long addr,
			   unsigned int mm_flags, unsigned long vm_flags,
			   struct task_struct *tsk)
{
	struct vm_area_struct *vma;
	int fault;

	vma = find_vma(mm, addr);
	fault = VM_FAULT_BADMAP;
	if (unlikely(!vma))
		goto out;
	if (unlikely(vma->vm_start > addr))
		goto check_stack;

	/*
	 * Ok, we have a good vm_area for this memory access, so we can handle
	 * it.
	 */
 good_area:
 	/*
 	 * Check that the permissions on the VMA allow for the fault which
	 * occurred. If we encountered a write or exec fault, we must have
	 * appropriate permissions, otherwise we allow any permission.
 	 */
 	if (!(vma->vm_flags & vm_flags)) {
 		fault = VM_FAULT_BADACCESS;
		goto out;
	}

	return handle_mm_fault(mm, vma, addr & PAGE_MASK, mm_flags);

check_stack:
	if (vma->vm_flags & VM_GROWSDOWN && !expand_stack(vma, addr))
		goto good_area;
out:
	return fault;
}
","static int __do_page_fault(struct mm_struct *mm, unsigned long addr,
			   unsigned int mm_flags, unsigned long vm_flags,
			   struct task_struct *tsk)
{
	struct vm_area_struct *vma;
	int fault;

	vma = find_vma(mm, addr);
	fault = VM_FAULT_BADMAP;
	if (unlikely(!vma))
		goto out;
	if (unlikely(vma->vm_start > addr))
		goto check_stack;

	/*
	 * Ok, we have a good vm_area for this memory access, so we can handle
	 * it.
	 */
 good_area:
 	/*
 	 * Check that the permissions on the VMA allow for the fault which
	 * occurred.
 	 */
 	if (!(vma->vm_flags & vm_flags)) {
 		fault = VM_FAULT_BADACCESS;
		goto out;
	}

	return handle_mm_fault(mm, vma, addr & PAGE_MASK, mm_flags);

check_stack:
	if (vma->vm_flags & VM_GROWSDOWN && !expand_stack(vma, addr))
		goto good_area;
out:
	return fault;
}
",C,"	 * occurred. If we encountered a write or exec fault, we must have
	 * appropriate permissions, otherwise we allow any permission.
","	 * occurred.
",,"@@ -173,7 +173,8 @@ static int __do_page_fault(struct mm_struct *mm, unsigned long addr,
 good_area:
 	/*
 	 * Check that the permissions on the VMA allow for the fault which
-	 * occurred.
+	 * occurred. If we encountered a write or exec fault, we must have
+	 * appropriate permissions, otherwise we allow any permission.
 	 */
 	if (!(vma->vm_flags & vm_flags)) {
 		fault = VM_FAULT_BADACCESS;
@@ -195,7 +196,7 @@ static int __kprobes do_page_fault(unsigned long addr, unsigned int esr,
 	struct task_struct *tsk;
 	struct mm_struct *mm;
 	int fault, sig, code;
-	unsigned long vm_flags = VM_READ | VM_WRITE;
+	unsigned long vm_flags = VM_READ | VM_WRITE | VM_EXEC;
 	unsigned int mm_flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;
 
 	tsk = current;",linux,5a0fdfada3a2aa50d7b947a2e958bf00cbe0d830,cf5c95db57ffa02e430c3840c08d1ee0403849d4,1,"static int __do_page_fault(struct mm_struct *mm, unsigned long addr,
			   unsigned int mm_flags, unsigned long vm_flags,
			   struct task_struct *tsk)
{
	struct vm_area_struct *vma;
	int fault;

	vma = find_vma(mm, addr);
	fault = VM_FAULT_BADMAP;
	if (unlikely(!vma))
		goto out;
	if (unlikely(vma->vm_start > addr))
		goto check_stack;

	/*
	 * Ok, we have a good vm_area for this memory access, so we can handle
	 * it.
	 */
 good_area:
 	/*
 	 * Check that the permissions on the VMA allow for the fault which
//flaw_line_below:
	 * occurred.
//fix_flaw_line_below:
//	 * occurred. If we encountered a write or exec fault, we must have
//fix_flaw_line_below:
//	 * appropriate permissions, otherwise we allow any permission.
 	 */
 	if (!(vma->vm_flags & vm_flags)) {
 		fault = VM_FAULT_BADACCESS;
		goto out;
	}

	return handle_mm_fault(mm, vma, addr & PAGE_MASK, mm_flags);

check_stack:
	if (vma->vm_flags & VM_GROWSDOWN && !expand_stack(vma, addr))
		goto good_area;
out:
	return fault;
}
"
3020,180756,,Remote,Not required,Complete,CVE-2014-9803,https://www.cvedetails.com/cve/CVE-2014-9803/,CWE-19,Medium,Complete,Complete,,2016-07-10,9.3,"arch/arm64/include/asm/pgtable.h in the Linux kernel before 3.15-rc5-next-20140519, as used in Android before 2016-07-05 on Nexus 5X and 6P devices, mishandles execute-only pages, which allows attackers to gain privileges via a crafted application, aka Android internal bug 28557020.",2016-07-12,+Priv ,1,https://github.com/torvalds/linux/commit/5a0fdfada3a2aa50d7b947a2e958bf00cbe0d830,5a0fdfada3a2aa50d7b947a2e958bf00cbe0d830,"Revert ""arm64: Introduce execute-only page access permissions""

This reverts commit bc07c2c6e9ed125d362af0214b6313dca180cb08.

While the aim is increased security for --x memory maps, it does not
protect against kernel level reads. Until SECCOMP is implemented for
arm64, revert this patch to avoid giving a false idea of execute-only
mappings.

Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>",1,arch/arm64/mm/fault.c,"{""sha"": ""aa150ed99f222e5eff7ba51aee46ebf7e22d79c1"", ""filename"": ""arch/arm64/include/asm/pgtable.h"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 6, ""changes"": 11, ""blob_url"": ""https://github.com/torvalds/linux/blob/5a0fdfada3a2aa50d7b947a2e958bf00cbe0d830/arch/arm64/include/asm/pgtable.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/5a0fdfada3a2aa50d7b947a2e958bf00cbe0d830/arch/arm64/include/asm/pgtable.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/arch/arm64/include/asm/pgtable.h?ref=5a0fdfada3a2aa50d7b947a2e958bf00cbe0d830"", ""patch"": ""@@ -86,13 +86,12 @@ extern void __pgd_error(const char *file, int line, unsigned long val);\n #define PAGE_COPY_EXEC\t\t__pgprot(_PAGE_DEFAULT | PTE_USER | PTE_NG | PTE_PXN)\n #define PAGE_READONLY\t\t__pgprot(_PAGE_DEFAULT | PTE_USER | PTE_NG | PTE_PXN | PTE_UXN)\n #define PAGE_READONLY_EXEC\t__pgprot(_PAGE_DEFAULT | PTE_USER | PTE_NG | PTE_PXN)\n-#define PAGE_EXECONLY\t\t__pgprot(_PAGE_DEFAULT | PTE_NG | PTE_PXN)\n \n #define __P000  PAGE_NONE\n #define __P001  PAGE_READONLY\n #define __P010  PAGE_COPY\n #define __P011  PAGE_COPY\n-#define __P100  PAGE_EXECONLY\n+#define __P100  PAGE_READONLY_EXEC\n #define __P101  PAGE_READONLY_EXEC\n #define __P110  PAGE_COPY_EXEC\n #define __P111  PAGE_COPY_EXEC\n@@ -101,7 +100,7 @@ extern void __pgd_error(const char *file, int line, unsigned long val);\n #define __S001  PAGE_READONLY\n #define __S010  PAGE_SHARED\n #define __S011  PAGE_SHARED\n-#define __S100  PAGE_EXECONLY\n+#define __S100  PAGE_READONLY_EXEC\n #define __S101  PAGE_READONLY_EXEC\n #define __S110  PAGE_SHARED_EXEC\n #define __S111  PAGE_SHARED_EXEC\n@@ -137,8 +136,8 @@ extern struct page *empty_zero_page;\n #define pte_write(pte)\t\t(!!(pte_val(pte) & PTE_WRITE))\n #define pte_exec(pte)\t\t(!(pte_val(pte) & PTE_UXN))\n \n-#define pte_valid_ng(pte) \\\n-\t((pte_val(pte) & (PTE_VALID | PTE_NG)) == (PTE_VALID | PTE_NG))\n+#define pte_valid_user(pte) \\\n+\t((pte_val(pte) & (PTE_VALID | PTE_USER)) == (PTE_VALID | PTE_USER))\n \n static inline pte_t pte_wrprotect(pte_t pte)\n {\n@@ -192,7 +191,7 @@ extern void __sync_icache_dcache(pte_t pteval, unsigned long addr);\n static inline void set_pte_at(struct mm_struct *mm, unsigned long addr,\n \t\t\t      pte_t *ptep, pte_t pte)\n {\n-\tif (pte_valid_ng(pte)) {\n+\tif (pte_valid_user(pte)) {\n \t\tif (!pte_special(pte) && pte_exec(pte))\n \t\t\t__sync_icache_dcache(pte, addr);\n \t\tif (pte_dirty(pte) && pte_write(pte))""}<_**next**_>{""sha"": ""bcc965e2cce1fefca8d0791c2792973d6ab3832b"", ""filename"": ""arch/arm64/mm/fault.c"", ""status"": ""modified"", ""additions"": 3, ""deletions"": 2, ""changes"": 5, ""blob_url"": ""https://github.com/torvalds/linux/blob/5a0fdfada3a2aa50d7b947a2e958bf00cbe0d830/arch/arm64/mm/fault.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/5a0fdfada3a2aa50d7b947a2e958bf00cbe0d830/arch/arm64/mm/fault.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/arch/arm64/mm/fault.c?ref=5a0fdfada3a2aa50d7b947a2e958bf00cbe0d830"", ""patch"": ""@@ -173,7 +173,8 @@ static int __do_page_fault(struct mm_struct *mm, unsigned long addr,\n good_area:\n \t/*\n \t * Check that the permissions on the VMA allow for the fault which\n-\t * occurred.\n+\t * occurred. If we encountered a write or exec fault, we must have\n+\t * appropriate permissions, otherwise we allow any permission.\n \t */\n \tif (!(vma->vm_flags & vm_flags)) {\n \t\tfault = VM_FAULT_BADACCESS;\n@@ -195,7 +196,7 @@ static int __kprobes do_page_fault(unsigned long addr, unsigned int esr,\n \tstruct task_struct *tsk;\n \tstruct mm_struct *mm;\n \tint fault, sig, code;\n-\tunsigned long vm_flags = VM_READ | VM_WRITE;\n+\tunsigned long vm_flags = VM_READ | VM_WRITE | VM_EXEC;\n \tunsigned int mm_flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;\n \n \ttsk = current;""}","static int __kprobes do_page_fault(unsigned long addr, unsigned int esr,
				   struct pt_regs *regs)
{
 	struct task_struct *tsk;
 	struct mm_struct *mm;
 	int fault, sig, code;
	unsigned long vm_flags = VM_READ | VM_WRITE | VM_EXEC;
 	unsigned int mm_flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;
 
 	tsk = current;
	mm  = tsk->mm;

	/* Enable interrupts if they were enabled in the parent context. */
	if (interrupts_enabled(regs))
		local_irq_enable();

	/*
	 * If we're in an interrupt or have no user context, we must not take
	 * the fault.
	 */
	if (in_atomic() || !mm)
		goto no_context;

	if (user_mode(regs))
		mm_flags |= FAULT_FLAG_USER;

	if (esr & ESR_LNX_EXEC) {
		vm_flags = VM_EXEC;
	} else if ((esr & ESR_EL1_WRITE) && !(esr & ESR_EL1_CM)) {
		vm_flags = VM_WRITE;
		mm_flags |= FAULT_FLAG_WRITE;
	}

	/*
	 * As per x86, we may deadlock here. However, since the kernel only
	 * validly references user space from well defined areas of the code,
	 * we can bug out early if this is from code which shouldn't.
	 */
	if (!down_read_trylock(&mm->mmap_sem)) {
		if (!user_mode(regs) && !search_exception_tables(regs->pc))
			goto no_context;
retry:
		down_read(&mm->mmap_sem);
	} else {
		/*
		 * The above down_read_trylock() might have succeeded in which
		 * case, we'll have missed the might_sleep() from down_read().
		 */
		might_sleep();
#ifdef CONFIG_DEBUG_VM
		if (!user_mode(regs) && !search_exception_tables(regs->pc))
			goto no_context;
#endif
	}

	fault = __do_page_fault(mm, addr, mm_flags, vm_flags, tsk);

	/*
	 * If we need to retry but a fatal signal is pending, handle the
	 * signal first. We do not need to release the mmap_sem because it
	 * would already be released in __lock_page_or_retry in mm/filemap.c.
	 */
	if ((fault & VM_FAULT_RETRY) && fatal_signal_pending(current))
		return 0;

	/*
	 * Major/minor page fault accounting is only done on the initial
	 * attempt. If we go through a retry, it is extremely likely that the
	 * page will be found in page cache at that point.
	 */

	perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, regs, addr);
	if (mm_flags & FAULT_FLAG_ALLOW_RETRY) {
		if (fault & VM_FAULT_MAJOR) {
			tsk->maj_flt++;
			perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MAJ, 1, regs,
				      addr);
		} else {
			tsk->min_flt++;
			perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MIN, 1, regs,
				      addr);
		}
		if (fault & VM_FAULT_RETRY) {
			/*
			 * Clear FAULT_FLAG_ALLOW_RETRY to avoid any risk of
			 * starvation.
			 */
			mm_flags &= ~FAULT_FLAG_ALLOW_RETRY;
			goto retry;
		}
	}

	up_read(&mm->mmap_sem);

	/*
	 * Handle the ""normal"" case first - VM_FAULT_MAJOR / VM_FAULT_MINOR
	 */
	if (likely(!(fault & (VM_FAULT_ERROR | VM_FAULT_BADMAP |
			      VM_FAULT_BADACCESS))))
		return 0;

	/*
	 * If we are in kernel mode at this point, we have no context to
	 * handle this fault with.
	 */
	if (!user_mode(regs))
		goto no_context;

	if (fault & VM_FAULT_OOM) {
		/*
		 * We ran out of memory, call the OOM killer, and return to
		 * userspace (which will retry the fault, or kill us if we got
		 * oom-killed).
		 */
		pagefault_out_of_memory();
		return 0;
	}

	if (fault & VM_FAULT_SIGBUS) {
		/*
		 * We had some memory, but were unable to successfully fix up
		 * this page fault.
		 */
		sig = SIGBUS;
		code = BUS_ADRERR;
	} else {
		/*
		 * Something tried to access memory that isn't in our memory
		 * map.
		 */
		sig = SIGSEGV;
		code = fault == VM_FAULT_BADACCESS ?
			SEGV_ACCERR : SEGV_MAPERR;
	}

	__do_user_fault(tsk, addr, esr, sig, code, regs);
	return 0;

no_context:
	__do_kernel_fault(mm, addr, esr, regs);
	return 0;
}
","static int __kprobes do_page_fault(unsigned long addr, unsigned int esr,
				   struct pt_regs *regs)
{
 	struct task_struct *tsk;
 	struct mm_struct *mm;
 	int fault, sig, code;
	unsigned long vm_flags = VM_READ | VM_WRITE;
 	unsigned int mm_flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;
 
 	tsk = current;
	mm  = tsk->mm;

	/* Enable interrupts if they were enabled in the parent context. */
	if (interrupts_enabled(regs))
		local_irq_enable();

	/*
	 * If we're in an interrupt or have no user context, we must not take
	 * the fault.
	 */
	if (in_atomic() || !mm)
		goto no_context;

	if (user_mode(regs))
		mm_flags |= FAULT_FLAG_USER;

	if (esr & ESR_LNX_EXEC) {
		vm_flags = VM_EXEC;
	} else if ((esr & ESR_EL1_WRITE) && !(esr & ESR_EL1_CM)) {
		vm_flags = VM_WRITE;
		mm_flags |= FAULT_FLAG_WRITE;
	}

	/*
	 * As per x86, we may deadlock here. However, since the kernel only
	 * validly references user space from well defined areas of the code,
	 * we can bug out early if this is from code which shouldn't.
	 */
	if (!down_read_trylock(&mm->mmap_sem)) {
		if (!user_mode(regs) && !search_exception_tables(regs->pc))
			goto no_context;
retry:
		down_read(&mm->mmap_sem);
	} else {
		/*
		 * The above down_read_trylock() might have succeeded in which
		 * case, we'll have missed the might_sleep() from down_read().
		 */
		might_sleep();
#ifdef CONFIG_DEBUG_VM
		if (!user_mode(regs) && !search_exception_tables(regs->pc))
			goto no_context;
#endif
	}

	fault = __do_page_fault(mm, addr, mm_flags, vm_flags, tsk);

	/*
	 * If we need to retry but a fatal signal is pending, handle the
	 * signal first. We do not need to release the mmap_sem because it
	 * would already be released in __lock_page_or_retry in mm/filemap.c.
	 */
	if ((fault & VM_FAULT_RETRY) && fatal_signal_pending(current))
		return 0;

	/*
	 * Major/minor page fault accounting is only done on the initial
	 * attempt. If we go through a retry, it is extremely likely that the
	 * page will be found in page cache at that point.
	 */

	perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, regs, addr);
	if (mm_flags & FAULT_FLAG_ALLOW_RETRY) {
		if (fault & VM_FAULT_MAJOR) {
			tsk->maj_flt++;
			perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MAJ, 1, regs,
				      addr);
		} else {
			tsk->min_flt++;
			perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MIN, 1, regs,
				      addr);
		}
		if (fault & VM_FAULT_RETRY) {
			/*
			 * Clear FAULT_FLAG_ALLOW_RETRY to avoid any risk of
			 * starvation.
			 */
			mm_flags &= ~FAULT_FLAG_ALLOW_RETRY;
			goto retry;
		}
	}

	up_read(&mm->mmap_sem);

	/*
	 * Handle the ""normal"" case first - VM_FAULT_MAJOR / VM_FAULT_MINOR
	 */
	if (likely(!(fault & (VM_FAULT_ERROR | VM_FAULT_BADMAP |
			      VM_FAULT_BADACCESS))))
		return 0;

	/*
	 * If we are in kernel mode at this point, we have no context to
	 * handle this fault with.
	 */
	if (!user_mode(regs))
		goto no_context;

	if (fault & VM_FAULT_OOM) {
		/*
		 * We ran out of memory, call the OOM killer, and return to
		 * userspace (which will retry the fault, or kill us if we got
		 * oom-killed).
		 */
		pagefault_out_of_memory();
		return 0;
	}

	if (fault & VM_FAULT_SIGBUS) {
		/*
		 * We had some memory, but were unable to successfully fix up
		 * this page fault.
		 */
		sig = SIGBUS;
		code = BUS_ADRERR;
	} else {
		/*
		 * Something tried to access memory that isn't in our memory
		 * map.
		 */
		sig = SIGSEGV;
		code = fault == VM_FAULT_BADACCESS ?
			SEGV_ACCERR : SEGV_MAPERR;
	}

	__do_user_fault(tsk, addr, esr, sig, code, regs);
	return 0;

no_context:
	__do_kernel_fault(mm, addr, esr, regs);
	return 0;
}
",C,"	unsigned long vm_flags = VM_READ | VM_WRITE | VM_EXEC;
","	unsigned long vm_flags = VM_READ | VM_WRITE;
",,"@@ -173,7 +173,8 @@ static int __do_page_fault(struct mm_struct *mm, unsigned long addr,
 good_area:
 	/*
 	 * Check that the permissions on the VMA allow for the fault which
-	 * occurred.
+	 * occurred. If we encountered a write or exec fault, we must have
+	 * appropriate permissions, otherwise we allow any permission.
 	 */
 	if (!(vma->vm_flags & vm_flags)) {
 		fault = VM_FAULT_BADACCESS;
@@ -195,7 +196,7 @@ static int __kprobes do_page_fault(unsigned long addr, unsigned int esr,
 	struct task_struct *tsk;
 	struct mm_struct *mm;
 	int fault, sig, code;
-	unsigned long vm_flags = VM_READ | VM_WRITE;
+	unsigned long vm_flags = VM_READ | VM_WRITE | VM_EXEC;
 	unsigned int mm_flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;
 
 	tsk = current;",linux,5a0fdfada3a2aa50d7b947a2e958bf00cbe0d830,cf5c95db57ffa02e430c3840c08d1ee0403849d4,1,"static int __kprobes do_page_fault(unsigned long addr, unsigned int esr,
				   struct pt_regs *regs)
{
 	struct task_struct *tsk;
 	struct mm_struct *mm;
 	int fault, sig, code;
//flaw_line_below:
	unsigned long vm_flags = VM_READ | VM_WRITE;
//fix_flaw_line_below:
//	unsigned long vm_flags = VM_READ | VM_WRITE | VM_EXEC;
 	unsigned int mm_flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;
 
 	tsk = current;
	mm  = tsk->mm;

	/* Enable interrupts if they were enabled in the parent context. */
	if (interrupts_enabled(regs))
		local_irq_enable();

	/*
	 * If we're in an interrupt or have no user context, we must not take
	 * the fault.
	 */
	if (in_atomic() || !mm)
		goto no_context;

	if (user_mode(regs))
		mm_flags |= FAULT_FLAG_USER;

	if (esr & ESR_LNX_EXEC) {
		vm_flags = VM_EXEC;
	} else if ((esr & ESR_EL1_WRITE) && !(esr & ESR_EL1_CM)) {
		vm_flags = VM_WRITE;
		mm_flags |= FAULT_FLAG_WRITE;
	}

	/*
	 * As per x86, we may deadlock here. However, since the kernel only
	 * validly references user space from well defined areas of the code,
	 * we can bug out early if this is from code which shouldn't.
	 */
	if (!down_read_trylock(&mm->mmap_sem)) {
		if (!user_mode(regs) && !search_exception_tables(regs->pc))
			goto no_context;
retry:
		down_read(&mm->mmap_sem);
	} else {
		/*
		 * The above down_read_trylock() might have succeeded in which
		 * case, we'll have missed the might_sleep() from down_read().
		 */
		might_sleep();
#ifdef CONFIG_DEBUG_VM
		if (!user_mode(regs) && !search_exception_tables(regs->pc))
			goto no_context;
#endif
	}

	fault = __do_page_fault(mm, addr, mm_flags, vm_flags, tsk);

	/*
	 * If we need to retry but a fatal signal is pending, handle the
	 * signal first. We do not need to release the mmap_sem because it
	 * would already be released in __lock_page_or_retry in mm/filemap.c.
	 */
	if ((fault & VM_FAULT_RETRY) && fatal_signal_pending(current))
		return 0;

	/*
	 * Major/minor page fault accounting is only done on the initial
	 * attempt. If we go through a retry, it is extremely likely that the
	 * page will be found in page cache at that point.
	 */

	perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, regs, addr);
	if (mm_flags & FAULT_FLAG_ALLOW_RETRY) {
		if (fault & VM_FAULT_MAJOR) {
			tsk->maj_flt++;
			perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MAJ, 1, regs,
				      addr);
		} else {
			tsk->min_flt++;
			perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MIN, 1, regs,
				      addr);
		}
		if (fault & VM_FAULT_RETRY) {
			/*
			 * Clear FAULT_FLAG_ALLOW_RETRY to avoid any risk of
			 * starvation.
			 */
			mm_flags &= ~FAULT_FLAG_ALLOW_RETRY;
			goto retry;
		}
	}

	up_read(&mm->mmap_sem);

	/*
	 * Handle the ""normal"" case first - VM_FAULT_MAJOR / VM_FAULT_MINOR
	 */
	if (likely(!(fault & (VM_FAULT_ERROR | VM_FAULT_BADMAP |
			      VM_FAULT_BADACCESS))))
		return 0;

	/*
	 * If we are in kernel mode at this point, we have no context to
	 * handle this fault with.
	 */
	if (!user_mode(regs))
		goto no_context;

	if (fault & VM_FAULT_OOM) {
		/*
		 * We ran out of memory, call the OOM killer, and return to
		 * userspace (which will retry the fault, or kill us if we got
		 * oom-killed).
		 */
		pagefault_out_of_memory();
		return 0;
	}

	if (fault & VM_FAULT_SIGBUS) {
		/*
		 * We had some memory, but were unable to successfully fix up
		 * this page fault.
		 */
		sig = SIGBUS;
		code = BUS_ADRERR;
	} else {
		/*
		 * Something tried to access memory that isn't in our memory
		 * map.
		 */
		sig = SIGSEGV;
		code = fault == VM_FAULT_BADACCESS ?
			SEGV_ACCERR : SEGV_MAPERR;
	}

	__do_user_fault(tsk, addr, esr, sig, code, regs);
	return 0;

no_context:
	__do_kernel_fault(mm, addr, esr, regs);
	return 0;
}
"
4222,181958,,Remote,Not required,Partial,CVE-2016-7540,https://www.cvedetails.com/cve/CVE-2016-7540/,CWE-19,Medium,,,,2017-04-20,4.3,coders/rgf.c in ImageMagick before 6.9.4-10 allows remote attackers to cause a denial of service (assertion failure) by converting an image to rgf format.,2017-05-08,DoS ,3,https://github.com/ImageMagick/ImageMagick/commit/a0108a892f9ea3c2bb1e7a49b7d71376c2ecbff7,a0108a892f9ea3c2bb1e7a49b7d71376c2ecbff7,"Fix abort when writing to rgf format

The rgf format (LEGO MINDSTORMS EV3 images) caused a software abort because
exception == NULL. When WriteRGFImage is called from WriteImage, it is only
passed two parameters, not three. So, removed the extra parameter and use
image->exception instead as in other coders.",5,coders/rgf.c,"{""sha"": ""e572f96d2441183b2e45850a6f8096f4ab2cc2b3"", ""filename"": ""coders/rgf.c"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 8, ""changes"": 13, ""blob_url"": ""https://github.com/ImageMagick/ImageMagick/blob/a0108a892f9ea3c2bb1e7a49b7d71376c2ecbff7/coders/rgf.c"", ""raw_url"": ""https://github.com/ImageMagick/ImageMagick/raw/a0108a892f9ea3c2bb1e7a49b7d71376c2ecbff7/coders/rgf.c"", ""contents_url"": ""https://api.github.com/repos/ImageMagick/ImageMagick/contents/coders/rgf.c?ref=a0108a892f9ea3c2bb1e7a49b7d71376c2ecbff7"", ""patch"": ""@@ -68,7 +68,7 @@\n   Forward declarations.\n */\n static MagickBooleanType\n-  WriteRGFImage(const ImageInfo *,Image *,ExceptionInfo *);\n+  WriteRGFImage(const ImageInfo *,Image *);\n \f\n /*\n %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n@@ -305,7 +305,7 @@ ModuleExport void UnregisterRGFImage(void)\n %  The format of the WriteRGFImage method is:\n %\n %      MagickBooleanType WriteRGFImage(const ImageInfo *image_info,\n-%        Image *image,ExceptionInfo *exception)\n+%        Image *image)\n %\n %  A description of each parameter follows.\n %\n@@ -316,8 +316,7 @@ ModuleExport void UnregisterRGFImage(void)\n %    o exception: return any errors or warnings in this structure.\n %\n */\n-static MagickBooleanType WriteRGFImage(const ImageInfo *image_info,Image *image,\n-  ExceptionInfo *exception)\n+static MagickBooleanType WriteRGFImage(const ImageInfo *image_info,Image *image)\n {\n   MagickBooleanType\n     status;\n@@ -346,9 +345,7 @@ static MagickBooleanType WriteRGFImage(const ImageInfo *image_info,Image *image,\n   assert(image->signature == MagickSignature);\n   if (image->debug != MagickFalse)\n     (void) LogMagickEvent(TraceEvent,GetMagickModule(),\""%s\"",image->filename);\n-  assert(exception != (ExceptionInfo *) NULL);\n-  assert(exception->signature == MagickSignature);\n-  status=OpenBlob(image_info,image,WriteBinaryBlobMode,exception);\n+  status=OpenBlob(image_info,image,WriteBinaryBlobMode,&image->exception);\n   if (status == MagickFalse)\n     return(status);\n   (void) TransformImageColorspace(image,sRGBColorspace);\n@@ -367,7 +364,7 @@ static MagickBooleanType WriteRGFImage(const ImageInfo *image_info,Image *image,\n   y=0;\n   for (y=0; y < (ssize_t) image->rows; y++)\n   {\n-    p=GetVirtualPixels(image,0,y,image->columns,1,exception);\n+    p=GetVirtualPixels(image,0,y,image->columns,1,&image->exception);\n     if (p == (const PixelPacket *) NULL)\n       break;\n     bit=0;""}","static MagickBooleanType WriteRGFImage(const ImageInfo *image_info,Image *image,
static MagickBooleanType WriteRGFImage(const ImageInfo *image_info,Image *image)
 {
   MagickBooleanType
     status;

  int
    bit;

  register const PixelPacket
    *p;

  register ssize_t
    x;

  ssize_t
    y;

  unsigned char
    byte;

  /*
    Open output image file.
  */
  assert(image_info != (const ImageInfo *) NULL);
  assert(image_info->signature == MagickSignature);
  assert(image != (Image *) NULL);
   assert(image->signature == MagickSignature);
   if (image->debug != MagickFalse)
     (void) LogMagickEvent(TraceEvent,GetMagickModule(),""%s"",image->filename);
  status=OpenBlob(image_info,image,WriteBinaryBlobMode,&image->exception);
   if (status == MagickFalse)
     return(status);
   (void) TransformImageColorspace(image,sRGBColorspace);
  if((image->columns > 255L) || (image->rows > 255L))
    ThrowWriterException(ImageError,""Dimensions must be less than 255x255"");
  /*
    Write header (just the image dimensions)
  */
  (void) WriteBlobByte(image,image->columns & 0xff);
  (void) WriteBlobByte(image,image->rows & 0xff);
  /*
    Convert MIFF to bit pixels.
  */
  (void) SetImageType(image,BilevelType);
  x=0;
   y=0;
   for (y=0; y < (ssize_t) image->rows; y++)
   {
    p=GetVirtualPixels(image,0,y,image->columns,1,&image->exception);
     if (p == (const PixelPacket *) NULL)
       break;
     bit=0;
    byte=0;
    for (x=0; x < (ssize_t) image->columns; x++)
    {
      byte>>=1;
      if (GetPixelLuma(image,p) < (QuantumRange/2.0))
        byte|=0x80;
      bit++;
      if (bit == 8)
        {
          /*
            Write a bitmap byte to the image file.
          */
       	  (void) WriteBlobByte(image,byte);
          bit=0;
          byte=0;
        }
      p++;
    }
    if (bit != 0)
      (void) WriteBlobByte(image,byte);
    status=SetImageProgress(image,SaveImageTag,(MagickOffsetType) y,
      image->rows);
    if (status == MagickFalse)
      break;
  }
  (void) CloseBlob(image);
  return(MagickTrue);
}
","static MagickBooleanType WriteRGFImage(const ImageInfo *image_info,Image *image,
  ExceptionInfo *exception)
 {
   MagickBooleanType
     status;

  int
    bit;

  register const PixelPacket
    *p;

  register ssize_t
    x;

  ssize_t
    y;

  unsigned char
    byte;

  /*
    Open output image file.
  */
  assert(image_info != (const ImageInfo *) NULL);
  assert(image_info->signature == MagickSignature);
  assert(image != (Image *) NULL);
   assert(image->signature == MagickSignature);
   if (image->debug != MagickFalse)
     (void) LogMagickEvent(TraceEvent,GetMagickModule(),""%s"",image->filename);
  assert(exception != (ExceptionInfo *) NULL);
  assert(exception->signature == MagickSignature);
  status=OpenBlob(image_info,image,WriteBinaryBlobMode,exception);
   if (status == MagickFalse)
     return(status);
   (void) TransformImageColorspace(image,sRGBColorspace);
  if((image->columns > 255L) || (image->rows > 255L))
    ThrowWriterException(ImageError,""Dimensions must be less than 255x255"");
  /*
    Write header (just the image dimensions)
  */
  (void) WriteBlobByte(image,image->columns & 0xff);
  (void) WriteBlobByte(image,image->rows & 0xff);
  /*
    Convert MIFF to bit pixels.
  */
  (void) SetImageType(image,BilevelType);
  x=0;
   y=0;
   for (y=0; y < (ssize_t) image->rows; y++)
   {
    p=GetVirtualPixels(image,0,y,image->columns,1,exception);
     if (p == (const PixelPacket *) NULL)
       break;
     bit=0;
    byte=0;
    for (x=0; x < (ssize_t) image->columns; x++)
    {
      byte>>=1;
      if (GetPixelLuma(image,p) < (QuantumRange/2.0))
        byte|=0x80;
      bit++;
      if (bit == 8)
        {
          /*
            Write a bitmap byte to the image file.
          */
       	  (void) WriteBlobByte(image,byte);
          bit=0;
          byte=0;
        }
      p++;
    }
    if (bit != 0)
      (void) WriteBlobByte(image,byte);
    status=SetImageProgress(image,SaveImageTag,(MagickOffsetType) y,
      image->rows);
    if (status == MagickFalse)
      break;
  }
  (void) CloseBlob(image);
  return(MagickTrue);
}
",C,"static MagickBooleanType WriteRGFImage(const ImageInfo *image_info,Image *image)
  status=OpenBlob(image_info,image,WriteBinaryBlobMode,&image->exception);
    p=GetVirtualPixels(image,0,y,image->columns,1,&image->exception);
","  ExceptionInfo *exception)
  assert(exception != (ExceptionInfo *) NULL);
  assert(exception->signature == MagickSignature);
  status=OpenBlob(image_info,image,WriteBinaryBlobMode,exception);
    p=GetVirtualPixels(image,0,y,image->columns,1,exception);
",,"@@ -68,7 +68,7 @@
   Forward declarations.
 */
 static MagickBooleanType
-  WriteRGFImage(const ImageInfo *,Image *,ExceptionInfo *);
+  WriteRGFImage(const ImageInfo *,Image *);
 
 /*
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@@ -305,7 +305,7 @@ ModuleExport void UnregisterRGFImage(void)
 %  The format of the WriteRGFImage method is:
 %
 %      MagickBooleanType WriteRGFImage(const ImageInfo *image_info,
-%        Image *image,ExceptionInfo *exception)
+%        Image *image)
 %
 %  A description of each parameter follows.
 %
@@ -316,8 +316,7 @@ ModuleExport void UnregisterRGFImage(void)
 %    o exception: return any errors or warnings in this structure.
 %
 */
-static MagickBooleanType WriteRGFImage(const ImageInfo *image_info,Image *image,
-  ExceptionInfo *exception)
+static MagickBooleanType WriteRGFImage(const ImageInfo *image_info,Image *image)
 {
   MagickBooleanType
     status;
@@ -346,9 +345,7 @@ static MagickBooleanType WriteRGFImage(const ImageInfo *image_info,Image *image,
   assert(image->signature == MagickSignature);
   if (image->debug != MagickFalse)
     (void) LogMagickEvent(TraceEvent,GetMagickModule(),""%s"",image->filename);
-  assert(exception != (ExceptionInfo *) NULL);
-  assert(exception->signature == MagickSignature);
-  status=OpenBlob(image_info,image,WriteBinaryBlobMode,exception);
+  status=OpenBlob(image_info,image,WriteBinaryBlobMode,&image->exception);
   if (status == MagickFalse)
     return(status);
   (void) TransformImageColorspace(image,sRGBColorspace);
@@ -367,7 +364,7 @@ static MagickBooleanType WriteRGFImage(const ImageInfo *image_info,Image *image,
   y=0;
   for (y=0; y < (ssize_t) image->rows; y++)
   {
-    p=GetVirtualPixels(image,0,y,image->columns,1,exception);
+    p=GetVirtualPixels(image,0,y,image->columns,1,&image->exception);
     if (p == (const PixelPacket *) NULL)
       break;
     bit=0;",ImageMagick,a0108a892f9ea3c2bb1e7a49b7d71376c2ecbff7,8627a99c524c27b203cb14555046326b9d53d0d9,1,"static MagickBooleanType WriteRGFImage(const ImageInfo *image_info,Image *image,
//flaw_line_below:
  ExceptionInfo *exception)
//fix_flaw_line_below:
//static MagickBooleanType WriteRGFImage(const ImageInfo *image_info,Image *image)
 {
   MagickBooleanType
     status;

  int
    bit;

  register const PixelPacket
    *p;

  register ssize_t
    x;

  ssize_t
    y;

  unsigned char
    byte;

  /*
    Open output image file.
  */
  assert(image_info != (const ImageInfo *) NULL);
  assert(image_info->signature == MagickSignature);
  assert(image != (Image *) NULL);
   assert(image->signature == MagickSignature);
   if (image->debug != MagickFalse)
     (void) LogMagickEvent(TraceEvent,GetMagickModule(),""%s"",image->filename);
//flaw_line_below:
  assert(exception != (ExceptionInfo *) NULL);
//flaw_line_below:
  assert(exception->signature == MagickSignature);
//flaw_line_below:
  status=OpenBlob(image_info,image,WriteBinaryBlobMode,exception);
//fix_flaw_line_below:
//  status=OpenBlob(image_info,image,WriteBinaryBlobMode,&image->exception);
   if (status == MagickFalse)
     return(status);
   (void) TransformImageColorspace(image,sRGBColorspace);
  if((image->columns > 255L) || (image->rows > 255L))
    ThrowWriterException(ImageError,""Dimensions must be less than 255x255"");
  /*
    Write header (just the image dimensions)
  */
  (void) WriteBlobByte(image,image->columns & 0xff);
  (void) WriteBlobByte(image,image->rows & 0xff);
  /*
    Convert MIFF to bit pixels.
  */
  (void) SetImageType(image,BilevelType);
  x=0;
   y=0;
   for (y=0; y < (ssize_t) image->rows; y++)
   {
//flaw_line_below:
    p=GetVirtualPixels(image,0,y,image->columns,1,exception);
//fix_flaw_line_below:
//    p=GetVirtualPixels(image,0,y,image->columns,1,&image->exception);
     if (p == (const PixelPacket *) NULL)
       break;
     bit=0;
    byte=0;
    for (x=0; x < (ssize_t) image->columns; x++)
    {
      byte>>=1;
      if (GetPixelLuma(image,p) < (QuantumRange/2.0))
        byte|=0x80;
      bit++;
      if (bit == 8)
        {
          /*
            Write a bitmap byte to the image file.
          */
       	  (void) WriteBlobByte(image,byte);
          bit=0;
          byte=0;
        }
      p++;
    }
    if (bit != 0)
      (void) WriteBlobByte(image,byte);
    status=SetImageProgress(image,SaveImageTag,(MagickOffsetType) y,
      image->rows);
    if (status == MagickFalse)
      break;
  }
  (void) CloseBlob(image);
  return(MagickTrue);
}
"
4356,182092,,Local,Not required,Complete,CVE-2006-5331,https://www.cvedetails.com/cve/CVE-2006-5331/,CWE-19,Low,,,,2017-10-29,4.9,"The altivec_unavailable_exception function in arch/powerpc/kernel/traps.c in the Linux kernel before 2.6.19 on 64-bit systems mishandles the case where CONFIG_ALTIVEC is defined and the CPU actually supports Altivec, but the Altivec support was not detected by the kernel, which allows local users to cause a denial of service (panic) by triggering execution of an Altivec instruction.",2017-11-17,DoS ,1,https://github.com/torvalds/linux/commit/6c4841c2b6c32a134f9f36e5e08857138cc12b10,6c4841c2b6c32a134f9f36e5e08857138cc12b10,"[POWERPC] Never panic when taking altivec exceptions from userspace

At the moment we rely on a cpu feature bit or a firmware property to
detect altivec. If we dont have either of these and the cpu does in fact
support altivec we can cause a panic from userspace.

It seems safer to always send a signal if we manage to get an 0xf20
exception from userspace.

Signed-off-by: Anton Blanchard <anton@samba.org>
Signed-off-by: Paul Mackerras <paulus@samba.org>",2,arch/powerpc/kernel/traps.c,"{""sha"": ""5ed4c2ceb5caa8632c11f229193afe0596893650"", ""filename"": ""arch/powerpc/kernel/traps.c"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 2, ""changes"": 3, ""blob_url"": ""https://github.com/torvalds/linux/blob/6c4841c2b6c32a134f9f36e5e08857138cc12b10/arch/powerpc/kernel/traps.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/6c4841c2b6c32a134f9f36e5e08857138cc12b10/arch/powerpc/kernel/traps.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/arch/powerpc/kernel/traps.c?ref=6c4841c2b6c32a134f9f36e5e08857138cc12b10"", ""patch"": ""@@ -900,14 +900,13 @@ void kernel_fp_unavailable_exception(struct pt_regs *regs)\n \n void altivec_unavailable_exception(struct pt_regs *regs)\n {\n-#if !defined(CONFIG_ALTIVEC)\n \tif (user_mode(regs)) {\n \t\t/* A user program has executed an altivec instruction,\n \t\t   but this kernel doesn't support altivec. */\n \t\t_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);\n \t\treturn;\n \t}\n-#endif\n+\n \tprintk(KERN_EMERG \""Unrecoverable VMX/Altivec Unavailable Exception \""\n \t\t\t\""%lx at %lx\\n\"", regs->trap, regs->nip);\n \tdie(\""Unrecoverable VMX/Altivec Unavailable Exception\"", regs, SIGABRT);""}"," void altivec_unavailable_exception(struct pt_regs *regs)
 {
 	if (user_mode(regs)) {
 		/* A user program has executed an altivec instruction,
 		   but this kernel doesn't support altivec. */
 		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
 		return;
 	}

 	printk(KERN_EMERG ""Unrecoverable VMX/Altivec Unavailable Exception ""
 			""%lx at %lx\n"", regs->trap, regs->nip);
 	die(""Unrecoverable VMX/Altivec Unavailable Exception"", regs, SIGABRT);
}
"," void altivec_unavailable_exception(struct pt_regs *regs)
 {
#if !defined(CONFIG_ALTIVEC)
 	if (user_mode(regs)) {
 		/* A user program has executed an altivec instruction,
 		   but this kernel doesn't support altivec. */
 		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
 		return;
 	}
#endif
 	printk(KERN_EMERG ""Unrecoverable VMX/Altivec Unavailable Exception ""
 			""%lx at %lx\n"", regs->trap, regs->nip);
 	die(""Unrecoverable VMX/Altivec Unavailable Exception"", regs, SIGABRT);
}
",C,"
","#if !defined(CONFIG_ALTIVEC)
#endif
",,"@@ -900,14 +900,13 @@ void kernel_fp_unavailable_exception(struct pt_regs *regs)
 
 void altivec_unavailable_exception(struct pt_regs *regs)
 {
-#if !defined(CONFIG_ALTIVEC)
 	if (user_mode(regs)) {
 		/* A user program has executed an altivec instruction,
 		   but this kernel doesn't support altivec. */
 		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
 		return;
 	}
-#endif
+
 	printk(KERN_EMERG ""Unrecoverable VMX/Altivec Unavailable Exception ""
 			""%lx at %lx\n"", regs->trap, regs->nip);
 	die(""Unrecoverable VMX/Altivec Unavailable Exception"", regs, SIGABRT);",linux,6c4841c2b6c32a134f9f36e5e08857138cc12b10,60b2a46cd60c54bd6551ddfa01f0aab08ca58a5d,1," void altivec_unavailable_exception(struct pt_regs *regs)
 {
//flaw_line_below:
#if !defined(CONFIG_ALTIVEC)
 	if (user_mode(regs)) {
 		/* A user program has executed an altivec instruction,
 		   but this kernel doesn't support altivec. */
 		_exception(SIGILL, regs, ILL_ILLOPC, regs->nip);
 		return;
 	}
//flaw_line_below:
#endif
//fix_flaw_line_below:
//
 	printk(KERN_EMERG ""Unrecoverable VMX/Altivec Unavailable Exception ""
 			""%lx at %lx\n"", regs->trap, regs->nip);
 	die(""Unrecoverable VMX/Altivec Unavailable Exception"", regs, SIGABRT);
}
"
5408,183144,,Local,Not required,Partial,CVE-2015-8952,https://www.cvedetails.com/cve/CVE-2015-8952/,CWE-19,Low,,,,2016-10-16,2.1,"The mbcache feature in the ext2 and ext4 filesystem implementations in the Linux kernel before 4.6 mishandles xattr block caching, which allows local users to cause a denial of service (soft lockup) via filesystem operations in environments that use many attributes, as demonstrated by Ceph and Samba.",2018-03-15,DoS ,0,https://github.com/torvalds/linux/commit/be0726d33cb8f411945884664924bed3cb8c70ee,be0726d33cb8f411945884664924bed3cb8c70ee,"ext2: convert to mbcache2

The conversion is generally straightforward. We convert filesystem from
a global cache to per-fs one. Similarly to ext4 the tricky part is that
xattr block corresponding to found mbcache entry can get freed before we
get buffer lock for that block. So we have to check whether the entry is
still valid after getting the buffer lock.

Signed-off-by: Jan Kara <jack@suse.cz>
Signed-off-by: Theodore Ts'o <tytso@mit.edu>",1,fs/ext2/super.c,"{""sha"": ""f98ce7e60a0f84f71743e0dfe069c7e96c6bd648"", ""filename"": ""fs/ext2/ext2.h"", ""status"": ""modified"", ""additions"": 3, ""deletions"": 0, ""changes"": 3, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/ext2.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -61,6 +61,8 @@ struct ext2_block_alloc_info {\n #define rsv_start rsv_window._rsv_start\n #define rsv_end rsv_window._rsv_end\n \n+struct mb2_cache;\n+\n /*\n  * second extended-fs super-block data in memory\n  */\n@@ -111,6 +113,7 @@ struct ext2_sb_info {\n \t * of the mount options.\n \t */\n \tspinlock_t s_lock;\n+\tstruct mb2_cache *s_mb_cache;\n };\n \n static inline spinlock_t *""}<_**next**_>{""sha"": ""b78caf25f746220ce635a3bd946bedeaf7e3e750"", ""filename"": ""fs/ext2/super.c"", ""status"": ""modified"", ""additions"": 17, ""deletions"": 8, ""changes"": 25, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/super.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -131,7 +131,10 @@ static void ext2_put_super (struct super_block * sb)\n \n \tdquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);\n \n-\text2_xattr_put_super(sb);\n+\tif (sbi->s_mb_cache) {\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n+\t\tsbi->s_mb_cache = NULL;\n+\t}\n \tif (!(sb->s_flags & MS_RDONLY)) {\n \t\tstruct ext2_super_block *es = sbi->s_es;\n \n@@ -1104,6 +1107,14 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\text2_msg(sb, KERN_ERR, \""error: insufficient memory\"");\n \t\tgoto failed_mount3;\n \t}\n+\n+#ifdef CONFIG_EXT2_FS_XATTR\n+\tsbi->s_mb_cache = ext2_xattr_create_cache();\n+\tif (!sbi->s_mb_cache) {\n+\t\text2_msg(sb, KERN_ERR, \""Failed to create an mb_cache\"");\n+\t\tgoto failed_mount3;\n+\t}\n+#endif\n \t/*\n \t * set up enough so that it can read an inode\n \t */\n@@ -1149,6 +1160,8 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\t\tsb->s_id);\n \tgoto failed_mount;\n failed_mount3:\n+\tif (sbi->s_mb_cache)\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n \tpercpu_counter_destroy(&sbi->s_freeblocks_counter);\n \tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n \tpercpu_counter_destroy(&sbi->s_dirs_counter);\n@@ -1555,28 +1568,24 @@ MODULE_ALIAS_FS(\""ext2\"");\n \n static int __init init_ext2_fs(void)\n {\n-\tint err = init_ext2_xattr();\n-\tif (err)\n-\t\treturn err;\n+\tint err;\n+\n \terr = init_inodecache();\n \tif (err)\n-\t\tgoto out1;\n+\t\treturn err;\n         err = register_filesystem(&ext2_fs_type);\n \tif (err)\n \t\tgoto out;\n \treturn 0;\n out:\n \tdestroy_inodecache();\n-out1:\n-\texit_ext2_xattr();\n \treturn err;\n }\n \n static void __exit exit_ext2_fs(void)\n {\n \tunregister_filesystem(&ext2_fs_type);\n \tdestroy_inodecache();\n-\texit_ext2_xattr();\n }\n \n MODULE_AUTHOR(\""Remy Card and others\"");""}<_**next**_>{""sha"": ""7162b4869bc32515800d8ffc06ac3835ea241c8b"", ""filename"": ""fs/ext2/xattr.c"", ""status"": ""modified"", ""additions"": 67, ""deletions"": 76, ""changes"": 143, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -56,7 +56,7 @@\n #include <linux/buffer_head.h>\n #include <linux/init.h>\n #include <linux/slab.h>\n-#include <linux/mbcache.h>\n+#include <linux/mbcache2.h>\n #include <linux/quotaops.h>\n #include <linux/rwsem.h>\n #include <linux/security.h>\n@@ -90,14 +90,12 @@\n static int ext2_xattr_set2(struct inode *, struct buffer_head *,\n \t\t\t   struct ext2_xattr_header *);\n \n-static int ext2_xattr_cache_insert(struct buffer_head *);\n+static int ext2_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);\n static struct buffer_head *ext2_xattr_cache_find(struct inode *,\n \t\t\t\t\t\t struct ext2_xattr_header *);\n static void ext2_xattr_rehash(struct ext2_xattr_header *,\n \t\t\t      struct ext2_xattr_entry *);\n \n-static struct mb_cache *ext2_xattr_cache;\n-\n static const struct xattr_handler *ext2_xattr_handler_map[] = {\n \t[EXT2_XATTR_INDEX_USER]\t\t     = &ext2_xattr_user_handler,\n #ifdef CONFIG_EXT2_FS_POSIX_ACL\n@@ -152,6 +150,7 @@ ext2_xattr_get(struct inode *inode, int name_index, const char *name,\n \tsize_t name_len, size;\n \tchar *end;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""name=%d.%s, buffer=%p, buffer_size=%ld\"",\n \t\t  name_index, name, buffer, (long)buffer_size);\n@@ -196,7 +195,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t\t\tgoto found;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \terror = -ENODATA;\n \tgoto cleanup;\n@@ -209,7 +208,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)\n \t\tgoto bad_block;\n \n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \tif (buffer) {\n \t\terror = -ERANGE;\n@@ -247,6 +246,7 @@ ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)\n \tchar *end;\n \tsize_t rest = buffer_size;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""buffer=%p, buffer_size=%ld\"",\n \t\t  buffer, (long)buffer_size);\n@@ -281,7 +281,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_list\"",\n \t\t\tgoto bad_block;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \n \t/* list the attribute names */\n@@ -483,22 +483,23 @@ bad_block:\t\text2_error(sb, \""ext2_xattr_set\"",\n \t/* Here we know that we can set the new attribute. */\n \n \tif (header) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/* assert(header == HDR(bh)); */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,\n-\t\t\t\t\tbh->b_blocknr);\n \t\tlock_buffer(bh);\n \t\tif (header->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(header->h_hash);\n+\n \t\t\tea_bdebug(bh, \""modifying in-place\"");\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect modified block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,\n+\t\t\t\t\t\t     hash, bh->b_blocknr);\n+\n \t\t\t/* keep the buffer locked while modifying it. */\n \t\t} else {\n \t\t\tint offset;\n \n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tunlock_buffer(bh);\n \t\t\tea_bdebug(bh, \""cloning\"");\n \t\t\theader = kmalloc(bh->b_size, GFP_KERNEL);\n@@ -626,6 +627,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \tstruct super_block *sb = inode->i_sb;\n \tstruct buffer_head *new_bh = NULL;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;\n \n \tif (header) {\n \t\tnew_bh = ext2_xattr_cache_find(inode, header);\n@@ -653,7 +655,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\t   don't need to change the reference count. */\n \t\t\tnew_bh = old_bh;\n \t\t\tget_bh(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t} else {\n \t\t\t/* We need to allocate a new block */\n \t\t\text2_fsblk_t goal = ext2_group_first_block_no(sb,\n@@ -674,7 +676,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\tmemcpy(new_bh->b_data, header, new_bh->b_size);\n \t\t\tset_buffer_uptodate(new_bh);\n \t\t\tunlock_buffer(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t\t\n \t\t\text2_xattr_update_super_block(sb);\n \t\t}\n@@ -707,19 +709,21 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \n \terror = 0;\n \tif (old_bh && old_bh != new_bh) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/*\n \t\t * If there was an old block and we are no longer using it,\n \t\t * release the old block.\n \t\t */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,\n-\t\t\t\t\told_bh->b_blocknr);\n \t\tlock_buffer(old_bh);\n \t\tif (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);\n+\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect freed block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(ext2_mb_cache,\n+\t\t\t\t\t\t     hash, old_bh->b_blocknr);\n \t\t\t/* Free the old block. */\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n \t\t\tea_bdebug(old_bh, \""freeing\"");\n \t\t\text2_free_blocks(inode, old_bh->b_blocknr, 1);\n \t\t\tmark_inode_dirty(inode);\n@@ -730,8 +734,6 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t} else {\n \t\t\t/* Decrement the refcount only. */\n \t\t\tle32_add_cpu(&HDR(old_bh)->h_refcount, -1);\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tdquot_free_block_nodirty(inode, 1);\n \t\t\tmark_inode_dirty(inode);\n \t\t\tmark_buffer_dirty(old_bh);\n@@ -757,7 +759,6 @@ void\n ext2_xattr_delete_inode(struct inode *inode)\n {\n \tstruct buffer_head *bh = NULL;\n-\tstruct mb_cache_entry *ce;\n \n \tdown_write(&EXT2_I(inode)->xattr_sem);\n \tif (!EXT2_I(inode)->i_file_acl)\n@@ -777,19 +778,22 @@ ext2_xattr_delete_inode(struct inode *inode)\n \t\t\tEXT2_I(inode)->i_file_acl);\n \t\tgoto cleanup;\n \t}\n-\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);\n \tlock_buffer(bh);\n \tif (HDR(bh)->h_refcount == cpu_to_le32(1)) {\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_free(ce);\n+\t\t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n+\n+\t\t/*\n+\t\t * This must happen under buffer lock for ext2_xattr_set2() to\n+\t\t * reliably detect freed block\n+\t\t */\n+\t\tmb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,\n+\t\t\t\t\t     hash, bh->b_blocknr);\n \t\text2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);\n \t\tget_bh(bh);\n \t\tbforget(bh);\n \t\tunlock_buffer(bh);\n \t} else {\n \t\tle32_add_cpu(&HDR(bh)->h_refcount, -1);\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_release(ce);\n \t\tea_bdebug(bh, \""refcount now=%d\"",\n \t\t\tle32_to_cpu(HDR(bh)->h_refcount));\n \t\tunlock_buffer(bh);\n@@ -805,18 +809,6 @@ ext2_xattr_delete_inode(struct inode *inode)\n \tup_write(&EXT2_I(inode)->xattr_sem);\n }\n \n-/*\n- * ext2_xattr_put_super()\n- *\n- * This is called when a file system is unmounted.\n- */\n-void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-\tmb_cache_shrink(sb->s_bdev);\n-}\n-\n-\n /*\n  * ext2_xattr_cache_insert()\n  *\n@@ -826,28 +818,20 @@ ext2_xattr_put_super(struct super_block *sb)\n  * Returns 0, or a negative error number on failure.\n  */\n static int\n-ext2_xattr_cache_insert(struct buffer_head *bh)\n+ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)\n {\n \t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n-\tstruct mb_cache_entry *ce;\n \tint error;\n \n-\tce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);\n-\tif (!ce)\n-\t\treturn -ENOMEM;\n-\terror = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);\n+\terror = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);\n \tif (error) {\n-\t\tmb_cache_entry_free(ce);\n \t\tif (error == -EBUSY) {\n \t\t\tea_bdebug(bh, \""already in cache (%d cache entries)\"",\n \t\t\t\tatomic_read(&ext2_xattr_cache->c_entry_count));\n \t\t\terror = 0;\n \t\t}\n-\t} else {\n-\t\tea_bdebug(bh, \""inserting [%x] (%d cache entries)\"", (int)hash,\n-\t\t\t  atomic_read(&ext2_xattr_cache->c_entry_count));\n-\t\tmb_cache_entry_release(ce);\n-\t}\n+\t} else\n+\t\tea_bdebug(bh, \""inserting [%x]\"", (int)hash);\n \treturn error;\n }\n \n@@ -903,31 +887,39 @@ static struct buffer_head *\n ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n {\n \t__u32 hash = le32_to_cpu(header->h_hash);\n-\tstruct mb_cache_entry *ce;\n+\tstruct mb2_cache_entry *ce;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tif (!header->h_hash)\n \t\treturn NULL;  /* never share */\n \tea_idebug(inode, \""looking for cached blocks [%x]\"", (int)hash);\n again:\n-\tce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,\n-\t\t\t\t       hash);\n+\tce = mb2_cache_entry_find_first(ext2_mb_cache, hash);\n \twhile (ce) {\n \t\tstruct buffer_head *bh;\n \n-\t\tif (IS_ERR(ce)) {\n-\t\t\tif (PTR_ERR(ce) == -EAGAIN)\n-\t\t\t\tgoto again;\n-\t\t\tbreak;\n-\t\t}\n-\n \t\tbh = sb_bread(inode->i_sb, ce->e_block);\n \t\tif (!bh) {\n \t\t\text2_error(inode->i_sb, \""ext2_xattr_cache_find\"",\n \t\t\t\t\""inode %ld: block %ld read error\"",\n \t\t\t\tinode->i_ino, (unsigned long) ce->e_block);\n \t\t} else {\n \t\t\tlock_buffer(bh);\n-\t\t\tif (le32_to_cpu(HDR(bh)->h_refcount) >\n+\t\t\t/*\n+\t\t\t * We have to be careful about races with freeing or\n+\t\t\t * rehashing of xattr block. Once we hold buffer lock\n+\t\t\t * xattr block's state is stable so we can check\n+\t\t\t * whether the block got freed / rehashed or not.\n+\t\t\t * Since we unhash mbcache entry under buffer lock when\n+\t\t\t * freeing / rehashing xattr block, checking whether\n+\t\t\t * entry is still hashed is reliable.\n+\t\t\t */\n+\t\t\tif (hlist_bl_unhashed(&ce->e_hash_list)) {\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n+\t\t\t\tunlock_buffer(bh);\n+\t\t\t\tbrelse(bh);\n+\t\t\t\tgoto again;\n+\t\t\t} else if (le32_to_cpu(HDR(bh)->h_refcount) >\n \t\t\t\t   EXT2_XATTR_REFCOUNT_MAX) {\n \t\t\t\tea_idebug(inode, \""block %ld refcount %d>%d\"",\n \t\t\t\t\t  (unsigned long) ce->e_block,\n@@ -936,13 +928,14 @@ ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n \t\t\t} else if (!ext2_xattr_cmp(header, HDR(bh))) {\n \t\t\t\tea_bdebug(bh, \""b_count=%d\"",\n \t\t\t\t\t  atomic_read(&(bh->b_count)));\n-\t\t\t\tmb_cache_entry_release(ce);\n+\t\t\t\tmb2_cache_entry_touch(ext2_mb_cache, ce);\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n \t\t\t\treturn bh;\n \t\t\t}\n \t\t\tunlock_buffer(bh);\n \t\t\tbrelse(bh);\n \t\t}\n-\t\tce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);\n+\t\tce = mb2_cache_entry_find_next(ext2_mb_cache, ce);\n \t}\n \treturn NULL;\n }\n@@ -1015,17 +1008,15 @@ static void ext2_xattr_rehash(struct ext2_xattr_header *header,\n \n #undef BLOCK_HASH_SHIFT\n \n-int __init\n-init_ext2_xattr(void)\n+#define HASH_BUCKET_BITS 10\n+\n+struct mb2_cache *ext2_xattr_create_cache(void)\n {\n-\text2_xattr_cache = mb_cache_create(\""ext2_xattr\"", 6);\n-\tif (!ext2_xattr_cache)\n-\t\treturn -ENOMEM;\n-\treturn 0;\n+\treturn mb2_cache_create(HASH_BUCKET_BITS);\n }\n \n-void\n-exit_ext2_xattr(void)\n+void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n-\tmb_cache_destroy(ext2_xattr_cache);\n+\tif (cache)\n+\t\tmb2_cache_destroy(cache);\n }""}<_**next**_>{""sha"": ""6ea38aa9563a00649bf25544eed131bbe8b1d88d"", ""filename"": ""fs/ext2/xattr.h"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 16, ""changes"": 21, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -53,6 +53,8 @@ struct ext2_xattr_entry {\n #define EXT2_XATTR_SIZE(size) \\\n \t(((size) + EXT2_XATTR_ROUND) & ~EXT2_XATTR_ROUND)\n \n+struct mb2_cache;\n+\n # ifdef CONFIG_EXT2_FS_XATTR\n \n extern const struct xattr_handler ext2_xattr_user_handler;\n@@ -65,10 +67,9 @@ extern int ext2_xattr_get(struct inode *, int, const char *, void *, size_t);\n extern int ext2_xattr_set(struct inode *, int, const char *, const void *, size_t, int);\n \n extern void ext2_xattr_delete_inode(struct inode *);\n-extern void ext2_xattr_put_super(struct super_block *);\n \n-extern int init_ext2_xattr(void);\n-extern void exit_ext2_xattr(void);\n+extern struct mb2_cache *ext2_xattr_create_cache(void);\n+extern void ext2_xattr_destroy_cache(struct mb2_cache *cache);\n \n extern const struct xattr_handler *ext2_xattr_handlers[];\n \n@@ -93,19 +94,7 @@ ext2_xattr_delete_inode(struct inode *inode)\n {\n }\n \n-static inline void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-}\n-\n-static inline int\n-init_ext2_xattr(void)\n-{\n-\treturn 0;\n-}\n-\n-static inline void\n-exit_ext2_xattr(void)\n+static inline void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n }\n ""}"," static void __exit exit_ext2_fs(void)
 {
 	unregister_filesystem(&ext2_fs_type);
 	destroy_inodecache();
 }
"," static void __exit exit_ext2_fs(void)
 {
 	unregister_filesystem(&ext2_fs_type);
 	destroy_inodecache();
	exit_ext2_xattr();
 }
",C,,"	exit_ext2_xattr();
",,"@@ -131,7 +131,10 @@ static void ext2_put_super (struct super_block * sb)
 
 	dquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);
 
-	ext2_xattr_put_super(sb);
+	if (sbi->s_mb_cache) {
+		ext2_xattr_destroy_cache(sbi->s_mb_cache);
+		sbi->s_mb_cache = NULL;
+	}
 	if (!(sb->s_flags & MS_RDONLY)) {
 		struct ext2_super_block *es = sbi->s_es;
 
@@ -1104,6 +1107,14 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)
 		ext2_msg(sb, KERN_ERR, ""error: insufficient memory"");
 		goto failed_mount3;
 	}
+
+#ifdef CONFIG_EXT2_FS_XATTR
+	sbi->s_mb_cache = ext2_xattr_create_cache();
+	if (!sbi->s_mb_cache) {
+		ext2_msg(sb, KERN_ERR, ""Failed to create an mb_cache"");
+		goto failed_mount3;
+	}
+#endif
 	/*
 	 * set up enough so that it can read an inode
 	 */
@@ -1149,6 +1160,8 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)
 			sb->s_id);
 	goto failed_mount;
 failed_mount3:
+	if (sbi->s_mb_cache)
+		ext2_xattr_destroy_cache(sbi->s_mb_cache);
 	percpu_counter_destroy(&sbi->s_freeblocks_counter);
 	percpu_counter_destroy(&sbi->s_freeinodes_counter);
 	percpu_counter_destroy(&sbi->s_dirs_counter);
@@ -1555,28 +1568,24 @@ MODULE_ALIAS_FS(""ext2"");
 
 static int __init init_ext2_fs(void)
 {
-	int err = init_ext2_xattr();
-	if (err)
-		return err;
+	int err;
+
 	err = init_inodecache();
 	if (err)
-		goto out1;
+		return err;
         err = register_filesystem(&ext2_fs_type);
 	if (err)
 		goto out;
 	return 0;
 out:
 	destroy_inodecache();
-out1:
-	exit_ext2_xattr();
 	return err;
 }
 
 static void __exit exit_ext2_fs(void)
 {
 	unregister_filesystem(&ext2_fs_type);
 	destroy_inodecache();
-	exit_ext2_xattr();
 }
 
 MODULE_AUTHOR(""Remy Card and others"");",linux,be0726d33cb8f411945884664924bed3cb8c70ee,82939d7999dfc1f1998c4b1c12e2f19edbdff272,1," static void __exit exit_ext2_fs(void)
 {
 	unregister_filesystem(&ext2_fs_type);
 	destroy_inodecache();
//flaw_line_below:
	exit_ext2_xattr();
 }
"
5409,183145,,Local,Not required,Partial,CVE-2015-8952,https://www.cvedetails.com/cve/CVE-2015-8952/,CWE-19,Low,,,,2016-10-16,2.1,"The mbcache feature in the ext2 and ext4 filesystem implementations in the Linux kernel before 4.6 mishandles xattr block caching, which allows local users to cause a denial of service (soft lockup) via filesystem operations in environments that use many attributes, as demonstrated by Ceph and Samba.",2018-03-15,DoS ,10,https://github.com/torvalds/linux/commit/be0726d33cb8f411945884664924bed3cb8c70ee,be0726d33cb8f411945884664924bed3cb8c70ee,"ext2: convert to mbcache2

The conversion is generally straightforward. We convert filesystem from
a global cache to per-fs one. Similarly to ext4 the tricky part is that
xattr block corresponding to found mbcache entry can get freed before we
get buffer lock for that block. So we have to check whether the entry is
still valid after getting the buffer lock.

Signed-off-by: Jan Kara <jack@suse.cz>
Signed-off-by: Theodore Ts'o <tytso@mit.edu>",0,fs/ext2/super.c,"{""sha"": ""f98ce7e60a0f84f71743e0dfe069c7e96c6bd648"", ""filename"": ""fs/ext2/ext2.h"", ""status"": ""modified"", ""additions"": 3, ""deletions"": 0, ""changes"": 3, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/ext2.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -61,6 +61,8 @@ struct ext2_block_alloc_info {\n #define rsv_start rsv_window._rsv_start\n #define rsv_end rsv_window._rsv_end\n \n+struct mb2_cache;\n+\n /*\n  * second extended-fs super-block data in memory\n  */\n@@ -111,6 +113,7 @@ struct ext2_sb_info {\n \t * of the mount options.\n \t */\n \tspinlock_t s_lock;\n+\tstruct mb2_cache *s_mb_cache;\n };\n \n static inline spinlock_t *""}<_**next**_>{""sha"": ""b78caf25f746220ce635a3bd946bedeaf7e3e750"", ""filename"": ""fs/ext2/super.c"", ""status"": ""modified"", ""additions"": 17, ""deletions"": 8, ""changes"": 25, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/super.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -131,7 +131,10 @@ static void ext2_put_super (struct super_block * sb)\n \n \tdquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);\n \n-\text2_xattr_put_super(sb);\n+\tif (sbi->s_mb_cache) {\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n+\t\tsbi->s_mb_cache = NULL;\n+\t}\n \tif (!(sb->s_flags & MS_RDONLY)) {\n \t\tstruct ext2_super_block *es = sbi->s_es;\n \n@@ -1104,6 +1107,14 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\text2_msg(sb, KERN_ERR, \""error: insufficient memory\"");\n \t\tgoto failed_mount3;\n \t}\n+\n+#ifdef CONFIG_EXT2_FS_XATTR\n+\tsbi->s_mb_cache = ext2_xattr_create_cache();\n+\tif (!sbi->s_mb_cache) {\n+\t\text2_msg(sb, KERN_ERR, \""Failed to create an mb_cache\"");\n+\t\tgoto failed_mount3;\n+\t}\n+#endif\n \t/*\n \t * set up enough so that it can read an inode\n \t */\n@@ -1149,6 +1160,8 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\t\tsb->s_id);\n \tgoto failed_mount;\n failed_mount3:\n+\tif (sbi->s_mb_cache)\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n \tpercpu_counter_destroy(&sbi->s_freeblocks_counter);\n \tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n \tpercpu_counter_destroy(&sbi->s_dirs_counter);\n@@ -1555,28 +1568,24 @@ MODULE_ALIAS_FS(\""ext2\"");\n \n static int __init init_ext2_fs(void)\n {\n-\tint err = init_ext2_xattr();\n-\tif (err)\n-\t\treturn err;\n+\tint err;\n+\n \terr = init_inodecache();\n \tif (err)\n-\t\tgoto out1;\n+\t\treturn err;\n         err = register_filesystem(&ext2_fs_type);\n \tif (err)\n \t\tgoto out;\n \treturn 0;\n out:\n \tdestroy_inodecache();\n-out1:\n-\texit_ext2_xattr();\n \treturn err;\n }\n \n static void __exit exit_ext2_fs(void)\n {\n \tunregister_filesystem(&ext2_fs_type);\n \tdestroy_inodecache();\n-\texit_ext2_xattr();\n }\n \n MODULE_AUTHOR(\""Remy Card and others\"");""}<_**next**_>{""sha"": ""7162b4869bc32515800d8ffc06ac3835ea241c8b"", ""filename"": ""fs/ext2/xattr.c"", ""status"": ""modified"", ""additions"": 67, ""deletions"": 76, ""changes"": 143, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -56,7 +56,7 @@\n #include <linux/buffer_head.h>\n #include <linux/init.h>\n #include <linux/slab.h>\n-#include <linux/mbcache.h>\n+#include <linux/mbcache2.h>\n #include <linux/quotaops.h>\n #include <linux/rwsem.h>\n #include <linux/security.h>\n@@ -90,14 +90,12 @@\n static int ext2_xattr_set2(struct inode *, struct buffer_head *,\n \t\t\t   struct ext2_xattr_header *);\n \n-static int ext2_xattr_cache_insert(struct buffer_head *);\n+static int ext2_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);\n static struct buffer_head *ext2_xattr_cache_find(struct inode *,\n \t\t\t\t\t\t struct ext2_xattr_header *);\n static void ext2_xattr_rehash(struct ext2_xattr_header *,\n \t\t\t      struct ext2_xattr_entry *);\n \n-static struct mb_cache *ext2_xattr_cache;\n-\n static const struct xattr_handler *ext2_xattr_handler_map[] = {\n \t[EXT2_XATTR_INDEX_USER]\t\t     = &ext2_xattr_user_handler,\n #ifdef CONFIG_EXT2_FS_POSIX_ACL\n@@ -152,6 +150,7 @@ ext2_xattr_get(struct inode *inode, int name_index, const char *name,\n \tsize_t name_len, size;\n \tchar *end;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""name=%d.%s, buffer=%p, buffer_size=%ld\"",\n \t\t  name_index, name, buffer, (long)buffer_size);\n@@ -196,7 +195,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t\t\tgoto found;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \terror = -ENODATA;\n \tgoto cleanup;\n@@ -209,7 +208,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)\n \t\tgoto bad_block;\n \n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \tif (buffer) {\n \t\terror = -ERANGE;\n@@ -247,6 +246,7 @@ ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)\n \tchar *end;\n \tsize_t rest = buffer_size;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""buffer=%p, buffer_size=%ld\"",\n \t\t  buffer, (long)buffer_size);\n@@ -281,7 +281,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_list\"",\n \t\t\tgoto bad_block;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \n \t/* list the attribute names */\n@@ -483,22 +483,23 @@ bad_block:\t\text2_error(sb, \""ext2_xattr_set\"",\n \t/* Here we know that we can set the new attribute. */\n \n \tif (header) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/* assert(header == HDR(bh)); */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,\n-\t\t\t\t\tbh->b_blocknr);\n \t\tlock_buffer(bh);\n \t\tif (header->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(header->h_hash);\n+\n \t\t\tea_bdebug(bh, \""modifying in-place\"");\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect modified block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,\n+\t\t\t\t\t\t     hash, bh->b_blocknr);\n+\n \t\t\t/* keep the buffer locked while modifying it. */\n \t\t} else {\n \t\t\tint offset;\n \n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tunlock_buffer(bh);\n \t\t\tea_bdebug(bh, \""cloning\"");\n \t\t\theader = kmalloc(bh->b_size, GFP_KERNEL);\n@@ -626,6 +627,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \tstruct super_block *sb = inode->i_sb;\n \tstruct buffer_head *new_bh = NULL;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;\n \n \tif (header) {\n \t\tnew_bh = ext2_xattr_cache_find(inode, header);\n@@ -653,7 +655,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\t   don't need to change the reference count. */\n \t\t\tnew_bh = old_bh;\n \t\t\tget_bh(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t} else {\n \t\t\t/* We need to allocate a new block */\n \t\t\text2_fsblk_t goal = ext2_group_first_block_no(sb,\n@@ -674,7 +676,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\tmemcpy(new_bh->b_data, header, new_bh->b_size);\n \t\t\tset_buffer_uptodate(new_bh);\n \t\t\tunlock_buffer(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t\t\n \t\t\text2_xattr_update_super_block(sb);\n \t\t}\n@@ -707,19 +709,21 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \n \terror = 0;\n \tif (old_bh && old_bh != new_bh) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/*\n \t\t * If there was an old block and we are no longer using it,\n \t\t * release the old block.\n \t\t */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,\n-\t\t\t\t\told_bh->b_blocknr);\n \t\tlock_buffer(old_bh);\n \t\tif (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);\n+\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect freed block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(ext2_mb_cache,\n+\t\t\t\t\t\t     hash, old_bh->b_blocknr);\n \t\t\t/* Free the old block. */\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n \t\t\tea_bdebug(old_bh, \""freeing\"");\n \t\t\text2_free_blocks(inode, old_bh->b_blocknr, 1);\n \t\t\tmark_inode_dirty(inode);\n@@ -730,8 +734,6 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t} else {\n \t\t\t/* Decrement the refcount only. */\n \t\t\tle32_add_cpu(&HDR(old_bh)->h_refcount, -1);\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tdquot_free_block_nodirty(inode, 1);\n \t\t\tmark_inode_dirty(inode);\n \t\t\tmark_buffer_dirty(old_bh);\n@@ -757,7 +759,6 @@ void\n ext2_xattr_delete_inode(struct inode *inode)\n {\n \tstruct buffer_head *bh = NULL;\n-\tstruct mb_cache_entry *ce;\n \n \tdown_write(&EXT2_I(inode)->xattr_sem);\n \tif (!EXT2_I(inode)->i_file_acl)\n@@ -777,19 +778,22 @@ ext2_xattr_delete_inode(struct inode *inode)\n \t\t\tEXT2_I(inode)->i_file_acl);\n \t\tgoto cleanup;\n \t}\n-\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);\n \tlock_buffer(bh);\n \tif (HDR(bh)->h_refcount == cpu_to_le32(1)) {\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_free(ce);\n+\t\t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n+\n+\t\t/*\n+\t\t * This must happen under buffer lock for ext2_xattr_set2() to\n+\t\t * reliably detect freed block\n+\t\t */\n+\t\tmb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,\n+\t\t\t\t\t     hash, bh->b_blocknr);\n \t\text2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);\n \t\tget_bh(bh);\n \t\tbforget(bh);\n \t\tunlock_buffer(bh);\n \t} else {\n \t\tle32_add_cpu(&HDR(bh)->h_refcount, -1);\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_release(ce);\n \t\tea_bdebug(bh, \""refcount now=%d\"",\n \t\t\tle32_to_cpu(HDR(bh)->h_refcount));\n \t\tunlock_buffer(bh);\n@@ -805,18 +809,6 @@ ext2_xattr_delete_inode(struct inode *inode)\n \tup_write(&EXT2_I(inode)->xattr_sem);\n }\n \n-/*\n- * ext2_xattr_put_super()\n- *\n- * This is called when a file system is unmounted.\n- */\n-void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-\tmb_cache_shrink(sb->s_bdev);\n-}\n-\n-\n /*\n  * ext2_xattr_cache_insert()\n  *\n@@ -826,28 +818,20 @@ ext2_xattr_put_super(struct super_block *sb)\n  * Returns 0, or a negative error number on failure.\n  */\n static int\n-ext2_xattr_cache_insert(struct buffer_head *bh)\n+ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)\n {\n \t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n-\tstruct mb_cache_entry *ce;\n \tint error;\n \n-\tce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);\n-\tif (!ce)\n-\t\treturn -ENOMEM;\n-\terror = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);\n+\terror = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);\n \tif (error) {\n-\t\tmb_cache_entry_free(ce);\n \t\tif (error == -EBUSY) {\n \t\t\tea_bdebug(bh, \""already in cache (%d cache entries)\"",\n \t\t\t\tatomic_read(&ext2_xattr_cache->c_entry_count));\n \t\t\terror = 0;\n \t\t}\n-\t} else {\n-\t\tea_bdebug(bh, \""inserting [%x] (%d cache entries)\"", (int)hash,\n-\t\t\t  atomic_read(&ext2_xattr_cache->c_entry_count));\n-\t\tmb_cache_entry_release(ce);\n-\t}\n+\t} else\n+\t\tea_bdebug(bh, \""inserting [%x]\"", (int)hash);\n \treturn error;\n }\n \n@@ -903,31 +887,39 @@ static struct buffer_head *\n ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n {\n \t__u32 hash = le32_to_cpu(header->h_hash);\n-\tstruct mb_cache_entry *ce;\n+\tstruct mb2_cache_entry *ce;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tif (!header->h_hash)\n \t\treturn NULL;  /* never share */\n \tea_idebug(inode, \""looking for cached blocks [%x]\"", (int)hash);\n again:\n-\tce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,\n-\t\t\t\t       hash);\n+\tce = mb2_cache_entry_find_first(ext2_mb_cache, hash);\n \twhile (ce) {\n \t\tstruct buffer_head *bh;\n \n-\t\tif (IS_ERR(ce)) {\n-\t\t\tif (PTR_ERR(ce) == -EAGAIN)\n-\t\t\t\tgoto again;\n-\t\t\tbreak;\n-\t\t}\n-\n \t\tbh = sb_bread(inode->i_sb, ce->e_block);\n \t\tif (!bh) {\n \t\t\text2_error(inode->i_sb, \""ext2_xattr_cache_find\"",\n \t\t\t\t\""inode %ld: block %ld read error\"",\n \t\t\t\tinode->i_ino, (unsigned long) ce->e_block);\n \t\t} else {\n \t\t\tlock_buffer(bh);\n-\t\t\tif (le32_to_cpu(HDR(bh)->h_refcount) >\n+\t\t\t/*\n+\t\t\t * We have to be careful about races with freeing or\n+\t\t\t * rehashing of xattr block. Once we hold buffer lock\n+\t\t\t * xattr block's state is stable so we can check\n+\t\t\t * whether the block got freed / rehashed or not.\n+\t\t\t * Since we unhash mbcache entry under buffer lock when\n+\t\t\t * freeing / rehashing xattr block, checking whether\n+\t\t\t * entry is still hashed is reliable.\n+\t\t\t */\n+\t\t\tif (hlist_bl_unhashed(&ce->e_hash_list)) {\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n+\t\t\t\tunlock_buffer(bh);\n+\t\t\t\tbrelse(bh);\n+\t\t\t\tgoto again;\n+\t\t\t} else if (le32_to_cpu(HDR(bh)->h_refcount) >\n \t\t\t\t   EXT2_XATTR_REFCOUNT_MAX) {\n \t\t\t\tea_idebug(inode, \""block %ld refcount %d>%d\"",\n \t\t\t\t\t  (unsigned long) ce->e_block,\n@@ -936,13 +928,14 @@ ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n \t\t\t} else if (!ext2_xattr_cmp(header, HDR(bh))) {\n \t\t\t\tea_bdebug(bh, \""b_count=%d\"",\n \t\t\t\t\t  atomic_read(&(bh->b_count)));\n-\t\t\t\tmb_cache_entry_release(ce);\n+\t\t\t\tmb2_cache_entry_touch(ext2_mb_cache, ce);\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n \t\t\t\treturn bh;\n \t\t\t}\n \t\t\tunlock_buffer(bh);\n \t\t\tbrelse(bh);\n \t\t}\n-\t\tce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);\n+\t\tce = mb2_cache_entry_find_next(ext2_mb_cache, ce);\n \t}\n \treturn NULL;\n }\n@@ -1015,17 +1008,15 @@ static void ext2_xattr_rehash(struct ext2_xattr_header *header,\n \n #undef BLOCK_HASH_SHIFT\n \n-int __init\n-init_ext2_xattr(void)\n+#define HASH_BUCKET_BITS 10\n+\n+struct mb2_cache *ext2_xattr_create_cache(void)\n {\n-\text2_xattr_cache = mb_cache_create(\""ext2_xattr\"", 6);\n-\tif (!ext2_xattr_cache)\n-\t\treturn -ENOMEM;\n-\treturn 0;\n+\treturn mb2_cache_create(HASH_BUCKET_BITS);\n }\n \n-void\n-exit_ext2_xattr(void)\n+void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n-\tmb_cache_destroy(ext2_xattr_cache);\n+\tif (cache)\n+\t\tmb2_cache_destroy(cache);\n }""}<_**next**_>{""sha"": ""6ea38aa9563a00649bf25544eed131bbe8b1d88d"", ""filename"": ""fs/ext2/xattr.h"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 16, ""changes"": 21, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -53,6 +53,8 @@ struct ext2_xattr_entry {\n #define EXT2_XATTR_SIZE(size) \\\n \t(((size) + EXT2_XATTR_ROUND) & ~EXT2_XATTR_ROUND)\n \n+struct mb2_cache;\n+\n # ifdef CONFIG_EXT2_FS_XATTR\n \n extern const struct xattr_handler ext2_xattr_user_handler;\n@@ -65,10 +67,9 @@ extern int ext2_xattr_get(struct inode *, int, const char *, void *, size_t);\n extern int ext2_xattr_set(struct inode *, int, const char *, const void *, size_t, int);\n \n extern void ext2_xattr_delete_inode(struct inode *);\n-extern void ext2_xattr_put_super(struct super_block *);\n \n-extern int init_ext2_xattr(void);\n-extern void exit_ext2_xattr(void);\n+extern struct mb2_cache *ext2_xattr_create_cache(void);\n+extern void ext2_xattr_destroy_cache(struct mb2_cache *cache);\n \n extern const struct xattr_handler *ext2_xattr_handlers[];\n \n@@ -93,19 +94,7 @@ ext2_xattr_delete_inode(struct inode *inode)\n {\n }\n \n-static inline void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-}\n-\n-static inline int\n-init_ext2_xattr(void)\n-{\n-\treturn 0;\n-}\n-\n-static inline void\n-exit_ext2_xattr(void)\n+static inline void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n }\n ""}","static int ext2_fill_super(struct super_block *sb, void *data, int silent)
{
	struct buffer_head * bh;
	struct ext2_sb_info * sbi;
	struct ext2_super_block * es;
	struct inode *root;
	unsigned long block;
	unsigned long sb_block = get_sb_block(&data);
	unsigned long logic_sb_block;
	unsigned long offset = 0;
	unsigned long def_mount_opts;
	long ret = -EINVAL;
	int blocksize = BLOCK_SIZE;
	int db_count;
	int i, j;
	__le32 features;
	int err;

	err = -ENOMEM;
	sbi = kzalloc(sizeof(*sbi), GFP_KERNEL);
	if (!sbi)
		goto failed;

	sbi->s_blockgroup_lock =
		kzalloc(sizeof(struct blockgroup_lock), GFP_KERNEL);
	if (!sbi->s_blockgroup_lock) {
		kfree(sbi);
		goto failed;
	}
	sb->s_fs_info = sbi;
	sbi->s_sb_block = sb_block;

	spin_lock_init(&sbi->s_lock);

	/*
	 * See what the current blocksize for the device is, and
	 * use that as the blocksize.  Otherwise (or if the blocksize
	 * is smaller than the default) use the default.
	 * This is important for devices that have a hardware
	 * sectorsize that is larger than the default.
	 */
	blocksize = sb_min_blocksize(sb, BLOCK_SIZE);
	if (!blocksize) {
		ext2_msg(sb, KERN_ERR, ""error: unable to set blocksize"");
		goto failed_sbi;
	}

	/*
	 * If the superblock doesn't start on a hardware sector boundary,
	 * calculate the offset.  
	 */
	if (blocksize != BLOCK_SIZE) {
		logic_sb_block = (sb_block*BLOCK_SIZE) / blocksize;
		offset = (sb_block*BLOCK_SIZE) % blocksize;
	} else {
		logic_sb_block = sb_block;
	}

	if (!(bh = sb_bread(sb, logic_sb_block))) {
		ext2_msg(sb, KERN_ERR, ""error: unable to read superblock"");
		goto failed_sbi;
	}
	/*
	 * Note: s_es must be initialized as soon as possible because
	 *       some ext2 macro-instructions depend on its value
	 */
	es = (struct ext2_super_block *) (((char *)bh->b_data) + offset);
	sbi->s_es = es;
	sb->s_magic = le16_to_cpu(es->s_magic);

	if (sb->s_magic != EXT2_SUPER_MAGIC)
		goto cantfind_ext2;

	/* Set defaults before we parse the mount options */
	def_mount_opts = le32_to_cpu(es->s_default_mount_opts);
	if (def_mount_opts & EXT2_DEFM_DEBUG)
		set_opt(sbi->s_mount_opt, DEBUG);
	if (def_mount_opts & EXT2_DEFM_BSDGROUPS)
		set_opt(sbi->s_mount_opt, GRPID);
	if (def_mount_opts & EXT2_DEFM_UID16)
		set_opt(sbi->s_mount_opt, NO_UID32);
#ifdef CONFIG_EXT2_FS_XATTR
	if (def_mount_opts & EXT2_DEFM_XATTR_USER)
		set_opt(sbi->s_mount_opt, XATTR_USER);
#endif
#ifdef CONFIG_EXT2_FS_POSIX_ACL
	if (def_mount_opts & EXT2_DEFM_ACL)
		set_opt(sbi->s_mount_opt, POSIX_ACL);
#endif
	
	if (le16_to_cpu(sbi->s_es->s_errors) == EXT2_ERRORS_PANIC)
		set_opt(sbi->s_mount_opt, ERRORS_PANIC);
	else if (le16_to_cpu(sbi->s_es->s_errors) == EXT2_ERRORS_CONTINUE)
		set_opt(sbi->s_mount_opt, ERRORS_CONT);
	else
		set_opt(sbi->s_mount_opt, ERRORS_RO);

	sbi->s_resuid = make_kuid(&init_user_ns, le16_to_cpu(es->s_def_resuid));
	sbi->s_resgid = make_kgid(&init_user_ns, le16_to_cpu(es->s_def_resgid));
	
	set_opt(sbi->s_mount_opt, RESERVATION);

	if (!parse_options((char *) data, sb))
		goto failed_mount;

	sb->s_flags = (sb->s_flags & ~MS_POSIXACL) |
		((EXT2_SB(sb)->s_mount_opt & EXT2_MOUNT_POSIX_ACL) ?
		 MS_POSIXACL : 0);
	sb->s_iflags |= SB_I_CGROUPWB;

	if (le32_to_cpu(es->s_rev_level) == EXT2_GOOD_OLD_REV &&
	    (EXT2_HAS_COMPAT_FEATURE(sb, ~0U) ||
	     EXT2_HAS_RO_COMPAT_FEATURE(sb, ~0U) ||
	     EXT2_HAS_INCOMPAT_FEATURE(sb, ~0U)))
		ext2_msg(sb, KERN_WARNING,
			""warning: feature flags set on rev 0 fs, ""
			""running e2fsck is recommended"");
	/*
	 * Check feature flags regardless of the revision level, since we
	 * previously didn't change the revision level when setting the flags,
	 * so there is a chance incompat flags are set on a rev 0 filesystem.
	 */
	features = EXT2_HAS_INCOMPAT_FEATURE(sb, ~EXT2_FEATURE_INCOMPAT_SUPP);
	if (features) {
		ext2_msg(sb, KERN_ERR,	""error: couldn't mount because of ""
		       ""unsupported optional features (%x)"",
			le32_to_cpu(features));
		goto failed_mount;
	}
	if (!(sb->s_flags & MS_RDONLY) &&
	    (features = EXT2_HAS_RO_COMPAT_FEATURE(sb, ~EXT2_FEATURE_RO_COMPAT_SUPP))){
		ext2_msg(sb, KERN_ERR, ""error: couldn't mount RDWR because of ""
		       ""unsupported optional features (%x)"",
		       le32_to_cpu(features));
		goto failed_mount;
	}

	blocksize = BLOCK_SIZE << le32_to_cpu(sbi->s_es->s_log_block_size);

	if (sbi->s_mount_opt & EXT2_MOUNT_DAX) {
		if (blocksize != PAGE_SIZE) {
			ext2_msg(sb, KERN_ERR,
					""error: unsupported blocksize for dax"");
			goto failed_mount;
		}
		if (!sb->s_bdev->bd_disk->fops->direct_access) {
			ext2_msg(sb, KERN_ERR,
					""error: device does not support dax"");
			goto failed_mount;
		}
	}

	/* If the blocksize doesn't match, re-read the thing.. */
	if (sb->s_blocksize != blocksize) {
		brelse(bh);

		if (!sb_set_blocksize(sb, blocksize)) {
			ext2_msg(sb, KERN_ERR,
				""error: bad blocksize %d"", blocksize);
			goto failed_sbi;
		}

		logic_sb_block = (sb_block*BLOCK_SIZE) / blocksize;
		offset = (sb_block*BLOCK_SIZE) % blocksize;
		bh = sb_bread(sb, logic_sb_block);
		if(!bh) {
			ext2_msg(sb, KERN_ERR, ""error: couldn't read""
				""superblock on 2nd try"");
			goto failed_sbi;
		}
		es = (struct ext2_super_block *) (((char *)bh->b_data) + offset);
		sbi->s_es = es;
		if (es->s_magic != cpu_to_le16(EXT2_SUPER_MAGIC)) {
			ext2_msg(sb, KERN_ERR, ""error: magic mismatch"");
			goto failed_mount;
		}
	}

	sb->s_maxbytes = ext2_max_size(sb->s_blocksize_bits);
	sb->s_max_links = EXT2_LINK_MAX;

	if (le32_to_cpu(es->s_rev_level) == EXT2_GOOD_OLD_REV) {
		sbi->s_inode_size = EXT2_GOOD_OLD_INODE_SIZE;
		sbi->s_first_ino = EXT2_GOOD_OLD_FIRST_INO;
	} else {
		sbi->s_inode_size = le16_to_cpu(es->s_inode_size);
		sbi->s_first_ino = le32_to_cpu(es->s_first_ino);
		if ((sbi->s_inode_size < EXT2_GOOD_OLD_INODE_SIZE) ||
		    !is_power_of_2(sbi->s_inode_size) ||
		    (sbi->s_inode_size > blocksize)) {
			ext2_msg(sb, KERN_ERR,
				""error: unsupported inode size: %d"",
				sbi->s_inode_size);
			goto failed_mount;
		}
	}

	sbi->s_frag_size = EXT2_MIN_FRAG_SIZE <<
				   le32_to_cpu(es->s_log_frag_size);
	if (sbi->s_frag_size == 0)
		goto cantfind_ext2;
	sbi->s_frags_per_block = sb->s_blocksize / sbi->s_frag_size;

	sbi->s_blocks_per_group = le32_to_cpu(es->s_blocks_per_group);
	sbi->s_frags_per_group = le32_to_cpu(es->s_frags_per_group);
	sbi->s_inodes_per_group = le32_to_cpu(es->s_inodes_per_group);

	if (EXT2_INODE_SIZE(sb) == 0)
		goto cantfind_ext2;
	sbi->s_inodes_per_block = sb->s_blocksize / EXT2_INODE_SIZE(sb);
	if (sbi->s_inodes_per_block == 0 || sbi->s_inodes_per_group == 0)
		goto cantfind_ext2;
	sbi->s_itb_per_group = sbi->s_inodes_per_group /
					sbi->s_inodes_per_block;
	sbi->s_desc_per_block = sb->s_blocksize /
					sizeof (struct ext2_group_desc);
	sbi->s_sbh = bh;
	sbi->s_mount_state = le16_to_cpu(es->s_state);
	sbi->s_addr_per_block_bits =
		ilog2 (EXT2_ADDR_PER_BLOCK(sb));
	sbi->s_desc_per_block_bits =
		ilog2 (EXT2_DESC_PER_BLOCK(sb));

	if (sb->s_magic != EXT2_SUPER_MAGIC)
		goto cantfind_ext2;

	if (sb->s_blocksize != bh->b_size) {
		if (!silent)
			ext2_msg(sb, KERN_ERR, ""error: unsupported blocksize"");
		goto failed_mount;
	}

	if (sb->s_blocksize != sbi->s_frag_size) {
		ext2_msg(sb, KERN_ERR,
			""error: fragsize %lu != blocksize %lu""
			""(not supported yet)"",
			sbi->s_frag_size, sb->s_blocksize);
		goto failed_mount;
	}

	if (sbi->s_blocks_per_group > sb->s_blocksize * 8) {
		ext2_msg(sb, KERN_ERR,
			""error: #blocks per group too big: %lu"",
			sbi->s_blocks_per_group);
		goto failed_mount;
	}
	if (sbi->s_frags_per_group > sb->s_blocksize * 8) {
		ext2_msg(sb, KERN_ERR,
			""error: #fragments per group too big: %lu"",
			sbi->s_frags_per_group);
		goto failed_mount;
	}
	if (sbi->s_inodes_per_group > sb->s_blocksize * 8) {
		ext2_msg(sb, KERN_ERR,
			""error: #inodes per group too big: %lu"",
			sbi->s_inodes_per_group);
		goto failed_mount;
	}

	if (EXT2_BLOCKS_PER_GROUP(sb) == 0)
		goto cantfind_ext2;
 	sbi->s_groups_count = ((le32_to_cpu(es->s_blocks_count) -
 				le32_to_cpu(es->s_first_data_block) - 1)
 					/ EXT2_BLOCKS_PER_GROUP(sb)) + 1;
	db_count = (sbi->s_groups_count + EXT2_DESC_PER_BLOCK(sb) - 1) /
		   EXT2_DESC_PER_BLOCK(sb);
	sbi->s_group_desc = kmalloc (db_count * sizeof (struct buffer_head *), GFP_KERNEL);
	if (sbi->s_group_desc == NULL) {
		ext2_msg(sb, KERN_ERR, ""error: not enough memory"");
		goto failed_mount;
	}
	bgl_lock_init(sbi->s_blockgroup_lock);
	sbi->s_debts = kcalloc(sbi->s_groups_count, sizeof(*sbi->s_debts), GFP_KERNEL);
	if (!sbi->s_debts) {
		ext2_msg(sb, KERN_ERR, ""error: not enough memory"");
		goto failed_mount_group_desc;
	}
	for (i = 0; i < db_count; i++) {
		block = descriptor_loc(sb, logic_sb_block, i);
		sbi->s_group_desc[i] = sb_bread(sb, block);
		if (!sbi->s_group_desc[i]) {
			for (j = 0; j < i; j++)
				brelse (sbi->s_group_desc[j]);
			ext2_msg(sb, KERN_ERR,
				""error: unable to read group descriptors"");
			goto failed_mount_group_desc;
		}
	}
	if (!ext2_check_descriptors (sb)) {
		ext2_msg(sb, KERN_ERR, ""group descriptors corrupted"");
		goto failed_mount2;
	}
	sbi->s_gdb_count = db_count;
	get_random_bytes(&sbi->s_next_generation, sizeof(u32));
	spin_lock_init(&sbi->s_next_gen_lock);

	/* per fileystem reservation list head & lock */
	spin_lock_init(&sbi->s_rsv_window_lock);
	sbi->s_rsv_window_root = RB_ROOT;
	/*
	 * Add a single, static dummy reservation to the start of the
	 * reservation window list --- it gives us a placeholder for
	 * append-at-start-of-list which makes the allocation logic
	 * _much_ simpler.
	 */
	sbi->s_rsv_window_head.rsv_start = EXT2_RESERVE_WINDOW_NOT_ALLOCATED;
	sbi->s_rsv_window_head.rsv_end = EXT2_RESERVE_WINDOW_NOT_ALLOCATED;
	sbi->s_rsv_window_head.rsv_alloc_hit = 0;
	sbi->s_rsv_window_head.rsv_goal_size = 0;
	ext2_rsv_window_add(sb, &sbi->s_rsv_window_head);

	err = percpu_counter_init(&sbi->s_freeblocks_counter,
				ext2_count_free_blocks(sb), GFP_KERNEL);
	if (!err) {
		err = percpu_counter_init(&sbi->s_freeinodes_counter,
				ext2_count_free_inodes(sb), GFP_KERNEL);
	}
	if (!err) {
		err = percpu_counter_init(&sbi->s_dirs_counter,
				ext2_count_dirs(sb), GFP_KERNEL);
	}
	if (err) {
 		ext2_msg(sb, KERN_ERR, ""error: insufficient memory"");
 		goto failed_mount3;
 	}

#ifdef CONFIG_EXT2_FS_XATTR
	sbi->s_mb_cache = ext2_xattr_create_cache();
	if (!sbi->s_mb_cache) {
		ext2_msg(sb, KERN_ERR, ""Failed to create an mb_cache"");
		goto failed_mount3;
	}
#endif
 	/*
 	 * set up enough so that it can read an inode
 	 */
	sb->s_op = &ext2_sops;
	sb->s_export_op = &ext2_export_ops;
	sb->s_xattr = ext2_xattr_handlers;

#ifdef CONFIG_QUOTA
	sb->dq_op = &dquot_operations;
	sb->s_qcop = &dquot_quotactl_ops;
	sb->s_quota_types = QTYPE_MASK_USR | QTYPE_MASK_GRP;
#endif

	root = ext2_iget(sb, EXT2_ROOT_INO);
	if (IS_ERR(root)) {
		ret = PTR_ERR(root);
		goto failed_mount3;
	}
	if (!S_ISDIR(root->i_mode) || !root->i_blocks || !root->i_size) {
		iput(root);
		ext2_msg(sb, KERN_ERR, ""error: corrupt root inode, run e2fsck"");
		goto failed_mount3;
	}

	sb->s_root = d_make_root(root);
	if (!sb->s_root) {
		ext2_msg(sb, KERN_ERR, ""error: get root inode failed"");
		ret = -ENOMEM;
		goto failed_mount3;
	}
	if (EXT2_HAS_COMPAT_FEATURE(sb, EXT3_FEATURE_COMPAT_HAS_JOURNAL))
		ext2_msg(sb, KERN_WARNING,
			""warning: mounting ext3 filesystem as ext2"");
	if (ext2_setup_super (sb, es, sb->s_flags & MS_RDONLY))
		sb->s_flags |= MS_RDONLY;
	ext2_write_super(sb);
	return 0;

cantfind_ext2:
	if (!silent)
		ext2_msg(sb, KERN_ERR,
			""error: can't find an ext2 filesystem on dev %s."",
 			sb->s_id);
 	goto failed_mount;
 failed_mount3:
	if (sbi->s_mb_cache)
		ext2_xattr_destroy_cache(sbi->s_mb_cache);
 	percpu_counter_destroy(&sbi->s_freeblocks_counter);
 	percpu_counter_destroy(&sbi->s_freeinodes_counter);
 	percpu_counter_destroy(&sbi->s_dirs_counter);
failed_mount2:
	for (i = 0; i < db_count; i++)
		brelse(sbi->s_group_desc[i]);
failed_mount_group_desc:
	kfree(sbi->s_group_desc);
	kfree(sbi->s_debts);
failed_mount:
	brelse(bh);
failed_sbi:
	sb->s_fs_info = NULL;
	kfree(sbi->s_blockgroup_lock);
	kfree(sbi);
failed:
	return ret;
}
","static int ext2_fill_super(struct super_block *sb, void *data, int silent)
{
	struct buffer_head * bh;
	struct ext2_sb_info * sbi;
	struct ext2_super_block * es;
	struct inode *root;
	unsigned long block;
	unsigned long sb_block = get_sb_block(&data);
	unsigned long logic_sb_block;
	unsigned long offset = 0;
	unsigned long def_mount_opts;
	long ret = -EINVAL;
	int blocksize = BLOCK_SIZE;
	int db_count;
	int i, j;
	__le32 features;
	int err;

	err = -ENOMEM;
	sbi = kzalloc(sizeof(*sbi), GFP_KERNEL);
	if (!sbi)
		goto failed;

	sbi->s_blockgroup_lock =
		kzalloc(sizeof(struct blockgroup_lock), GFP_KERNEL);
	if (!sbi->s_blockgroup_lock) {
		kfree(sbi);
		goto failed;
	}
	sb->s_fs_info = sbi;
	sbi->s_sb_block = sb_block;

	spin_lock_init(&sbi->s_lock);

	/*
	 * See what the current blocksize for the device is, and
	 * use that as the blocksize.  Otherwise (or if the blocksize
	 * is smaller than the default) use the default.
	 * This is important for devices that have a hardware
	 * sectorsize that is larger than the default.
	 */
	blocksize = sb_min_blocksize(sb, BLOCK_SIZE);
	if (!blocksize) {
		ext2_msg(sb, KERN_ERR, ""error: unable to set blocksize"");
		goto failed_sbi;
	}

	/*
	 * If the superblock doesn't start on a hardware sector boundary,
	 * calculate the offset.  
	 */
	if (blocksize != BLOCK_SIZE) {
		logic_sb_block = (sb_block*BLOCK_SIZE) / blocksize;
		offset = (sb_block*BLOCK_SIZE) % blocksize;
	} else {
		logic_sb_block = sb_block;
	}

	if (!(bh = sb_bread(sb, logic_sb_block))) {
		ext2_msg(sb, KERN_ERR, ""error: unable to read superblock"");
		goto failed_sbi;
	}
	/*
	 * Note: s_es must be initialized as soon as possible because
	 *       some ext2 macro-instructions depend on its value
	 */
	es = (struct ext2_super_block *) (((char *)bh->b_data) + offset);
	sbi->s_es = es;
	sb->s_magic = le16_to_cpu(es->s_magic);

	if (sb->s_magic != EXT2_SUPER_MAGIC)
		goto cantfind_ext2;

	/* Set defaults before we parse the mount options */
	def_mount_opts = le32_to_cpu(es->s_default_mount_opts);
	if (def_mount_opts & EXT2_DEFM_DEBUG)
		set_opt(sbi->s_mount_opt, DEBUG);
	if (def_mount_opts & EXT2_DEFM_BSDGROUPS)
		set_opt(sbi->s_mount_opt, GRPID);
	if (def_mount_opts & EXT2_DEFM_UID16)
		set_opt(sbi->s_mount_opt, NO_UID32);
#ifdef CONFIG_EXT2_FS_XATTR
	if (def_mount_opts & EXT2_DEFM_XATTR_USER)
		set_opt(sbi->s_mount_opt, XATTR_USER);
#endif
#ifdef CONFIG_EXT2_FS_POSIX_ACL
	if (def_mount_opts & EXT2_DEFM_ACL)
		set_opt(sbi->s_mount_opt, POSIX_ACL);
#endif
	
	if (le16_to_cpu(sbi->s_es->s_errors) == EXT2_ERRORS_PANIC)
		set_opt(sbi->s_mount_opt, ERRORS_PANIC);
	else if (le16_to_cpu(sbi->s_es->s_errors) == EXT2_ERRORS_CONTINUE)
		set_opt(sbi->s_mount_opt, ERRORS_CONT);
	else
		set_opt(sbi->s_mount_opt, ERRORS_RO);

	sbi->s_resuid = make_kuid(&init_user_ns, le16_to_cpu(es->s_def_resuid));
	sbi->s_resgid = make_kgid(&init_user_ns, le16_to_cpu(es->s_def_resgid));
	
	set_opt(sbi->s_mount_opt, RESERVATION);

	if (!parse_options((char *) data, sb))
		goto failed_mount;

	sb->s_flags = (sb->s_flags & ~MS_POSIXACL) |
		((EXT2_SB(sb)->s_mount_opt & EXT2_MOUNT_POSIX_ACL) ?
		 MS_POSIXACL : 0);
	sb->s_iflags |= SB_I_CGROUPWB;

	if (le32_to_cpu(es->s_rev_level) == EXT2_GOOD_OLD_REV &&
	    (EXT2_HAS_COMPAT_FEATURE(sb, ~0U) ||
	     EXT2_HAS_RO_COMPAT_FEATURE(sb, ~0U) ||
	     EXT2_HAS_INCOMPAT_FEATURE(sb, ~0U)))
		ext2_msg(sb, KERN_WARNING,
			""warning: feature flags set on rev 0 fs, ""
			""running e2fsck is recommended"");
	/*
	 * Check feature flags regardless of the revision level, since we
	 * previously didn't change the revision level when setting the flags,
	 * so there is a chance incompat flags are set on a rev 0 filesystem.
	 */
	features = EXT2_HAS_INCOMPAT_FEATURE(sb, ~EXT2_FEATURE_INCOMPAT_SUPP);
	if (features) {
		ext2_msg(sb, KERN_ERR,	""error: couldn't mount because of ""
		       ""unsupported optional features (%x)"",
			le32_to_cpu(features));
		goto failed_mount;
	}
	if (!(sb->s_flags & MS_RDONLY) &&
	    (features = EXT2_HAS_RO_COMPAT_FEATURE(sb, ~EXT2_FEATURE_RO_COMPAT_SUPP))){
		ext2_msg(sb, KERN_ERR, ""error: couldn't mount RDWR because of ""
		       ""unsupported optional features (%x)"",
		       le32_to_cpu(features));
		goto failed_mount;
	}

	blocksize = BLOCK_SIZE << le32_to_cpu(sbi->s_es->s_log_block_size);

	if (sbi->s_mount_opt & EXT2_MOUNT_DAX) {
		if (blocksize != PAGE_SIZE) {
			ext2_msg(sb, KERN_ERR,
					""error: unsupported blocksize for dax"");
			goto failed_mount;
		}
		if (!sb->s_bdev->bd_disk->fops->direct_access) {
			ext2_msg(sb, KERN_ERR,
					""error: device does not support dax"");
			goto failed_mount;
		}
	}

	/* If the blocksize doesn't match, re-read the thing.. */
	if (sb->s_blocksize != blocksize) {
		brelse(bh);

		if (!sb_set_blocksize(sb, blocksize)) {
			ext2_msg(sb, KERN_ERR,
				""error: bad blocksize %d"", blocksize);
			goto failed_sbi;
		}

		logic_sb_block = (sb_block*BLOCK_SIZE) / blocksize;
		offset = (sb_block*BLOCK_SIZE) % blocksize;
		bh = sb_bread(sb, logic_sb_block);
		if(!bh) {
			ext2_msg(sb, KERN_ERR, ""error: couldn't read""
				""superblock on 2nd try"");
			goto failed_sbi;
		}
		es = (struct ext2_super_block *) (((char *)bh->b_data) + offset);
		sbi->s_es = es;
		if (es->s_magic != cpu_to_le16(EXT2_SUPER_MAGIC)) {
			ext2_msg(sb, KERN_ERR, ""error: magic mismatch"");
			goto failed_mount;
		}
	}

	sb->s_maxbytes = ext2_max_size(sb->s_blocksize_bits);
	sb->s_max_links = EXT2_LINK_MAX;

	if (le32_to_cpu(es->s_rev_level) == EXT2_GOOD_OLD_REV) {
		sbi->s_inode_size = EXT2_GOOD_OLD_INODE_SIZE;
		sbi->s_first_ino = EXT2_GOOD_OLD_FIRST_INO;
	} else {
		sbi->s_inode_size = le16_to_cpu(es->s_inode_size);
		sbi->s_first_ino = le32_to_cpu(es->s_first_ino);
		if ((sbi->s_inode_size < EXT2_GOOD_OLD_INODE_SIZE) ||
		    !is_power_of_2(sbi->s_inode_size) ||
		    (sbi->s_inode_size > blocksize)) {
			ext2_msg(sb, KERN_ERR,
				""error: unsupported inode size: %d"",
				sbi->s_inode_size);
			goto failed_mount;
		}
	}

	sbi->s_frag_size = EXT2_MIN_FRAG_SIZE <<
				   le32_to_cpu(es->s_log_frag_size);
	if (sbi->s_frag_size == 0)
		goto cantfind_ext2;
	sbi->s_frags_per_block = sb->s_blocksize / sbi->s_frag_size;

	sbi->s_blocks_per_group = le32_to_cpu(es->s_blocks_per_group);
	sbi->s_frags_per_group = le32_to_cpu(es->s_frags_per_group);
	sbi->s_inodes_per_group = le32_to_cpu(es->s_inodes_per_group);

	if (EXT2_INODE_SIZE(sb) == 0)
		goto cantfind_ext2;
	sbi->s_inodes_per_block = sb->s_blocksize / EXT2_INODE_SIZE(sb);
	if (sbi->s_inodes_per_block == 0 || sbi->s_inodes_per_group == 0)
		goto cantfind_ext2;
	sbi->s_itb_per_group = sbi->s_inodes_per_group /
					sbi->s_inodes_per_block;
	sbi->s_desc_per_block = sb->s_blocksize /
					sizeof (struct ext2_group_desc);
	sbi->s_sbh = bh;
	sbi->s_mount_state = le16_to_cpu(es->s_state);
	sbi->s_addr_per_block_bits =
		ilog2 (EXT2_ADDR_PER_BLOCK(sb));
	sbi->s_desc_per_block_bits =
		ilog2 (EXT2_DESC_PER_BLOCK(sb));

	if (sb->s_magic != EXT2_SUPER_MAGIC)
		goto cantfind_ext2;

	if (sb->s_blocksize != bh->b_size) {
		if (!silent)
			ext2_msg(sb, KERN_ERR, ""error: unsupported blocksize"");
		goto failed_mount;
	}

	if (sb->s_blocksize != sbi->s_frag_size) {
		ext2_msg(sb, KERN_ERR,
			""error: fragsize %lu != blocksize %lu""
			""(not supported yet)"",
			sbi->s_frag_size, sb->s_blocksize);
		goto failed_mount;
	}

	if (sbi->s_blocks_per_group > sb->s_blocksize * 8) {
		ext2_msg(sb, KERN_ERR,
			""error: #blocks per group too big: %lu"",
			sbi->s_blocks_per_group);
		goto failed_mount;
	}
	if (sbi->s_frags_per_group > sb->s_blocksize * 8) {
		ext2_msg(sb, KERN_ERR,
			""error: #fragments per group too big: %lu"",
			sbi->s_frags_per_group);
		goto failed_mount;
	}
	if (sbi->s_inodes_per_group > sb->s_blocksize * 8) {
		ext2_msg(sb, KERN_ERR,
			""error: #inodes per group too big: %lu"",
			sbi->s_inodes_per_group);
		goto failed_mount;
	}

	if (EXT2_BLOCKS_PER_GROUP(sb) == 0)
		goto cantfind_ext2;
 	sbi->s_groups_count = ((le32_to_cpu(es->s_blocks_count) -
 				le32_to_cpu(es->s_first_data_block) - 1)
 					/ EXT2_BLOCKS_PER_GROUP(sb)) + 1;
	db_count = (sbi->s_groups_count + EXT2_DESC_PER_BLOCK(sb) - 1) /
		   EXT2_DESC_PER_BLOCK(sb);
	sbi->s_group_desc = kmalloc (db_count * sizeof (struct buffer_head *), GFP_KERNEL);
	if (sbi->s_group_desc == NULL) {
		ext2_msg(sb, KERN_ERR, ""error: not enough memory"");
		goto failed_mount;
	}
	bgl_lock_init(sbi->s_blockgroup_lock);
	sbi->s_debts = kcalloc(sbi->s_groups_count, sizeof(*sbi->s_debts), GFP_KERNEL);
	if (!sbi->s_debts) {
		ext2_msg(sb, KERN_ERR, ""error: not enough memory"");
		goto failed_mount_group_desc;
	}
	for (i = 0; i < db_count; i++) {
		block = descriptor_loc(sb, logic_sb_block, i);
		sbi->s_group_desc[i] = sb_bread(sb, block);
		if (!sbi->s_group_desc[i]) {
			for (j = 0; j < i; j++)
				brelse (sbi->s_group_desc[j]);
			ext2_msg(sb, KERN_ERR,
				""error: unable to read group descriptors"");
			goto failed_mount_group_desc;
		}
	}
	if (!ext2_check_descriptors (sb)) {
		ext2_msg(sb, KERN_ERR, ""group descriptors corrupted"");
		goto failed_mount2;
	}
	sbi->s_gdb_count = db_count;
	get_random_bytes(&sbi->s_next_generation, sizeof(u32));
	spin_lock_init(&sbi->s_next_gen_lock);

	/* per fileystem reservation list head & lock */
	spin_lock_init(&sbi->s_rsv_window_lock);
	sbi->s_rsv_window_root = RB_ROOT;
	/*
	 * Add a single, static dummy reservation to the start of the
	 * reservation window list --- it gives us a placeholder for
	 * append-at-start-of-list which makes the allocation logic
	 * _much_ simpler.
	 */
	sbi->s_rsv_window_head.rsv_start = EXT2_RESERVE_WINDOW_NOT_ALLOCATED;
	sbi->s_rsv_window_head.rsv_end = EXT2_RESERVE_WINDOW_NOT_ALLOCATED;
	sbi->s_rsv_window_head.rsv_alloc_hit = 0;
	sbi->s_rsv_window_head.rsv_goal_size = 0;
	ext2_rsv_window_add(sb, &sbi->s_rsv_window_head);

	err = percpu_counter_init(&sbi->s_freeblocks_counter,
				ext2_count_free_blocks(sb), GFP_KERNEL);
	if (!err) {
		err = percpu_counter_init(&sbi->s_freeinodes_counter,
				ext2_count_free_inodes(sb), GFP_KERNEL);
	}
	if (!err) {
		err = percpu_counter_init(&sbi->s_dirs_counter,
				ext2_count_dirs(sb), GFP_KERNEL);
	}
	if (err) {
 		ext2_msg(sb, KERN_ERR, ""error: insufficient memory"");
 		goto failed_mount3;
 	}
 	/*
 	 * set up enough so that it can read an inode
 	 */
	sb->s_op = &ext2_sops;
	sb->s_export_op = &ext2_export_ops;
	sb->s_xattr = ext2_xattr_handlers;

#ifdef CONFIG_QUOTA
	sb->dq_op = &dquot_operations;
	sb->s_qcop = &dquot_quotactl_ops;
	sb->s_quota_types = QTYPE_MASK_USR | QTYPE_MASK_GRP;
#endif

	root = ext2_iget(sb, EXT2_ROOT_INO);
	if (IS_ERR(root)) {
		ret = PTR_ERR(root);
		goto failed_mount3;
	}
	if (!S_ISDIR(root->i_mode) || !root->i_blocks || !root->i_size) {
		iput(root);
		ext2_msg(sb, KERN_ERR, ""error: corrupt root inode, run e2fsck"");
		goto failed_mount3;
	}

	sb->s_root = d_make_root(root);
	if (!sb->s_root) {
		ext2_msg(sb, KERN_ERR, ""error: get root inode failed"");
		ret = -ENOMEM;
		goto failed_mount3;
	}
	if (EXT2_HAS_COMPAT_FEATURE(sb, EXT3_FEATURE_COMPAT_HAS_JOURNAL))
		ext2_msg(sb, KERN_WARNING,
			""warning: mounting ext3 filesystem as ext2"");
	if (ext2_setup_super (sb, es, sb->s_flags & MS_RDONLY))
		sb->s_flags |= MS_RDONLY;
	ext2_write_super(sb);
	return 0;

cantfind_ext2:
	if (!silent)
		ext2_msg(sb, KERN_ERR,
			""error: can't find an ext2 filesystem on dev %s."",
 			sb->s_id);
 	goto failed_mount;
 failed_mount3:
 	percpu_counter_destroy(&sbi->s_freeblocks_counter);
 	percpu_counter_destroy(&sbi->s_freeinodes_counter);
 	percpu_counter_destroy(&sbi->s_dirs_counter);
failed_mount2:
	for (i = 0; i < db_count; i++)
		brelse(sbi->s_group_desc[i]);
failed_mount_group_desc:
	kfree(sbi->s_group_desc);
	kfree(sbi->s_debts);
failed_mount:
	brelse(bh);
failed_sbi:
	sb->s_fs_info = NULL;
	kfree(sbi->s_blockgroup_lock);
	kfree(sbi);
failed:
	return ret;
}
",C,"
#ifdef CONFIG_EXT2_FS_XATTR
	sbi->s_mb_cache = ext2_xattr_create_cache();
	if (!sbi->s_mb_cache) {
		ext2_msg(sb, KERN_ERR, ""Failed to create an mb_cache"");
		goto failed_mount3;
	}
#endif
	if (sbi->s_mb_cache)
		ext2_xattr_destroy_cache(sbi->s_mb_cache);
",,,"@@ -131,7 +131,10 @@ static void ext2_put_super (struct super_block * sb)
 
 	dquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);
 
-	ext2_xattr_put_super(sb);
+	if (sbi->s_mb_cache) {
+		ext2_xattr_destroy_cache(sbi->s_mb_cache);
+		sbi->s_mb_cache = NULL;
+	}
 	if (!(sb->s_flags & MS_RDONLY)) {
 		struct ext2_super_block *es = sbi->s_es;
 
@@ -1104,6 +1107,14 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)
 		ext2_msg(sb, KERN_ERR, ""error: insufficient memory"");
 		goto failed_mount3;
 	}
+
+#ifdef CONFIG_EXT2_FS_XATTR
+	sbi->s_mb_cache = ext2_xattr_create_cache();
+	if (!sbi->s_mb_cache) {
+		ext2_msg(sb, KERN_ERR, ""Failed to create an mb_cache"");
+		goto failed_mount3;
+	}
+#endif
 	/*
 	 * set up enough so that it can read an inode
 	 */
@@ -1149,6 +1160,8 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)
 			sb->s_id);
 	goto failed_mount;
 failed_mount3:
+	if (sbi->s_mb_cache)
+		ext2_xattr_destroy_cache(sbi->s_mb_cache);
 	percpu_counter_destroy(&sbi->s_freeblocks_counter);
 	percpu_counter_destroy(&sbi->s_freeinodes_counter);
 	percpu_counter_destroy(&sbi->s_dirs_counter);
@@ -1555,28 +1568,24 @@ MODULE_ALIAS_FS(""ext2"");
 
 static int __init init_ext2_fs(void)
 {
-	int err = init_ext2_xattr();
-	if (err)
-		return err;
+	int err;
+
 	err = init_inodecache();
 	if (err)
-		goto out1;
+		return err;
         err = register_filesystem(&ext2_fs_type);
 	if (err)
 		goto out;
 	return 0;
 out:
 	destroy_inodecache();
-out1:
-	exit_ext2_xattr();
 	return err;
 }
 
 static void __exit exit_ext2_fs(void)
 {
 	unregister_filesystem(&ext2_fs_type);
 	destroy_inodecache();
-	exit_ext2_xattr();
 }
 
 MODULE_AUTHOR(""Remy Card and others"");",linux,be0726d33cb8f411945884664924bed3cb8c70ee,82939d7999dfc1f1998c4b1c12e2f19edbdff272,1,"static int ext2_fill_super(struct super_block *sb, void *data, int silent)
{
	struct buffer_head * bh;
	struct ext2_sb_info * sbi;
	struct ext2_super_block * es;
	struct inode *root;
	unsigned long block;
	unsigned long sb_block = get_sb_block(&data);
	unsigned long logic_sb_block;
	unsigned long offset = 0;
	unsigned long def_mount_opts;
	long ret = -EINVAL;
	int blocksize = BLOCK_SIZE;
	int db_count;
	int i, j;
	__le32 features;
	int err;

	err = -ENOMEM;
	sbi = kzalloc(sizeof(*sbi), GFP_KERNEL);
	if (!sbi)
		goto failed;

	sbi->s_blockgroup_lock =
		kzalloc(sizeof(struct blockgroup_lock), GFP_KERNEL);
	if (!sbi->s_blockgroup_lock) {
		kfree(sbi);
		goto failed;
	}
	sb->s_fs_info = sbi;
	sbi->s_sb_block = sb_block;

	spin_lock_init(&sbi->s_lock);

	/*
	 * See what the current blocksize for the device is, and
	 * use that as the blocksize.  Otherwise (or if the blocksize
	 * is smaller than the default) use the default.
	 * This is important for devices that have a hardware
	 * sectorsize that is larger than the default.
	 */
	blocksize = sb_min_blocksize(sb, BLOCK_SIZE);
	if (!blocksize) {
		ext2_msg(sb, KERN_ERR, ""error: unable to set blocksize"");
		goto failed_sbi;
	}

	/*
	 * If the superblock doesn't start on a hardware sector boundary,
	 * calculate the offset.  
	 */
	if (blocksize != BLOCK_SIZE) {
		logic_sb_block = (sb_block*BLOCK_SIZE) / blocksize;
		offset = (sb_block*BLOCK_SIZE) % blocksize;
	} else {
		logic_sb_block = sb_block;
	}

	if (!(bh = sb_bread(sb, logic_sb_block))) {
		ext2_msg(sb, KERN_ERR, ""error: unable to read superblock"");
		goto failed_sbi;
	}
	/*
	 * Note: s_es must be initialized as soon as possible because
	 *       some ext2 macro-instructions depend on its value
	 */
	es = (struct ext2_super_block *) (((char *)bh->b_data) + offset);
	sbi->s_es = es;
	sb->s_magic = le16_to_cpu(es->s_magic);

	if (sb->s_magic != EXT2_SUPER_MAGIC)
		goto cantfind_ext2;

	/* Set defaults before we parse the mount options */
	def_mount_opts = le32_to_cpu(es->s_default_mount_opts);
	if (def_mount_opts & EXT2_DEFM_DEBUG)
		set_opt(sbi->s_mount_opt, DEBUG);
	if (def_mount_opts & EXT2_DEFM_BSDGROUPS)
		set_opt(sbi->s_mount_opt, GRPID);
	if (def_mount_opts & EXT2_DEFM_UID16)
		set_opt(sbi->s_mount_opt, NO_UID32);
#ifdef CONFIG_EXT2_FS_XATTR
	if (def_mount_opts & EXT2_DEFM_XATTR_USER)
		set_opt(sbi->s_mount_opt, XATTR_USER);
#endif
#ifdef CONFIG_EXT2_FS_POSIX_ACL
	if (def_mount_opts & EXT2_DEFM_ACL)
		set_opt(sbi->s_mount_opt, POSIX_ACL);
#endif
	
	if (le16_to_cpu(sbi->s_es->s_errors) == EXT2_ERRORS_PANIC)
		set_opt(sbi->s_mount_opt, ERRORS_PANIC);
	else if (le16_to_cpu(sbi->s_es->s_errors) == EXT2_ERRORS_CONTINUE)
		set_opt(sbi->s_mount_opt, ERRORS_CONT);
	else
		set_opt(sbi->s_mount_opt, ERRORS_RO);

	sbi->s_resuid = make_kuid(&init_user_ns, le16_to_cpu(es->s_def_resuid));
	sbi->s_resgid = make_kgid(&init_user_ns, le16_to_cpu(es->s_def_resgid));
	
	set_opt(sbi->s_mount_opt, RESERVATION);

	if (!parse_options((char *) data, sb))
		goto failed_mount;

	sb->s_flags = (sb->s_flags & ~MS_POSIXACL) |
		((EXT2_SB(sb)->s_mount_opt & EXT2_MOUNT_POSIX_ACL) ?
		 MS_POSIXACL : 0);
	sb->s_iflags |= SB_I_CGROUPWB;

	if (le32_to_cpu(es->s_rev_level) == EXT2_GOOD_OLD_REV &&
	    (EXT2_HAS_COMPAT_FEATURE(sb, ~0U) ||
	     EXT2_HAS_RO_COMPAT_FEATURE(sb, ~0U) ||
	     EXT2_HAS_INCOMPAT_FEATURE(sb, ~0U)))
		ext2_msg(sb, KERN_WARNING,
			""warning: feature flags set on rev 0 fs, ""
			""running e2fsck is recommended"");
	/*
	 * Check feature flags regardless of the revision level, since we
	 * previously didn't change the revision level when setting the flags,
	 * so there is a chance incompat flags are set on a rev 0 filesystem.
	 */
	features = EXT2_HAS_INCOMPAT_FEATURE(sb, ~EXT2_FEATURE_INCOMPAT_SUPP);
	if (features) {
		ext2_msg(sb, KERN_ERR,	""error: couldn't mount because of ""
		       ""unsupported optional features (%x)"",
			le32_to_cpu(features));
		goto failed_mount;
	}
	if (!(sb->s_flags & MS_RDONLY) &&
	    (features = EXT2_HAS_RO_COMPAT_FEATURE(sb, ~EXT2_FEATURE_RO_COMPAT_SUPP))){
		ext2_msg(sb, KERN_ERR, ""error: couldn't mount RDWR because of ""
		       ""unsupported optional features (%x)"",
		       le32_to_cpu(features));
		goto failed_mount;
	}

	blocksize = BLOCK_SIZE << le32_to_cpu(sbi->s_es->s_log_block_size);

	if (sbi->s_mount_opt & EXT2_MOUNT_DAX) {
		if (blocksize != PAGE_SIZE) {
			ext2_msg(sb, KERN_ERR,
					""error: unsupported blocksize for dax"");
			goto failed_mount;
		}
		if (!sb->s_bdev->bd_disk->fops->direct_access) {
			ext2_msg(sb, KERN_ERR,
					""error: device does not support dax"");
			goto failed_mount;
		}
	}

	/* If the blocksize doesn't match, re-read the thing.. */
	if (sb->s_blocksize != blocksize) {
		brelse(bh);

		if (!sb_set_blocksize(sb, blocksize)) {
			ext2_msg(sb, KERN_ERR,
				""error: bad blocksize %d"", blocksize);
			goto failed_sbi;
		}

		logic_sb_block = (sb_block*BLOCK_SIZE) / blocksize;
		offset = (sb_block*BLOCK_SIZE) % blocksize;
		bh = sb_bread(sb, logic_sb_block);
		if(!bh) {
			ext2_msg(sb, KERN_ERR, ""error: couldn't read""
				""superblock on 2nd try"");
			goto failed_sbi;
		}
		es = (struct ext2_super_block *) (((char *)bh->b_data) + offset);
		sbi->s_es = es;
		if (es->s_magic != cpu_to_le16(EXT2_SUPER_MAGIC)) {
			ext2_msg(sb, KERN_ERR, ""error: magic mismatch"");
			goto failed_mount;
		}
	}

	sb->s_maxbytes = ext2_max_size(sb->s_blocksize_bits);
	sb->s_max_links = EXT2_LINK_MAX;

	if (le32_to_cpu(es->s_rev_level) == EXT2_GOOD_OLD_REV) {
		sbi->s_inode_size = EXT2_GOOD_OLD_INODE_SIZE;
		sbi->s_first_ino = EXT2_GOOD_OLD_FIRST_INO;
	} else {
		sbi->s_inode_size = le16_to_cpu(es->s_inode_size);
		sbi->s_first_ino = le32_to_cpu(es->s_first_ino);
		if ((sbi->s_inode_size < EXT2_GOOD_OLD_INODE_SIZE) ||
		    !is_power_of_2(sbi->s_inode_size) ||
		    (sbi->s_inode_size > blocksize)) {
			ext2_msg(sb, KERN_ERR,
				""error: unsupported inode size: %d"",
				sbi->s_inode_size);
			goto failed_mount;
		}
	}

	sbi->s_frag_size = EXT2_MIN_FRAG_SIZE <<
				   le32_to_cpu(es->s_log_frag_size);
	if (sbi->s_frag_size == 0)
		goto cantfind_ext2;
	sbi->s_frags_per_block = sb->s_blocksize / sbi->s_frag_size;

	sbi->s_blocks_per_group = le32_to_cpu(es->s_blocks_per_group);
	sbi->s_frags_per_group = le32_to_cpu(es->s_frags_per_group);
	sbi->s_inodes_per_group = le32_to_cpu(es->s_inodes_per_group);

	if (EXT2_INODE_SIZE(sb) == 0)
		goto cantfind_ext2;
	sbi->s_inodes_per_block = sb->s_blocksize / EXT2_INODE_SIZE(sb);
	if (sbi->s_inodes_per_block == 0 || sbi->s_inodes_per_group == 0)
		goto cantfind_ext2;
	sbi->s_itb_per_group = sbi->s_inodes_per_group /
					sbi->s_inodes_per_block;
	sbi->s_desc_per_block = sb->s_blocksize /
					sizeof (struct ext2_group_desc);
	sbi->s_sbh = bh;
	sbi->s_mount_state = le16_to_cpu(es->s_state);
	sbi->s_addr_per_block_bits =
		ilog2 (EXT2_ADDR_PER_BLOCK(sb));
	sbi->s_desc_per_block_bits =
		ilog2 (EXT2_DESC_PER_BLOCK(sb));

	if (sb->s_magic != EXT2_SUPER_MAGIC)
		goto cantfind_ext2;

	if (sb->s_blocksize != bh->b_size) {
		if (!silent)
			ext2_msg(sb, KERN_ERR, ""error: unsupported blocksize"");
		goto failed_mount;
	}

	if (sb->s_blocksize != sbi->s_frag_size) {
		ext2_msg(sb, KERN_ERR,
			""error: fragsize %lu != blocksize %lu""
			""(not supported yet)"",
			sbi->s_frag_size, sb->s_blocksize);
		goto failed_mount;
	}

	if (sbi->s_blocks_per_group > sb->s_blocksize * 8) {
		ext2_msg(sb, KERN_ERR,
			""error: #blocks per group too big: %lu"",
			sbi->s_blocks_per_group);
		goto failed_mount;
	}
	if (sbi->s_frags_per_group > sb->s_blocksize * 8) {
		ext2_msg(sb, KERN_ERR,
			""error: #fragments per group too big: %lu"",
			sbi->s_frags_per_group);
		goto failed_mount;
	}
	if (sbi->s_inodes_per_group > sb->s_blocksize * 8) {
		ext2_msg(sb, KERN_ERR,
			""error: #inodes per group too big: %lu"",
			sbi->s_inodes_per_group);
		goto failed_mount;
	}

	if (EXT2_BLOCKS_PER_GROUP(sb) == 0)
		goto cantfind_ext2;
 	sbi->s_groups_count = ((le32_to_cpu(es->s_blocks_count) -
 				le32_to_cpu(es->s_first_data_block) - 1)
 					/ EXT2_BLOCKS_PER_GROUP(sb)) + 1;
	db_count = (sbi->s_groups_count + EXT2_DESC_PER_BLOCK(sb) - 1) /
		   EXT2_DESC_PER_BLOCK(sb);
	sbi->s_group_desc = kmalloc (db_count * sizeof (struct buffer_head *), GFP_KERNEL);
	if (sbi->s_group_desc == NULL) {
		ext2_msg(sb, KERN_ERR, ""error: not enough memory"");
		goto failed_mount;
	}
	bgl_lock_init(sbi->s_blockgroup_lock);
	sbi->s_debts = kcalloc(sbi->s_groups_count, sizeof(*sbi->s_debts), GFP_KERNEL);
	if (!sbi->s_debts) {
		ext2_msg(sb, KERN_ERR, ""error: not enough memory"");
		goto failed_mount_group_desc;
	}
	for (i = 0; i < db_count; i++) {
		block = descriptor_loc(sb, logic_sb_block, i);
		sbi->s_group_desc[i] = sb_bread(sb, block);
		if (!sbi->s_group_desc[i]) {
			for (j = 0; j < i; j++)
				brelse (sbi->s_group_desc[j]);
			ext2_msg(sb, KERN_ERR,
				""error: unable to read group descriptors"");
			goto failed_mount_group_desc;
		}
	}
	if (!ext2_check_descriptors (sb)) {
		ext2_msg(sb, KERN_ERR, ""group descriptors corrupted"");
		goto failed_mount2;
	}
	sbi->s_gdb_count = db_count;
	get_random_bytes(&sbi->s_next_generation, sizeof(u32));
	spin_lock_init(&sbi->s_next_gen_lock);

	/* per fileystem reservation list head & lock */
	spin_lock_init(&sbi->s_rsv_window_lock);
	sbi->s_rsv_window_root = RB_ROOT;
	/*
	 * Add a single, static dummy reservation to the start of the
	 * reservation window list --- it gives us a placeholder for
	 * append-at-start-of-list which makes the allocation logic
	 * _much_ simpler.
	 */
	sbi->s_rsv_window_head.rsv_start = EXT2_RESERVE_WINDOW_NOT_ALLOCATED;
	sbi->s_rsv_window_head.rsv_end = EXT2_RESERVE_WINDOW_NOT_ALLOCATED;
	sbi->s_rsv_window_head.rsv_alloc_hit = 0;
	sbi->s_rsv_window_head.rsv_goal_size = 0;
	ext2_rsv_window_add(sb, &sbi->s_rsv_window_head);

	err = percpu_counter_init(&sbi->s_freeblocks_counter,
				ext2_count_free_blocks(sb), GFP_KERNEL);
	if (!err) {
		err = percpu_counter_init(&sbi->s_freeinodes_counter,
				ext2_count_free_inodes(sb), GFP_KERNEL);
	}
	if (!err) {
		err = percpu_counter_init(&sbi->s_dirs_counter,
				ext2_count_dirs(sb), GFP_KERNEL);
	}
	if (err) {
 		ext2_msg(sb, KERN_ERR, ""error: insufficient memory"");
 		goto failed_mount3;
 	}
//fix_flaw_line_below:
//
//fix_flaw_line_below:
//#ifdef CONFIG_EXT2_FS_XATTR
//fix_flaw_line_below:
//	sbi->s_mb_cache = ext2_xattr_create_cache();
//fix_flaw_line_below:
//	if (!sbi->s_mb_cache) {
//fix_flaw_line_below:
//		ext2_msg(sb, KERN_ERR, ""Failed to create an mb_cache"");
//fix_flaw_line_below:
//		goto failed_mount3;
//fix_flaw_line_below:
//	}
//fix_flaw_line_below:
//#endif
 	/*
 	 * set up enough so that it can read an inode
 	 */
	sb->s_op = &ext2_sops;
	sb->s_export_op = &ext2_export_ops;
	sb->s_xattr = ext2_xattr_handlers;

#ifdef CONFIG_QUOTA
	sb->dq_op = &dquot_operations;
	sb->s_qcop = &dquot_quotactl_ops;
	sb->s_quota_types = QTYPE_MASK_USR | QTYPE_MASK_GRP;
#endif

	root = ext2_iget(sb, EXT2_ROOT_INO);
	if (IS_ERR(root)) {
		ret = PTR_ERR(root);
		goto failed_mount3;
	}
	if (!S_ISDIR(root->i_mode) || !root->i_blocks || !root->i_size) {
		iput(root);
		ext2_msg(sb, KERN_ERR, ""error: corrupt root inode, run e2fsck"");
		goto failed_mount3;
	}

	sb->s_root = d_make_root(root);
	if (!sb->s_root) {
		ext2_msg(sb, KERN_ERR, ""error: get root inode failed"");
		ret = -ENOMEM;
		goto failed_mount3;
	}
	if (EXT2_HAS_COMPAT_FEATURE(sb, EXT3_FEATURE_COMPAT_HAS_JOURNAL))
		ext2_msg(sb, KERN_WARNING,
			""warning: mounting ext3 filesystem as ext2"");
	if (ext2_setup_super (sb, es, sb->s_flags & MS_RDONLY))
		sb->s_flags |= MS_RDONLY;
	ext2_write_super(sb);
	return 0;

cantfind_ext2:
	if (!silent)
		ext2_msg(sb, KERN_ERR,
			""error: can't find an ext2 filesystem on dev %s."",
 			sb->s_id);
 	goto failed_mount;
 failed_mount3:
//fix_flaw_line_below:
//	if (sbi->s_mb_cache)
//fix_flaw_line_below:
//		ext2_xattr_destroy_cache(sbi->s_mb_cache);
 	percpu_counter_destroy(&sbi->s_freeblocks_counter);
 	percpu_counter_destroy(&sbi->s_freeinodes_counter);
 	percpu_counter_destroy(&sbi->s_dirs_counter);
failed_mount2:
	for (i = 0; i < db_count; i++)
		brelse(sbi->s_group_desc[i]);
failed_mount_group_desc:
	kfree(sbi->s_group_desc);
	kfree(sbi->s_debts);
failed_mount:
	brelse(bh);
failed_sbi:
	sb->s_fs_info = NULL;
	kfree(sbi->s_blockgroup_lock);
	kfree(sbi);
failed:
	return ret;
}
"
5410,183146,,Local,Not required,Partial,CVE-2015-8952,https://www.cvedetails.com/cve/CVE-2015-8952/,CWE-19,Low,,,,2016-10-16,2.1,"The mbcache feature in the ext2 and ext4 filesystem implementations in the Linux kernel before 4.6 mishandles xattr block caching, which allows local users to cause a denial of service (soft lockup) via filesystem operations in environments that use many attributes, as demonstrated by Ceph and Samba.",2018-03-15,DoS ,4,https://github.com/torvalds/linux/commit/be0726d33cb8f411945884664924bed3cb8c70ee,be0726d33cb8f411945884664924bed3cb8c70ee,"ext2: convert to mbcache2

The conversion is generally straightforward. We convert filesystem from
a global cache to per-fs one. Similarly to ext4 the tricky part is that
xattr block corresponding to found mbcache entry can get freed before we
get buffer lock for that block. So we have to check whether the entry is
still valid after getting the buffer lock.

Signed-off-by: Jan Kara <jack@suse.cz>
Signed-off-by: Theodore Ts'o <tytso@mit.edu>",1,fs/ext2/super.c,"{""sha"": ""f98ce7e60a0f84f71743e0dfe069c7e96c6bd648"", ""filename"": ""fs/ext2/ext2.h"", ""status"": ""modified"", ""additions"": 3, ""deletions"": 0, ""changes"": 3, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/ext2.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -61,6 +61,8 @@ struct ext2_block_alloc_info {\n #define rsv_start rsv_window._rsv_start\n #define rsv_end rsv_window._rsv_end\n \n+struct mb2_cache;\n+\n /*\n  * second extended-fs super-block data in memory\n  */\n@@ -111,6 +113,7 @@ struct ext2_sb_info {\n \t * of the mount options.\n \t */\n \tspinlock_t s_lock;\n+\tstruct mb2_cache *s_mb_cache;\n };\n \n static inline spinlock_t *""}<_**next**_>{""sha"": ""b78caf25f746220ce635a3bd946bedeaf7e3e750"", ""filename"": ""fs/ext2/super.c"", ""status"": ""modified"", ""additions"": 17, ""deletions"": 8, ""changes"": 25, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/super.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -131,7 +131,10 @@ static void ext2_put_super (struct super_block * sb)\n \n \tdquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);\n \n-\text2_xattr_put_super(sb);\n+\tif (sbi->s_mb_cache) {\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n+\t\tsbi->s_mb_cache = NULL;\n+\t}\n \tif (!(sb->s_flags & MS_RDONLY)) {\n \t\tstruct ext2_super_block *es = sbi->s_es;\n \n@@ -1104,6 +1107,14 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\text2_msg(sb, KERN_ERR, \""error: insufficient memory\"");\n \t\tgoto failed_mount3;\n \t}\n+\n+#ifdef CONFIG_EXT2_FS_XATTR\n+\tsbi->s_mb_cache = ext2_xattr_create_cache();\n+\tif (!sbi->s_mb_cache) {\n+\t\text2_msg(sb, KERN_ERR, \""Failed to create an mb_cache\"");\n+\t\tgoto failed_mount3;\n+\t}\n+#endif\n \t/*\n \t * set up enough so that it can read an inode\n \t */\n@@ -1149,6 +1160,8 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\t\tsb->s_id);\n \tgoto failed_mount;\n failed_mount3:\n+\tif (sbi->s_mb_cache)\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n \tpercpu_counter_destroy(&sbi->s_freeblocks_counter);\n \tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n \tpercpu_counter_destroy(&sbi->s_dirs_counter);\n@@ -1555,28 +1568,24 @@ MODULE_ALIAS_FS(\""ext2\"");\n \n static int __init init_ext2_fs(void)\n {\n-\tint err = init_ext2_xattr();\n-\tif (err)\n-\t\treturn err;\n+\tint err;\n+\n \terr = init_inodecache();\n \tif (err)\n-\t\tgoto out1;\n+\t\treturn err;\n         err = register_filesystem(&ext2_fs_type);\n \tif (err)\n \t\tgoto out;\n \treturn 0;\n out:\n \tdestroy_inodecache();\n-out1:\n-\texit_ext2_xattr();\n \treturn err;\n }\n \n static void __exit exit_ext2_fs(void)\n {\n \tunregister_filesystem(&ext2_fs_type);\n \tdestroy_inodecache();\n-\texit_ext2_xattr();\n }\n \n MODULE_AUTHOR(\""Remy Card and others\"");""}<_**next**_>{""sha"": ""7162b4869bc32515800d8ffc06ac3835ea241c8b"", ""filename"": ""fs/ext2/xattr.c"", ""status"": ""modified"", ""additions"": 67, ""deletions"": 76, ""changes"": 143, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -56,7 +56,7 @@\n #include <linux/buffer_head.h>\n #include <linux/init.h>\n #include <linux/slab.h>\n-#include <linux/mbcache.h>\n+#include <linux/mbcache2.h>\n #include <linux/quotaops.h>\n #include <linux/rwsem.h>\n #include <linux/security.h>\n@@ -90,14 +90,12 @@\n static int ext2_xattr_set2(struct inode *, struct buffer_head *,\n \t\t\t   struct ext2_xattr_header *);\n \n-static int ext2_xattr_cache_insert(struct buffer_head *);\n+static int ext2_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);\n static struct buffer_head *ext2_xattr_cache_find(struct inode *,\n \t\t\t\t\t\t struct ext2_xattr_header *);\n static void ext2_xattr_rehash(struct ext2_xattr_header *,\n \t\t\t      struct ext2_xattr_entry *);\n \n-static struct mb_cache *ext2_xattr_cache;\n-\n static const struct xattr_handler *ext2_xattr_handler_map[] = {\n \t[EXT2_XATTR_INDEX_USER]\t\t     = &ext2_xattr_user_handler,\n #ifdef CONFIG_EXT2_FS_POSIX_ACL\n@@ -152,6 +150,7 @@ ext2_xattr_get(struct inode *inode, int name_index, const char *name,\n \tsize_t name_len, size;\n \tchar *end;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""name=%d.%s, buffer=%p, buffer_size=%ld\"",\n \t\t  name_index, name, buffer, (long)buffer_size);\n@@ -196,7 +195,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t\t\tgoto found;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \terror = -ENODATA;\n \tgoto cleanup;\n@@ -209,7 +208,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)\n \t\tgoto bad_block;\n \n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \tif (buffer) {\n \t\terror = -ERANGE;\n@@ -247,6 +246,7 @@ ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)\n \tchar *end;\n \tsize_t rest = buffer_size;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""buffer=%p, buffer_size=%ld\"",\n \t\t  buffer, (long)buffer_size);\n@@ -281,7 +281,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_list\"",\n \t\t\tgoto bad_block;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \n \t/* list the attribute names */\n@@ -483,22 +483,23 @@ bad_block:\t\text2_error(sb, \""ext2_xattr_set\"",\n \t/* Here we know that we can set the new attribute. */\n \n \tif (header) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/* assert(header == HDR(bh)); */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,\n-\t\t\t\t\tbh->b_blocknr);\n \t\tlock_buffer(bh);\n \t\tif (header->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(header->h_hash);\n+\n \t\t\tea_bdebug(bh, \""modifying in-place\"");\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect modified block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,\n+\t\t\t\t\t\t     hash, bh->b_blocknr);\n+\n \t\t\t/* keep the buffer locked while modifying it. */\n \t\t} else {\n \t\t\tint offset;\n \n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tunlock_buffer(bh);\n \t\t\tea_bdebug(bh, \""cloning\"");\n \t\t\theader = kmalloc(bh->b_size, GFP_KERNEL);\n@@ -626,6 +627,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \tstruct super_block *sb = inode->i_sb;\n \tstruct buffer_head *new_bh = NULL;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;\n \n \tif (header) {\n \t\tnew_bh = ext2_xattr_cache_find(inode, header);\n@@ -653,7 +655,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\t   don't need to change the reference count. */\n \t\t\tnew_bh = old_bh;\n \t\t\tget_bh(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t} else {\n \t\t\t/* We need to allocate a new block */\n \t\t\text2_fsblk_t goal = ext2_group_first_block_no(sb,\n@@ -674,7 +676,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\tmemcpy(new_bh->b_data, header, new_bh->b_size);\n \t\t\tset_buffer_uptodate(new_bh);\n \t\t\tunlock_buffer(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t\t\n \t\t\text2_xattr_update_super_block(sb);\n \t\t}\n@@ -707,19 +709,21 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \n \terror = 0;\n \tif (old_bh && old_bh != new_bh) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/*\n \t\t * If there was an old block and we are no longer using it,\n \t\t * release the old block.\n \t\t */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,\n-\t\t\t\t\told_bh->b_blocknr);\n \t\tlock_buffer(old_bh);\n \t\tif (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);\n+\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect freed block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(ext2_mb_cache,\n+\t\t\t\t\t\t     hash, old_bh->b_blocknr);\n \t\t\t/* Free the old block. */\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n \t\t\tea_bdebug(old_bh, \""freeing\"");\n \t\t\text2_free_blocks(inode, old_bh->b_blocknr, 1);\n \t\t\tmark_inode_dirty(inode);\n@@ -730,8 +734,6 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t} else {\n \t\t\t/* Decrement the refcount only. */\n \t\t\tle32_add_cpu(&HDR(old_bh)->h_refcount, -1);\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tdquot_free_block_nodirty(inode, 1);\n \t\t\tmark_inode_dirty(inode);\n \t\t\tmark_buffer_dirty(old_bh);\n@@ -757,7 +759,6 @@ void\n ext2_xattr_delete_inode(struct inode *inode)\n {\n \tstruct buffer_head *bh = NULL;\n-\tstruct mb_cache_entry *ce;\n \n \tdown_write(&EXT2_I(inode)->xattr_sem);\n \tif (!EXT2_I(inode)->i_file_acl)\n@@ -777,19 +778,22 @@ ext2_xattr_delete_inode(struct inode *inode)\n \t\t\tEXT2_I(inode)->i_file_acl);\n \t\tgoto cleanup;\n \t}\n-\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);\n \tlock_buffer(bh);\n \tif (HDR(bh)->h_refcount == cpu_to_le32(1)) {\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_free(ce);\n+\t\t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n+\n+\t\t/*\n+\t\t * This must happen under buffer lock for ext2_xattr_set2() to\n+\t\t * reliably detect freed block\n+\t\t */\n+\t\tmb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,\n+\t\t\t\t\t     hash, bh->b_blocknr);\n \t\text2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);\n \t\tget_bh(bh);\n \t\tbforget(bh);\n \t\tunlock_buffer(bh);\n \t} else {\n \t\tle32_add_cpu(&HDR(bh)->h_refcount, -1);\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_release(ce);\n \t\tea_bdebug(bh, \""refcount now=%d\"",\n \t\t\tle32_to_cpu(HDR(bh)->h_refcount));\n \t\tunlock_buffer(bh);\n@@ -805,18 +809,6 @@ ext2_xattr_delete_inode(struct inode *inode)\n \tup_write(&EXT2_I(inode)->xattr_sem);\n }\n \n-/*\n- * ext2_xattr_put_super()\n- *\n- * This is called when a file system is unmounted.\n- */\n-void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-\tmb_cache_shrink(sb->s_bdev);\n-}\n-\n-\n /*\n  * ext2_xattr_cache_insert()\n  *\n@@ -826,28 +818,20 @@ ext2_xattr_put_super(struct super_block *sb)\n  * Returns 0, or a negative error number on failure.\n  */\n static int\n-ext2_xattr_cache_insert(struct buffer_head *bh)\n+ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)\n {\n \t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n-\tstruct mb_cache_entry *ce;\n \tint error;\n \n-\tce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);\n-\tif (!ce)\n-\t\treturn -ENOMEM;\n-\terror = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);\n+\terror = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);\n \tif (error) {\n-\t\tmb_cache_entry_free(ce);\n \t\tif (error == -EBUSY) {\n \t\t\tea_bdebug(bh, \""already in cache (%d cache entries)\"",\n \t\t\t\tatomic_read(&ext2_xattr_cache->c_entry_count));\n \t\t\terror = 0;\n \t\t}\n-\t} else {\n-\t\tea_bdebug(bh, \""inserting [%x] (%d cache entries)\"", (int)hash,\n-\t\t\t  atomic_read(&ext2_xattr_cache->c_entry_count));\n-\t\tmb_cache_entry_release(ce);\n-\t}\n+\t} else\n+\t\tea_bdebug(bh, \""inserting [%x]\"", (int)hash);\n \treturn error;\n }\n \n@@ -903,31 +887,39 @@ static struct buffer_head *\n ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n {\n \t__u32 hash = le32_to_cpu(header->h_hash);\n-\tstruct mb_cache_entry *ce;\n+\tstruct mb2_cache_entry *ce;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tif (!header->h_hash)\n \t\treturn NULL;  /* never share */\n \tea_idebug(inode, \""looking for cached blocks [%x]\"", (int)hash);\n again:\n-\tce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,\n-\t\t\t\t       hash);\n+\tce = mb2_cache_entry_find_first(ext2_mb_cache, hash);\n \twhile (ce) {\n \t\tstruct buffer_head *bh;\n \n-\t\tif (IS_ERR(ce)) {\n-\t\t\tif (PTR_ERR(ce) == -EAGAIN)\n-\t\t\t\tgoto again;\n-\t\t\tbreak;\n-\t\t}\n-\n \t\tbh = sb_bread(inode->i_sb, ce->e_block);\n \t\tif (!bh) {\n \t\t\text2_error(inode->i_sb, \""ext2_xattr_cache_find\"",\n \t\t\t\t\""inode %ld: block %ld read error\"",\n \t\t\t\tinode->i_ino, (unsigned long) ce->e_block);\n \t\t} else {\n \t\t\tlock_buffer(bh);\n-\t\t\tif (le32_to_cpu(HDR(bh)->h_refcount) >\n+\t\t\t/*\n+\t\t\t * We have to be careful about races with freeing or\n+\t\t\t * rehashing of xattr block. Once we hold buffer lock\n+\t\t\t * xattr block's state is stable so we can check\n+\t\t\t * whether the block got freed / rehashed or not.\n+\t\t\t * Since we unhash mbcache entry under buffer lock when\n+\t\t\t * freeing / rehashing xattr block, checking whether\n+\t\t\t * entry is still hashed is reliable.\n+\t\t\t */\n+\t\t\tif (hlist_bl_unhashed(&ce->e_hash_list)) {\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n+\t\t\t\tunlock_buffer(bh);\n+\t\t\t\tbrelse(bh);\n+\t\t\t\tgoto again;\n+\t\t\t} else if (le32_to_cpu(HDR(bh)->h_refcount) >\n \t\t\t\t   EXT2_XATTR_REFCOUNT_MAX) {\n \t\t\t\tea_idebug(inode, \""block %ld refcount %d>%d\"",\n \t\t\t\t\t  (unsigned long) ce->e_block,\n@@ -936,13 +928,14 @@ ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n \t\t\t} else if (!ext2_xattr_cmp(header, HDR(bh))) {\n \t\t\t\tea_bdebug(bh, \""b_count=%d\"",\n \t\t\t\t\t  atomic_read(&(bh->b_count)));\n-\t\t\t\tmb_cache_entry_release(ce);\n+\t\t\t\tmb2_cache_entry_touch(ext2_mb_cache, ce);\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n \t\t\t\treturn bh;\n \t\t\t}\n \t\t\tunlock_buffer(bh);\n \t\t\tbrelse(bh);\n \t\t}\n-\t\tce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);\n+\t\tce = mb2_cache_entry_find_next(ext2_mb_cache, ce);\n \t}\n \treturn NULL;\n }\n@@ -1015,17 +1008,15 @@ static void ext2_xattr_rehash(struct ext2_xattr_header *header,\n \n #undef BLOCK_HASH_SHIFT\n \n-int __init\n-init_ext2_xattr(void)\n+#define HASH_BUCKET_BITS 10\n+\n+struct mb2_cache *ext2_xattr_create_cache(void)\n {\n-\text2_xattr_cache = mb_cache_create(\""ext2_xattr\"", 6);\n-\tif (!ext2_xattr_cache)\n-\t\treturn -ENOMEM;\n-\treturn 0;\n+\treturn mb2_cache_create(HASH_BUCKET_BITS);\n }\n \n-void\n-exit_ext2_xattr(void)\n+void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n-\tmb_cache_destroy(ext2_xattr_cache);\n+\tif (cache)\n+\t\tmb2_cache_destroy(cache);\n }""}<_**next**_>{""sha"": ""6ea38aa9563a00649bf25544eed131bbe8b1d88d"", ""filename"": ""fs/ext2/xattr.h"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 16, ""changes"": 21, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -53,6 +53,8 @@ struct ext2_xattr_entry {\n #define EXT2_XATTR_SIZE(size) \\\n \t(((size) + EXT2_XATTR_ROUND) & ~EXT2_XATTR_ROUND)\n \n+struct mb2_cache;\n+\n # ifdef CONFIG_EXT2_FS_XATTR\n \n extern const struct xattr_handler ext2_xattr_user_handler;\n@@ -65,10 +67,9 @@ extern int ext2_xattr_get(struct inode *, int, const char *, void *, size_t);\n extern int ext2_xattr_set(struct inode *, int, const char *, const void *, size_t, int);\n \n extern void ext2_xattr_delete_inode(struct inode *);\n-extern void ext2_xattr_put_super(struct super_block *);\n \n-extern int init_ext2_xattr(void);\n-extern void exit_ext2_xattr(void);\n+extern struct mb2_cache *ext2_xattr_create_cache(void);\n+extern void ext2_xattr_destroy_cache(struct mb2_cache *cache);\n \n extern const struct xattr_handler *ext2_xattr_handlers[];\n \n@@ -93,19 +94,7 @@ ext2_xattr_delete_inode(struct inode *inode)\n {\n }\n \n-static inline void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-}\n-\n-static inline int\n-init_ext2_xattr(void)\n-{\n-\treturn 0;\n-}\n-\n-static inline void\n-exit_ext2_xattr(void)\n+static inline void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n }\n ""}","static void ext2_put_super (struct super_block * sb)
{
	int db_count;
	int i;
	struct ext2_sb_info *sbi = EXT2_SB(sb);
 
 	dquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);
 
	if (sbi->s_mb_cache) {
		ext2_xattr_destroy_cache(sbi->s_mb_cache);
		sbi->s_mb_cache = NULL;
	}
 	if (!(sb->s_flags & MS_RDONLY)) {
 		struct ext2_super_block *es = sbi->s_es;
 
		spin_lock(&sbi->s_lock);
		es->s_state = cpu_to_le16(sbi->s_mount_state);
		spin_unlock(&sbi->s_lock);
		ext2_sync_super(sb, es, 1);
	}
	db_count = sbi->s_gdb_count;
	for (i = 0; i < db_count; i++)
		if (sbi->s_group_desc[i])
			brelse (sbi->s_group_desc[i]);
	kfree(sbi->s_group_desc);
	kfree(sbi->s_debts);
	percpu_counter_destroy(&sbi->s_freeblocks_counter);
	percpu_counter_destroy(&sbi->s_freeinodes_counter);
	percpu_counter_destroy(&sbi->s_dirs_counter);
	brelse (sbi->s_sbh);
	sb->s_fs_info = NULL;
	kfree(sbi->s_blockgroup_lock);
	kfree(sbi);
}
","static void ext2_put_super (struct super_block * sb)
{
	int db_count;
	int i;
	struct ext2_sb_info *sbi = EXT2_SB(sb);
 
 	dquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);
 
	ext2_xattr_put_super(sb);
 	if (!(sb->s_flags & MS_RDONLY)) {
 		struct ext2_super_block *es = sbi->s_es;
 
		spin_lock(&sbi->s_lock);
		es->s_state = cpu_to_le16(sbi->s_mount_state);
		spin_unlock(&sbi->s_lock);
		ext2_sync_super(sb, es, 1);
	}
	db_count = sbi->s_gdb_count;
	for (i = 0; i < db_count; i++)
		if (sbi->s_group_desc[i])
			brelse (sbi->s_group_desc[i]);
	kfree(sbi->s_group_desc);
	kfree(sbi->s_debts);
	percpu_counter_destroy(&sbi->s_freeblocks_counter);
	percpu_counter_destroy(&sbi->s_freeinodes_counter);
	percpu_counter_destroy(&sbi->s_dirs_counter);
	brelse (sbi->s_sbh);
	sb->s_fs_info = NULL;
	kfree(sbi->s_blockgroup_lock);
	kfree(sbi);
}
",C,"	if (sbi->s_mb_cache) {
		ext2_xattr_destroy_cache(sbi->s_mb_cache);
		sbi->s_mb_cache = NULL;
	}
","	ext2_xattr_put_super(sb);
",,"@@ -131,7 +131,10 @@ static void ext2_put_super (struct super_block * sb)
 
 	dquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);
 
-	ext2_xattr_put_super(sb);
+	if (sbi->s_mb_cache) {
+		ext2_xattr_destroy_cache(sbi->s_mb_cache);
+		sbi->s_mb_cache = NULL;
+	}
 	if (!(sb->s_flags & MS_RDONLY)) {
 		struct ext2_super_block *es = sbi->s_es;
 
@@ -1104,6 +1107,14 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)
 		ext2_msg(sb, KERN_ERR, ""error: insufficient memory"");
 		goto failed_mount3;
 	}
+
+#ifdef CONFIG_EXT2_FS_XATTR
+	sbi->s_mb_cache = ext2_xattr_create_cache();
+	if (!sbi->s_mb_cache) {
+		ext2_msg(sb, KERN_ERR, ""Failed to create an mb_cache"");
+		goto failed_mount3;
+	}
+#endif
 	/*
 	 * set up enough so that it can read an inode
 	 */
@@ -1149,6 +1160,8 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)
 			sb->s_id);
 	goto failed_mount;
 failed_mount3:
+	if (sbi->s_mb_cache)
+		ext2_xattr_destroy_cache(sbi->s_mb_cache);
 	percpu_counter_destroy(&sbi->s_freeblocks_counter);
 	percpu_counter_destroy(&sbi->s_freeinodes_counter);
 	percpu_counter_destroy(&sbi->s_dirs_counter);
@@ -1555,28 +1568,24 @@ MODULE_ALIAS_FS(""ext2"");
 
 static int __init init_ext2_fs(void)
 {
-	int err = init_ext2_xattr();
-	if (err)
-		return err;
+	int err;
+
 	err = init_inodecache();
 	if (err)
-		goto out1;
+		return err;
         err = register_filesystem(&ext2_fs_type);
 	if (err)
 		goto out;
 	return 0;
 out:
 	destroy_inodecache();
-out1:
-	exit_ext2_xattr();
 	return err;
 }
 
 static void __exit exit_ext2_fs(void)
 {
 	unregister_filesystem(&ext2_fs_type);
 	destroy_inodecache();
-	exit_ext2_xattr();
 }
 
 MODULE_AUTHOR(""Remy Card and others"");",linux,be0726d33cb8f411945884664924bed3cb8c70ee,82939d7999dfc1f1998c4b1c12e2f19edbdff272,1,"static void ext2_put_super (struct super_block * sb)
{
	int db_count;
	int i;
	struct ext2_sb_info *sbi = EXT2_SB(sb);
 
 	dquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);
 
//flaw_line_below:
	ext2_xattr_put_super(sb);
//fix_flaw_line_below:
//	if (sbi->s_mb_cache) {
//fix_flaw_line_below:
//		ext2_xattr_destroy_cache(sbi->s_mb_cache);
//fix_flaw_line_below:
//		sbi->s_mb_cache = NULL;
//fix_flaw_line_below:
//	}
 	if (!(sb->s_flags & MS_RDONLY)) {
 		struct ext2_super_block *es = sbi->s_es;
 
		spin_lock(&sbi->s_lock);
		es->s_state = cpu_to_le16(sbi->s_mount_state);
		spin_unlock(&sbi->s_lock);
		ext2_sync_super(sb, es, 1);
	}
	db_count = sbi->s_gdb_count;
	for (i = 0; i < db_count; i++)
		if (sbi->s_group_desc[i])
			brelse (sbi->s_group_desc[i]);
	kfree(sbi->s_group_desc);
	kfree(sbi->s_debts);
	percpu_counter_destroy(&sbi->s_freeblocks_counter);
	percpu_counter_destroy(&sbi->s_freeinodes_counter);
	percpu_counter_destroy(&sbi->s_dirs_counter);
	brelse (sbi->s_sbh);
	sb->s_fs_info = NULL;
	kfree(sbi->s_blockgroup_lock);
	kfree(sbi);
}
"
5411,183147,,Local,Not required,Partial,CVE-2015-8952,https://www.cvedetails.com/cve/CVE-2015-8952/,CWE-19,Low,,,,2016-10-16,2.1,"The mbcache feature in the ext2 and ext4 filesystem implementations in the Linux kernel before 4.6 mishandles xattr block caching, which allows local users to cause a denial of service (soft lockup) via filesystem operations in environments that use many attributes, as demonstrated by Ceph and Samba.",2018-03-15,DoS ,3,https://github.com/torvalds/linux/commit/be0726d33cb8f411945884664924bed3cb8c70ee,be0726d33cb8f411945884664924bed3cb8c70ee,"ext2: convert to mbcache2

The conversion is generally straightforward. We convert filesystem from
a global cache to per-fs one. Similarly to ext4 the tricky part is that
xattr block corresponding to found mbcache entry can get freed before we
get buffer lock for that block. So we have to check whether the entry is
still valid after getting the buffer lock.

Signed-off-by: Jan Kara <jack@suse.cz>
Signed-off-by: Theodore Ts'o <tytso@mit.edu>",6,fs/ext2/super.c,"{""sha"": ""f98ce7e60a0f84f71743e0dfe069c7e96c6bd648"", ""filename"": ""fs/ext2/ext2.h"", ""status"": ""modified"", ""additions"": 3, ""deletions"": 0, ""changes"": 3, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/ext2.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -61,6 +61,8 @@ struct ext2_block_alloc_info {\n #define rsv_start rsv_window._rsv_start\n #define rsv_end rsv_window._rsv_end\n \n+struct mb2_cache;\n+\n /*\n  * second extended-fs super-block data in memory\n  */\n@@ -111,6 +113,7 @@ struct ext2_sb_info {\n \t * of the mount options.\n \t */\n \tspinlock_t s_lock;\n+\tstruct mb2_cache *s_mb_cache;\n };\n \n static inline spinlock_t *""}<_**next**_>{""sha"": ""b78caf25f746220ce635a3bd946bedeaf7e3e750"", ""filename"": ""fs/ext2/super.c"", ""status"": ""modified"", ""additions"": 17, ""deletions"": 8, ""changes"": 25, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/super.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -131,7 +131,10 @@ static void ext2_put_super (struct super_block * sb)\n \n \tdquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);\n \n-\text2_xattr_put_super(sb);\n+\tif (sbi->s_mb_cache) {\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n+\t\tsbi->s_mb_cache = NULL;\n+\t}\n \tif (!(sb->s_flags & MS_RDONLY)) {\n \t\tstruct ext2_super_block *es = sbi->s_es;\n \n@@ -1104,6 +1107,14 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\text2_msg(sb, KERN_ERR, \""error: insufficient memory\"");\n \t\tgoto failed_mount3;\n \t}\n+\n+#ifdef CONFIG_EXT2_FS_XATTR\n+\tsbi->s_mb_cache = ext2_xattr_create_cache();\n+\tif (!sbi->s_mb_cache) {\n+\t\text2_msg(sb, KERN_ERR, \""Failed to create an mb_cache\"");\n+\t\tgoto failed_mount3;\n+\t}\n+#endif\n \t/*\n \t * set up enough so that it can read an inode\n \t */\n@@ -1149,6 +1160,8 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\t\tsb->s_id);\n \tgoto failed_mount;\n failed_mount3:\n+\tif (sbi->s_mb_cache)\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n \tpercpu_counter_destroy(&sbi->s_freeblocks_counter);\n \tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n \tpercpu_counter_destroy(&sbi->s_dirs_counter);\n@@ -1555,28 +1568,24 @@ MODULE_ALIAS_FS(\""ext2\"");\n \n static int __init init_ext2_fs(void)\n {\n-\tint err = init_ext2_xattr();\n-\tif (err)\n-\t\treturn err;\n+\tint err;\n+\n \terr = init_inodecache();\n \tif (err)\n-\t\tgoto out1;\n+\t\treturn err;\n         err = register_filesystem(&ext2_fs_type);\n \tif (err)\n \t\tgoto out;\n \treturn 0;\n out:\n \tdestroy_inodecache();\n-out1:\n-\texit_ext2_xattr();\n \treturn err;\n }\n \n static void __exit exit_ext2_fs(void)\n {\n \tunregister_filesystem(&ext2_fs_type);\n \tdestroy_inodecache();\n-\texit_ext2_xattr();\n }\n \n MODULE_AUTHOR(\""Remy Card and others\"");""}<_**next**_>{""sha"": ""7162b4869bc32515800d8ffc06ac3835ea241c8b"", ""filename"": ""fs/ext2/xattr.c"", ""status"": ""modified"", ""additions"": 67, ""deletions"": 76, ""changes"": 143, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -56,7 +56,7 @@\n #include <linux/buffer_head.h>\n #include <linux/init.h>\n #include <linux/slab.h>\n-#include <linux/mbcache.h>\n+#include <linux/mbcache2.h>\n #include <linux/quotaops.h>\n #include <linux/rwsem.h>\n #include <linux/security.h>\n@@ -90,14 +90,12 @@\n static int ext2_xattr_set2(struct inode *, struct buffer_head *,\n \t\t\t   struct ext2_xattr_header *);\n \n-static int ext2_xattr_cache_insert(struct buffer_head *);\n+static int ext2_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);\n static struct buffer_head *ext2_xattr_cache_find(struct inode *,\n \t\t\t\t\t\t struct ext2_xattr_header *);\n static void ext2_xattr_rehash(struct ext2_xattr_header *,\n \t\t\t      struct ext2_xattr_entry *);\n \n-static struct mb_cache *ext2_xattr_cache;\n-\n static const struct xattr_handler *ext2_xattr_handler_map[] = {\n \t[EXT2_XATTR_INDEX_USER]\t\t     = &ext2_xattr_user_handler,\n #ifdef CONFIG_EXT2_FS_POSIX_ACL\n@@ -152,6 +150,7 @@ ext2_xattr_get(struct inode *inode, int name_index, const char *name,\n \tsize_t name_len, size;\n \tchar *end;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""name=%d.%s, buffer=%p, buffer_size=%ld\"",\n \t\t  name_index, name, buffer, (long)buffer_size);\n@@ -196,7 +195,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t\t\tgoto found;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \terror = -ENODATA;\n \tgoto cleanup;\n@@ -209,7 +208,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)\n \t\tgoto bad_block;\n \n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \tif (buffer) {\n \t\terror = -ERANGE;\n@@ -247,6 +246,7 @@ ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)\n \tchar *end;\n \tsize_t rest = buffer_size;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""buffer=%p, buffer_size=%ld\"",\n \t\t  buffer, (long)buffer_size);\n@@ -281,7 +281,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_list\"",\n \t\t\tgoto bad_block;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \n \t/* list the attribute names */\n@@ -483,22 +483,23 @@ bad_block:\t\text2_error(sb, \""ext2_xattr_set\"",\n \t/* Here we know that we can set the new attribute. */\n \n \tif (header) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/* assert(header == HDR(bh)); */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,\n-\t\t\t\t\tbh->b_blocknr);\n \t\tlock_buffer(bh);\n \t\tif (header->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(header->h_hash);\n+\n \t\t\tea_bdebug(bh, \""modifying in-place\"");\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect modified block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,\n+\t\t\t\t\t\t     hash, bh->b_blocknr);\n+\n \t\t\t/* keep the buffer locked while modifying it. */\n \t\t} else {\n \t\t\tint offset;\n \n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tunlock_buffer(bh);\n \t\t\tea_bdebug(bh, \""cloning\"");\n \t\t\theader = kmalloc(bh->b_size, GFP_KERNEL);\n@@ -626,6 +627,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \tstruct super_block *sb = inode->i_sb;\n \tstruct buffer_head *new_bh = NULL;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;\n \n \tif (header) {\n \t\tnew_bh = ext2_xattr_cache_find(inode, header);\n@@ -653,7 +655,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\t   don't need to change the reference count. */\n \t\t\tnew_bh = old_bh;\n \t\t\tget_bh(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t} else {\n \t\t\t/* We need to allocate a new block */\n \t\t\text2_fsblk_t goal = ext2_group_first_block_no(sb,\n@@ -674,7 +676,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\tmemcpy(new_bh->b_data, header, new_bh->b_size);\n \t\t\tset_buffer_uptodate(new_bh);\n \t\t\tunlock_buffer(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t\t\n \t\t\text2_xattr_update_super_block(sb);\n \t\t}\n@@ -707,19 +709,21 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \n \terror = 0;\n \tif (old_bh && old_bh != new_bh) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/*\n \t\t * If there was an old block and we are no longer using it,\n \t\t * release the old block.\n \t\t */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,\n-\t\t\t\t\told_bh->b_blocknr);\n \t\tlock_buffer(old_bh);\n \t\tif (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);\n+\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect freed block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(ext2_mb_cache,\n+\t\t\t\t\t\t     hash, old_bh->b_blocknr);\n \t\t\t/* Free the old block. */\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n \t\t\tea_bdebug(old_bh, \""freeing\"");\n \t\t\text2_free_blocks(inode, old_bh->b_blocknr, 1);\n \t\t\tmark_inode_dirty(inode);\n@@ -730,8 +734,6 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t} else {\n \t\t\t/* Decrement the refcount only. */\n \t\t\tle32_add_cpu(&HDR(old_bh)->h_refcount, -1);\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tdquot_free_block_nodirty(inode, 1);\n \t\t\tmark_inode_dirty(inode);\n \t\t\tmark_buffer_dirty(old_bh);\n@@ -757,7 +759,6 @@ void\n ext2_xattr_delete_inode(struct inode *inode)\n {\n \tstruct buffer_head *bh = NULL;\n-\tstruct mb_cache_entry *ce;\n \n \tdown_write(&EXT2_I(inode)->xattr_sem);\n \tif (!EXT2_I(inode)->i_file_acl)\n@@ -777,19 +778,22 @@ ext2_xattr_delete_inode(struct inode *inode)\n \t\t\tEXT2_I(inode)->i_file_acl);\n \t\tgoto cleanup;\n \t}\n-\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);\n \tlock_buffer(bh);\n \tif (HDR(bh)->h_refcount == cpu_to_le32(1)) {\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_free(ce);\n+\t\t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n+\n+\t\t/*\n+\t\t * This must happen under buffer lock for ext2_xattr_set2() to\n+\t\t * reliably detect freed block\n+\t\t */\n+\t\tmb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,\n+\t\t\t\t\t     hash, bh->b_blocknr);\n \t\text2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);\n \t\tget_bh(bh);\n \t\tbforget(bh);\n \t\tunlock_buffer(bh);\n \t} else {\n \t\tle32_add_cpu(&HDR(bh)->h_refcount, -1);\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_release(ce);\n \t\tea_bdebug(bh, \""refcount now=%d\"",\n \t\t\tle32_to_cpu(HDR(bh)->h_refcount));\n \t\tunlock_buffer(bh);\n@@ -805,18 +809,6 @@ ext2_xattr_delete_inode(struct inode *inode)\n \tup_write(&EXT2_I(inode)->xattr_sem);\n }\n \n-/*\n- * ext2_xattr_put_super()\n- *\n- * This is called when a file system is unmounted.\n- */\n-void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-\tmb_cache_shrink(sb->s_bdev);\n-}\n-\n-\n /*\n  * ext2_xattr_cache_insert()\n  *\n@@ -826,28 +818,20 @@ ext2_xattr_put_super(struct super_block *sb)\n  * Returns 0, or a negative error number on failure.\n  */\n static int\n-ext2_xattr_cache_insert(struct buffer_head *bh)\n+ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)\n {\n \t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n-\tstruct mb_cache_entry *ce;\n \tint error;\n \n-\tce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);\n-\tif (!ce)\n-\t\treturn -ENOMEM;\n-\terror = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);\n+\terror = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);\n \tif (error) {\n-\t\tmb_cache_entry_free(ce);\n \t\tif (error == -EBUSY) {\n \t\t\tea_bdebug(bh, \""already in cache (%d cache entries)\"",\n \t\t\t\tatomic_read(&ext2_xattr_cache->c_entry_count));\n \t\t\terror = 0;\n \t\t}\n-\t} else {\n-\t\tea_bdebug(bh, \""inserting [%x] (%d cache entries)\"", (int)hash,\n-\t\t\t  atomic_read(&ext2_xattr_cache->c_entry_count));\n-\t\tmb_cache_entry_release(ce);\n-\t}\n+\t} else\n+\t\tea_bdebug(bh, \""inserting [%x]\"", (int)hash);\n \treturn error;\n }\n \n@@ -903,31 +887,39 @@ static struct buffer_head *\n ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n {\n \t__u32 hash = le32_to_cpu(header->h_hash);\n-\tstruct mb_cache_entry *ce;\n+\tstruct mb2_cache_entry *ce;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tif (!header->h_hash)\n \t\treturn NULL;  /* never share */\n \tea_idebug(inode, \""looking for cached blocks [%x]\"", (int)hash);\n again:\n-\tce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,\n-\t\t\t\t       hash);\n+\tce = mb2_cache_entry_find_first(ext2_mb_cache, hash);\n \twhile (ce) {\n \t\tstruct buffer_head *bh;\n \n-\t\tif (IS_ERR(ce)) {\n-\t\t\tif (PTR_ERR(ce) == -EAGAIN)\n-\t\t\t\tgoto again;\n-\t\t\tbreak;\n-\t\t}\n-\n \t\tbh = sb_bread(inode->i_sb, ce->e_block);\n \t\tif (!bh) {\n \t\t\text2_error(inode->i_sb, \""ext2_xattr_cache_find\"",\n \t\t\t\t\""inode %ld: block %ld read error\"",\n \t\t\t\tinode->i_ino, (unsigned long) ce->e_block);\n \t\t} else {\n \t\t\tlock_buffer(bh);\n-\t\t\tif (le32_to_cpu(HDR(bh)->h_refcount) >\n+\t\t\t/*\n+\t\t\t * We have to be careful about races with freeing or\n+\t\t\t * rehashing of xattr block. Once we hold buffer lock\n+\t\t\t * xattr block's state is stable so we can check\n+\t\t\t * whether the block got freed / rehashed or not.\n+\t\t\t * Since we unhash mbcache entry under buffer lock when\n+\t\t\t * freeing / rehashing xattr block, checking whether\n+\t\t\t * entry is still hashed is reliable.\n+\t\t\t */\n+\t\t\tif (hlist_bl_unhashed(&ce->e_hash_list)) {\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n+\t\t\t\tunlock_buffer(bh);\n+\t\t\t\tbrelse(bh);\n+\t\t\t\tgoto again;\n+\t\t\t} else if (le32_to_cpu(HDR(bh)->h_refcount) >\n \t\t\t\t   EXT2_XATTR_REFCOUNT_MAX) {\n \t\t\t\tea_idebug(inode, \""block %ld refcount %d>%d\"",\n \t\t\t\t\t  (unsigned long) ce->e_block,\n@@ -936,13 +928,14 @@ ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n \t\t\t} else if (!ext2_xattr_cmp(header, HDR(bh))) {\n \t\t\t\tea_bdebug(bh, \""b_count=%d\"",\n \t\t\t\t\t  atomic_read(&(bh->b_count)));\n-\t\t\t\tmb_cache_entry_release(ce);\n+\t\t\t\tmb2_cache_entry_touch(ext2_mb_cache, ce);\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n \t\t\t\treturn bh;\n \t\t\t}\n \t\t\tunlock_buffer(bh);\n \t\t\tbrelse(bh);\n \t\t}\n-\t\tce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);\n+\t\tce = mb2_cache_entry_find_next(ext2_mb_cache, ce);\n \t}\n \treturn NULL;\n }\n@@ -1015,17 +1008,15 @@ static void ext2_xattr_rehash(struct ext2_xattr_header *header,\n \n #undef BLOCK_HASH_SHIFT\n \n-int __init\n-init_ext2_xattr(void)\n+#define HASH_BUCKET_BITS 10\n+\n+struct mb2_cache *ext2_xattr_create_cache(void)\n {\n-\text2_xattr_cache = mb_cache_create(\""ext2_xattr\"", 6);\n-\tif (!ext2_xattr_cache)\n-\t\treturn -ENOMEM;\n-\treturn 0;\n+\treturn mb2_cache_create(HASH_BUCKET_BITS);\n }\n \n-void\n-exit_ext2_xattr(void)\n+void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n-\tmb_cache_destroy(ext2_xattr_cache);\n+\tif (cache)\n+\t\tmb2_cache_destroy(cache);\n }""}<_**next**_>{""sha"": ""6ea38aa9563a00649bf25544eed131bbe8b1d88d"", ""filename"": ""fs/ext2/xattr.h"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 16, ""changes"": 21, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -53,6 +53,8 @@ struct ext2_xattr_entry {\n #define EXT2_XATTR_SIZE(size) \\\n \t(((size) + EXT2_XATTR_ROUND) & ~EXT2_XATTR_ROUND)\n \n+struct mb2_cache;\n+\n # ifdef CONFIG_EXT2_FS_XATTR\n \n extern const struct xattr_handler ext2_xattr_user_handler;\n@@ -65,10 +67,9 @@ extern int ext2_xattr_get(struct inode *, int, const char *, void *, size_t);\n extern int ext2_xattr_set(struct inode *, int, const char *, const void *, size_t, int);\n \n extern void ext2_xattr_delete_inode(struct inode *);\n-extern void ext2_xattr_put_super(struct super_block *);\n \n-extern int init_ext2_xattr(void);\n-extern void exit_ext2_xattr(void);\n+extern struct mb2_cache *ext2_xattr_create_cache(void);\n+extern void ext2_xattr_destroy_cache(struct mb2_cache *cache);\n \n extern const struct xattr_handler *ext2_xattr_handlers[];\n \n@@ -93,19 +94,7 @@ ext2_xattr_delete_inode(struct inode *inode)\n {\n }\n \n-static inline void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-}\n-\n-static inline int\n-init_ext2_xattr(void)\n-{\n-\treturn 0;\n-}\n-\n-static inline void\n-exit_ext2_xattr(void)\n+static inline void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n }\n ""}"," static int __init init_ext2_fs(void)
 {
	int err;

 	err = init_inodecache();
 	if (err)
		return err;
         err = register_filesystem(&ext2_fs_type);
 	if (err)
 		goto out;
 	return 0;
 out:
 	destroy_inodecache();
 	return err;
 }
"," static int __init init_ext2_fs(void)
 {
	int err = init_ext2_xattr();
	if (err)
		return err;
 	err = init_inodecache();
 	if (err)
		goto out1;
         err = register_filesystem(&ext2_fs_type);
 	if (err)
 		goto out;
 	return 0;
 out:
 	destroy_inodecache();
out1:
	exit_ext2_xattr();
 	return err;
 }
",C,"	int err;

		return err;
","	int err = init_ext2_xattr();
	if (err)
		return err;
		goto out1;
out1:
	exit_ext2_xattr();
",,"@@ -131,7 +131,10 @@ static void ext2_put_super (struct super_block * sb)
 
 	dquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);
 
-	ext2_xattr_put_super(sb);
+	if (sbi->s_mb_cache) {
+		ext2_xattr_destroy_cache(sbi->s_mb_cache);
+		sbi->s_mb_cache = NULL;
+	}
 	if (!(sb->s_flags & MS_RDONLY)) {
 		struct ext2_super_block *es = sbi->s_es;
 
@@ -1104,6 +1107,14 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)
 		ext2_msg(sb, KERN_ERR, ""error: insufficient memory"");
 		goto failed_mount3;
 	}
+
+#ifdef CONFIG_EXT2_FS_XATTR
+	sbi->s_mb_cache = ext2_xattr_create_cache();
+	if (!sbi->s_mb_cache) {
+		ext2_msg(sb, KERN_ERR, ""Failed to create an mb_cache"");
+		goto failed_mount3;
+	}
+#endif
 	/*
 	 * set up enough so that it can read an inode
 	 */
@@ -1149,6 +1160,8 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)
 			sb->s_id);
 	goto failed_mount;
 failed_mount3:
+	if (sbi->s_mb_cache)
+		ext2_xattr_destroy_cache(sbi->s_mb_cache);
 	percpu_counter_destroy(&sbi->s_freeblocks_counter);
 	percpu_counter_destroy(&sbi->s_freeinodes_counter);
 	percpu_counter_destroy(&sbi->s_dirs_counter);
@@ -1555,28 +1568,24 @@ MODULE_ALIAS_FS(""ext2"");
 
 static int __init init_ext2_fs(void)
 {
-	int err = init_ext2_xattr();
-	if (err)
-		return err;
+	int err;
+
 	err = init_inodecache();
 	if (err)
-		goto out1;
+		return err;
         err = register_filesystem(&ext2_fs_type);
 	if (err)
 		goto out;
 	return 0;
 out:
 	destroy_inodecache();
-out1:
-	exit_ext2_xattr();
 	return err;
 }
 
 static void __exit exit_ext2_fs(void)
 {
 	unregister_filesystem(&ext2_fs_type);
 	destroy_inodecache();
-	exit_ext2_xattr();
 }
 
 MODULE_AUTHOR(""Remy Card and others"");",linux,be0726d33cb8f411945884664924bed3cb8c70ee,82939d7999dfc1f1998c4b1c12e2f19edbdff272,1," static int __init init_ext2_fs(void)
 {
//flaw_line_below:
	int err = init_ext2_xattr();
//flaw_line_below:
	if (err)
//flaw_line_below:
		return err;
//fix_flaw_line_below:
//	int err;
//fix_flaw_line_below:
//
 	err = init_inodecache();
 	if (err)
//flaw_line_below:
		goto out1;
//fix_flaw_line_below:
//		return err;
         err = register_filesystem(&ext2_fs_type);
 	if (err)
 		goto out;
 	return 0;
 out:
 	destroy_inodecache();
//flaw_line_below:
out1:
//flaw_line_below:
	exit_ext2_xattr();
 	return err;
 }
"
5412,183148,,Local,Not required,Partial,CVE-2015-8952,https://www.cvedetails.com/cve/CVE-2015-8952/,CWE-19,Low,,,,2016-10-16,2.1,"The mbcache feature in the ext2 and ext4 filesystem implementations in the Linux kernel before 4.6 mishandles xattr block caching, which allows local users to cause a denial of service (soft lockup) via filesystem operations in environments that use many attributes, as demonstrated by Ceph and Samba.",2018-03-15,DoS ,3,https://github.com/torvalds/linux/commit/be0726d33cb8f411945884664924bed3cb8c70ee,be0726d33cb8f411945884664924bed3cb8c70ee,"ext2: convert to mbcache2

The conversion is generally straightforward. We convert filesystem from
a global cache to per-fs one. Similarly to ext4 the tricky part is that
xattr block corresponding to found mbcache entry can get freed before we
get buffer lock for that block. So we have to check whether the entry is
still valid after getting the buffer lock.

Signed-off-by: Jan Kara <jack@suse.cz>
Signed-off-by: Theodore Ts'o <tytso@mit.edu>",1,fs/ext2/xattr.c,"{""sha"": ""f98ce7e60a0f84f71743e0dfe069c7e96c6bd648"", ""filename"": ""fs/ext2/ext2.h"", ""status"": ""modified"", ""additions"": 3, ""deletions"": 0, ""changes"": 3, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/ext2.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -61,6 +61,8 @@ struct ext2_block_alloc_info {\n #define rsv_start rsv_window._rsv_start\n #define rsv_end rsv_window._rsv_end\n \n+struct mb2_cache;\n+\n /*\n  * second extended-fs super-block data in memory\n  */\n@@ -111,6 +113,7 @@ struct ext2_sb_info {\n \t * of the mount options.\n \t */\n \tspinlock_t s_lock;\n+\tstruct mb2_cache *s_mb_cache;\n };\n \n static inline spinlock_t *""}<_**next**_>{""sha"": ""b78caf25f746220ce635a3bd946bedeaf7e3e750"", ""filename"": ""fs/ext2/super.c"", ""status"": ""modified"", ""additions"": 17, ""deletions"": 8, ""changes"": 25, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/super.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -131,7 +131,10 @@ static void ext2_put_super (struct super_block * sb)\n \n \tdquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);\n \n-\text2_xattr_put_super(sb);\n+\tif (sbi->s_mb_cache) {\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n+\t\tsbi->s_mb_cache = NULL;\n+\t}\n \tif (!(sb->s_flags & MS_RDONLY)) {\n \t\tstruct ext2_super_block *es = sbi->s_es;\n \n@@ -1104,6 +1107,14 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\text2_msg(sb, KERN_ERR, \""error: insufficient memory\"");\n \t\tgoto failed_mount3;\n \t}\n+\n+#ifdef CONFIG_EXT2_FS_XATTR\n+\tsbi->s_mb_cache = ext2_xattr_create_cache();\n+\tif (!sbi->s_mb_cache) {\n+\t\text2_msg(sb, KERN_ERR, \""Failed to create an mb_cache\"");\n+\t\tgoto failed_mount3;\n+\t}\n+#endif\n \t/*\n \t * set up enough so that it can read an inode\n \t */\n@@ -1149,6 +1160,8 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\t\tsb->s_id);\n \tgoto failed_mount;\n failed_mount3:\n+\tif (sbi->s_mb_cache)\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n \tpercpu_counter_destroy(&sbi->s_freeblocks_counter);\n \tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n \tpercpu_counter_destroy(&sbi->s_dirs_counter);\n@@ -1555,28 +1568,24 @@ MODULE_ALIAS_FS(\""ext2\"");\n \n static int __init init_ext2_fs(void)\n {\n-\tint err = init_ext2_xattr();\n-\tif (err)\n-\t\treturn err;\n+\tint err;\n+\n \terr = init_inodecache();\n \tif (err)\n-\t\tgoto out1;\n+\t\treturn err;\n         err = register_filesystem(&ext2_fs_type);\n \tif (err)\n \t\tgoto out;\n \treturn 0;\n out:\n \tdestroy_inodecache();\n-out1:\n-\texit_ext2_xattr();\n \treturn err;\n }\n \n static void __exit exit_ext2_fs(void)\n {\n \tunregister_filesystem(&ext2_fs_type);\n \tdestroy_inodecache();\n-\texit_ext2_xattr();\n }\n \n MODULE_AUTHOR(\""Remy Card and others\"");""}<_**next**_>{""sha"": ""7162b4869bc32515800d8ffc06ac3835ea241c8b"", ""filename"": ""fs/ext2/xattr.c"", ""status"": ""modified"", ""additions"": 67, ""deletions"": 76, ""changes"": 143, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -56,7 +56,7 @@\n #include <linux/buffer_head.h>\n #include <linux/init.h>\n #include <linux/slab.h>\n-#include <linux/mbcache.h>\n+#include <linux/mbcache2.h>\n #include <linux/quotaops.h>\n #include <linux/rwsem.h>\n #include <linux/security.h>\n@@ -90,14 +90,12 @@\n static int ext2_xattr_set2(struct inode *, struct buffer_head *,\n \t\t\t   struct ext2_xattr_header *);\n \n-static int ext2_xattr_cache_insert(struct buffer_head *);\n+static int ext2_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);\n static struct buffer_head *ext2_xattr_cache_find(struct inode *,\n \t\t\t\t\t\t struct ext2_xattr_header *);\n static void ext2_xattr_rehash(struct ext2_xattr_header *,\n \t\t\t      struct ext2_xattr_entry *);\n \n-static struct mb_cache *ext2_xattr_cache;\n-\n static const struct xattr_handler *ext2_xattr_handler_map[] = {\n \t[EXT2_XATTR_INDEX_USER]\t\t     = &ext2_xattr_user_handler,\n #ifdef CONFIG_EXT2_FS_POSIX_ACL\n@@ -152,6 +150,7 @@ ext2_xattr_get(struct inode *inode, int name_index, const char *name,\n \tsize_t name_len, size;\n \tchar *end;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""name=%d.%s, buffer=%p, buffer_size=%ld\"",\n \t\t  name_index, name, buffer, (long)buffer_size);\n@@ -196,7 +195,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t\t\tgoto found;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \terror = -ENODATA;\n \tgoto cleanup;\n@@ -209,7 +208,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)\n \t\tgoto bad_block;\n \n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \tif (buffer) {\n \t\terror = -ERANGE;\n@@ -247,6 +246,7 @@ ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)\n \tchar *end;\n \tsize_t rest = buffer_size;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""buffer=%p, buffer_size=%ld\"",\n \t\t  buffer, (long)buffer_size);\n@@ -281,7 +281,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_list\"",\n \t\t\tgoto bad_block;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \n \t/* list the attribute names */\n@@ -483,22 +483,23 @@ bad_block:\t\text2_error(sb, \""ext2_xattr_set\"",\n \t/* Here we know that we can set the new attribute. */\n \n \tif (header) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/* assert(header == HDR(bh)); */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,\n-\t\t\t\t\tbh->b_blocknr);\n \t\tlock_buffer(bh);\n \t\tif (header->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(header->h_hash);\n+\n \t\t\tea_bdebug(bh, \""modifying in-place\"");\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect modified block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,\n+\t\t\t\t\t\t     hash, bh->b_blocknr);\n+\n \t\t\t/* keep the buffer locked while modifying it. */\n \t\t} else {\n \t\t\tint offset;\n \n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tunlock_buffer(bh);\n \t\t\tea_bdebug(bh, \""cloning\"");\n \t\t\theader = kmalloc(bh->b_size, GFP_KERNEL);\n@@ -626,6 +627,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \tstruct super_block *sb = inode->i_sb;\n \tstruct buffer_head *new_bh = NULL;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;\n \n \tif (header) {\n \t\tnew_bh = ext2_xattr_cache_find(inode, header);\n@@ -653,7 +655,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\t   don't need to change the reference count. */\n \t\t\tnew_bh = old_bh;\n \t\t\tget_bh(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t} else {\n \t\t\t/* We need to allocate a new block */\n \t\t\text2_fsblk_t goal = ext2_group_first_block_no(sb,\n@@ -674,7 +676,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\tmemcpy(new_bh->b_data, header, new_bh->b_size);\n \t\t\tset_buffer_uptodate(new_bh);\n \t\t\tunlock_buffer(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t\t\n \t\t\text2_xattr_update_super_block(sb);\n \t\t}\n@@ -707,19 +709,21 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \n \terror = 0;\n \tif (old_bh && old_bh != new_bh) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/*\n \t\t * If there was an old block and we are no longer using it,\n \t\t * release the old block.\n \t\t */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,\n-\t\t\t\t\told_bh->b_blocknr);\n \t\tlock_buffer(old_bh);\n \t\tif (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);\n+\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect freed block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(ext2_mb_cache,\n+\t\t\t\t\t\t     hash, old_bh->b_blocknr);\n \t\t\t/* Free the old block. */\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n \t\t\tea_bdebug(old_bh, \""freeing\"");\n \t\t\text2_free_blocks(inode, old_bh->b_blocknr, 1);\n \t\t\tmark_inode_dirty(inode);\n@@ -730,8 +734,6 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t} else {\n \t\t\t/* Decrement the refcount only. */\n \t\t\tle32_add_cpu(&HDR(old_bh)->h_refcount, -1);\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tdquot_free_block_nodirty(inode, 1);\n \t\t\tmark_inode_dirty(inode);\n \t\t\tmark_buffer_dirty(old_bh);\n@@ -757,7 +759,6 @@ void\n ext2_xattr_delete_inode(struct inode *inode)\n {\n \tstruct buffer_head *bh = NULL;\n-\tstruct mb_cache_entry *ce;\n \n \tdown_write(&EXT2_I(inode)->xattr_sem);\n \tif (!EXT2_I(inode)->i_file_acl)\n@@ -777,19 +778,22 @@ ext2_xattr_delete_inode(struct inode *inode)\n \t\t\tEXT2_I(inode)->i_file_acl);\n \t\tgoto cleanup;\n \t}\n-\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);\n \tlock_buffer(bh);\n \tif (HDR(bh)->h_refcount == cpu_to_le32(1)) {\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_free(ce);\n+\t\t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n+\n+\t\t/*\n+\t\t * This must happen under buffer lock for ext2_xattr_set2() to\n+\t\t * reliably detect freed block\n+\t\t */\n+\t\tmb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,\n+\t\t\t\t\t     hash, bh->b_blocknr);\n \t\text2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);\n \t\tget_bh(bh);\n \t\tbforget(bh);\n \t\tunlock_buffer(bh);\n \t} else {\n \t\tle32_add_cpu(&HDR(bh)->h_refcount, -1);\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_release(ce);\n \t\tea_bdebug(bh, \""refcount now=%d\"",\n \t\t\tle32_to_cpu(HDR(bh)->h_refcount));\n \t\tunlock_buffer(bh);\n@@ -805,18 +809,6 @@ ext2_xattr_delete_inode(struct inode *inode)\n \tup_write(&EXT2_I(inode)->xattr_sem);\n }\n \n-/*\n- * ext2_xattr_put_super()\n- *\n- * This is called when a file system is unmounted.\n- */\n-void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-\tmb_cache_shrink(sb->s_bdev);\n-}\n-\n-\n /*\n  * ext2_xattr_cache_insert()\n  *\n@@ -826,28 +818,20 @@ ext2_xattr_put_super(struct super_block *sb)\n  * Returns 0, or a negative error number on failure.\n  */\n static int\n-ext2_xattr_cache_insert(struct buffer_head *bh)\n+ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)\n {\n \t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n-\tstruct mb_cache_entry *ce;\n \tint error;\n \n-\tce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);\n-\tif (!ce)\n-\t\treturn -ENOMEM;\n-\terror = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);\n+\terror = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);\n \tif (error) {\n-\t\tmb_cache_entry_free(ce);\n \t\tif (error == -EBUSY) {\n \t\t\tea_bdebug(bh, \""already in cache (%d cache entries)\"",\n \t\t\t\tatomic_read(&ext2_xattr_cache->c_entry_count));\n \t\t\terror = 0;\n \t\t}\n-\t} else {\n-\t\tea_bdebug(bh, \""inserting [%x] (%d cache entries)\"", (int)hash,\n-\t\t\t  atomic_read(&ext2_xattr_cache->c_entry_count));\n-\t\tmb_cache_entry_release(ce);\n-\t}\n+\t} else\n+\t\tea_bdebug(bh, \""inserting [%x]\"", (int)hash);\n \treturn error;\n }\n \n@@ -903,31 +887,39 @@ static struct buffer_head *\n ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n {\n \t__u32 hash = le32_to_cpu(header->h_hash);\n-\tstruct mb_cache_entry *ce;\n+\tstruct mb2_cache_entry *ce;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tif (!header->h_hash)\n \t\treturn NULL;  /* never share */\n \tea_idebug(inode, \""looking for cached blocks [%x]\"", (int)hash);\n again:\n-\tce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,\n-\t\t\t\t       hash);\n+\tce = mb2_cache_entry_find_first(ext2_mb_cache, hash);\n \twhile (ce) {\n \t\tstruct buffer_head *bh;\n \n-\t\tif (IS_ERR(ce)) {\n-\t\t\tif (PTR_ERR(ce) == -EAGAIN)\n-\t\t\t\tgoto again;\n-\t\t\tbreak;\n-\t\t}\n-\n \t\tbh = sb_bread(inode->i_sb, ce->e_block);\n \t\tif (!bh) {\n \t\t\text2_error(inode->i_sb, \""ext2_xattr_cache_find\"",\n \t\t\t\t\""inode %ld: block %ld read error\"",\n \t\t\t\tinode->i_ino, (unsigned long) ce->e_block);\n \t\t} else {\n \t\t\tlock_buffer(bh);\n-\t\t\tif (le32_to_cpu(HDR(bh)->h_refcount) >\n+\t\t\t/*\n+\t\t\t * We have to be careful about races with freeing or\n+\t\t\t * rehashing of xattr block. Once we hold buffer lock\n+\t\t\t * xattr block's state is stable so we can check\n+\t\t\t * whether the block got freed / rehashed or not.\n+\t\t\t * Since we unhash mbcache entry under buffer lock when\n+\t\t\t * freeing / rehashing xattr block, checking whether\n+\t\t\t * entry is still hashed is reliable.\n+\t\t\t */\n+\t\t\tif (hlist_bl_unhashed(&ce->e_hash_list)) {\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n+\t\t\t\tunlock_buffer(bh);\n+\t\t\t\tbrelse(bh);\n+\t\t\t\tgoto again;\n+\t\t\t} else if (le32_to_cpu(HDR(bh)->h_refcount) >\n \t\t\t\t   EXT2_XATTR_REFCOUNT_MAX) {\n \t\t\t\tea_idebug(inode, \""block %ld refcount %d>%d\"",\n \t\t\t\t\t  (unsigned long) ce->e_block,\n@@ -936,13 +928,14 @@ ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n \t\t\t} else if (!ext2_xattr_cmp(header, HDR(bh))) {\n \t\t\t\tea_bdebug(bh, \""b_count=%d\"",\n \t\t\t\t\t  atomic_read(&(bh->b_count)));\n-\t\t\t\tmb_cache_entry_release(ce);\n+\t\t\t\tmb2_cache_entry_touch(ext2_mb_cache, ce);\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n \t\t\t\treturn bh;\n \t\t\t}\n \t\t\tunlock_buffer(bh);\n \t\t\tbrelse(bh);\n \t\t}\n-\t\tce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);\n+\t\tce = mb2_cache_entry_find_next(ext2_mb_cache, ce);\n \t}\n \treturn NULL;\n }\n@@ -1015,17 +1008,15 @@ static void ext2_xattr_rehash(struct ext2_xattr_header *header,\n \n #undef BLOCK_HASH_SHIFT\n \n-int __init\n-init_ext2_xattr(void)\n+#define HASH_BUCKET_BITS 10\n+\n+struct mb2_cache *ext2_xattr_create_cache(void)\n {\n-\text2_xattr_cache = mb_cache_create(\""ext2_xattr\"", 6);\n-\tif (!ext2_xattr_cache)\n-\t\treturn -ENOMEM;\n-\treturn 0;\n+\treturn mb2_cache_create(HASH_BUCKET_BITS);\n }\n \n-void\n-exit_ext2_xattr(void)\n+void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n-\tmb_cache_destroy(ext2_xattr_cache);\n+\tif (cache)\n+\t\tmb2_cache_destroy(cache);\n }""}<_**next**_>{""sha"": ""6ea38aa9563a00649bf25544eed131bbe8b1d88d"", ""filename"": ""fs/ext2/xattr.h"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 16, ""changes"": 21, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -53,6 +53,8 @@ struct ext2_xattr_entry {\n #define EXT2_XATTR_SIZE(size) \\\n \t(((size) + EXT2_XATTR_ROUND) & ~EXT2_XATTR_ROUND)\n \n+struct mb2_cache;\n+\n # ifdef CONFIG_EXT2_FS_XATTR\n \n extern const struct xattr_handler ext2_xattr_user_handler;\n@@ -65,10 +67,9 @@ extern int ext2_xattr_get(struct inode *, int, const char *, void *, size_t);\n extern int ext2_xattr_set(struct inode *, int, const char *, const void *, size_t, int);\n \n extern void ext2_xattr_delete_inode(struct inode *);\n-extern void ext2_xattr_put_super(struct super_block *);\n \n-extern int init_ext2_xattr(void);\n-extern void exit_ext2_xattr(void);\n+extern struct mb2_cache *ext2_xattr_create_cache(void);\n+extern void ext2_xattr_destroy_cache(struct mb2_cache *cache);\n \n extern const struct xattr_handler *ext2_xattr_handlers[];\n \n@@ -93,19 +94,7 @@ ext2_xattr_delete_inode(struct inode *inode)\n {\n }\n \n-static inline void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-}\n-\n-static inline int\n-init_ext2_xattr(void)\n-{\n-\treturn 0;\n-}\n-\n-static inline void\n-exit_ext2_xattr(void)\n+static inline void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n }\n ""}","exit_ext2_xattr(void)
void ext2_xattr_destroy_cache(struct mb2_cache *cache)
 {
	if (cache)
		mb2_cache_destroy(cache);
 }
","exit_ext2_xattr(void)
 {
	mb_cache_destroy(ext2_xattr_cache);
 }
",C,"void ext2_xattr_destroy_cache(struct mb2_cache *cache)
	if (cache)
		mb2_cache_destroy(cache);
","	mb_cache_destroy(ext2_xattr_cache);
",,"@@ -56,7 +56,7 @@
 #include <linux/buffer_head.h>
 #include <linux/init.h>
 #include <linux/slab.h>
-#include <linux/mbcache.h>
+#include <linux/mbcache2.h>
 #include <linux/quotaops.h>
 #include <linux/rwsem.h>
 #include <linux/security.h>
@@ -90,14 +90,12 @@
 static int ext2_xattr_set2(struct inode *, struct buffer_head *,
 			   struct ext2_xattr_header *);
 
-static int ext2_xattr_cache_insert(struct buffer_head *);
+static int ext2_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);
 static struct buffer_head *ext2_xattr_cache_find(struct inode *,
 						 struct ext2_xattr_header *);
 static void ext2_xattr_rehash(struct ext2_xattr_header *,
 			      struct ext2_xattr_entry *);
 
-static struct mb_cache *ext2_xattr_cache;
-
 static const struct xattr_handler *ext2_xattr_handler_map[] = {
 	[EXT2_XATTR_INDEX_USER]		     = &ext2_xattr_user_handler,
 #ifdef CONFIG_EXT2_FS_POSIX_ACL
@@ -152,6 +150,7 @@ ext2_xattr_get(struct inode *inode, int name_index, const char *name,
 	size_t name_len, size;
 	char *end;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	ea_idebug(inode, ""name=%d.%s, buffer=%p, buffer_size=%ld"",
 		  name_index, name, buffer, (long)buffer_size);
@@ -196,7 +195,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_get"",
 			goto found;
 		entry = next;
 	}
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 	error = -ENODATA;
 	goto cleanup;
@@ -209,7 +208,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_get"",
 	    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)
 		goto bad_block;
 
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 	if (buffer) {
 		error = -ERANGE;
@@ -247,6 +246,7 @@ ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)
 	char *end;
 	size_t rest = buffer_size;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	ea_idebug(inode, ""buffer=%p, buffer_size=%ld"",
 		  buffer, (long)buffer_size);
@@ -281,7 +281,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_list"",
 			goto bad_block;
 		entry = next;
 	}
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 
 	/* list the attribute names */
@@ -483,22 +483,23 @@ bad_block:		ext2_error(sb, ""ext2_xattr_set"",
 	/* Here we know that we can set the new attribute. */
 
 	if (header) {
-		struct mb_cache_entry *ce;
-
 		/* assert(header == HDR(bh)); */
-		ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,
-					bh->b_blocknr);
 		lock_buffer(bh);
 		if (header->h_refcount == cpu_to_le32(1)) {
+			__u32 hash = le32_to_cpu(header->h_hash);
+
 			ea_bdebug(bh, ""modifying in-place"");
-			if (ce)
-				mb_cache_entry_free(ce);
+			/*
+			 * This must happen under buffer lock for
+			 * ext2_xattr_set2() to reliably detect modified block
+			 */
+			mb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,
+						     hash, bh->b_blocknr);
+
 			/* keep the buffer locked while modifying it. */
 		} else {
 			int offset;
 
-			if (ce)
-				mb_cache_entry_release(ce);
 			unlock_buffer(bh);
 			ea_bdebug(bh, ""cloning"");
 			header = kmalloc(bh->b_size, GFP_KERNEL);
@@ -626,6 +627,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *new_bh = NULL;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;
 
 	if (header) {
 		new_bh = ext2_xattr_cache_find(inode, header);
@@ -653,7 +655,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 			   don't need to change the reference count. */
 			new_bh = old_bh;
 			get_bh(new_bh);
-			ext2_xattr_cache_insert(new_bh);
+			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
 		} else {
 			/* We need to allocate a new block */
 			ext2_fsblk_t goal = ext2_group_first_block_no(sb,
@@ -674,7 +676,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 			memcpy(new_bh->b_data, header, new_bh->b_size);
 			set_buffer_uptodate(new_bh);
 			unlock_buffer(new_bh);
-			ext2_xattr_cache_insert(new_bh);
+			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
 			
 			ext2_xattr_update_super_block(sb);
 		}
@@ -707,19 +709,21 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 
 	error = 0;
 	if (old_bh && old_bh != new_bh) {
-		struct mb_cache_entry *ce;
-
 		/*
 		 * If there was an old block and we are no longer using it,
 		 * release the old block.
 		 */
-		ce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,
-					old_bh->b_blocknr);
 		lock_buffer(old_bh);
 		if (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {
+			__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);
+
+			/*
+			 * This must happen under buffer lock for
+			 * ext2_xattr_set2() to reliably detect freed block
+			 */
+			mb2_cache_entry_delete_block(ext2_mb_cache,
+						     hash, old_bh->b_blocknr);
 			/* Free the old block. */
-			if (ce)
-				mb_cache_entry_free(ce);
 			ea_bdebug(old_bh, ""freeing"");
 			ext2_free_blocks(inode, old_bh->b_blocknr, 1);
 			mark_inode_dirty(inode);
@@ -730,8 +734,6 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 		} else {
 			/* Decrement the refcount only. */
 			le32_add_cpu(&HDR(old_bh)->h_refcount, -1);
-			if (ce)
-				mb_cache_entry_release(ce);
 			dquot_free_block_nodirty(inode, 1);
 			mark_inode_dirty(inode);
 			mark_buffer_dirty(old_bh);
@@ -757,7 +759,6 @@ void
 ext2_xattr_delete_inode(struct inode *inode)
 {
 	struct buffer_head *bh = NULL;
-	struct mb_cache_entry *ce;
 
 	down_write(&EXT2_I(inode)->xattr_sem);
 	if (!EXT2_I(inode)->i_file_acl)
@@ -777,19 +778,22 @@ ext2_xattr_delete_inode(struct inode *inode)
 			EXT2_I(inode)->i_file_acl);
 		goto cleanup;
 	}
-	ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);
 	lock_buffer(bh);
 	if (HDR(bh)->h_refcount == cpu_to_le32(1)) {
-		if (ce)
-			mb_cache_entry_free(ce);
+		__u32 hash = le32_to_cpu(HDR(bh)->h_hash);
+
+		/*
+		 * This must happen under buffer lock for ext2_xattr_set2() to
+		 * reliably detect freed block
+		 */
+		mb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,
+					     hash, bh->b_blocknr);
 		ext2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);
 		get_bh(bh);
 		bforget(bh);
 		unlock_buffer(bh);
 	} else {
 		le32_add_cpu(&HDR(bh)->h_refcount, -1);
-		if (ce)
-			mb_cache_entry_release(ce);
 		ea_bdebug(bh, ""refcount now=%d"",
 			le32_to_cpu(HDR(bh)->h_refcount));
 		unlock_buffer(bh);
@@ -805,18 +809,6 @@ ext2_xattr_delete_inode(struct inode *inode)
 	up_write(&EXT2_I(inode)->xattr_sem);
 }
 
-/*
- * ext2_xattr_put_super()
- *
- * This is called when a file system is unmounted.
- */
-void
-ext2_xattr_put_super(struct super_block *sb)
-{
-	mb_cache_shrink(sb->s_bdev);
-}
-
-
 /*
  * ext2_xattr_cache_insert()
  *
@@ -826,28 +818,20 @@ ext2_xattr_put_super(struct super_block *sb)
  * Returns 0, or a negative error number on failure.
  */
 static int
-ext2_xattr_cache_insert(struct buffer_head *bh)
+ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)
 {
 	__u32 hash = le32_to_cpu(HDR(bh)->h_hash);
-	struct mb_cache_entry *ce;
 	int error;
 
-	ce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);
-	if (!ce)
-		return -ENOMEM;
-	error = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);
+	error = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);
 	if (error) {
-		mb_cache_entry_free(ce);
 		if (error == -EBUSY) {
 			ea_bdebug(bh, ""already in cache (%d cache entries)"",
 				atomic_read(&ext2_xattr_cache->c_entry_count));
 			error = 0;
 		}
-	} else {
-		ea_bdebug(bh, ""inserting [%x] (%d cache entries)"", (int)hash,
-			  atomic_read(&ext2_xattr_cache->c_entry_count));
-		mb_cache_entry_release(ce);
-	}
+	} else
+		ea_bdebug(bh, ""inserting [%x]"", (int)hash);
 	return error;
 }
 
@@ -903,31 +887,39 @@ static struct buffer_head *
 ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)
 {
 	__u32 hash = le32_to_cpu(header->h_hash);
-	struct mb_cache_entry *ce;
+	struct mb2_cache_entry *ce;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	if (!header->h_hash)
 		return NULL;  /* never share */
 	ea_idebug(inode, ""looking for cached blocks [%x]"", (int)hash);
 again:
-	ce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,
-				       hash);
+	ce = mb2_cache_entry_find_first(ext2_mb_cache, hash);
 	while (ce) {
 		struct buffer_head *bh;
 
-		if (IS_ERR(ce)) {
-			if (PTR_ERR(ce) == -EAGAIN)
-				goto again;
-			break;
-		}
-
 		bh = sb_bread(inode->i_sb, ce->e_block);
 		if (!bh) {
 			ext2_error(inode->i_sb, ""ext2_xattr_cache_find"",
 				""inode %ld: block %ld read error"",
 				inode->i_ino, (unsigned long) ce->e_block);
 		} else {
 			lock_buffer(bh);
-			if (le32_to_cpu(HDR(bh)->h_refcount) >
+			/*
+			 * We have to be careful about races with freeing or
+			 * rehashing of xattr block. Once we hold buffer lock
+			 * xattr block's state is stable so we can check
+			 * whether the block got freed / rehashed or not.
+			 * Since we unhash mbcache entry under buffer lock when
+			 * freeing / rehashing xattr block, checking whether
+			 * entry is still hashed is reliable.
+			 */
+			if (hlist_bl_unhashed(&ce->e_hash_list)) {
+				mb2_cache_entry_put(ext2_mb_cache, ce);
+				unlock_buffer(bh);
+				brelse(bh);
+				goto again;
+			} else if (le32_to_cpu(HDR(bh)->h_refcount) >
 				   EXT2_XATTR_REFCOUNT_MAX) {
 				ea_idebug(inode, ""block %ld refcount %d>%d"",
 					  (unsigned long) ce->e_block,
@@ -936,13 +928,14 @@ ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)
 			} else if (!ext2_xattr_cmp(header, HDR(bh))) {
 				ea_bdebug(bh, ""b_count=%d"",
 					  atomic_read(&(bh->b_count)));
-				mb_cache_entry_release(ce);
+				mb2_cache_entry_touch(ext2_mb_cache, ce);
+				mb2_cache_entry_put(ext2_mb_cache, ce);
 				return bh;
 			}
 			unlock_buffer(bh);
 			brelse(bh);
 		}
-		ce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);
+		ce = mb2_cache_entry_find_next(ext2_mb_cache, ce);
 	}
 	return NULL;
 }
@@ -1015,17 +1008,15 @@ static void ext2_xattr_rehash(struct ext2_xattr_header *header,
 
 #undef BLOCK_HASH_SHIFT
 
-int __init
-init_ext2_xattr(void)
+#define HASH_BUCKET_BITS 10
+
+struct mb2_cache *ext2_xattr_create_cache(void)
 {
-	ext2_xattr_cache = mb_cache_create(""ext2_xattr"", 6);
-	if (!ext2_xattr_cache)
-		return -ENOMEM;
-	return 0;
+	return mb2_cache_create(HASH_BUCKET_BITS);
 }
 
-void
-exit_ext2_xattr(void)
+void ext2_xattr_destroy_cache(struct mb2_cache *cache)
 {
-	mb_cache_destroy(ext2_xattr_cache);
+	if (cache)
+		mb2_cache_destroy(cache);
 }",linux,be0726d33cb8f411945884664924bed3cb8c70ee,82939d7999dfc1f1998c4b1c12e2f19edbdff272,1,"exit_ext2_xattr(void)
//fix_flaw_line_below:
//void ext2_xattr_destroy_cache(struct mb2_cache *cache)
 {
//flaw_line_below:
	mb_cache_destroy(ext2_xattr_cache);
//fix_flaw_line_below:
//	if (cache)
//fix_flaw_line_below:
//		mb2_cache_destroy(cache);
 }
"
5413,183149,,Local,Not required,Partial,CVE-2015-8952,https://www.cvedetails.com/cve/CVE-2015-8952/,CWE-19,Low,,,,2016-10-16,2.1,"The mbcache feature in the ext2 and ext4 filesystem implementations in the Linux kernel before 4.6 mishandles xattr block caching, which allows local users to cause a denial of service (soft lockup) via filesystem operations in environments that use many attributes, as demonstrated by Ceph and Samba.",2018-03-15,DoS ,21,https://github.com/torvalds/linux/commit/be0726d33cb8f411945884664924bed3cb8c70ee,be0726d33cb8f411945884664924bed3cb8c70ee,"ext2: convert to mbcache2

The conversion is generally straightforward. We convert filesystem from
a global cache to per-fs one. Similarly to ext4 the tricky part is that
xattr block corresponding to found mbcache entry can get freed before we
get buffer lock for that block. So we have to check whether the entry is
still valid after getting the buffer lock.

Signed-off-by: Jan Kara <jack@suse.cz>
Signed-off-by: Theodore Ts'o <tytso@mit.edu>",11,fs/ext2/xattr.c,"{""sha"": ""f98ce7e60a0f84f71743e0dfe069c7e96c6bd648"", ""filename"": ""fs/ext2/ext2.h"", ""status"": ""modified"", ""additions"": 3, ""deletions"": 0, ""changes"": 3, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/ext2.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -61,6 +61,8 @@ struct ext2_block_alloc_info {\n #define rsv_start rsv_window._rsv_start\n #define rsv_end rsv_window._rsv_end\n \n+struct mb2_cache;\n+\n /*\n  * second extended-fs super-block data in memory\n  */\n@@ -111,6 +113,7 @@ struct ext2_sb_info {\n \t * of the mount options.\n \t */\n \tspinlock_t s_lock;\n+\tstruct mb2_cache *s_mb_cache;\n };\n \n static inline spinlock_t *""}<_**next**_>{""sha"": ""b78caf25f746220ce635a3bd946bedeaf7e3e750"", ""filename"": ""fs/ext2/super.c"", ""status"": ""modified"", ""additions"": 17, ""deletions"": 8, ""changes"": 25, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/super.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -131,7 +131,10 @@ static void ext2_put_super (struct super_block * sb)\n \n \tdquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);\n \n-\text2_xattr_put_super(sb);\n+\tif (sbi->s_mb_cache) {\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n+\t\tsbi->s_mb_cache = NULL;\n+\t}\n \tif (!(sb->s_flags & MS_RDONLY)) {\n \t\tstruct ext2_super_block *es = sbi->s_es;\n \n@@ -1104,6 +1107,14 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\text2_msg(sb, KERN_ERR, \""error: insufficient memory\"");\n \t\tgoto failed_mount3;\n \t}\n+\n+#ifdef CONFIG_EXT2_FS_XATTR\n+\tsbi->s_mb_cache = ext2_xattr_create_cache();\n+\tif (!sbi->s_mb_cache) {\n+\t\text2_msg(sb, KERN_ERR, \""Failed to create an mb_cache\"");\n+\t\tgoto failed_mount3;\n+\t}\n+#endif\n \t/*\n \t * set up enough so that it can read an inode\n \t */\n@@ -1149,6 +1160,8 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\t\tsb->s_id);\n \tgoto failed_mount;\n failed_mount3:\n+\tif (sbi->s_mb_cache)\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n \tpercpu_counter_destroy(&sbi->s_freeblocks_counter);\n \tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n \tpercpu_counter_destroy(&sbi->s_dirs_counter);\n@@ -1555,28 +1568,24 @@ MODULE_ALIAS_FS(\""ext2\"");\n \n static int __init init_ext2_fs(void)\n {\n-\tint err = init_ext2_xattr();\n-\tif (err)\n-\t\treturn err;\n+\tint err;\n+\n \terr = init_inodecache();\n \tif (err)\n-\t\tgoto out1;\n+\t\treturn err;\n         err = register_filesystem(&ext2_fs_type);\n \tif (err)\n \t\tgoto out;\n \treturn 0;\n out:\n \tdestroy_inodecache();\n-out1:\n-\texit_ext2_xattr();\n \treturn err;\n }\n \n static void __exit exit_ext2_fs(void)\n {\n \tunregister_filesystem(&ext2_fs_type);\n \tdestroy_inodecache();\n-\texit_ext2_xattr();\n }\n \n MODULE_AUTHOR(\""Remy Card and others\"");""}<_**next**_>{""sha"": ""7162b4869bc32515800d8ffc06ac3835ea241c8b"", ""filename"": ""fs/ext2/xattr.c"", ""status"": ""modified"", ""additions"": 67, ""deletions"": 76, ""changes"": 143, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -56,7 +56,7 @@\n #include <linux/buffer_head.h>\n #include <linux/init.h>\n #include <linux/slab.h>\n-#include <linux/mbcache.h>\n+#include <linux/mbcache2.h>\n #include <linux/quotaops.h>\n #include <linux/rwsem.h>\n #include <linux/security.h>\n@@ -90,14 +90,12 @@\n static int ext2_xattr_set2(struct inode *, struct buffer_head *,\n \t\t\t   struct ext2_xattr_header *);\n \n-static int ext2_xattr_cache_insert(struct buffer_head *);\n+static int ext2_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);\n static struct buffer_head *ext2_xattr_cache_find(struct inode *,\n \t\t\t\t\t\t struct ext2_xattr_header *);\n static void ext2_xattr_rehash(struct ext2_xattr_header *,\n \t\t\t      struct ext2_xattr_entry *);\n \n-static struct mb_cache *ext2_xattr_cache;\n-\n static const struct xattr_handler *ext2_xattr_handler_map[] = {\n \t[EXT2_XATTR_INDEX_USER]\t\t     = &ext2_xattr_user_handler,\n #ifdef CONFIG_EXT2_FS_POSIX_ACL\n@@ -152,6 +150,7 @@ ext2_xattr_get(struct inode *inode, int name_index, const char *name,\n \tsize_t name_len, size;\n \tchar *end;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""name=%d.%s, buffer=%p, buffer_size=%ld\"",\n \t\t  name_index, name, buffer, (long)buffer_size);\n@@ -196,7 +195,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t\t\tgoto found;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \terror = -ENODATA;\n \tgoto cleanup;\n@@ -209,7 +208,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)\n \t\tgoto bad_block;\n \n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \tif (buffer) {\n \t\terror = -ERANGE;\n@@ -247,6 +246,7 @@ ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)\n \tchar *end;\n \tsize_t rest = buffer_size;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""buffer=%p, buffer_size=%ld\"",\n \t\t  buffer, (long)buffer_size);\n@@ -281,7 +281,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_list\"",\n \t\t\tgoto bad_block;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \n \t/* list the attribute names */\n@@ -483,22 +483,23 @@ bad_block:\t\text2_error(sb, \""ext2_xattr_set\"",\n \t/* Here we know that we can set the new attribute. */\n \n \tif (header) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/* assert(header == HDR(bh)); */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,\n-\t\t\t\t\tbh->b_blocknr);\n \t\tlock_buffer(bh);\n \t\tif (header->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(header->h_hash);\n+\n \t\t\tea_bdebug(bh, \""modifying in-place\"");\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect modified block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,\n+\t\t\t\t\t\t     hash, bh->b_blocknr);\n+\n \t\t\t/* keep the buffer locked while modifying it. */\n \t\t} else {\n \t\t\tint offset;\n \n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tunlock_buffer(bh);\n \t\t\tea_bdebug(bh, \""cloning\"");\n \t\t\theader = kmalloc(bh->b_size, GFP_KERNEL);\n@@ -626,6 +627,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \tstruct super_block *sb = inode->i_sb;\n \tstruct buffer_head *new_bh = NULL;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;\n \n \tif (header) {\n \t\tnew_bh = ext2_xattr_cache_find(inode, header);\n@@ -653,7 +655,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\t   don't need to change the reference count. */\n \t\t\tnew_bh = old_bh;\n \t\t\tget_bh(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t} else {\n \t\t\t/* We need to allocate a new block */\n \t\t\text2_fsblk_t goal = ext2_group_first_block_no(sb,\n@@ -674,7 +676,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\tmemcpy(new_bh->b_data, header, new_bh->b_size);\n \t\t\tset_buffer_uptodate(new_bh);\n \t\t\tunlock_buffer(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t\t\n \t\t\text2_xattr_update_super_block(sb);\n \t\t}\n@@ -707,19 +709,21 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \n \terror = 0;\n \tif (old_bh && old_bh != new_bh) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/*\n \t\t * If there was an old block and we are no longer using it,\n \t\t * release the old block.\n \t\t */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,\n-\t\t\t\t\told_bh->b_blocknr);\n \t\tlock_buffer(old_bh);\n \t\tif (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);\n+\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect freed block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(ext2_mb_cache,\n+\t\t\t\t\t\t     hash, old_bh->b_blocknr);\n \t\t\t/* Free the old block. */\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n \t\t\tea_bdebug(old_bh, \""freeing\"");\n \t\t\text2_free_blocks(inode, old_bh->b_blocknr, 1);\n \t\t\tmark_inode_dirty(inode);\n@@ -730,8 +734,6 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t} else {\n \t\t\t/* Decrement the refcount only. */\n \t\t\tle32_add_cpu(&HDR(old_bh)->h_refcount, -1);\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tdquot_free_block_nodirty(inode, 1);\n \t\t\tmark_inode_dirty(inode);\n \t\t\tmark_buffer_dirty(old_bh);\n@@ -757,7 +759,6 @@ void\n ext2_xattr_delete_inode(struct inode *inode)\n {\n \tstruct buffer_head *bh = NULL;\n-\tstruct mb_cache_entry *ce;\n \n \tdown_write(&EXT2_I(inode)->xattr_sem);\n \tif (!EXT2_I(inode)->i_file_acl)\n@@ -777,19 +778,22 @@ ext2_xattr_delete_inode(struct inode *inode)\n \t\t\tEXT2_I(inode)->i_file_acl);\n \t\tgoto cleanup;\n \t}\n-\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);\n \tlock_buffer(bh);\n \tif (HDR(bh)->h_refcount == cpu_to_le32(1)) {\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_free(ce);\n+\t\t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n+\n+\t\t/*\n+\t\t * This must happen under buffer lock for ext2_xattr_set2() to\n+\t\t * reliably detect freed block\n+\t\t */\n+\t\tmb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,\n+\t\t\t\t\t     hash, bh->b_blocknr);\n \t\text2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);\n \t\tget_bh(bh);\n \t\tbforget(bh);\n \t\tunlock_buffer(bh);\n \t} else {\n \t\tle32_add_cpu(&HDR(bh)->h_refcount, -1);\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_release(ce);\n \t\tea_bdebug(bh, \""refcount now=%d\"",\n \t\t\tle32_to_cpu(HDR(bh)->h_refcount));\n \t\tunlock_buffer(bh);\n@@ -805,18 +809,6 @@ ext2_xattr_delete_inode(struct inode *inode)\n \tup_write(&EXT2_I(inode)->xattr_sem);\n }\n \n-/*\n- * ext2_xattr_put_super()\n- *\n- * This is called when a file system is unmounted.\n- */\n-void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-\tmb_cache_shrink(sb->s_bdev);\n-}\n-\n-\n /*\n  * ext2_xattr_cache_insert()\n  *\n@@ -826,28 +818,20 @@ ext2_xattr_put_super(struct super_block *sb)\n  * Returns 0, or a negative error number on failure.\n  */\n static int\n-ext2_xattr_cache_insert(struct buffer_head *bh)\n+ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)\n {\n \t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n-\tstruct mb_cache_entry *ce;\n \tint error;\n \n-\tce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);\n-\tif (!ce)\n-\t\treturn -ENOMEM;\n-\terror = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);\n+\terror = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);\n \tif (error) {\n-\t\tmb_cache_entry_free(ce);\n \t\tif (error == -EBUSY) {\n \t\t\tea_bdebug(bh, \""already in cache (%d cache entries)\"",\n \t\t\t\tatomic_read(&ext2_xattr_cache->c_entry_count));\n \t\t\terror = 0;\n \t\t}\n-\t} else {\n-\t\tea_bdebug(bh, \""inserting [%x] (%d cache entries)\"", (int)hash,\n-\t\t\t  atomic_read(&ext2_xattr_cache->c_entry_count));\n-\t\tmb_cache_entry_release(ce);\n-\t}\n+\t} else\n+\t\tea_bdebug(bh, \""inserting [%x]\"", (int)hash);\n \treturn error;\n }\n \n@@ -903,31 +887,39 @@ static struct buffer_head *\n ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n {\n \t__u32 hash = le32_to_cpu(header->h_hash);\n-\tstruct mb_cache_entry *ce;\n+\tstruct mb2_cache_entry *ce;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tif (!header->h_hash)\n \t\treturn NULL;  /* never share */\n \tea_idebug(inode, \""looking for cached blocks [%x]\"", (int)hash);\n again:\n-\tce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,\n-\t\t\t\t       hash);\n+\tce = mb2_cache_entry_find_first(ext2_mb_cache, hash);\n \twhile (ce) {\n \t\tstruct buffer_head *bh;\n \n-\t\tif (IS_ERR(ce)) {\n-\t\t\tif (PTR_ERR(ce) == -EAGAIN)\n-\t\t\t\tgoto again;\n-\t\t\tbreak;\n-\t\t}\n-\n \t\tbh = sb_bread(inode->i_sb, ce->e_block);\n \t\tif (!bh) {\n \t\t\text2_error(inode->i_sb, \""ext2_xattr_cache_find\"",\n \t\t\t\t\""inode %ld: block %ld read error\"",\n \t\t\t\tinode->i_ino, (unsigned long) ce->e_block);\n \t\t} else {\n \t\t\tlock_buffer(bh);\n-\t\t\tif (le32_to_cpu(HDR(bh)->h_refcount) >\n+\t\t\t/*\n+\t\t\t * We have to be careful about races with freeing or\n+\t\t\t * rehashing of xattr block. Once we hold buffer lock\n+\t\t\t * xattr block's state is stable so we can check\n+\t\t\t * whether the block got freed / rehashed or not.\n+\t\t\t * Since we unhash mbcache entry under buffer lock when\n+\t\t\t * freeing / rehashing xattr block, checking whether\n+\t\t\t * entry is still hashed is reliable.\n+\t\t\t */\n+\t\t\tif (hlist_bl_unhashed(&ce->e_hash_list)) {\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n+\t\t\t\tunlock_buffer(bh);\n+\t\t\t\tbrelse(bh);\n+\t\t\t\tgoto again;\n+\t\t\t} else if (le32_to_cpu(HDR(bh)->h_refcount) >\n \t\t\t\t   EXT2_XATTR_REFCOUNT_MAX) {\n \t\t\t\tea_idebug(inode, \""block %ld refcount %d>%d\"",\n \t\t\t\t\t  (unsigned long) ce->e_block,\n@@ -936,13 +928,14 @@ ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n \t\t\t} else if (!ext2_xattr_cmp(header, HDR(bh))) {\n \t\t\t\tea_bdebug(bh, \""b_count=%d\"",\n \t\t\t\t\t  atomic_read(&(bh->b_count)));\n-\t\t\t\tmb_cache_entry_release(ce);\n+\t\t\t\tmb2_cache_entry_touch(ext2_mb_cache, ce);\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n \t\t\t\treturn bh;\n \t\t\t}\n \t\t\tunlock_buffer(bh);\n \t\t\tbrelse(bh);\n \t\t}\n-\t\tce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);\n+\t\tce = mb2_cache_entry_find_next(ext2_mb_cache, ce);\n \t}\n \treturn NULL;\n }\n@@ -1015,17 +1008,15 @@ static void ext2_xattr_rehash(struct ext2_xattr_header *header,\n \n #undef BLOCK_HASH_SHIFT\n \n-int __init\n-init_ext2_xattr(void)\n+#define HASH_BUCKET_BITS 10\n+\n+struct mb2_cache *ext2_xattr_create_cache(void)\n {\n-\text2_xattr_cache = mb_cache_create(\""ext2_xattr\"", 6);\n-\tif (!ext2_xattr_cache)\n-\t\treturn -ENOMEM;\n-\treturn 0;\n+\treturn mb2_cache_create(HASH_BUCKET_BITS);\n }\n \n-void\n-exit_ext2_xattr(void)\n+void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n-\tmb_cache_destroy(ext2_xattr_cache);\n+\tif (cache)\n+\t\tmb2_cache_destroy(cache);\n }""}<_**next**_>{""sha"": ""6ea38aa9563a00649bf25544eed131bbe8b1d88d"", ""filename"": ""fs/ext2/xattr.h"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 16, ""changes"": 21, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -53,6 +53,8 @@ struct ext2_xattr_entry {\n #define EXT2_XATTR_SIZE(size) \\\n \t(((size) + EXT2_XATTR_ROUND) & ~EXT2_XATTR_ROUND)\n \n+struct mb2_cache;\n+\n # ifdef CONFIG_EXT2_FS_XATTR\n \n extern const struct xattr_handler ext2_xattr_user_handler;\n@@ -65,10 +67,9 @@ extern int ext2_xattr_get(struct inode *, int, const char *, void *, size_t);\n extern int ext2_xattr_set(struct inode *, int, const char *, const void *, size_t, int);\n \n extern void ext2_xattr_delete_inode(struct inode *);\n-extern void ext2_xattr_put_super(struct super_block *);\n \n-extern int init_ext2_xattr(void);\n-extern void exit_ext2_xattr(void);\n+extern struct mb2_cache *ext2_xattr_create_cache(void);\n+extern void ext2_xattr_destroy_cache(struct mb2_cache *cache);\n \n extern const struct xattr_handler *ext2_xattr_handlers[];\n \n@@ -93,19 +94,7 @@ ext2_xattr_delete_inode(struct inode *inode)\n {\n }\n \n-static inline void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-}\n-\n-static inline int\n-init_ext2_xattr(void)\n-{\n-\treturn 0;\n-}\n-\n-static inline void\n-exit_ext2_xattr(void)\n+static inline void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n }\n ""}"," ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)
 {
 	__u32 hash = le32_to_cpu(header->h_hash);
	struct mb2_cache_entry *ce;
	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	if (!header->h_hash)
 		return NULL;  /* never share */
 	ea_idebug(inode, ""looking for cached blocks [%x]"", (int)hash);
 again:
	ce = mb2_cache_entry_find_first(ext2_mb_cache, hash);
 	while (ce) {
 		struct buffer_head *bh;
 
 		bh = sb_bread(inode->i_sb, ce->e_block);
 		if (!bh) {
 			ext2_error(inode->i_sb, ""ext2_xattr_cache_find"",
 				""inode %ld: block %ld read error"",
 				inode->i_ino, (unsigned long) ce->e_block);
 		} else {
 			lock_buffer(bh);
			/*
			 * We have to be careful about races with freeing or
			 * rehashing of xattr block. Once we hold buffer lock
			 * xattr block's state is stable so we can check
			 * whether the block got freed / rehashed or not.
			 * Since we unhash mbcache entry under buffer lock when
			 * freeing / rehashing xattr block, checking whether
			 * entry is still hashed is reliable.
			 */
			if (hlist_bl_unhashed(&ce->e_hash_list)) {
				mb2_cache_entry_put(ext2_mb_cache, ce);
				unlock_buffer(bh);
				brelse(bh);
				goto again;
			} else if (le32_to_cpu(HDR(bh)->h_refcount) >
 				   EXT2_XATTR_REFCOUNT_MAX) {
 				ea_idebug(inode, ""block %ld refcount %d>%d"",
 					  (unsigned long) ce->e_block,
					  le32_to_cpu(HDR(bh)->h_refcount),
					  EXT2_XATTR_REFCOUNT_MAX);
 			} else if (!ext2_xattr_cmp(header, HDR(bh))) {
 				ea_bdebug(bh, ""b_count=%d"",
 					  atomic_read(&(bh->b_count)));
				mb2_cache_entry_touch(ext2_mb_cache, ce);
				mb2_cache_entry_put(ext2_mb_cache, ce);
 				return bh;
 			}
 			unlock_buffer(bh);
 			brelse(bh);
 		}
		ce = mb2_cache_entry_find_next(ext2_mb_cache, ce);
 	}
 	return NULL;
 }
"," ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)
 {
 	__u32 hash = le32_to_cpu(header->h_hash);
	struct mb_cache_entry *ce;
 
 	if (!header->h_hash)
 		return NULL;  /* never share */
 	ea_idebug(inode, ""looking for cached blocks [%x]"", (int)hash);
 again:
	ce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,
				       hash);
 	while (ce) {
 		struct buffer_head *bh;
 
		if (IS_ERR(ce)) {
			if (PTR_ERR(ce) == -EAGAIN)
				goto again;
			break;
		}
 		bh = sb_bread(inode->i_sb, ce->e_block);
 		if (!bh) {
 			ext2_error(inode->i_sb, ""ext2_xattr_cache_find"",
 				""inode %ld: block %ld read error"",
 				inode->i_ino, (unsigned long) ce->e_block);
 		} else {
 			lock_buffer(bh);
			if (le32_to_cpu(HDR(bh)->h_refcount) >
 				   EXT2_XATTR_REFCOUNT_MAX) {
 				ea_idebug(inode, ""block %ld refcount %d>%d"",
 					  (unsigned long) ce->e_block,
					  le32_to_cpu(HDR(bh)->h_refcount),
					  EXT2_XATTR_REFCOUNT_MAX);
 			} else if (!ext2_xattr_cmp(header, HDR(bh))) {
 				ea_bdebug(bh, ""b_count=%d"",
 					  atomic_read(&(bh->b_count)));
				mb_cache_entry_release(ce);
 				return bh;
 			}
 			unlock_buffer(bh);
 			brelse(bh);
 		}
		ce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);
 	}
 	return NULL;
 }
",C,"	struct mb2_cache_entry *ce;
	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
	ce = mb2_cache_entry_find_first(ext2_mb_cache, hash);
			/*
			 * We have to be careful about races with freeing or
			 * rehashing of xattr block. Once we hold buffer lock
			 * xattr block's state is stable so we can check
			 * whether the block got freed / rehashed or not.
			 * Since we unhash mbcache entry under buffer lock when
			 * freeing / rehashing xattr block, checking whether
			 * entry is still hashed is reliable.
			 */
			if (hlist_bl_unhashed(&ce->e_hash_list)) {
				mb2_cache_entry_put(ext2_mb_cache, ce);
				unlock_buffer(bh);
				brelse(bh);
				goto again;
			} else if (le32_to_cpu(HDR(bh)->h_refcount) >
				mb2_cache_entry_touch(ext2_mb_cache, ce);
				mb2_cache_entry_put(ext2_mb_cache, ce);
		ce = mb2_cache_entry_find_next(ext2_mb_cache, ce);
","	struct mb_cache_entry *ce;
	ce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,
				       hash);
		if (IS_ERR(ce)) {
			if (PTR_ERR(ce) == -EAGAIN)
				goto again;
			break;
		}
			if (le32_to_cpu(HDR(bh)->h_refcount) >
				mb_cache_entry_release(ce);
		ce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);
",,"@@ -56,7 +56,7 @@
 #include <linux/buffer_head.h>
 #include <linux/init.h>
 #include <linux/slab.h>
-#include <linux/mbcache.h>
+#include <linux/mbcache2.h>
 #include <linux/quotaops.h>
 #include <linux/rwsem.h>
 #include <linux/security.h>
@@ -90,14 +90,12 @@
 static int ext2_xattr_set2(struct inode *, struct buffer_head *,
 			   struct ext2_xattr_header *);
 
-static int ext2_xattr_cache_insert(struct buffer_head *);
+static int ext2_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);
 static struct buffer_head *ext2_xattr_cache_find(struct inode *,
 						 struct ext2_xattr_header *);
 static void ext2_xattr_rehash(struct ext2_xattr_header *,
 			      struct ext2_xattr_entry *);
 
-static struct mb_cache *ext2_xattr_cache;
-
 static const struct xattr_handler *ext2_xattr_handler_map[] = {
 	[EXT2_XATTR_INDEX_USER]		     = &ext2_xattr_user_handler,
 #ifdef CONFIG_EXT2_FS_POSIX_ACL
@@ -152,6 +150,7 @@ ext2_xattr_get(struct inode *inode, int name_index, const char *name,
 	size_t name_len, size;
 	char *end;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	ea_idebug(inode, ""name=%d.%s, buffer=%p, buffer_size=%ld"",
 		  name_index, name, buffer, (long)buffer_size);
@@ -196,7 +195,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_get"",
 			goto found;
 		entry = next;
 	}
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 	error = -ENODATA;
 	goto cleanup;
@@ -209,7 +208,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_get"",
 	    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)
 		goto bad_block;
 
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 	if (buffer) {
 		error = -ERANGE;
@@ -247,6 +246,7 @@ ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)
 	char *end;
 	size_t rest = buffer_size;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	ea_idebug(inode, ""buffer=%p, buffer_size=%ld"",
 		  buffer, (long)buffer_size);
@@ -281,7 +281,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_list"",
 			goto bad_block;
 		entry = next;
 	}
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 
 	/* list the attribute names */
@@ -483,22 +483,23 @@ bad_block:		ext2_error(sb, ""ext2_xattr_set"",
 	/* Here we know that we can set the new attribute. */
 
 	if (header) {
-		struct mb_cache_entry *ce;
-
 		/* assert(header == HDR(bh)); */
-		ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,
-					bh->b_blocknr);
 		lock_buffer(bh);
 		if (header->h_refcount == cpu_to_le32(1)) {
+			__u32 hash = le32_to_cpu(header->h_hash);
+
 			ea_bdebug(bh, ""modifying in-place"");
-			if (ce)
-				mb_cache_entry_free(ce);
+			/*
+			 * This must happen under buffer lock for
+			 * ext2_xattr_set2() to reliably detect modified block
+			 */
+			mb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,
+						     hash, bh->b_blocknr);
+
 			/* keep the buffer locked while modifying it. */
 		} else {
 			int offset;
 
-			if (ce)
-				mb_cache_entry_release(ce);
 			unlock_buffer(bh);
 			ea_bdebug(bh, ""cloning"");
 			header = kmalloc(bh->b_size, GFP_KERNEL);
@@ -626,6 +627,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *new_bh = NULL;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;
 
 	if (header) {
 		new_bh = ext2_xattr_cache_find(inode, header);
@@ -653,7 +655,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 			   don't need to change the reference count. */
 			new_bh = old_bh;
 			get_bh(new_bh);
-			ext2_xattr_cache_insert(new_bh);
+			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
 		} else {
 			/* We need to allocate a new block */
 			ext2_fsblk_t goal = ext2_group_first_block_no(sb,
@@ -674,7 +676,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 			memcpy(new_bh->b_data, header, new_bh->b_size);
 			set_buffer_uptodate(new_bh);
 			unlock_buffer(new_bh);
-			ext2_xattr_cache_insert(new_bh);
+			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
 			
 			ext2_xattr_update_super_block(sb);
 		}
@@ -707,19 +709,21 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 
 	error = 0;
 	if (old_bh && old_bh != new_bh) {
-		struct mb_cache_entry *ce;
-
 		/*
 		 * If there was an old block and we are no longer using it,
 		 * release the old block.
 		 */
-		ce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,
-					old_bh->b_blocknr);
 		lock_buffer(old_bh);
 		if (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {
+			__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);
+
+			/*
+			 * This must happen under buffer lock for
+			 * ext2_xattr_set2() to reliably detect freed block
+			 */
+			mb2_cache_entry_delete_block(ext2_mb_cache,
+						     hash, old_bh->b_blocknr);
 			/* Free the old block. */
-			if (ce)
-				mb_cache_entry_free(ce);
 			ea_bdebug(old_bh, ""freeing"");
 			ext2_free_blocks(inode, old_bh->b_blocknr, 1);
 			mark_inode_dirty(inode);
@@ -730,8 +734,6 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 		} else {
 			/* Decrement the refcount only. */
 			le32_add_cpu(&HDR(old_bh)->h_refcount, -1);
-			if (ce)
-				mb_cache_entry_release(ce);
 			dquot_free_block_nodirty(inode, 1);
 			mark_inode_dirty(inode);
 			mark_buffer_dirty(old_bh);
@@ -757,7 +759,6 @@ void
 ext2_xattr_delete_inode(struct inode *inode)
 {
 	struct buffer_head *bh = NULL;
-	struct mb_cache_entry *ce;
 
 	down_write(&EXT2_I(inode)->xattr_sem);
 	if (!EXT2_I(inode)->i_file_acl)
@@ -777,19 +778,22 @@ ext2_xattr_delete_inode(struct inode *inode)
 			EXT2_I(inode)->i_file_acl);
 		goto cleanup;
 	}
-	ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);
 	lock_buffer(bh);
 	if (HDR(bh)->h_refcount == cpu_to_le32(1)) {
-		if (ce)
-			mb_cache_entry_free(ce);
+		__u32 hash = le32_to_cpu(HDR(bh)->h_hash);
+
+		/*
+		 * This must happen under buffer lock for ext2_xattr_set2() to
+		 * reliably detect freed block
+		 */
+		mb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,
+					     hash, bh->b_blocknr);
 		ext2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);
 		get_bh(bh);
 		bforget(bh);
 		unlock_buffer(bh);
 	} else {
 		le32_add_cpu(&HDR(bh)->h_refcount, -1);
-		if (ce)
-			mb_cache_entry_release(ce);
 		ea_bdebug(bh, ""refcount now=%d"",
 			le32_to_cpu(HDR(bh)->h_refcount));
 		unlock_buffer(bh);
@@ -805,18 +809,6 @@ ext2_xattr_delete_inode(struct inode *inode)
 	up_write(&EXT2_I(inode)->xattr_sem);
 }
 
-/*
- * ext2_xattr_put_super()
- *
- * This is called when a file system is unmounted.
- */
-void
-ext2_xattr_put_super(struct super_block *sb)
-{
-	mb_cache_shrink(sb->s_bdev);
-}
-
-
 /*
  * ext2_xattr_cache_insert()
  *
@@ -826,28 +818,20 @@ ext2_xattr_put_super(struct super_block *sb)
  * Returns 0, or a negative error number on failure.
  */
 static int
-ext2_xattr_cache_insert(struct buffer_head *bh)
+ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)
 {
 	__u32 hash = le32_to_cpu(HDR(bh)->h_hash);
-	struct mb_cache_entry *ce;
 	int error;
 
-	ce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);
-	if (!ce)
-		return -ENOMEM;
-	error = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);
+	error = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);
 	if (error) {
-		mb_cache_entry_free(ce);
 		if (error == -EBUSY) {
 			ea_bdebug(bh, ""already in cache (%d cache entries)"",
 				atomic_read(&ext2_xattr_cache->c_entry_count));
 			error = 0;
 		}
-	} else {
-		ea_bdebug(bh, ""inserting [%x] (%d cache entries)"", (int)hash,
-			  atomic_read(&ext2_xattr_cache->c_entry_count));
-		mb_cache_entry_release(ce);
-	}
+	} else
+		ea_bdebug(bh, ""inserting [%x]"", (int)hash);
 	return error;
 }
 
@@ -903,31 +887,39 @@ static struct buffer_head *
 ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)
 {
 	__u32 hash = le32_to_cpu(header->h_hash);
-	struct mb_cache_entry *ce;
+	struct mb2_cache_entry *ce;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	if (!header->h_hash)
 		return NULL;  /* never share */
 	ea_idebug(inode, ""looking for cached blocks [%x]"", (int)hash);
 again:
-	ce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,
-				       hash);
+	ce = mb2_cache_entry_find_first(ext2_mb_cache, hash);
 	while (ce) {
 		struct buffer_head *bh;
 
-		if (IS_ERR(ce)) {
-			if (PTR_ERR(ce) == -EAGAIN)
-				goto again;
-			break;
-		}
-
 		bh = sb_bread(inode->i_sb, ce->e_block);
 		if (!bh) {
 			ext2_error(inode->i_sb, ""ext2_xattr_cache_find"",
 				""inode %ld: block %ld read error"",
 				inode->i_ino, (unsigned long) ce->e_block);
 		} else {
 			lock_buffer(bh);
-			if (le32_to_cpu(HDR(bh)->h_refcount) >
+			/*
+			 * We have to be careful about races with freeing or
+			 * rehashing of xattr block. Once we hold buffer lock
+			 * xattr block's state is stable so we can check
+			 * whether the block got freed / rehashed or not.
+			 * Since we unhash mbcache entry under buffer lock when
+			 * freeing / rehashing xattr block, checking whether
+			 * entry is still hashed is reliable.
+			 */
+			if (hlist_bl_unhashed(&ce->e_hash_list)) {
+				mb2_cache_entry_put(ext2_mb_cache, ce);
+				unlock_buffer(bh);
+				brelse(bh);
+				goto again;
+			} else if (le32_to_cpu(HDR(bh)->h_refcount) >
 				   EXT2_XATTR_REFCOUNT_MAX) {
 				ea_idebug(inode, ""block %ld refcount %d>%d"",
 					  (unsigned long) ce->e_block,
@@ -936,13 +928,14 @@ ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)
 			} else if (!ext2_xattr_cmp(header, HDR(bh))) {
 				ea_bdebug(bh, ""b_count=%d"",
 					  atomic_read(&(bh->b_count)));
-				mb_cache_entry_release(ce);
+				mb2_cache_entry_touch(ext2_mb_cache, ce);
+				mb2_cache_entry_put(ext2_mb_cache, ce);
 				return bh;
 			}
 			unlock_buffer(bh);
 			brelse(bh);
 		}
-		ce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);
+		ce = mb2_cache_entry_find_next(ext2_mb_cache, ce);
 	}
 	return NULL;
 }
@@ -1015,17 +1008,15 @@ static void ext2_xattr_rehash(struct ext2_xattr_header *header,
 
 #undef BLOCK_HASH_SHIFT
 
-int __init
-init_ext2_xattr(void)
+#define HASH_BUCKET_BITS 10
+
+struct mb2_cache *ext2_xattr_create_cache(void)
 {
-	ext2_xattr_cache = mb_cache_create(""ext2_xattr"", 6);
-	if (!ext2_xattr_cache)
-		return -ENOMEM;
-	return 0;
+	return mb2_cache_create(HASH_BUCKET_BITS);
 }
 
-void
-exit_ext2_xattr(void)
+void ext2_xattr_destroy_cache(struct mb2_cache *cache)
 {
-	mb_cache_destroy(ext2_xattr_cache);
+	if (cache)
+		mb2_cache_destroy(cache);
 }",linux,be0726d33cb8f411945884664924bed3cb8c70ee,82939d7999dfc1f1998c4b1c12e2f19edbdff272,1," ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)
 {
 	__u32 hash = le32_to_cpu(header->h_hash);
//flaw_line_below:
	struct mb_cache_entry *ce;
//fix_flaw_line_below:
//	struct mb2_cache_entry *ce;
//fix_flaw_line_below:
//	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	if (!header->h_hash)
 		return NULL;  /* never share */
 	ea_idebug(inode, ""looking for cached blocks [%x]"", (int)hash);
 again:
//flaw_line_below:
	ce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,
//flaw_line_below:
				       hash);
//fix_flaw_line_below:
//	ce = mb2_cache_entry_find_first(ext2_mb_cache, hash);
 	while (ce) {
 		struct buffer_head *bh;
 
//flaw_line_below:
		if (IS_ERR(ce)) {
//flaw_line_below:
			if (PTR_ERR(ce) == -EAGAIN)
//flaw_line_below:
				goto again;
//flaw_line_below:
			break;
//flaw_line_below:
		}
//flaw_line_below:

 		bh = sb_bread(inode->i_sb, ce->e_block);
 		if (!bh) {
 			ext2_error(inode->i_sb, ""ext2_xattr_cache_find"",
 				""inode %ld: block %ld read error"",
 				inode->i_ino, (unsigned long) ce->e_block);
 		} else {
 			lock_buffer(bh);
//flaw_line_below:
			if (le32_to_cpu(HDR(bh)->h_refcount) >
//fix_flaw_line_below:
//			/*
//fix_flaw_line_below:
//			 * We have to be careful about races with freeing or
//fix_flaw_line_below:
//			 * rehashing of xattr block. Once we hold buffer lock
//fix_flaw_line_below:
//			 * xattr block's state is stable so we can check
//fix_flaw_line_below:
//			 * whether the block got freed / rehashed or not.
//fix_flaw_line_below:
//			 * Since we unhash mbcache entry under buffer lock when
//fix_flaw_line_below:
//			 * freeing / rehashing xattr block, checking whether
//fix_flaw_line_below:
//			 * entry is still hashed is reliable.
//fix_flaw_line_below:
//			 */
//fix_flaw_line_below:
//			if (hlist_bl_unhashed(&ce->e_hash_list)) {
//fix_flaw_line_below:
//				mb2_cache_entry_put(ext2_mb_cache, ce);
//fix_flaw_line_below:
//				unlock_buffer(bh);
//fix_flaw_line_below:
//				brelse(bh);
//fix_flaw_line_below:
//				goto again;
//fix_flaw_line_below:
//			} else if (le32_to_cpu(HDR(bh)->h_refcount) >
 				   EXT2_XATTR_REFCOUNT_MAX) {
 				ea_idebug(inode, ""block %ld refcount %d>%d"",
 					  (unsigned long) ce->e_block,
					  le32_to_cpu(HDR(bh)->h_refcount),
					  EXT2_XATTR_REFCOUNT_MAX);
 			} else if (!ext2_xattr_cmp(header, HDR(bh))) {
 				ea_bdebug(bh, ""b_count=%d"",
 					  atomic_read(&(bh->b_count)));
//flaw_line_below:
				mb_cache_entry_release(ce);
//fix_flaw_line_below:
//				mb2_cache_entry_touch(ext2_mb_cache, ce);
//fix_flaw_line_below:
//				mb2_cache_entry_put(ext2_mb_cache, ce);
 				return bh;
 			}
 			unlock_buffer(bh);
 			brelse(bh);
 		}
//flaw_line_below:
		ce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);
//fix_flaw_line_below:
//		ce = mb2_cache_entry_find_next(ext2_mb_cache, ce);
 	}
 	return NULL;
 }
"
5414,183150,,Local,Not required,Partial,CVE-2015-8952,https://www.cvedetails.com/cve/CVE-2015-8952/,CWE-19,Low,,,,2016-10-16,2.1,"The mbcache feature in the ext2 and ext4 filesystem implementations in the Linux kernel before 4.6 mishandles xattr block caching, which allows local users to cause a denial of service (soft lockup) via filesystem operations in environments that use many attributes, as demonstrated by Ceph and Samba.",2018-03-15,DoS ,4,https://github.com/torvalds/linux/commit/be0726d33cb8f411945884664924bed3cb8c70ee,be0726d33cb8f411945884664924bed3cb8c70ee,"ext2: convert to mbcache2

The conversion is generally straightforward. We convert filesystem from
a global cache to per-fs one. Similarly to ext4 the tricky part is that
xattr block corresponding to found mbcache entry can get freed before we
get buffer lock for that block. So we have to check whether the entry is
still valid after getting the buffer lock.

Signed-off-by: Jan Kara <jack@suse.cz>
Signed-off-by: Theodore Ts'o <tytso@mit.edu>",11,fs/ext2/xattr.c,"{""sha"": ""f98ce7e60a0f84f71743e0dfe069c7e96c6bd648"", ""filename"": ""fs/ext2/ext2.h"", ""status"": ""modified"", ""additions"": 3, ""deletions"": 0, ""changes"": 3, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/ext2.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -61,6 +61,8 @@ struct ext2_block_alloc_info {\n #define rsv_start rsv_window._rsv_start\n #define rsv_end rsv_window._rsv_end\n \n+struct mb2_cache;\n+\n /*\n  * second extended-fs super-block data in memory\n  */\n@@ -111,6 +113,7 @@ struct ext2_sb_info {\n \t * of the mount options.\n \t */\n \tspinlock_t s_lock;\n+\tstruct mb2_cache *s_mb_cache;\n };\n \n static inline spinlock_t *""}<_**next**_>{""sha"": ""b78caf25f746220ce635a3bd946bedeaf7e3e750"", ""filename"": ""fs/ext2/super.c"", ""status"": ""modified"", ""additions"": 17, ""deletions"": 8, ""changes"": 25, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/super.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -131,7 +131,10 @@ static void ext2_put_super (struct super_block * sb)\n \n \tdquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);\n \n-\text2_xattr_put_super(sb);\n+\tif (sbi->s_mb_cache) {\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n+\t\tsbi->s_mb_cache = NULL;\n+\t}\n \tif (!(sb->s_flags & MS_RDONLY)) {\n \t\tstruct ext2_super_block *es = sbi->s_es;\n \n@@ -1104,6 +1107,14 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\text2_msg(sb, KERN_ERR, \""error: insufficient memory\"");\n \t\tgoto failed_mount3;\n \t}\n+\n+#ifdef CONFIG_EXT2_FS_XATTR\n+\tsbi->s_mb_cache = ext2_xattr_create_cache();\n+\tif (!sbi->s_mb_cache) {\n+\t\text2_msg(sb, KERN_ERR, \""Failed to create an mb_cache\"");\n+\t\tgoto failed_mount3;\n+\t}\n+#endif\n \t/*\n \t * set up enough so that it can read an inode\n \t */\n@@ -1149,6 +1160,8 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\t\tsb->s_id);\n \tgoto failed_mount;\n failed_mount3:\n+\tif (sbi->s_mb_cache)\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n \tpercpu_counter_destroy(&sbi->s_freeblocks_counter);\n \tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n \tpercpu_counter_destroy(&sbi->s_dirs_counter);\n@@ -1555,28 +1568,24 @@ MODULE_ALIAS_FS(\""ext2\"");\n \n static int __init init_ext2_fs(void)\n {\n-\tint err = init_ext2_xattr();\n-\tif (err)\n-\t\treturn err;\n+\tint err;\n+\n \terr = init_inodecache();\n \tif (err)\n-\t\tgoto out1;\n+\t\treturn err;\n         err = register_filesystem(&ext2_fs_type);\n \tif (err)\n \t\tgoto out;\n \treturn 0;\n out:\n \tdestroy_inodecache();\n-out1:\n-\texit_ext2_xattr();\n \treturn err;\n }\n \n static void __exit exit_ext2_fs(void)\n {\n \tunregister_filesystem(&ext2_fs_type);\n \tdestroy_inodecache();\n-\texit_ext2_xattr();\n }\n \n MODULE_AUTHOR(\""Remy Card and others\"");""}<_**next**_>{""sha"": ""7162b4869bc32515800d8ffc06ac3835ea241c8b"", ""filename"": ""fs/ext2/xattr.c"", ""status"": ""modified"", ""additions"": 67, ""deletions"": 76, ""changes"": 143, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -56,7 +56,7 @@\n #include <linux/buffer_head.h>\n #include <linux/init.h>\n #include <linux/slab.h>\n-#include <linux/mbcache.h>\n+#include <linux/mbcache2.h>\n #include <linux/quotaops.h>\n #include <linux/rwsem.h>\n #include <linux/security.h>\n@@ -90,14 +90,12 @@\n static int ext2_xattr_set2(struct inode *, struct buffer_head *,\n \t\t\t   struct ext2_xattr_header *);\n \n-static int ext2_xattr_cache_insert(struct buffer_head *);\n+static int ext2_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);\n static struct buffer_head *ext2_xattr_cache_find(struct inode *,\n \t\t\t\t\t\t struct ext2_xattr_header *);\n static void ext2_xattr_rehash(struct ext2_xattr_header *,\n \t\t\t      struct ext2_xattr_entry *);\n \n-static struct mb_cache *ext2_xattr_cache;\n-\n static const struct xattr_handler *ext2_xattr_handler_map[] = {\n \t[EXT2_XATTR_INDEX_USER]\t\t     = &ext2_xattr_user_handler,\n #ifdef CONFIG_EXT2_FS_POSIX_ACL\n@@ -152,6 +150,7 @@ ext2_xattr_get(struct inode *inode, int name_index, const char *name,\n \tsize_t name_len, size;\n \tchar *end;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""name=%d.%s, buffer=%p, buffer_size=%ld\"",\n \t\t  name_index, name, buffer, (long)buffer_size);\n@@ -196,7 +195,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t\t\tgoto found;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \terror = -ENODATA;\n \tgoto cleanup;\n@@ -209,7 +208,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)\n \t\tgoto bad_block;\n \n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \tif (buffer) {\n \t\terror = -ERANGE;\n@@ -247,6 +246,7 @@ ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)\n \tchar *end;\n \tsize_t rest = buffer_size;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""buffer=%p, buffer_size=%ld\"",\n \t\t  buffer, (long)buffer_size);\n@@ -281,7 +281,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_list\"",\n \t\t\tgoto bad_block;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \n \t/* list the attribute names */\n@@ -483,22 +483,23 @@ bad_block:\t\text2_error(sb, \""ext2_xattr_set\"",\n \t/* Here we know that we can set the new attribute. */\n \n \tif (header) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/* assert(header == HDR(bh)); */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,\n-\t\t\t\t\tbh->b_blocknr);\n \t\tlock_buffer(bh);\n \t\tif (header->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(header->h_hash);\n+\n \t\t\tea_bdebug(bh, \""modifying in-place\"");\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect modified block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,\n+\t\t\t\t\t\t     hash, bh->b_blocknr);\n+\n \t\t\t/* keep the buffer locked while modifying it. */\n \t\t} else {\n \t\t\tint offset;\n \n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tunlock_buffer(bh);\n \t\t\tea_bdebug(bh, \""cloning\"");\n \t\t\theader = kmalloc(bh->b_size, GFP_KERNEL);\n@@ -626,6 +627,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \tstruct super_block *sb = inode->i_sb;\n \tstruct buffer_head *new_bh = NULL;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;\n \n \tif (header) {\n \t\tnew_bh = ext2_xattr_cache_find(inode, header);\n@@ -653,7 +655,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\t   don't need to change the reference count. */\n \t\t\tnew_bh = old_bh;\n \t\t\tget_bh(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t} else {\n \t\t\t/* We need to allocate a new block */\n \t\t\text2_fsblk_t goal = ext2_group_first_block_no(sb,\n@@ -674,7 +676,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\tmemcpy(new_bh->b_data, header, new_bh->b_size);\n \t\t\tset_buffer_uptodate(new_bh);\n \t\t\tunlock_buffer(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t\t\n \t\t\text2_xattr_update_super_block(sb);\n \t\t}\n@@ -707,19 +709,21 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \n \terror = 0;\n \tif (old_bh && old_bh != new_bh) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/*\n \t\t * If there was an old block and we are no longer using it,\n \t\t * release the old block.\n \t\t */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,\n-\t\t\t\t\told_bh->b_blocknr);\n \t\tlock_buffer(old_bh);\n \t\tif (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);\n+\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect freed block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(ext2_mb_cache,\n+\t\t\t\t\t\t     hash, old_bh->b_blocknr);\n \t\t\t/* Free the old block. */\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n \t\t\tea_bdebug(old_bh, \""freeing\"");\n \t\t\text2_free_blocks(inode, old_bh->b_blocknr, 1);\n \t\t\tmark_inode_dirty(inode);\n@@ -730,8 +734,6 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t} else {\n \t\t\t/* Decrement the refcount only. */\n \t\t\tle32_add_cpu(&HDR(old_bh)->h_refcount, -1);\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tdquot_free_block_nodirty(inode, 1);\n \t\t\tmark_inode_dirty(inode);\n \t\t\tmark_buffer_dirty(old_bh);\n@@ -757,7 +759,6 @@ void\n ext2_xattr_delete_inode(struct inode *inode)\n {\n \tstruct buffer_head *bh = NULL;\n-\tstruct mb_cache_entry *ce;\n \n \tdown_write(&EXT2_I(inode)->xattr_sem);\n \tif (!EXT2_I(inode)->i_file_acl)\n@@ -777,19 +778,22 @@ ext2_xattr_delete_inode(struct inode *inode)\n \t\t\tEXT2_I(inode)->i_file_acl);\n \t\tgoto cleanup;\n \t}\n-\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);\n \tlock_buffer(bh);\n \tif (HDR(bh)->h_refcount == cpu_to_le32(1)) {\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_free(ce);\n+\t\t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n+\n+\t\t/*\n+\t\t * This must happen under buffer lock for ext2_xattr_set2() to\n+\t\t * reliably detect freed block\n+\t\t */\n+\t\tmb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,\n+\t\t\t\t\t     hash, bh->b_blocknr);\n \t\text2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);\n \t\tget_bh(bh);\n \t\tbforget(bh);\n \t\tunlock_buffer(bh);\n \t} else {\n \t\tle32_add_cpu(&HDR(bh)->h_refcount, -1);\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_release(ce);\n \t\tea_bdebug(bh, \""refcount now=%d\"",\n \t\t\tle32_to_cpu(HDR(bh)->h_refcount));\n \t\tunlock_buffer(bh);\n@@ -805,18 +809,6 @@ ext2_xattr_delete_inode(struct inode *inode)\n \tup_write(&EXT2_I(inode)->xattr_sem);\n }\n \n-/*\n- * ext2_xattr_put_super()\n- *\n- * This is called when a file system is unmounted.\n- */\n-void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-\tmb_cache_shrink(sb->s_bdev);\n-}\n-\n-\n /*\n  * ext2_xattr_cache_insert()\n  *\n@@ -826,28 +818,20 @@ ext2_xattr_put_super(struct super_block *sb)\n  * Returns 0, or a negative error number on failure.\n  */\n static int\n-ext2_xattr_cache_insert(struct buffer_head *bh)\n+ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)\n {\n \t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n-\tstruct mb_cache_entry *ce;\n \tint error;\n \n-\tce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);\n-\tif (!ce)\n-\t\treturn -ENOMEM;\n-\terror = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);\n+\terror = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);\n \tif (error) {\n-\t\tmb_cache_entry_free(ce);\n \t\tif (error == -EBUSY) {\n \t\t\tea_bdebug(bh, \""already in cache (%d cache entries)\"",\n \t\t\t\tatomic_read(&ext2_xattr_cache->c_entry_count));\n \t\t\terror = 0;\n \t\t}\n-\t} else {\n-\t\tea_bdebug(bh, \""inserting [%x] (%d cache entries)\"", (int)hash,\n-\t\t\t  atomic_read(&ext2_xattr_cache->c_entry_count));\n-\t\tmb_cache_entry_release(ce);\n-\t}\n+\t} else\n+\t\tea_bdebug(bh, \""inserting [%x]\"", (int)hash);\n \treturn error;\n }\n \n@@ -903,31 +887,39 @@ static struct buffer_head *\n ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n {\n \t__u32 hash = le32_to_cpu(header->h_hash);\n-\tstruct mb_cache_entry *ce;\n+\tstruct mb2_cache_entry *ce;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tif (!header->h_hash)\n \t\treturn NULL;  /* never share */\n \tea_idebug(inode, \""looking for cached blocks [%x]\"", (int)hash);\n again:\n-\tce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,\n-\t\t\t\t       hash);\n+\tce = mb2_cache_entry_find_first(ext2_mb_cache, hash);\n \twhile (ce) {\n \t\tstruct buffer_head *bh;\n \n-\t\tif (IS_ERR(ce)) {\n-\t\t\tif (PTR_ERR(ce) == -EAGAIN)\n-\t\t\t\tgoto again;\n-\t\t\tbreak;\n-\t\t}\n-\n \t\tbh = sb_bread(inode->i_sb, ce->e_block);\n \t\tif (!bh) {\n \t\t\text2_error(inode->i_sb, \""ext2_xattr_cache_find\"",\n \t\t\t\t\""inode %ld: block %ld read error\"",\n \t\t\t\tinode->i_ino, (unsigned long) ce->e_block);\n \t\t} else {\n \t\t\tlock_buffer(bh);\n-\t\t\tif (le32_to_cpu(HDR(bh)->h_refcount) >\n+\t\t\t/*\n+\t\t\t * We have to be careful about races with freeing or\n+\t\t\t * rehashing of xattr block. Once we hold buffer lock\n+\t\t\t * xattr block's state is stable so we can check\n+\t\t\t * whether the block got freed / rehashed or not.\n+\t\t\t * Since we unhash mbcache entry under buffer lock when\n+\t\t\t * freeing / rehashing xattr block, checking whether\n+\t\t\t * entry is still hashed is reliable.\n+\t\t\t */\n+\t\t\tif (hlist_bl_unhashed(&ce->e_hash_list)) {\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n+\t\t\t\tunlock_buffer(bh);\n+\t\t\t\tbrelse(bh);\n+\t\t\t\tgoto again;\n+\t\t\t} else if (le32_to_cpu(HDR(bh)->h_refcount) >\n \t\t\t\t   EXT2_XATTR_REFCOUNT_MAX) {\n \t\t\t\tea_idebug(inode, \""block %ld refcount %d>%d\"",\n \t\t\t\t\t  (unsigned long) ce->e_block,\n@@ -936,13 +928,14 @@ ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n \t\t\t} else if (!ext2_xattr_cmp(header, HDR(bh))) {\n \t\t\t\tea_bdebug(bh, \""b_count=%d\"",\n \t\t\t\t\t  atomic_read(&(bh->b_count)));\n-\t\t\t\tmb_cache_entry_release(ce);\n+\t\t\t\tmb2_cache_entry_touch(ext2_mb_cache, ce);\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n \t\t\t\treturn bh;\n \t\t\t}\n \t\t\tunlock_buffer(bh);\n \t\t\tbrelse(bh);\n \t\t}\n-\t\tce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);\n+\t\tce = mb2_cache_entry_find_next(ext2_mb_cache, ce);\n \t}\n \treturn NULL;\n }\n@@ -1015,17 +1008,15 @@ static void ext2_xattr_rehash(struct ext2_xattr_header *header,\n \n #undef BLOCK_HASH_SHIFT\n \n-int __init\n-init_ext2_xattr(void)\n+#define HASH_BUCKET_BITS 10\n+\n+struct mb2_cache *ext2_xattr_create_cache(void)\n {\n-\text2_xattr_cache = mb_cache_create(\""ext2_xattr\"", 6);\n-\tif (!ext2_xattr_cache)\n-\t\treturn -ENOMEM;\n-\treturn 0;\n+\treturn mb2_cache_create(HASH_BUCKET_BITS);\n }\n \n-void\n-exit_ext2_xattr(void)\n+void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n-\tmb_cache_destroy(ext2_xattr_cache);\n+\tif (cache)\n+\t\tmb2_cache_destroy(cache);\n }""}<_**next**_>{""sha"": ""6ea38aa9563a00649bf25544eed131bbe8b1d88d"", ""filename"": ""fs/ext2/xattr.h"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 16, ""changes"": 21, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -53,6 +53,8 @@ struct ext2_xattr_entry {\n #define EXT2_XATTR_SIZE(size) \\\n \t(((size) + EXT2_XATTR_ROUND) & ~EXT2_XATTR_ROUND)\n \n+struct mb2_cache;\n+\n # ifdef CONFIG_EXT2_FS_XATTR\n \n extern const struct xattr_handler ext2_xattr_user_handler;\n@@ -65,10 +67,9 @@ extern int ext2_xattr_get(struct inode *, int, const char *, void *, size_t);\n extern int ext2_xattr_set(struct inode *, int, const char *, const void *, size_t, int);\n \n extern void ext2_xattr_delete_inode(struct inode *);\n-extern void ext2_xattr_put_super(struct super_block *);\n \n-extern int init_ext2_xattr(void);\n-extern void exit_ext2_xattr(void);\n+extern struct mb2_cache *ext2_xattr_create_cache(void);\n+extern void ext2_xattr_destroy_cache(struct mb2_cache *cache);\n \n extern const struct xattr_handler *ext2_xattr_handlers[];\n \n@@ -93,19 +94,7 @@ ext2_xattr_delete_inode(struct inode *inode)\n {\n }\n \n-static inline void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-}\n-\n-static inline int\n-init_ext2_xattr(void)\n-{\n-\treturn 0;\n-}\n-\n-static inline void\n-exit_ext2_xattr(void)\n+static inline void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n }\n ""}","ext2_xattr_cache_insert(struct buffer_head *bh)
ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)
 {
 	__u32 hash = le32_to_cpu(HDR(bh)->h_hash);
 	int error;
 
	error = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);
 	if (error) {
 		if (error == -EBUSY) {
 			ea_bdebug(bh, ""already in cache (%d cache entries)"",
 				atomic_read(&ext2_xattr_cache->c_entry_count));
 			error = 0;
 		}
	} else
		ea_bdebug(bh, ""inserting [%x]"", (int)hash);
 	return error;
 }
","ext2_xattr_cache_insert(struct buffer_head *bh)
 {
 	__u32 hash = le32_to_cpu(HDR(bh)->h_hash);
	struct mb_cache_entry *ce;
 	int error;
 
	ce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);
	if (!ce)
		return -ENOMEM;
	error = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);
 	if (error) {
		mb_cache_entry_free(ce);
 		if (error == -EBUSY) {
 			ea_bdebug(bh, ""already in cache (%d cache entries)"",
 				atomic_read(&ext2_xattr_cache->c_entry_count));
 			error = 0;
 		}
	} else {
		ea_bdebug(bh, ""inserting [%x] (%d cache entries)"", (int)hash,
			  atomic_read(&ext2_xattr_cache->c_entry_count));
		mb_cache_entry_release(ce);
	}
 	return error;
 }
",C,"ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)
	error = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);
	} else
		ea_bdebug(bh, ""inserting [%x]"", (int)hash);
","	struct mb_cache_entry *ce;
	ce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);
	if (!ce)
		return -ENOMEM;
	error = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);
		mb_cache_entry_free(ce);
	} else {
		ea_bdebug(bh, ""inserting [%x] (%d cache entries)"", (int)hash,
			  atomic_read(&ext2_xattr_cache->c_entry_count));
		mb_cache_entry_release(ce);
	}
",,"@@ -56,7 +56,7 @@
 #include <linux/buffer_head.h>
 #include <linux/init.h>
 #include <linux/slab.h>
-#include <linux/mbcache.h>
+#include <linux/mbcache2.h>
 #include <linux/quotaops.h>
 #include <linux/rwsem.h>
 #include <linux/security.h>
@@ -90,14 +90,12 @@
 static int ext2_xattr_set2(struct inode *, struct buffer_head *,
 			   struct ext2_xattr_header *);
 
-static int ext2_xattr_cache_insert(struct buffer_head *);
+static int ext2_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);
 static struct buffer_head *ext2_xattr_cache_find(struct inode *,
 						 struct ext2_xattr_header *);
 static void ext2_xattr_rehash(struct ext2_xattr_header *,
 			      struct ext2_xattr_entry *);
 
-static struct mb_cache *ext2_xattr_cache;
-
 static const struct xattr_handler *ext2_xattr_handler_map[] = {
 	[EXT2_XATTR_INDEX_USER]		     = &ext2_xattr_user_handler,
 #ifdef CONFIG_EXT2_FS_POSIX_ACL
@@ -152,6 +150,7 @@ ext2_xattr_get(struct inode *inode, int name_index, const char *name,
 	size_t name_len, size;
 	char *end;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	ea_idebug(inode, ""name=%d.%s, buffer=%p, buffer_size=%ld"",
 		  name_index, name, buffer, (long)buffer_size);
@@ -196,7 +195,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_get"",
 			goto found;
 		entry = next;
 	}
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 	error = -ENODATA;
 	goto cleanup;
@@ -209,7 +208,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_get"",
 	    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)
 		goto bad_block;
 
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 	if (buffer) {
 		error = -ERANGE;
@@ -247,6 +246,7 @@ ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)
 	char *end;
 	size_t rest = buffer_size;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	ea_idebug(inode, ""buffer=%p, buffer_size=%ld"",
 		  buffer, (long)buffer_size);
@@ -281,7 +281,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_list"",
 			goto bad_block;
 		entry = next;
 	}
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 
 	/* list the attribute names */
@@ -483,22 +483,23 @@ bad_block:		ext2_error(sb, ""ext2_xattr_set"",
 	/* Here we know that we can set the new attribute. */
 
 	if (header) {
-		struct mb_cache_entry *ce;
-
 		/* assert(header == HDR(bh)); */
-		ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,
-					bh->b_blocknr);
 		lock_buffer(bh);
 		if (header->h_refcount == cpu_to_le32(1)) {
+			__u32 hash = le32_to_cpu(header->h_hash);
+
 			ea_bdebug(bh, ""modifying in-place"");
-			if (ce)
-				mb_cache_entry_free(ce);
+			/*
+			 * This must happen under buffer lock for
+			 * ext2_xattr_set2() to reliably detect modified block
+			 */
+			mb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,
+						     hash, bh->b_blocknr);
+
 			/* keep the buffer locked while modifying it. */
 		} else {
 			int offset;
 
-			if (ce)
-				mb_cache_entry_release(ce);
 			unlock_buffer(bh);
 			ea_bdebug(bh, ""cloning"");
 			header = kmalloc(bh->b_size, GFP_KERNEL);
@@ -626,6 +627,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *new_bh = NULL;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;
 
 	if (header) {
 		new_bh = ext2_xattr_cache_find(inode, header);
@@ -653,7 +655,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 			   don't need to change the reference count. */
 			new_bh = old_bh;
 			get_bh(new_bh);
-			ext2_xattr_cache_insert(new_bh);
+			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
 		} else {
 			/* We need to allocate a new block */
 			ext2_fsblk_t goal = ext2_group_first_block_no(sb,
@@ -674,7 +676,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 			memcpy(new_bh->b_data, header, new_bh->b_size);
 			set_buffer_uptodate(new_bh);
 			unlock_buffer(new_bh);
-			ext2_xattr_cache_insert(new_bh);
+			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
 			
 			ext2_xattr_update_super_block(sb);
 		}
@@ -707,19 +709,21 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 
 	error = 0;
 	if (old_bh && old_bh != new_bh) {
-		struct mb_cache_entry *ce;
-
 		/*
 		 * If there was an old block and we are no longer using it,
 		 * release the old block.
 		 */
-		ce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,
-					old_bh->b_blocknr);
 		lock_buffer(old_bh);
 		if (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {
+			__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);
+
+			/*
+			 * This must happen under buffer lock for
+			 * ext2_xattr_set2() to reliably detect freed block
+			 */
+			mb2_cache_entry_delete_block(ext2_mb_cache,
+						     hash, old_bh->b_blocknr);
 			/* Free the old block. */
-			if (ce)
-				mb_cache_entry_free(ce);
 			ea_bdebug(old_bh, ""freeing"");
 			ext2_free_blocks(inode, old_bh->b_blocknr, 1);
 			mark_inode_dirty(inode);
@@ -730,8 +734,6 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 		} else {
 			/* Decrement the refcount only. */
 			le32_add_cpu(&HDR(old_bh)->h_refcount, -1);
-			if (ce)
-				mb_cache_entry_release(ce);
 			dquot_free_block_nodirty(inode, 1);
 			mark_inode_dirty(inode);
 			mark_buffer_dirty(old_bh);
@@ -757,7 +759,6 @@ void
 ext2_xattr_delete_inode(struct inode *inode)
 {
 	struct buffer_head *bh = NULL;
-	struct mb_cache_entry *ce;
 
 	down_write(&EXT2_I(inode)->xattr_sem);
 	if (!EXT2_I(inode)->i_file_acl)
@@ -777,19 +778,22 @@ ext2_xattr_delete_inode(struct inode *inode)
 			EXT2_I(inode)->i_file_acl);
 		goto cleanup;
 	}
-	ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);
 	lock_buffer(bh);
 	if (HDR(bh)->h_refcount == cpu_to_le32(1)) {
-		if (ce)
-			mb_cache_entry_free(ce);
+		__u32 hash = le32_to_cpu(HDR(bh)->h_hash);
+
+		/*
+		 * This must happen under buffer lock for ext2_xattr_set2() to
+		 * reliably detect freed block
+		 */
+		mb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,
+					     hash, bh->b_blocknr);
 		ext2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);
 		get_bh(bh);
 		bforget(bh);
 		unlock_buffer(bh);
 	} else {
 		le32_add_cpu(&HDR(bh)->h_refcount, -1);
-		if (ce)
-			mb_cache_entry_release(ce);
 		ea_bdebug(bh, ""refcount now=%d"",
 			le32_to_cpu(HDR(bh)->h_refcount));
 		unlock_buffer(bh);
@@ -805,18 +809,6 @@ ext2_xattr_delete_inode(struct inode *inode)
 	up_write(&EXT2_I(inode)->xattr_sem);
 }
 
-/*
- * ext2_xattr_put_super()
- *
- * This is called when a file system is unmounted.
- */
-void
-ext2_xattr_put_super(struct super_block *sb)
-{
-	mb_cache_shrink(sb->s_bdev);
-}
-
-
 /*
  * ext2_xattr_cache_insert()
  *
@@ -826,28 +818,20 @@ ext2_xattr_put_super(struct super_block *sb)
  * Returns 0, or a negative error number on failure.
  */
 static int
-ext2_xattr_cache_insert(struct buffer_head *bh)
+ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)
 {
 	__u32 hash = le32_to_cpu(HDR(bh)->h_hash);
-	struct mb_cache_entry *ce;
 	int error;
 
-	ce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);
-	if (!ce)
-		return -ENOMEM;
-	error = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);
+	error = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);
 	if (error) {
-		mb_cache_entry_free(ce);
 		if (error == -EBUSY) {
 			ea_bdebug(bh, ""already in cache (%d cache entries)"",
 				atomic_read(&ext2_xattr_cache->c_entry_count));
 			error = 0;
 		}
-	} else {
-		ea_bdebug(bh, ""inserting [%x] (%d cache entries)"", (int)hash,
-			  atomic_read(&ext2_xattr_cache->c_entry_count));
-		mb_cache_entry_release(ce);
-	}
+	} else
+		ea_bdebug(bh, ""inserting [%x]"", (int)hash);
 	return error;
 }
 
@@ -903,31 +887,39 @@ static struct buffer_head *
 ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)
 {
 	__u32 hash = le32_to_cpu(header->h_hash);
-	struct mb_cache_entry *ce;
+	struct mb2_cache_entry *ce;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	if (!header->h_hash)
 		return NULL;  /* never share */
 	ea_idebug(inode, ""looking for cached blocks [%x]"", (int)hash);
 again:
-	ce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,
-				       hash);
+	ce = mb2_cache_entry_find_first(ext2_mb_cache, hash);
 	while (ce) {
 		struct buffer_head *bh;
 
-		if (IS_ERR(ce)) {
-			if (PTR_ERR(ce) == -EAGAIN)
-				goto again;
-			break;
-		}
-
 		bh = sb_bread(inode->i_sb, ce->e_block);
 		if (!bh) {
 			ext2_error(inode->i_sb, ""ext2_xattr_cache_find"",
 				""inode %ld: block %ld read error"",
 				inode->i_ino, (unsigned long) ce->e_block);
 		} else {
 			lock_buffer(bh);
-			if (le32_to_cpu(HDR(bh)->h_refcount) >
+			/*
+			 * We have to be careful about races with freeing or
+			 * rehashing of xattr block. Once we hold buffer lock
+			 * xattr block's state is stable so we can check
+			 * whether the block got freed / rehashed or not.
+			 * Since we unhash mbcache entry under buffer lock when
+			 * freeing / rehashing xattr block, checking whether
+			 * entry is still hashed is reliable.
+			 */
+			if (hlist_bl_unhashed(&ce->e_hash_list)) {
+				mb2_cache_entry_put(ext2_mb_cache, ce);
+				unlock_buffer(bh);
+				brelse(bh);
+				goto again;
+			} else if (le32_to_cpu(HDR(bh)->h_refcount) >
 				   EXT2_XATTR_REFCOUNT_MAX) {
 				ea_idebug(inode, ""block %ld refcount %d>%d"",
 					  (unsigned long) ce->e_block,
@@ -936,13 +928,14 @@ ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)
 			} else if (!ext2_xattr_cmp(header, HDR(bh))) {
 				ea_bdebug(bh, ""b_count=%d"",
 					  atomic_read(&(bh->b_count)));
-				mb_cache_entry_release(ce);
+				mb2_cache_entry_touch(ext2_mb_cache, ce);
+				mb2_cache_entry_put(ext2_mb_cache, ce);
 				return bh;
 			}
 			unlock_buffer(bh);
 			brelse(bh);
 		}
-		ce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);
+		ce = mb2_cache_entry_find_next(ext2_mb_cache, ce);
 	}
 	return NULL;
 }
@@ -1015,17 +1008,15 @@ static void ext2_xattr_rehash(struct ext2_xattr_header *header,
 
 #undef BLOCK_HASH_SHIFT
 
-int __init
-init_ext2_xattr(void)
+#define HASH_BUCKET_BITS 10
+
+struct mb2_cache *ext2_xattr_create_cache(void)
 {
-	ext2_xattr_cache = mb_cache_create(""ext2_xattr"", 6);
-	if (!ext2_xattr_cache)
-		return -ENOMEM;
-	return 0;
+	return mb2_cache_create(HASH_BUCKET_BITS);
 }
 
-void
-exit_ext2_xattr(void)
+void ext2_xattr_destroy_cache(struct mb2_cache *cache)
 {
-	mb_cache_destroy(ext2_xattr_cache);
+	if (cache)
+		mb2_cache_destroy(cache);
 }",linux,be0726d33cb8f411945884664924bed3cb8c70ee,82939d7999dfc1f1998c4b1c12e2f19edbdff272,1,"ext2_xattr_cache_insert(struct buffer_head *bh)
//fix_flaw_line_below:
//ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)
 {
 	__u32 hash = le32_to_cpu(HDR(bh)->h_hash);
//flaw_line_below:
	struct mb_cache_entry *ce;
 	int error;
 
//flaw_line_below:
	ce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);
//flaw_line_below:
	if (!ce)
//flaw_line_below:
		return -ENOMEM;
//flaw_line_below:
	error = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);
//fix_flaw_line_below:
//	error = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);
 	if (error) {
//flaw_line_below:
		mb_cache_entry_free(ce);
 		if (error == -EBUSY) {
 			ea_bdebug(bh, ""already in cache (%d cache entries)"",
 				atomic_read(&ext2_xattr_cache->c_entry_count));
 			error = 0;
 		}
//flaw_line_below:
	} else {
//flaw_line_below:
		ea_bdebug(bh, ""inserting [%x] (%d cache entries)"", (int)hash,
//flaw_line_below:
			  atomic_read(&ext2_xattr_cache->c_entry_count));
//flaw_line_below:
		mb_cache_entry_release(ce);
//flaw_line_below:
	}
//fix_flaw_line_below:
//	} else
//fix_flaw_line_below:
//		ea_bdebug(bh, ""inserting [%x]"", (int)hash);
 	return error;
 }
"
5415,183151,,Local,Not required,Partial,CVE-2015-8952,https://www.cvedetails.com/cve/CVE-2015-8952/,CWE-19,Low,,,,2016-10-16,2.1,"The mbcache feature in the ext2 and ext4 filesystem implementations in the Linux kernel before 4.6 mishandles xattr block caching, which allows local users to cause a denial of service (soft lockup) via filesystem operations in environments that use many attributes, as demonstrated by Ceph and Samba.",2018-03-15,DoS ,8,https://github.com/torvalds/linux/commit/be0726d33cb8f411945884664924bed3cb8c70ee,be0726d33cb8f411945884664924bed3cb8c70ee,"ext2: convert to mbcache2

The conversion is generally straightforward. We convert filesystem from
a global cache to per-fs one. Similarly to ext4 the tricky part is that
xattr block corresponding to found mbcache entry can get freed before we
get buffer lock for that block. So we have to check whether the entry is
still valid after getting the buffer lock.

Signed-off-by: Jan Kara <jack@suse.cz>
Signed-off-by: Theodore Ts'o <tytso@mit.edu>",6,fs/ext2/xattr.c,"{""sha"": ""f98ce7e60a0f84f71743e0dfe069c7e96c6bd648"", ""filename"": ""fs/ext2/ext2.h"", ""status"": ""modified"", ""additions"": 3, ""deletions"": 0, ""changes"": 3, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/ext2.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -61,6 +61,8 @@ struct ext2_block_alloc_info {\n #define rsv_start rsv_window._rsv_start\n #define rsv_end rsv_window._rsv_end\n \n+struct mb2_cache;\n+\n /*\n  * second extended-fs super-block data in memory\n  */\n@@ -111,6 +113,7 @@ struct ext2_sb_info {\n \t * of the mount options.\n \t */\n \tspinlock_t s_lock;\n+\tstruct mb2_cache *s_mb_cache;\n };\n \n static inline spinlock_t *""}<_**next**_>{""sha"": ""b78caf25f746220ce635a3bd946bedeaf7e3e750"", ""filename"": ""fs/ext2/super.c"", ""status"": ""modified"", ""additions"": 17, ""deletions"": 8, ""changes"": 25, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/super.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -131,7 +131,10 @@ static void ext2_put_super (struct super_block * sb)\n \n \tdquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);\n \n-\text2_xattr_put_super(sb);\n+\tif (sbi->s_mb_cache) {\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n+\t\tsbi->s_mb_cache = NULL;\n+\t}\n \tif (!(sb->s_flags & MS_RDONLY)) {\n \t\tstruct ext2_super_block *es = sbi->s_es;\n \n@@ -1104,6 +1107,14 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\text2_msg(sb, KERN_ERR, \""error: insufficient memory\"");\n \t\tgoto failed_mount3;\n \t}\n+\n+#ifdef CONFIG_EXT2_FS_XATTR\n+\tsbi->s_mb_cache = ext2_xattr_create_cache();\n+\tif (!sbi->s_mb_cache) {\n+\t\text2_msg(sb, KERN_ERR, \""Failed to create an mb_cache\"");\n+\t\tgoto failed_mount3;\n+\t}\n+#endif\n \t/*\n \t * set up enough so that it can read an inode\n \t */\n@@ -1149,6 +1160,8 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\t\tsb->s_id);\n \tgoto failed_mount;\n failed_mount3:\n+\tif (sbi->s_mb_cache)\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n \tpercpu_counter_destroy(&sbi->s_freeblocks_counter);\n \tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n \tpercpu_counter_destroy(&sbi->s_dirs_counter);\n@@ -1555,28 +1568,24 @@ MODULE_ALIAS_FS(\""ext2\"");\n \n static int __init init_ext2_fs(void)\n {\n-\tint err = init_ext2_xattr();\n-\tif (err)\n-\t\treturn err;\n+\tint err;\n+\n \terr = init_inodecache();\n \tif (err)\n-\t\tgoto out1;\n+\t\treturn err;\n         err = register_filesystem(&ext2_fs_type);\n \tif (err)\n \t\tgoto out;\n \treturn 0;\n out:\n \tdestroy_inodecache();\n-out1:\n-\texit_ext2_xattr();\n \treturn err;\n }\n \n static void __exit exit_ext2_fs(void)\n {\n \tunregister_filesystem(&ext2_fs_type);\n \tdestroy_inodecache();\n-\texit_ext2_xattr();\n }\n \n MODULE_AUTHOR(\""Remy Card and others\"");""}<_**next**_>{""sha"": ""7162b4869bc32515800d8ffc06ac3835ea241c8b"", ""filename"": ""fs/ext2/xattr.c"", ""status"": ""modified"", ""additions"": 67, ""deletions"": 76, ""changes"": 143, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -56,7 +56,7 @@\n #include <linux/buffer_head.h>\n #include <linux/init.h>\n #include <linux/slab.h>\n-#include <linux/mbcache.h>\n+#include <linux/mbcache2.h>\n #include <linux/quotaops.h>\n #include <linux/rwsem.h>\n #include <linux/security.h>\n@@ -90,14 +90,12 @@\n static int ext2_xattr_set2(struct inode *, struct buffer_head *,\n \t\t\t   struct ext2_xattr_header *);\n \n-static int ext2_xattr_cache_insert(struct buffer_head *);\n+static int ext2_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);\n static struct buffer_head *ext2_xattr_cache_find(struct inode *,\n \t\t\t\t\t\t struct ext2_xattr_header *);\n static void ext2_xattr_rehash(struct ext2_xattr_header *,\n \t\t\t      struct ext2_xattr_entry *);\n \n-static struct mb_cache *ext2_xattr_cache;\n-\n static const struct xattr_handler *ext2_xattr_handler_map[] = {\n \t[EXT2_XATTR_INDEX_USER]\t\t     = &ext2_xattr_user_handler,\n #ifdef CONFIG_EXT2_FS_POSIX_ACL\n@@ -152,6 +150,7 @@ ext2_xattr_get(struct inode *inode, int name_index, const char *name,\n \tsize_t name_len, size;\n \tchar *end;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""name=%d.%s, buffer=%p, buffer_size=%ld\"",\n \t\t  name_index, name, buffer, (long)buffer_size);\n@@ -196,7 +195,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t\t\tgoto found;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \terror = -ENODATA;\n \tgoto cleanup;\n@@ -209,7 +208,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)\n \t\tgoto bad_block;\n \n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \tif (buffer) {\n \t\terror = -ERANGE;\n@@ -247,6 +246,7 @@ ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)\n \tchar *end;\n \tsize_t rest = buffer_size;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""buffer=%p, buffer_size=%ld\"",\n \t\t  buffer, (long)buffer_size);\n@@ -281,7 +281,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_list\"",\n \t\t\tgoto bad_block;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \n \t/* list the attribute names */\n@@ -483,22 +483,23 @@ bad_block:\t\text2_error(sb, \""ext2_xattr_set\"",\n \t/* Here we know that we can set the new attribute. */\n \n \tif (header) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/* assert(header == HDR(bh)); */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,\n-\t\t\t\t\tbh->b_blocknr);\n \t\tlock_buffer(bh);\n \t\tif (header->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(header->h_hash);\n+\n \t\t\tea_bdebug(bh, \""modifying in-place\"");\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect modified block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,\n+\t\t\t\t\t\t     hash, bh->b_blocknr);\n+\n \t\t\t/* keep the buffer locked while modifying it. */\n \t\t} else {\n \t\t\tint offset;\n \n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tunlock_buffer(bh);\n \t\t\tea_bdebug(bh, \""cloning\"");\n \t\t\theader = kmalloc(bh->b_size, GFP_KERNEL);\n@@ -626,6 +627,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \tstruct super_block *sb = inode->i_sb;\n \tstruct buffer_head *new_bh = NULL;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;\n \n \tif (header) {\n \t\tnew_bh = ext2_xattr_cache_find(inode, header);\n@@ -653,7 +655,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\t   don't need to change the reference count. */\n \t\t\tnew_bh = old_bh;\n \t\t\tget_bh(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t} else {\n \t\t\t/* We need to allocate a new block */\n \t\t\text2_fsblk_t goal = ext2_group_first_block_no(sb,\n@@ -674,7 +676,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\tmemcpy(new_bh->b_data, header, new_bh->b_size);\n \t\t\tset_buffer_uptodate(new_bh);\n \t\t\tunlock_buffer(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t\t\n \t\t\text2_xattr_update_super_block(sb);\n \t\t}\n@@ -707,19 +709,21 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \n \terror = 0;\n \tif (old_bh && old_bh != new_bh) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/*\n \t\t * If there was an old block and we are no longer using it,\n \t\t * release the old block.\n \t\t */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,\n-\t\t\t\t\told_bh->b_blocknr);\n \t\tlock_buffer(old_bh);\n \t\tif (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);\n+\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect freed block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(ext2_mb_cache,\n+\t\t\t\t\t\t     hash, old_bh->b_blocknr);\n \t\t\t/* Free the old block. */\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n \t\t\tea_bdebug(old_bh, \""freeing\"");\n \t\t\text2_free_blocks(inode, old_bh->b_blocknr, 1);\n \t\t\tmark_inode_dirty(inode);\n@@ -730,8 +734,6 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t} else {\n \t\t\t/* Decrement the refcount only. */\n \t\t\tle32_add_cpu(&HDR(old_bh)->h_refcount, -1);\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tdquot_free_block_nodirty(inode, 1);\n \t\t\tmark_inode_dirty(inode);\n \t\t\tmark_buffer_dirty(old_bh);\n@@ -757,7 +759,6 @@ void\n ext2_xattr_delete_inode(struct inode *inode)\n {\n \tstruct buffer_head *bh = NULL;\n-\tstruct mb_cache_entry *ce;\n \n \tdown_write(&EXT2_I(inode)->xattr_sem);\n \tif (!EXT2_I(inode)->i_file_acl)\n@@ -777,19 +778,22 @@ ext2_xattr_delete_inode(struct inode *inode)\n \t\t\tEXT2_I(inode)->i_file_acl);\n \t\tgoto cleanup;\n \t}\n-\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);\n \tlock_buffer(bh);\n \tif (HDR(bh)->h_refcount == cpu_to_le32(1)) {\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_free(ce);\n+\t\t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n+\n+\t\t/*\n+\t\t * This must happen under buffer lock for ext2_xattr_set2() to\n+\t\t * reliably detect freed block\n+\t\t */\n+\t\tmb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,\n+\t\t\t\t\t     hash, bh->b_blocknr);\n \t\text2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);\n \t\tget_bh(bh);\n \t\tbforget(bh);\n \t\tunlock_buffer(bh);\n \t} else {\n \t\tle32_add_cpu(&HDR(bh)->h_refcount, -1);\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_release(ce);\n \t\tea_bdebug(bh, \""refcount now=%d\"",\n \t\t\tle32_to_cpu(HDR(bh)->h_refcount));\n \t\tunlock_buffer(bh);\n@@ -805,18 +809,6 @@ ext2_xattr_delete_inode(struct inode *inode)\n \tup_write(&EXT2_I(inode)->xattr_sem);\n }\n \n-/*\n- * ext2_xattr_put_super()\n- *\n- * This is called when a file system is unmounted.\n- */\n-void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-\tmb_cache_shrink(sb->s_bdev);\n-}\n-\n-\n /*\n  * ext2_xattr_cache_insert()\n  *\n@@ -826,28 +818,20 @@ ext2_xattr_put_super(struct super_block *sb)\n  * Returns 0, or a negative error number on failure.\n  */\n static int\n-ext2_xattr_cache_insert(struct buffer_head *bh)\n+ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)\n {\n \t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n-\tstruct mb_cache_entry *ce;\n \tint error;\n \n-\tce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);\n-\tif (!ce)\n-\t\treturn -ENOMEM;\n-\terror = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);\n+\terror = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);\n \tif (error) {\n-\t\tmb_cache_entry_free(ce);\n \t\tif (error == -EBUSY) {\n \t\t\tea_bdebug(bh, \""already in cache (%d cache entries)\"",\n \t\t\t\tatomic_read(&ext2_xattr_cache->c_entry_count));\n \t\t\terror = 0;\n \t\t}\n-\t} else {\n-\t\tea_bdebug(bh, \""inserting [%x] (%d cache entries)\"", (int)hash,\n-\t\t\t  atomic_read(&ext2_xattr_cache->c_entry_count));\n-\t\tmb_cache_entry_release(ce);\n-\t}\n+\t} else\n+\t\tea_bdebug(bh, \""inserting [%x]\"", (int)hash);\n \treturn error;\n }\n \n@@ -903,31 +887,39 @@ static struct buffer_head *\n ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n {\n \t__u32 hash = le32_to_cpu(header->h_hash);\n-\tstruct mb_cache_entry *ce;\n+\tstruct mb2_cache_entry *ce;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tif (!header->h_hash)\n \t\treturn NULL;  /* never share */\n \tea_idebug(inode, \""looking for cached blocks [%x]\"", (int)hash);\n again:\n-\tce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,\n-\t\t\t\t       hash);\n+\tce = mb2_cache_entry_find_first(ext2_mb_cache, hash);\n \twhile (ce) {\n \t\tstruct buffer_head *bh;\n \n-\t\tif (IS_ERR(ce)) {\n-\t\t\tif (PTR_ERR(ce) == -EAGAIN)\n-\t\t\t\tgoto again;\n-\t\t\tbreak;\n-\t\t}\n-\n \t\tbh = sb_bread(inode->i_sb, ce->e_block);\n \t\tif (!bh) {\n \t\t\text2_error(inode->i_sb, \""ext2_xattr_cache_find\"",\n \t\t\t\t\""inode %ld: block %ld read error\"",\n \t\t\t\tinode->i_ino, (unsigned long) ce->e_block);\n \t\t} else {\n \t\t\tlock_buffer(bh);\n-\t\t\tif (le32_to_cpu(HDR(bh)->h_refcount) >\n+\t\t\t/*\n+\t\t\t * We have to be careful about races with freeing or\n+\t\t\t * rehashing of xattr block. Once we hold buffer lock\n+\t\t\t * xattr block's state is stable so we can check\n+\t\t\t * whether the block got freed / rehashed or not.\n+\t\t\t * Since we unhash mbcache entry under buffer lock when\n+\t\t\t * freeing / rehashing xattr block, checking whether\n+\t\t\t * entry is still hashed is reliable.\n+\t\t\t */\n+\t\t\tif (hlist_bl_unhashed(&ce->e_hash_list)) {\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n+\t\t\t\tunlock_buffer(bh);\n+\t\t\t\tbrelse(bh);\n+\t\t\t\tgoto again;\n+\t\t\t} else if (le32_to_cpu(HDR(bh)->h_refcount) >\n \t\t\t\t   EXT2_XATTR_REFCOUNT_MAX) {\n \t\t\t\tea_idebug(inode, \""block %ld refcount %d>%d\"",\n \t\t\t\t\t  (unsigned long) ce->e_block,\n@@ -936,13 +928,14 @@ ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n \t\t\t} else if (!ext2_xattr_cmp(header, HDR(bh))) {\n \t\t\t\tea_bdebug(bh, \""b_count=%d\"",\n \t\t\t\t\t  atomic_read(&(bh->b_count)));\n-\t\t\t\tmb_cache_entry_release(ce);\n+\t\t\t\tmb2_cache_entry_touch(ext2_mb_cache, ce);\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n \t\t\t\treturn bh;\n \t\t\t}\n \t\t\tunlock_buffer(bh);\n \t\t\tbrelse(bh);\n \t\t}\n-\t\tce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);\n+\t\tce = mb2_cache_entry_find_next(ext2_mb_cache, ce);\n \t}\n \treturn NULL;\n }\n@@ -1015,17 +1008,15 @@ static void ext2_xattr_rehash(struct ext2_xattr_header *header,\n \n #undef BLOCK_HASH_SHIFT\n \n-int __init\n-init_ext2_xattr(void)\n+#define HASH_BUCKET_BITS 10\n+\n+struct mb2_cache *ext2_xattr_create_cache(void)\n {\n-\text2_xattr_cache = mb_cache_create(\""ext2_xattr\"", 6);\n-\tif (!ext2_xattr_cache)\n-\t\treturn -ENOMEM;\n-\treturn 0;\n+\treturn mb2_cache_create(HASH_BUCKET_BITS);\n }\n \n-void\n-exit_ext2_xattr(void)\n+void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n-\tmb_cache_destroy(ext2_xattr_cache);\n+\tif (cache)\n+\t\tmb2_cache_destroy(cache);\n }""}<_**next**_>{""sha"": ""6ea38aa9563a00649bf25544eed131bbe8b1d88d"", ""filename"": ""fs/ext2/xattr.h"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 16, ""changes"": 21, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -53,6 +53,8 @@ struct ext2_xattr_entry {\n #define EXT2_XATTR_SIZE(size) \\\n \t(((size) + EXT2_XATTR_ROUND) & ~EXT2_XATTR_ROUND)\n \n+struct mb2_cache;\n+\n # ifdef CONFIG_EXT2_FS_XATTR\n \n extern const struct xattr_handler ext2_xattr_user_handler;\n@@ -65,10 +67,9 @@ extern int ext2_xattr_get(struct inode *, int, const char *, void *, size_t);\n extern int ext2_xattr_set(struct inode *, int, const char *, const void *, size_t, int);\n \n extern void ext2_xattr_delete_inode(struct inode *);\n-extern void ext2_xattr_put_super(struct super_block *);\n \n-extern int init_ext2_xattr(void);\n-extern void exit_ext2_xattr(void);\n+extern struct mb2_cache *ext2_xattr_create_cache(void);\n+extern void ext2_xattr_destroy_cache(struct mb2_cache *cache);\n \n extern const struct xattr_handler *ext2_xattr_handlers[];\n \n@@ -93,19 +94,7 @@ ext2_xattr_delete_inode(struct inode *inode)\n {\n }\n \n-static inline void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-}\n-\n-static inline int\n-init_ext2_xattr(void)\n-{\n-\treturn 0;\n-}\n-\n-static inline void\n-exit_ext2_xattr(void)\n+static inline void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n }\n ""}"," ext2_xattr_delete_inode(struct inode *inode)
 {
 	struct buffer_head *bh = NULL;
 
 	down_write(&EXT2_I(inode)->xattr_sem);
 	if (!EXT2_I(inode)->i_file_acl)
		goto cleanup;
	bh = sb_bread(inode->i_sb, EXT2_I(inode)->i_file_acl);
	if (!bh) {
		ext2_error(inode->i_sb, ""ext2_xattr_delete_inode"",
			""inode %ld: block %d read error"", inode->i_ino,
			EXT2_I(inode)->i_file_acl);
		goto cleanup;
	}
	ea_bdebug(bh, ""b_count=%d"", atomic_read(&(bh->b_count)));
	if (HDR(bh)->h_magic != cpu_to_le32(EXT2_XATTR_MAGIC) ||
	    HDR(bh)->h_blocks != cpu_to_le32(1)) {
		ext2_error(inode->i_sb, ""ext2_xattr_delete_inode"",
			""inode %ld: bad block %d"", inode->i_ino,
 			EXT2_I(inode)->i_file_acl);
 		goto cleanup;
 	}
 	lock_buffer(bh);
 	if (HDR(bh)->h_refcount == cpu_to_le32(1)) {
		__u32 hash = le32_to_cpu(HDR(bh)->h_hash);

		/*
		 * This must happen under buffer lock for ext2_xattr_set2() to
		 * reliably detect freed block
		 */
		mb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,
					     hash, bh->b_blocknr);
 		ext2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);
 		get_bh(bh);
 		bforget(bh);
 		unlock_buffer(bh);
 	} else {
 		le32_add_cpu(&HDR(bh)->h_refcount, -1);
 		ea_bdebug(bh, ""refcount now=%d"",
 			le32_to_cpu(HDR(bh)->h_refcount));
 		unlock_buffer(bh);
		mark_buffer_dirty(bh);
		if (IS_SYNC(inode))
			sync_dirty_buffer(bh);
		dquot_free_block_nodirty(inode, 1);
	}
	EXT2_I(inode)->i_file_acl = 0;

cleanup:
	brelse(bh);
 	up_write(&EXT2_I(inode)->xattr_sem);
 }
"," ext2_xattr_delete_inode(struct inode *inode)
 {
 	struct buffer_head *bh = NULL;
	struct mb_cache_entry *ce;
 
 	down_write(&EXT2_I(inode)->xattr_sem);
 	if (!EXT2_I(inode)->i_file_acl)
		goto cleanup;
	bh = sb_bread(inode->i_sb, EXT2_I(inode)->i_file_acl);
	if (!bh) {
		ext2_error(inode->i_sb, ""ext2_xattr_delete_inode"",
			""inode %ld: block %d read error"", inode->i_ino,
			EXT2_I(inode)->i_file_acl);
		goto cleanup;
	}
	ea_bdebug(bh, ""b_count=%d"", atomic_read(&(bh->b_count)));
	if (HDR(bh)->h_magic != cpu_to_le32(EXT2_XATTR_MAGIC) ||
	    HDR(bh)->h_blocks != cpu_to_le32(1)) {
		ext2_error(inode->i_sb, ""ext2_xattr_delete_inode"",
			""inode %ld: bad block %d"", inode->i_ino,
 			EXT2_I(inode)->i_file_acl);
 		goto cleanup;
 	}
	ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);
 	lock_buffer(bh);
 	if (HDR(bh)->h_refcount == cpu_to_le32(1)) {
		if (ce)
			mb_cache_entry_free(ce);
 		ext2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);
 		get_bh(bh);
 		bforget(bh);
 		unlock_buffer(bh);
 	} else {
 		le32_add_cpu(&HDR(bh)->h_refcount, -1);
		if (ce)
			mb_cache_entry_release(ce);
 		ea_bdebug(bh, ""refcount now=%d"",
 			le32_to_cpu(HDR(bh)->h_refcount));
 		unlock_buffer(bh);
		mark_buffer_dirty(bh);
		if (IS_SYNC(inode))
			sync_dirty_buffer(bh);
		dquot_free_block_nodirty(inode, 1);
	}
	EXT2_I(inode)->i_file_acl = 0;

cleanup:
	brelse(bh);
 	up_write(&EXT2_I(inode)->xattr_sem);
 }
",C,"		__u32 hash = le32_to_cpu(HDR(bh)->h_hash);

		/*
		 * This must happen under buffer lock for ext2_xattr_set2() to
		 * reliably detect freed block
		 */
		mb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,
					     hash, bh->b_blocknr);
","	struct mb_cache_entry *ce;
	ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);
		if (ce)
			mb_cache_entry_free(ce);
		if (ce)
			mb_cache_entry_release(ce);
",,"@@ -56,7 +56,7 @@
 #include <linux/buffer_head.h>
 #include <linux/init.h>
 #include <linux/slab.h>
-#include <linux/mbcache.h>
+#include <linux/mbcache2.h>
 #include <linux/quotaops.h>
 #include <linux/rwsem.h>
 #include <linux/security.h>
@@ -90,14 +90,12 @@
 static int ext2_xattr_set2(struct inode *, struct buffer_head *,
 			   struct ext2_xattr_header *);
 
-static int ext2_xattr_cache_insert(struct buffer_head *);
+static int ext2_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);
 static struct buffer_head *ext2_xattr_cache_find(struct inode *,
 						 struct ext2_xattr_header *);
 static void ext2_xattr_rehash(struct ext2_xattr_header *,
 			      struct ext2_xattr_entry *);
 
-static struct mb_cache *ext2_xattr_cache;
-
 static const struct xattr_handler *ext2_xattr_handler_map[] = {
 	[EXT2_XATTR_INDEX_USER]		     = &ext2_xattr_user_handler,
 #ifdef CONFIG_EXT2_FS_POSIX_ACL
@@ -152,6 +150,7 @@ ext2_xattr_get(struct inode *inode, int name_index, const char *name,
 	size_t name_len, size;
 	char *end;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	ea_idebug(inode, ""name=%d.%s, buffer=%p, buffer_size=%ld"",
 		  name_index, name, buffer, (long)buffer_size);
@@ -196,7 +195,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_get"",
 			goto found;
 		entry = next;
 	}
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 	error = -ENODATA;
 	goto cleanup;
@@ -209,7 +208,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_get"",
 	    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)
 		goto bad_block;
 
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 	if (buffer) {
 		error = -ERANGE;
@@ -247,6 +246,7 @@ ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)
 	char *end;
 	size_t rest = buffer_size;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	ea_idebug(inode, ""buffer=%p, buffer_size=%ld"",
 		  buffer, (long)buffer_size);
@@ -281,7 +281,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_list"",
 			goto bad_block;
 		entry = next;
 	}
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 
 	/* list the attribute names */
@@ -483,22 +483,23 @@ bad_block:		ext2_error(sb, ""ext2_xattr_set"",
 	/* Here we know that we can set the new attribute. */
 
 	if (header) {
-		struct mb_cache_entry *ce;
-
 		/* assert(header == HDR(bh)); */
-		ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,
-					bh->b_blocknr);
 		lock_buffer(bh);
 		if (header->h_refcount == cpu_to_le32(1)) {
+			__u32 hash = le32_to_cpu(header->h_hash);
+
 			ea_bdebug(bh, ""modifying in-place"");
-			if (ce)
-				mb_cache_entry_free(ce);
+			/*
+			 * This must happen under buffer lock for
+			 * ext2_xattr_set2() to reliably detect modified block
+			 */
+			mb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,
+						     hash, bh->b_blocknr);
+
 			/* keep the buffer locked while modifying it. */
 		} else {
 			int offset;
 
-			if (ce)
-				mb_cache_entry_release(ce);
 			unlock_buffer(bh);
 			ea_bdebug(bh, ""cloning"");
 			header = kmalloc(bh->b_size, GFP_KERNEL);
@@ -626,6 +627,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *new_bh = NULL;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;
 
 	if (header) {
 		new_bh = ext2_xattr_cache_find(inode, header);
@@ -653,7 +655,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 			   don't need to change the reference count. */
 			new_bh = old_bh;
 			get_bh(new_bh);
-			ext2_xattr_cache_insert(new_bh);
+			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
 		} else {
 			/* We need to allocate a new block */
 			ext2_fsblk_t goal = ext2_group_first_block_no(sb,
@@ -674,7 +676,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 			memcpy(new_bh->b_data, header, new_bh->b_size);
 			set_buffer_uptodate(new_bh);
 			unlock_buffer(new_bh);
-			ext2_xattr_cache_insert(new_bh);
+			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
 			
 			ext2_xattr_update_super_block(sb);
 		}
@@ -707,19 +709,21 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 
 	error = 0;
 	if (old_bh && old_bh != new_bh) {
-		struct mb_cache_entry *ce;
-
 		/*
 		 * If there was an old block and we are no longer using it,
 		 * release the old block.
 		 */
-		ce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,
-					old_bh->b_blocknr);
 		lock_buffer(old_bh);
 		if (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {
+			__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);
+
+			/*
+			 * This must happen under buffer lock for
+			 * ext2_xattr_set2() to reliably detect freed block
+			 */
+			mb2_cache_entry_delete_block(ext2_mb_cache,
+						     hash, old_bh->b_blocknr);
 			/* Free the old block. */
-			if (ce)
-				mb_cache_entry_free(ce);
 			ea_bdebug(old_bh, ""freeing"");
 			ext2_free_blocks(inode, old_bh->b_blocknr, 1);
 			mark_inode_dirty(inode);
@@ -730,8 +734,6 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 		} else {
 			/* Decrement the refcount only. */
 			le32_add_cpu(&HDR(old_bh)->h_refcount, -1);
-			if (ce)
-				mb_cache_entry_release(ce);
 			dquot_free_block_nodirty(inode, 1);
 			mark_inode_dirty(inode);
 			mark_buffer_dirty(old_bh);
@@ -757,7 +759,6 @@ void
 ext2_xattr_delete_inode(struct inode *inode)
 {
 	struct buffer_head *bh = NULL;
-	struct mb_cache_entry *ce;
 
 	down_write(&EXT2_I(inode)->xattr_sem);
 	if (!EXT2_I(inode)->i_file_acl)
@@ -777,19 +778,22 @@ ext2_xattr_delete_inode(struct inode *inode)
 			EXT2_I(inode)->i_file_acl);
 		goto cleanup;
 	}
-	ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);
 	lock_buffer(bh);
 	if (HDR(bh)->h_refcount == cpu_to_le32(1)) {
-		if (ce)
-			mb_cache_entry_free(ce);
+		__u32 hash = le32_to_cpu(HDR(bh)->h_hash);
+
+		/*
+		 * This must happen under buffer lock for ext2_xattr_set2() to
+		 * reliably detect freed block
+		 */
+		mb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,
+					     hash, bh->b_blocknr);
 		ext2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);
 		get_bh(bh);
 		bforget(bh);
 		unlock_buffer(bh);
 	} else {
 		le32_add_cpu(&HDR(bh)->h_refcount, -1);
-		if (ce)
-			mb_cache_entry_release(ce);
 		ea_bdebug(bh, ""refcount now=%d"",
 			le32_to_cpu(HDR(bh)->h_refcount));
 		unlock_buffer(bh);
@@ -805,18 +809,6 @@ ext2_xattr_delete_inode(struct inode *inode)
 	up_write(&EXT2_I(inode)->xattr_sem);
 }
 
-/*
- * ext2_xattr_put_super()
- *
- * This is called when a file system is unmounted.
- */
-void
-ext2_xattr_put_super(struct super_block *sb)
-{
-	mb_cache_shrink(sb->s_bdev);
-}
-
-
 /*
  * ext2_xattr_cache_insert()
  *
@@ -826,28 +818,20 @@ ext2_xattr_put_super(struct super_block *sb)
  * Returns 0, or a negative error number on failure.
  */
 static int
-ext2_xattr_cache_insert(struct buffer_head *bh)
+ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)
 {
 	__u32 hash = le32_to_cpu(HDR(bh)->h_hash);
-	struct mb_cache_entry *ce;
 	int error;
 
-	ce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);
-	if (!ce)
-		return -ENOMEM;
-	error = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);
+	error = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);
 	if (error) {
-		mb_cache_entry_free(ce);
 		if (error == -EBUSY) {
 			ea_bdebug(bh, ""already in cache (%d cache entries)"",
 				atomic_read(&ext2_xattr_cache->c_entry_count));
 			error = 0;
 		}
-	} else {
-		ea_bdebug(bh, ""inserting [%x] (%d cache entries)"", (int)hash,
-			  atomic_read(&ext2_xattr_cache->c_entry_count));
-		mb_cache_entry_release(ce);
-	}
+	} else
+		ea_bdebug(bh, ""inserting [%x]"", (int)hash);
 	return error;
 }
 
@@ -903,31 +887,39 @@ static struct buffer_head *
 ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)
 {
 	__u32 hash = le32_to_cpu(header->h_hash);
-	struct mb_cache_entry *ce;
+	struct mb2_cache_entry *ce;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	if (!header->h_hash)
 		return NULL;  /* never share */
 	ea_idebug(inode, ""looking for cached blocks [%x]"", (int)hash);
 again:
-	ce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,
-				       hash);
+	ce = mb2_cache_entry_find_first(ext2_mb_cache, hash);
 	while (ce) {
 		struct buffer_head *bh;
 
-		if (IS_ERR(ce)) {
-			if (PTR_ERR(ce) == -EAGAIN)
-				goto again;
-			break;
-		}
-
 		bh = sb_bread(inode->i_sb, ce->e_block);
 		if (!bh) {
 			ext2_error(inode->i_sb, ""ext2_xattr_cache_find"",
 				""inode %ld: block %ld read error"",
 				inode->i_ino, (unsigned long) ce->e_block);
 		} else {
 			lock_buffer(bh);
-			if (le32_to_cpu(HDR(bh)->h_refcount) >
+			/*
+			 * We have to be careful about races with freeing or
+			 * rehashing of xattr block. Once we hold buffer lock
+			 * xattr block's state is stable so we can check
+			 * whether the block got freed / rehashed or not.
+			 * Since we unhash mbcache entry under buffer lock when
+			 * freeing / rehashing xattr block, checking whether
+			 * entry is still hashed is reliable.
+			 */
+			if (hlist_bl_unhashed(&ce->e_hash_list)) {
+				mb2_cache_entry_put(ext2_mb_cache, ce);
+				unlock_buffer(bh);
+				brelse(bh);
+				goto again;
+			} else if (le32_to_cpu(HDR(bh)->h_refcount) >
 				   EXT2_XATTR_REFCOUNT_MAX) {
 				ea_idebug(inode, ""block %ld refcount %d>%d"",
 					  (unsigned long) ce->e_block,
@@ -936,13 +928,14 @@ ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)
 			} else if (!ext2_xattr_cmp(header, HDR(bh))) {
 				ea_bdebug(bh, ""b_count=%d"",
 					  atomic_read(&(bh->b_count)));
-				mb_cache_entry_release(ce);
+				mb2_cache_entry_touch(ext2_mb_cache, ce);
+				mb2_cache_entry_put(ext2_mb_cache, ce);
 				return bh;
 			}
 			unlock_buffer(bh);
 			brelse(bh);
 		}
-		ce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);
+		ce = mb2_cache_entry_find_next(ext2_mb_cache, ce);
 	}
 	return NULL;
 }
@@ -1015,17 +1008,15 @@ static void ext2_xattr_rehash(struct ext2_xattr_header *header,
 
 #undef BLOCK_HASH_SHIFT
 
-int __init
-init_ext2_xattr(void)
+#define HASH_BUCKET_BITS 10
+
+struct mb2_cache *ext2_xattr_create_cache(void)
 {
-	ext2_xattr_cache = mb_cache_create(""ext2_xattr"", 6);
-	if (!ext2_xattr_cache)
-		return -ENOMEM;
-	return 0;
+	return mb2_cache_create(HASH_BUCKET_BITS);
 }
 
-void
-exit_ext2_xattr(void)
+void ext2_xattr_destroy_cache(struct mb2_cache *cache)
 {
-	mb_cache_destroy(ext2_xattr_cache);
+	if (cache)
+		mb2_cache_destroy(cache);
 }",linux,be0726d33cb8f411945884664924bed3cb8c70ee,82939d7999dfc1f1998c4b1c12e2f19edbdff272,1," ext2_xattr_delete_inode(struct inode *inode)
 {
 	struct buffer_head *bh = NULL;
//flaw_line_below:
	struct mb_cache_entry *ce;
 
 	down_write(&EXT2_I(inode)->xattr_sem);
 	if (!EXT2_I(inode)->i_file_acl)
		goto cleanup;
	bh = sb_bread(inode->i_sb, EXT2_I(inode)->i_file_acl);
	if (!bh) {
		ext2_error(inode->i_sb, ""ext2_xattr_delete_inode"",
			""inode %ld: block %d read error"", inode->i_ino,
			EXT2_I(inode)->i_file_acl);
		goto cleanup;
	}
	ea_bdebug(bh, ""b_count=%d"", atomic_read(&(bh->b_count)));
	if (HDR(bh)->h_magic != cpu_to_le32(EXT2_XATTR_MAGIC) ||
	    HDR(bh)->h_blocks != cpu_to_le32(1)) {
		ext2_error(inode->i_sb, ""ext2_xattr_delete_inode"",
			""inode %ld: bad block %d"", inode->i_ino,
 			EXT2_I(inode)->i_file_acl);
 		goto cleanup;
 	}
//flaw_line_below:
	ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);
 	lock_buffer(bh);
 	if (HDR(bh)->h_refcount == cpu_to_le32(1)) {
//flaw_line_below:
		if (ce)
//flaw_line_below:
			mb_cache_entry_free(ce);
//fix_flaw_line_below:
//		__u32 hash = le32_to_cpu(HDR(bh)->h_hash);
//fix_flaw_line_below:
//
//fix_flaw_line_below:
//		/*
//fix_flaw_line_below:
//		 * This must happen under buffer lock for ext2_xattr_set2() to
//fix_flaw_line_below:
//		 * reliably detect freed block
//fix_flaw_line_below:
//		 */
//fix_flaw_line_below:
//		mb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,
//fix_flaw_line_below:
//					     hash, bh->b_blocknr);
 		ext2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);
 		get_bh(bh);
 		bforget(bh);
 		unlock_buffer(bh);
 	} else {
 		le32_add_cpu(&HDR(bh)->h_refcount, -1);
//flaw_line_below:
		if (ce)
//flaw_line_below:
			mb_cache_entry_release(ce);
 		ea_bdebug(bh, ""refcount now=%d"",
 			le32_to_cpu(HDR(bh)->h_refcount));
 		unlock_buffer(bh);
		mark_buffer_dirty(bh);
		if (IS_SYNC(inode))
			sync_dirty_buffer(bh);
		dquot_free_block_nodirty(inode, 1);
	}
	EXT2_I(inode)->i_file_acl = 0;

cleanup:
	brelse(bh);
 	up_write(&EXT2_I(inode)->xattr_sem);
 }
"
5416,183152,,Local,Not required,Partial,CVE-2015-8952,https://www.cvedetails.com/cve/CVE-2015-8952/,CWE-19,Low,,,,2016-10-16,2.1,"The mbcache feature in the ext2 and ext4 filesystem implementations in the Linux kernel before 4.6 mishandles xattr block caching, which allows local users to cause a denial of service (soft lockup) via filesystem operations in environments that use many attributes, as demonstrated by Ceph and Samba.",2018-03-15,DoS ,3,https://github.com/torvalds/linux/commit/be0726d33cb8f411945884664924bed3cb8c70ee,be0726d33cb8f411945884664924bed3cb8c70ee,"ext2: convert to mbcache2

The conversion is generally straightforward. We convert filesystem from
a global cache to per-fs one. Similarly to ext4 the tricky part is that
xattr block corresponding to found mbcache entry can get freed before we
get buffer lock for that block. So we have to check whether the entry is
still valid after getting the buffer lock.

Signed-off-by: Jan Kara <jack@suse.cz>
Signed-off-by: Theodore Ts'o <tytso@mit.edu>",2,fs/ext2/xattr.c,"{""sha"": ""f98ce7e60a0f84f71743e0dfe069c7e96c6bd648"", ""filename"": ""fs/ext2/ext2.h"", ""status"": ""modified"", ""additions"": 3, ""deletions"": 0, ""changes"": 3, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/ext2.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -61,6 +61,8 @@ struct ext2_block_alloc_info {\n #define rsv_start rsv_window._rsv_start\n #define rsv_end rsv_window._rsv_end\n \n+struct mb2_cache;\n+\n /*\n  * second extended-fs super-block data in memory\n  */\n@@ -111,6 +113,7 @@ struct ext2_sb_info {\n \t * of the mount options.\n \t */\n \tspinlock_t s_lock;\n+\tstruct mb2_cache *s_mb_cache;\n };\n \n static inline spinlock_t *""}<_**next**_>{""sha"": ""b78caf25f746220ce635a3bd946bedeaf7e3e750"", ""filename"": ""fs/ext2/super.c"", ""status"": ""modified"", ""additions"": 17, ""deletions"": 8, ""changes"": 25, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/super.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -131,7 +131,10 @@ static void ext2_put_super (struct super_block * sb)\n \n \tdquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);\n \n-\text2_xattr_put_super(sb);\n+\tif (sbi->s_mb_cache) {\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n+\t\tsbi->s_mb_cache = NULL;\n+\t}\n \tif (!(sb->s_flags & MS_RDONLY)) {\n \t\tstruct ext2_super_block *es = sbi->s_es;\n \n@@ -1104,6 +1107,14 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\text2_msg(sb, KERN_ERR, \""error: insufficient memory\"");\n \t\tgoto failed_mount3;\n \t}\n+\n+#ifdef CONFIG_EXT2_FS_XATTR\n+\tsbi->s_mb_cache = ext2_xattr_create_cache();\n+\tif (!sbi->s_mb_cache) {\n+\t\text2_msg(sb, KERN_ERR, \""Failed to create an mb_cache\"");\n+\t\tgoto failed_mount3;\n+\t}\n+#endif\n \t/*\n \t * set up enough so that it can read an inode\n \t */\n@@ -1149,6 +1160,8 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\t\tsb->s_id);\n \tgoto failed_mount;\n failed_mount3:\n+\tif (sbi->s_mb_cache)\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n \tpercpu_counter_destroy(&sbi->s_freeblocks_counter);\n \tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n \tpercpu_counter_destroy(&sbi->s_dirs_counter);\n@@ -1555,28 +1568,24 @@ MODULE_ALIAS_FS(\""ext2\"");\n \n static int __init init_ext2_fs(void)\n {\n-\tint err = init_ext2_xattr();\n-\tif (err)\n-\t\treturn err;\n+\tint err;\n+\n \terr = init_inodecache();\n \tif (err)\n-\t\tgoto out1;\n+\t\treturn err;\n         err = register_filesystem(&ext2_fs_type);\n \tif (err)\n \t\tgoto out;\n \treturn 0;\n out:\n \tdestroy_inodecache();\n-out1:\n-\texit_ext2_xattr();\n \treturn err;\n }\n \n static void __exit exit_ext2_fs(void)\n {\n \tunregister_filesystem(&ext2_fs_type);\n \tdestroy_inodecache();\n-\texit_ext2_xattr();\n }\n \n MODULE_AUTHOR(\""Remy Card and others\"");""}<_**next**_>{""sha"": ""7162b4869bc32515800d8ffc06ac3835ea241c8b"", ""filename"": ""fs/ext2/xattr.c"", ""status"": ""modified"", ""additions"": 67, ""deletions"": 76, ""changes"": 143, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -56,7 +56,7 @@\n #include <linux/buffer_head.h>\n #include <linux/init.h>\n #include <linux/slab.h>\n-#include <linux/mbcache.h>\n+#include <linux/mbcache2.h>\n #include <linux/quotaops.h>\n #include <linux/rwsem.h>\n #include <linux/security.h>\n@@ -90,14 +90,12 @@\n static int ext2_xattr_set2(struct inode *, struct buffer_head *,\n \t\t\t   struct ext2_xattr_header *);\n \n-static int ext2_xattr_cache_insert(struct buffer_head *);\n+static int ext2_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);\n static struct buffer_head *ext2_xattr_cache_find(struct inode *,\n \t\t\t\t\t\t struct ext2_xattr_header *);\n static void ext2_xattr_rehash(struct ext2_xattr_header *,\n \t\t\t      struct ext2_xattr_entry *);\n \n-static struct mb_cache *ext2_xattr_cache;\n-\n static const struct xattr_handler *ext2_xattr_handler_map[] = {\n \t[EXT2_XATTR_INDEX_USER]\t\t     = &ext2_xattr_user_handler,\n #ifdef CONFIG_EXT2_FS_POSIX_ACL\n@@ -152,6 +150,7 @@ ext2_xattr_get(struct inode *inode, int name_index, const char *name,\n \tsize_t name_len, size;\n \tchar *end;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""name=%d.%s, buffer=%p, buffer_size=%ld\"",\n \t\t  name_index, name, buffer, (long)buffer_size);\n@@ -196,7 +195,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t\t\tgoto found;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \terror = -ENODATA;\n \tgoto cleanup;\n@@ -209,7 +208,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)\n \t\tgoto bad_block;\n \n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \tif (buffer) {\n \t\terror = -ERANGE;\n@@ -247,6 +246,7 @@ ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)\n \tchar *end;\n \tsize_t rest = buffer_size;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""buffer=%p, buffer_size=%ld\"",\n \t\t  buffer, (long)buffer_size);\n@@ -281,7 +281,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_list\"",\n \t\t\tgoto bad_block;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \n \t/* list the attribute names */\n@@ -483,22 +483,23 @@ bad_block:\t\text2_error(sb, \""ext2_xattr_set\"",\n \t/* Here we know that we can set the new attribute. */\n \n \tif (header) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/* assert(header == HDR(bh)); */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,\n-\t\t\t\t\tbh->b_blocknr);\n \t\tlock_buffer(bh);\n \t\tif (header->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(header->h_hash);\n+\n \t\t\tea_bdebug(bh, \""modifying in-place\"");\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect modified block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,\n+\t\t\t\t\t\t     hash, bh->b_blocknr);\n+\n \t\t\t/* keep the buffer locked while modifying it. */\n \t\t} else {\n \t\t\tint offset;\n \n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tunlock_buffer(bh);\n \t\t\tea_bdebug(bh, \""cloning\"");\n \t\t\theader = kmalloc(bh->b_size, GFP_KERNEL);\n@@ -626,6 +627,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \tstruct super_block *sb = inode->i_sb;\n \tstruct buffer_head *new_bh = NULL;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;\n \n \tif (header) {\n \t\tnew_bh = ext2_xattr_cache_find(inode, header);\n@@ -653,7 +655,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\t   don't need to change the reference count. */\n \t\t\tnew_bh = old_bh;\n \t\t\tget_bh(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t} else {\n \t\t\t/* We need to allocate a new block */\n \t\t\text2_fsblk_t goal = ext2_group_first_block_no(sb,\n@@ -674,7 +676,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\tmemcpy(new_bh->b_data, header, new_bh->b_size);\n \t\t\tset_buffer_uptodate(new_bh);\n \t\t\tunlock_buffer(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t\t\n \t\t\text2_xattr_update_super_block(sb);\n \t\t}\n@@ -707,19 +709,21 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \n \terror = 0;\n \tif (old_bh && old_bh != new_bh) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/*\n \t\t * If there was an old block and we are no longer using it,\n \t\t * release the old block.\n \t\t */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,\n-\t\t\t\t\told_bh->b_blocknr);\n \t\tlock_buffer(old_bh);\n \t\tif (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);\n+\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect freed block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(ext2_mb_cache,\n+\t\t\t\t\t\t     hash, old_bh->b_blocknr);\n \t\t\t/* Free the old block. */\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n \t\t\tea_bdebug(old_bh, \""freeing\"");\n \t\t\text2_free_blocks(inode, old_bh->b_blocknr, 1);\n \t\t\tmark_inode_dirty(inode);\n@@ -730,8 +734,6 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t} else {\n \t\t\t/* Decrement the refcount only. */\n \t\t\tle32_add_cpu(&HDR(old_bh)->h_refcount, -1);\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tdquot_free_block_nodirty(inode, 1);\n \t\t\tmark_inode_dirty(inode);\n \t\t\tmark_buffer_dirty(old_bh);\n@@ -757,7 +759,6 @@ void\n ext2_xattr_delete_inode(struct inode *inode)\n {\n \tstruct buffer_head *bh = NULL;\n-\tstruct mb_cache_entry *ce;\n \n \tdown_write(&EXT2_I(inode)->xattr_sem);\n \tif (!EXT2_I(inode)->i_file_acl)\n@@ -777,19 +778,22 @@ ext2_xattr_delete_inode(struct inode *inode)\n \t\t\tEXT2_I(inode)->i_file_acl);\n \t\tgoto cleanup;\n \t}\n-\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);\n \tlock_buffer(bh);\n \tif (HDR(bh)->h_refcount == cpu_to_le32(1)) {\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_free(ce);\n+\t\t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n+\n+\t\t/*\n+\t\t * This must happen under buffer lock for ext2_xattr_set2() to\n+\t\t * reliably detect freed block\n+\t\t */\n+\t\tmb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,\n+\t\t\t\t\t     hash, bh->b_blocknr);\n \t\text2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);\n \t\tget_bh(bh);\n \t\tbforget(bh);\n \t\tunlock_buffer(bh);\n \t} else {\n \t\tle32_add_cpu(&HDR(bh)->h_refcount, -1);\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_release(ce);\n \t\tea_bdebug(bh, \""refcount now=%d\"",\n \t\t\tle32_to_cpu(HDR(bh)->h_refcount));\n \t\tunlock_buffer(bh);\n@@ -805,18 +809,6 @@ ext2_xattr_delete_inode(struct inode *inode)\n \tup_write(&EXT2_I(inode)->xattr_sem);\n }\n \n-/*\n- * ext2_xattr_put_super()\n- *\n- * This is called when a file system is unmounted.\n- */\n-void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-\tmb_cache_shrink(sb->s_bdev);\n-}\n-\n-\n /*\n  * ext2_xattr_cache_insert()\n  *\n@@ -826,28 +818,20 @@ ext2_xattr_put_super(struct super_block *sb)\n  * Returns 0, or a negative error number on failure.\n  */\n static int\n-ext2_xattr_cache_insert(struct buffer_head *bh)\n+ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)\n {\n \t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n-\tstruct mb_cache_entry *ce;\n \tint error;\n \n-\tce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);\n-\tif (!ce)\n-\t\treturn -ENOMEM;\n-\terror = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);\n+\terror = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);\n \tif (error) {\n-\t\tmb_cache_entry_free(ce);\n \t\tif (error == -EBUSY) {\n \t\t\tea_bdebug(bh, \""already in cache (%d cache entries)\"",\n \t\t\t\tatomic_read(&ext2_xattr_cache->c_entry_count));\n \t\t\terror = 0;\n \t\t}\n-\t} else {\n-\t\tea_bdebug(bh, \""inserting [%x] (%d cache entries)\"", (int)hash,\n-\t\t\t  atomic_read(&ext2_xattr_cache->c_entry_count));\n-\t\tmb_cache_entry_release(ce);\n-\t}\n+\t} else\n+\t\tea_bdebug(bh, \""inserting [%x]\"", (int)hash);\n \treturn error;\n }\n \n@@ -903,31 +887,39 @@ static struct buffer_head *\n ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n {\n \t__u32 hash = le32_to_cpu(header->h_hash);\n-\tstruct mb_cache_entry *ce;\n+\tstruct mb2_cache_entry *ce;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tif (!header->h_hash)\n \t\treturn NULL;  /* never share */\n \tea_idebug(inode, \""looking for cached blocks [%x]\"", (int)hash);\n again:\n-\tce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,\n-\t\t\t\t       hash);\n+\tce = mb2_cache_entry_find_first(ext2_mb_cache, hash);\n \twhile (ce) {\n \t\tstruct buffer_head *bh;\n \n-\t\tif (IS_ERR(ce)) {\n-\t\t\tif (PTR_ERR(ce) == -EAGAIN)\n-\t\t\t\tgoto again;\n-\t\t\tbreak;\n-\t\t}\n-\n \t\tbh = sb_bread(inode->i_sb, ce->e_block);\n \t\tif (!bh) {\n \t\t\text2_error(inode->i_sb, \""ext2_xattr_cache_find\"",\n \t\t\t\t\""inode %ld: block %ld read error\"",\n \t\t\t\tinode->i_ino, (unsigned long) ce->e_block);\n \t\t} else {\n \t\t\tlock_buffer(bh);\n-\t\t\tif (le32_to_cpu(HDR(bh)->h_refcount) >\n+\t\t\t/*\n+\t\t\t * We have to be careful about races with freeing or\n+\t\t\t * rehashing of xattr block. Once we hold buffer lock\n+\t\t\t * xattr block's state is stable so we can check\n+\t\t\t * whether the block got freed / rehashed or not.\n+\t\t\t * Since we unhash mbcache entry under buffer lock when\n+\t\t\t * freeing / rehashing xattr block, checking whether\n+\t\t\t * entry is still hashed is reliable.\n+\t\t\t */\n+\t\t\tif (hlist_bl_unhashed(&ce->e_hash_list)) {\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n+\t\t\t\tunlock_buffer(bh);\n+\t\t\t\tbrelse(bh);\n+\t\t\t\tgoto again;\n+\t\t\t} else if (le32_to_cpu(HDR(bh)->h_refcount) >\n \t\t\t\t   EXT2_XATTR_REFCOUNT_MAX) {\n \t\t\t\tea_idebug(inode, \""block %ld refcount %d>%d\"",\n \t\t\t\t\t  (unsigned long) ce->e_block,\n@@ -936,13 +928,14 @@ ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n \t\t\t} else if (!ext2_xattr_cmp(header, HDR(bh))) {\n \t\t\t\tea_bdebug(bh, \""b_count=%d\"",\n \t\t\t\t\t  atomic_read(&(bh->b_count)));\n-\t\t\t\tmb_cache_entry_release(ce);\n+\t\t\t\tmb2_cache_entry_touch(ext2_mb_cache, ce);\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n \t\t\t\treturn bh;\n \t\t\t}\n \t\t\tunlock_buffer(bh);\n \t\t\tbrelse(bh);\n \t\t}\n-\t\tce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);\n+\t\tce = mb2_cache_entry_find_next(ext2_mb_cache, ce);\n \t}\n \treturn NULL;\n }\n@@ -1015,17 +1008,15 @@ static void ext2_xattr_rehash(struct ext2_xattr_header *header,\n \n #undef BLOCK_HASH_SHIFT\n \n-int __init\n-init_ext2_xattr(void)\n+#define HASH_BUCKET_BITS 10\n+\n+struct mb2_cache *ext2_xattr_create_cache(void)\n {\n-\text2_xattr_cache = mb_cache_create(\""ext2_xattr\"", 6);\n-\tif (!ext2_xattr_cache)\n-\t\treturn -ENOMEM;\n-\treturn 0;\n+\treturn mb2_cache_create(HASH_BUCKET_BITS);\n }\n \n-void\n-exit_ext2_xattr(void)\n+void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n-\tmb_cache_destroy(ext2_xattr_cache);\n+\tif (cache)\n+\t\tmb2_cache_destroy(cache);\n }""}<_**next**_>{""sha"": ""6ea38aa9563a00649bf25544eed131bbe8b1d88d"", ""filename"": ""fs/ext2/xattr.h"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 16, ""changes"": 21, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -53,6 +53,8 @@ struct ext2_xattr_entry {\n #define EXT2_XATTR_SIZE(size) \\\n \t(((size) + EXT2_XATTR_ROUND) & ~EXT2_XATTR_ROUND)\n \n+struct mb2_cache;\n+\n # ifdef CONFIG_EXT2_FS_XATTR\n \n extern const struct xattr_handler ext2_xattr_user_handler;\n@@ -65,10 +67,9 @@ extern int ext2_xattr_get(struct inode *, int, const char *, void *, size_t);\n extern int ext2_xattr_set(struct inode *, int, const char *, const void *, size_t, int);\n \n extern void ext2_xattr_delete_inode(struct inode *);\n-extern void ext2_xattr_put_super(struct super_block *);\n \n-extern int init_ext2_xattr(void);\n-extern void exit_ext2_xattr(void);\n+extern struct mb2_cache *ext2_xattr_create_cache(void);\n+extern void ext2_xattr_destroy_cache(struct mb2_cache *cache);\n \n extern const struct xattr_handler *ext2_xattr_handlers[];\n \n@@ -93,19 +94,7 @@ ext2_xattr_delete_inode(struct inode *inode)\n {\n }\n \n-static inline void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-}\n-\n-static inline int\n-init_ext2_xattr(void)\n-{\n-\treturn 0;\n-}\n-\n-static inline void\n-exit_ext2_xattr(void)\n+static inline void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n }\n ""}","ext2_xattr_get(struct inode *inode, int name_index, const char *name,
	       void *buffer, size_t buffer_size)
{
	struct buffer_head *bh = NULL;
	struct ext2_xattr_entry *entry;
 	size_t name_len, size;
 	char *end;
 	int error;
	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	ea_idebug(inode, ""name=%d.%s, buffer=%p, buffer_size=%ld"",
 		  name_index, name, buffer, (long)buffer_size);

	if (name == NULL)
		return -EINVAL;
	name_len = strlen(name);
	if (name_len > 255)
		return -ERANGE;

	down_read(&EXT2_I(inode)->xattr_sem);
	error = -ENODATA;
	if (!EXT2_I(inode)->i_file_acl)
		goto cleanup;
	ea_idebug(inode, ""reading block %d"", EXT2_I(inode)->i_file_acl);
	bh = sb_bread(inode->i_sb, EXT2_I(inode)->i_file_acl);
	error = -EIO;
	if (!bh)
		goto cleanup;
	ea_bdebug(bh, ""b_count=%d, refcount=%d"",
		atomic_read(&(bh->b_count)), le32_to_cpu(HDR(bh)->h_refcount));
	end = bh->b_data + bh->b_size;
	if (HDR(bh)->h_magic != cpu_to_le32(EXT2_XATTR_MAGIC) ||
	    HDR(bh)->h_blocks != cpu_to_le32(1)) {
bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_get"",
			""inode %ld: bad block %d"", inode->i_ino,
			EXT2_I(inode)->i_file_acl);
		error = -EIO;
		goto cleanup;
	}

	/* find named attribute */
	entry = FIRST_ENTRY(bh);
	while (!IS_LAST_ENTRY(entry)) {
		struct ext2_xattr_entry *next =
			EXT2_XATTR_NEXT(entry);
		if ((char *)next >= end)
			goto bad_block;
		if (name_index == entry->e_name_index &&
		    name_len == entry->e_name_len &&
		    memcmp(name, entry->e_name, name_len) == 0)
 			goto found;
 		entry = next;
 	}
	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 	error = -ENODATA;
 	goto cleanup;
found:
	/* check the buffer size */
	if (entry->e_value_block != 0)
		goto bad_block;
	size = le32_to_cpu(entry->e_value_size);
	if (size > inode->i_sb->s_blocksize ||
 	    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)
 		goto bad_block;
 
	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 	if (buffer) {
 		error = -ERANGE;
		if (size > buffer_size)
			goto cleanup;
		/* return value of attribute */
		memcpy(buffer, bh->b_data + le16_to_cpu(entry->e_value_offs),
			size);
	}
	error = size;

cleanup:
	brelse(bh);
	up_read(&EXT2_I(inode)->xattr_sem);

	return error;
}
","ext2_xattr_get(struct inode *inode, int name_index, const char *name,
	       void *buffer, size_t buffer_size)
{
	struct buffer_head *bh = NULL;
	struct ext2_xattr_entry *entry;
 	size_t name_len, size;
 	char *end;
 	int error;
 
 	ea_idebug(inode, ""name=%d.%s, buffer=%p, buffer_size=%ld"",
 		  name_index, name, buffer, (long)buffer_size);

	if (name == NULL)
		return -EINVAL;
	name_len = strlen(name);
	if (name_len > 255)
		return -ERANGE;

	down_read(&EXT2_I(inode)->xattr_sem);
	error = -ENODATA;
	if (!EXT2_I(inode)->i_file_acl)
		goto cleanup;
	ea_idebug(inode, ""reading block %d"", EXT2_I(inode)->i_file_acl);
	bh = sb_bread(inode->i_sb, EXT2_I(inode)->i_file_acl);
	error = -EIO;
	if (!bh)
		goto cleanup;
	ea_bdebug(bh, ""b_count=%d, refcount=%d"",
		atomic_read(&(bh->b_count)), le32_to_cpu(HDR(bh)->h_refcount));
	end = bh->b_data + bh->b_size;
	if (HDR(bh)->h_magic != cpu_to_le32(EXT2_XATTR_MAGIC) ||
	    HDR(bh)->h_blocks != cpu_to_le32(1)) {
bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_get"",
			""inode %ld: bad block %d"", inode->i_ino,
			EXT2_I(inode)->i_file_acl);
		error = -EIO;
		goto cleanup;
	}

	/* find named attribute */
	entry = FIRST_ENTRY(bh);
	while (!IS_LAST_ENTRY(entry)) {
		struct ext2_xattr_entry *next =
			EXT2_XATTR_NEXT(entry);
		if ((char *)next >= end)
			goto bad_block;
		if (name_index == entry->e_name_index &&
		    name_len == entry->e_name_len &&
		    memcmp(name, entry->e_name, name_len) == 0)
 			goto found;
 		entry = next;
 	}
	if (ext2_xattr_cache_insert(bh))
 		ea_idebug(inode, ""cache insert failed"");
 	error = -ENODATA;
 	goto cleanup;
found:
	/* check the buffer size */
	if (entry->e_value_block != 0)
		goto bad_block;
	size = le32_to_cpu(entry->e_value_size);
	if (size > inode->i_sb->s_blocksize ||
 	    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)
 		goto bad_block;
 
	if (ext2_xattr_cache_insert(bh))
 		ea_idebug(inode, ""cache insert failed"");
 	if (buffer) {
 		error = -ERANGE;
		if (size > buffer_size)
			goto cleanup;
		/* return value of attribute */
		memcpy(buffer, bh->b_data + le16_to_cpu(entry->e_value_offs),
			size);
	}
	error = size;

cleanup:
	brelse(bh);
	up_read(&EXT2_I(inode)->xattr_sem);

	return error;
}
",C,"	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
","	if (ext2_xattr_cache_insert(bh))
	if (ext2_xattr_cache_insert(bh))
",,"@@ -56,7 +56,7 @@
 #include <linux/buffer_head.h>
 #include <linux/init.h>
 #include <linux/slab.h>
-#include <linux/mbcache.h>
+#include <linux/mbcache2.h>
 #include <linux/quotaops.h>
 #include <linux/rwsem.h>
 #include <linux/security.h>
@@ -90,14 +90,12 @@
 static int ext2_xattr_set2(struct inode *, struct buffer_head *,
 			   struct ext2_xattr_header *);
 
-static int ext2_xattr_cache_insert(struct buffer_head *);
+static int ext2_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);
 static struct buffer_head *ext2_xattr_cache_find(struct inode *,
 						 struct ext2_xattr_header *);
 static void ext2_xattr_rehash(struct ext2_xattr_header *,
 			      struct ext2_xattr_entry *);
 
-static struct mb_cache *ext2_xattr_cache;
-
 static const struct xattr_handler *ext2_xattr_handler_map[] = {
 	[EXT2_XATTR_INDEX_USER]		     = &ext2_xattr_user_handler,
 #ifdef CONFIG_EXT2_FS_POSIX_ACL
@@ -152,6 +150,7 @@ ext2_xattr_get(struct inode *inode, int name_index, const char *name,
 	size_t name_len, size;
 	char *end;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	ea_idebug(inode, ""name=%d.%s, buffer=%p, buffer_size=%ld"",
 		  name_index, name, buffer, (long)buffer_size);
@@ -196,7 +195,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_get"",
 			goto found;
 		entry = next;
 	}
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 	error = -ENODATA;
 	goto cleanup;
@@ -209,7 +208,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_get"",
 	    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)
 		goto bad_block;
 
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 	if (buffer) {
 		error = -ERANGE;
@@ -247,6 +246,7 @@ ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)
 	char *end;
 	size_t rest = buffer_size;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	ea_idebug(inode, ""buffer=%p, buffer_size=%ld"",
 		  buffer, (long)buffer_size);
@@ -281,7 +281,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_list"",
 			goto bad_block;
 		entry = next;
 	}
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 
 	/* list the attribute names */
@@ -483,22 +483,23 @@ bad_block:		ext2_error(sb, ""ext2_xattr_set"",
 	/* Here we know that we can set the new attribute. */
 
 	if (header) {
-		struct mb_cache_entry *ce;
-
 		/* assert(header == HDR(bh)); */
-		ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,
-					bh->b_blocknr);
 		lock_buffer(bh);
 		if (header->h_refcount == cpu_to_le32(1)) {
+			__u32 hash = le32_to_cpu(header->h_hash);
+
 			ea_bdebug(bh, ""modifying in-place"");
-			if (ce)
-				mb_cache_entry_free(ce);
+			/*
+			 * This must happen under buffer lock for
+			 * ext2_xattr_set2() to reliably detect modified block
+			 */
+			mb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,
+						     hash, bh->b_blocknr);
+
 			/* keep the buffer locked while modifying it. */
 		} else {
 			int offset;
 
-			if (ce)
-				mb_cache_entry_release(ce);
 			unlock_buffer(bh);
 			ea_bdebug(bh, ""cloning"");
 			header = kmalloc(bh->b_size, GFP_KERNEL);
@@ -626,6 +627,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *new_bh = NULL;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;
 
 	if (header) {
 		new_bh = ext2_xattr_cache_find(inode, header);
@@ -653,7 +655,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 			   don't need to change the reference count. */
 			new_bh = old_bh;
 			get_bh(new_bh);
-			ext2_xattr_cache_insert(new_bh);
+			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
 		} else {
 			/* We need to allocate a new block */
 			ext2_fsblk_t goal = ext2_group_first_block_no(sb,
@@ -674,7 +676,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 			memcpy(new_bh->b_data, header, new_bh->b_size);
 			set_buffer_uptodate(new_bh);
 			unlock_buffer(new_bh);
-			ext2_xattr_cache_insert(new_bh);
+			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
 			
 			ext2_xattr_update_super_block(sb);
 		}
@@ -707,19 +709,21 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 
 	error = 0;
 	if (old_bh && old_bh != new_bh) {
-		struct mb_cache_entry *ce;
-
 		/*
 		 * If there was an old block and we are no longer using it,
 		 * release the old block.
 		 */
-		ce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,
-					old_bh->b_blocknr);
 		lock_buffer(old_bh);
 		if (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {
+			__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);
+
+			/*
+			 * This must happen under buffer lock for
+			 * ext2_xattr_set2() to reliably detect freed block
+			 */
+			mb2_cache_entry_delete_block(ext2_mb_cache,
+						     hash, old_bh->b_blocknr);
 			/* Free the old block. */
-			if (ce)
-				mb_cache_entry_free(ce);
 			ea_bdebug(old_bh, ""freeing"");
 			ext2_free_blocks(inode, old_bh->b_blocknr, 1);
 			mark_inode_dirty(inode);
@@ -730,8 +734,6 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 		} else {
 			/* Decrement the refcount only. */
 			le32_add_cpu(&HDR(old_bh)->h_refcount, -1);
-			if (ce)
-				mb_cache_entry_release(ce);
 			dquot_free_block_nodirty(inode, 1);
 			mark_inode_dirty(inode);
 			mark_buffer_dirty(old_bh);
@@ -757,7 +759,6 @@ void
 ext2_xattr_delete_inode(struct inode *inode)
 {
 	struct buffer_head *bh = NULL;
-	struct mb_cache_entry *ce;
 
 	down_write(&EXT2_I(inode)->xattr_sem);
 	if (!EXT2_I(inode)->i_file_acl)
@@ -777,19 +778,22 @@ ext2_xattr_delete_inode(struct inode *inode)
 			EXT2_I(inode)->i_file_acl);
 		goto cleanup;
 	}
-	ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);
 	lock_buffer(bh);
 	if (HDR(bh)->h_refcount == cpu_to_le32(1)) {
-		if (ce)
-			mb_cache_entry_free(ce);
+		__u32 hash = le32_to_cpu(HDR(bh)->h_hash);
+
+		/*
+		 * This must happen under buffer lock for ext2_xattr_set2() to
+		 * reliably detect freed block
+		 */
+		mb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,
+					     hash, bh->b_blocknr);
 		ext2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);
 		get_bh(bh);
 		bforget(bh);
 		unlock_buffer(bh);
 	} else {
 		le32_add_cpu(&HDR(bh)->h_refcount, -1);
-		if (ce)
-			mb_cache_entry_release(ce);
 		ea_bdebug(bh, ""refcount now=%d"",
 			le32_to_cpu(HDR(bh)->h_refcount));
 		unlock_buffer(bh);
@@ -805,18 +809,6 @@ ext2_xattr_delete_inode(struct inode *inode)
 	up_write(&EXT2_I(inode)->xattr_sem);
 }
 
-/*
- * ext2_xattr_put_super()
- *
- * This is called when a file system is unmounted.
- */
-void
-ext2_xattr_put_super(struct super_block *sb)
-{
-	mb_cache_shrink(sb->s_bdev);
-}
-
-
 /*
  * ext2_xattr_cache_insert()
  *
@@ -826,28 +818,20 @@ ext2_xattr_put_super(struct super_block *sb)
  * Returns 0, or a negative error number on failure.
  */
 static int
-ext2_xattr_cache_insert(struct buffer_head *bh)
+ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)
 {
 	__u32 hash = le32_to_cpu(HDR(bh)->h_hash);
-	struct mb_cache_entry *ce;
 	int error;
 
-	ce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);
-	if (!ce)
-		return -ENOMEM;
-	error = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);
+	error = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);
 	if (error) {
-		mb_cache_entry_free(ce);
 		if (error == -EBUSY) {
 			ea_bdebug(bh, ""already in cache (%d cache entries)"",
 				atomic_read(&ext2_xattr_cache->c_entry_count));
 			error = 0;
 		}
-	} else {
-		ea_bdebug(bh, ""inserting [%x] (%d cache entries)"", (int)hash,
-			  atomic_read(&ext2_xattr_cache->c_entry_count));
-		mb_cache_entry_release(ce);
-	}
+	} else
+		ea_bdebug(bh, ""inserting [%x]"", (int)hash);
 	return error;
 }
 
@@ -903,31 +887,39 @@ static struct buffer_head *
 ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)
 {
 	__u32 hash = le32_to_cpu(header->h_hash);
-	struct mb_cache_entry *ce;
+	struct mb2_cache_entry *ce;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	if (!header->h_hash)
 		return NULL;  /* never share */
 	ea_idebug(inode, ""looking for cached blocks [%x]"", (int)hash);
 again:
-	ce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,
-				       hash);
+	ce = mb2_cache_entry_find_first(ext2_mb_cache, hash);
 	while (ce) {
 		struct buffer_head *bh;
 
-		if (IS_ERR(ce)) {
-			if (PTR_ERR(ce) == -EAGAIN)
-				goto again;
-			break;
-		}
-
 		bh = sb_bread(inode->i_sb, ce->e_block);
 		if (!bh) {
 			ext2_error(inode->i_sb, ""ext2_xattr_cache_find"",
 				""inode %ld: block %ld read error"",
 				inode->i_ino, (unsigned long) ce->e_block);
 		} else {
 			lock_buffer(bh);
-			if (le32_to_cpu(HDR(bh)->h_refcount) >
+			/*
+			 * We have to be careful about races with freeing or
+			 * rehashing of xattr block. Once we hold buffer lock
+			 * xattr block's state is stable so we can check
+			 * whether the block got freed / rehashed or not.
+			 * Since we unhash mbcache entry under buffer lock when
+			 * freeing / rehashing xattr block, checking whether
+			 * entry is still hashed is reliable.
+			 */
+			if (hlist_bl_unhashed(&ce->e_hash_list)) {
+				mb2_cache_entry_put(ext2_mb_cache, ce);
+				unlock_buffer(bh);
+				brelse(bh);
+				goto again;
+			} else if (le32_to_cpu(HDR(bh)->h_refcount) >
 				   EXT2_XATTR_REFCOUNT_MAX) {
 				ea_idebug(inode, ""block %ld refcount %d>%d"",
 					  (unsigned long) ce->e_block,
@@ -936,13 +928,14 @@ ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)
 			} else if (!ext2_xattr_cmp(header, HDR(bh))) {
 				ea_bdebug(bh, ""b_count=%d"",
 					  atomic_read(&(bh->b_count)));
-				mb_cache_entry_release(ce);
+				mb2_cache_entry_touch(ext2_mb_cache, ce);
+				mb2_cache_entry_put(ext2_mb_cache, ce);
 				return bh;
 			}
 			unlock_buffer(bh);
 			brelse(bh);
 		}
-		ce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);
+		ce = mb2_cache_entry_find_next(ext2_mb_cache, ce);
 	}
 	return NULL;
 }
@@ -1015,17 +1008,15 @@ static void ext2_xattr_rehash(struct ext2_xattr_header *header,
 
 #undef BLOCK_HASH_SHIFT
 
-int __init
-init_ext2_xattr(void)
+#define HASH_BUCKET_BITS 10
+
+struct mb2_cache *ext2_xattr_create_cache(void)
 {
-	ext2_xattr_cache = mb_cache_create(""ext2_xattr"", 6);
-	if (!ext2_xattr_cache)
-		return -ENOMEM;
-	return 0;
+	return mb2_cache_create(HASH_BUCKET_BITS);
 }
 
-void
-exit_ext2_xattr(void)
+void ext2_xattr_destroy_cache(struct mb2_cache *cache)
 {
-	mb_cache_destroy(ext2_xattr_cache);
+	if (cache)
+		mb2_cache_destroy(cache);
 }",linux,be0726d33cb8f411945884664924bed3cb8c70ee,82939d7999dfc1f1998c4b1c12e2f19edbdff272,1,"ext2_xattr_get(struct inode *inode, int name_index, const char *name,
	       void *buffer, size_t buffer_size)
{
	struct buffer_head *bh = NULL;
	struct ext2_xattr_entry *entry;
 	size_t name_len, size;
 	char *end;
 	int error;
//fix_flaw_line_below:
//	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	ea_idebug(inode, ""name=%d.%s, buffer=%p, buffer_size=%ld"",
 		  name_index, name, buffer, (long)buffer_size);

	if (name == NULL)
		return -EINVAL;
	name_len = strlen(name);
	if (name_len > 255)
		return -ERANGE;

	down_read(&EXT2_I(inode)->xattr_sem);
	error = -ENODATA;
	if (!EXT2_I(inode)->i_file_acl)
		goto cleanup;
	ea_idebug(inode, ""reading block %d"", EXT2_I(inode)->i_file_acl);
	bh = sb_bread(inode->i_sb, EXT2_I(inode)->i_file_acl);
	error = -EIO;
	if (!bh)
		goto cleanup;
	ea_bdebug(bh, ""b_count=%d, refcount=%d"",
		atomic_read(&(bh->b_count)), le32_to_cpu(HDR(bh)->h_refcount));
	end = bh->b_data + bh->b_size;
	if (HDR(bh)->h_magic != cpu_to_le32(EXT2_XATTR_MAGIC) ||
	    HDR(bh)->h_blocks != cpu_to_le32(1)) {
bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_get"",
			""inode %ld: bad block %d"", inode->i_ino,
			EXT2_I(inode)->i_file_acl);
		error = -EIO;
		goto cleanup;
	}

	/* find named attribute */
	entry = FIRST_ENTRY(bh);
	while (!IS_LAST_ENTRY(entry)) {
		struct ext2_xattr_entry *next =
			EXT2_XATTR_NEXT(entry);
		if ((char *)next >= end)
			goto bad_block;
		if (name_index == entry->e_name_index &&
		    name_len == entry->e_name_len &&
		    memcmp(name, entry->e_name, name_len) == 0)
 			goto found;
 		entry = next;
 	}
//flaw_line_below:
	if (ext2_xattr_cache_insert(bh))
//fix_flaw_line_below:
//	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 	error = -ENODATA;
 	goto cleanup;
found:
	/* check the buffer size */
	if (entry->e_value_block != 0)
		goto bad_block;
	size = le32_to_cpu(entry->e_value_size);
	if (size > inode->i_sb->s_blocksize ||
 	    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)
 		goto bad_block;
 
//flaw_line_below:
	if (ext2_xattr_cache_insert(bh))
//fix_flaw_line_below:
//	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 	if (buffer) {
 		error = -ERANGE;
		if (size > buffer_size)
			goto cleanup;
		/* return value of attribute */
		memcpy(buffer, bh->b_data + le16_to_cpu(entry->e_value_offs),
			size);
	}
	error = size;

cleanup:
	brelse(bh);
	up_read(&EXT2_I(inode)->xattr_sem);

	return error;
}
"
5417,183153,,Local,Not required,Partial,CVE-2015-8952,https://www.cvedetails.com/cve/CVE-2015-8952/,CWE-19,Low,,,,2016-10-16,2.1,"The mbcache feature in the ext2 and ext4 filesystem implementations in the Linux kernel before 4.6 mishandles xattr block caching, which allows local users to cause a denial of service (soft lockup) via filesystem operations in environments that use many attributes, as demonstrated by Ceph and Samba.",2018-03-15,DoS ,2,https://github.com/torvalds/linux/commit/be0726d33cb8f411945884664924bed3cb8c70ee,be0726d33cb8f411945884664924bed3cb8c70ee,"ext2: convert to mbcache2

The conversion is generally straightforward. We convert filesystem from
a global cache to per-fs one. Similarly to ext4 the tricky part is that
xattr block corresponding to found mbcache entry can get freed before we
get buffer lock for that block. So we have to check whether the entry is
still valid after getting the buffer lock.

Signed-off-by: Jan Kara <jack@suse.cz>
Signed-off-by: Theodore Ts'o <tytso@mit.edu>",1,fs/ext2/xattr.c,"{""sha"": ""f98ce7e60a0f84f71743e0dfe069c7e96c6bd648"", ""filename"": ""fs/ext2/ext2.h"", ""status"": ""modified"", ""additions"": 3, ""deletions"": 0, ""changes"": 3, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/ext2.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -61,6 +61,8 @@ struct ext2_block_alloc_info {\n #define rsv_start rsv_window._rsv_start\n #define rsv_end rsv_window._rsv_end\n \n+struct mb2_cache;\n+\n /*\n  * second extended-fs super-block data in memory\n  */\n@@ -111,6 +113,7 @@ struct ext2_sb_info {\n \t * of the mount options.\n \t */\n \tspinlock_t s_lock;\n+\tstruct mb2_cache *s_mb_cache;\n };\n \n static inline spinlock_t *""}<_**next**_>{""sha"": ""b78caf25f746220ce635a3bd946bedeaf7e3e750"", ""filename"": ""fs/ext2/super.c"", ""status"": ""modified"", ""additions"": 17, ""deletions"": 8, ""changes"": 25, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/super.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -131,7 +131,10 @@ static void ext2_put_super (struct super_block * sb)\n \n \tdquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);\n \n-\text2_xattr_put_super(sb);\n+\tif (sbi->s_mb_cache) {\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n+\t\tsbi->s_mb_cache = NULL;\n+\t}\n \tif (!(sb->s_flags & MS_RDONLY)) {\n \t\tstruct ext2_super_block *es = sbi->s_es;\n \n@@ -1104,6 +1107,14 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\text2_msg(sb, KERN_ERR, \""error: insufficient memory\"");\n \t\tgoto failed_mount3;\n \t}\n+\n+#ifdef CONFIG_EXT2_FS_XATTR\n+\tsbi->s_mb_cache = ext2_xattr_create_cache();\n+\tif (!sbi->s_mb_cache) {\n+\t\text2_msg(sb, KERN_ERR, \""Failed to create an mb_cache\"");\n+\t\tgoto failed_mount3;\n+\t}\n+#endif\n \t/*\n \t * set up enough so that it can read an inode\n \t */\n@@ -1149,6 +1160,8 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\t\tsb->s_id);\n \tgoto failed_mount;\n failed_mount3:\n+\tif (sbi->s_mb_cache)\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n \tpercpu_counter_destroy(&sbi->s_freeblocks_counter);\n \tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n \tpercpu_counter_destroy(&sbi->s_dirs_counter);\n@@ -1555,28 +1568,24 @@ MODULE_ALIAS_FS(\""ext2\"");\n \n static int __init init_ext2_fs(void)\n {\n-\tint err = init_ext2_xattr();\n-\tif (err)\n-\t\treturn err;\n+\tint err;\n+\n \terr = init_inodecache();\n \tif (err)\n-\t\tgoto out1;\n+\t\treturn err;\n         err = register_filesystem(&ext2_fs_type);\n \tif (err)\n \t\tgoto out;\n \treturn 0;\n out:\n \tdestroy_inodecache();\n-out1:\n-\texit_ext2_xattr();\n \treturn err;\n }\n \n static void __exit exit_ext2_fs(void)\n {\n \tunregister_filesystem(&ext2_fs_type);\n \tdestroy_inodecache();\n-\texit_ext2_xattr();\n }\n \n MODULE_AUTHOR(\""Remy Card and others\"");""}<_**next**_>{""sha"": ""7162b4869bc32515800d8ffc06ac3835ea241c8b"", ""filename"": ""fs/ext2/xattr.c"", ""status"": ""modified"", ""additions"": 67, ""deletions"": 76, ""changes"": 143, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -56,7 +56,7 @@\n #include <linux/buffer_head.h>\n #include <linux/init.h>\n #include <linux/slab.h>\n-#include <linux/mbcache.h>\n+#include <linux/mbcache2.h>\n #include <linux/quotaops.h>\n #include <linux/rwsem.h>\n #include <linux/security.h>\n@@ -90,14 +90,12 @@\n static int ext2_xattr_set2(struct inode *, struct buffer_head *,\n \t\t\t   struct ext2_xattr_header *);\n \n-static int ext2_xattr_cache_insert(struct buffer_head *);\n+static int ext2_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);\n static struct buffer_head *ext2_xattr_cache_find(struct inode *,\n \t\t\t\t\t\t struct ext2_xattr_header *);\n static void ext2_xattr_rehash(struct ext2_xattr_header *,\n \t\t\t      struct ext2_xattr_entry *);\n \n-static struct mb_cache *ext2_xattr_cache;\n-\n static const struct xattr_handler *ext2_xattr_handler_map[] = {\n \t[EXT2_XATTR_INDEX_USER]\t\t     = &ext2_xattr_user_handler,\n #ifdef CONFIG_EXT2_FS_POSIX_ACL\n@@ -152,6 +150,7 @@ ext2_xattr_get(struct inode *inode, int name_index, const char *name,\n \tsize_t name_len, size;\n \tchar *end;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""name=%d.%s, buffer=%p, buffer_size=%ld\"",\n \t\t  name_index, name, buffer, (long)buffer_size);\n@@ -196,7 +195,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t\t\tgoto found;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \terror = -ENODATA;\n \tgoto cleanup;\n@@ -209,7 +208,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)\n \t\tgoto bad_block;\n \n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \tif (buffer) {\n \t\terror = -ERANGE;\n@@ -247,6 +246,7 @@ ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)\n \tchar *end;\n \tsize_t rest = buffer_size;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""buffer=%p, buffer_size=%ld\"",\n \t\t  buffer, (long)buffer_size);\n@@ -281,7 +281,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_list\"",\n \t\t\tgoto bad_block;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \n \t/* list the attribute names */\n@@ -483,22 +483,23 @@ bad_block:\t\text2_error(sb, \""ext2_xattr_set\"",\n \t/* Here we know that we can set the new attribute. */\n \n \tif (header) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/* assert(header == HDR(bh)); */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,\n-\t\t\t\t\tbh->b_blocknr);\n \t\tlock_buffer(bh);\n \t\tif (header->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(header->h_hash);\n+\n \t\t\tea_bdebug(bh, \""modifying in-place\"");\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect modified block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,\n+\t\t\t\t\t\t     hash, bh->b_blocknr);\n+\n \t\t\t/* keep the buffer locked while modifying it. */\n \t\t} else {\n \t\t\tint offset;\n \n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tunlock_buffer(bh);\n \t\t\tea_bdebug(bh, \""cloning\"");\n \t\t\theader = kmalloc(bh->b_size, GFP_KERNEL);\n@@ -626,6 +627,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \tstruct super_block *sb = inode->i_sb;\n \tstruct buffer_head *new_bh = NULL;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;\n \n \tif (header) {\n \t\tnew_bh = ext2_xattr_cache_find(inode, header);\n@@ -653,7 +655,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\t   don't need to change the reference count. */\n \t\t\tnew_bh = old_bh;\n \t\t\tget_bh(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t} else {\n \t\t\t/* We need to allocate a new block */\n \t\t\text2_fsblk_t goal = ext2_group_first_block_no(sb,\n@@ -674,7 +676,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\tmemcpy(new_bh->b_data, header, new_bh->b_size);\n \t\t\tset_buffer_uptodate(new_bh);\n \t\t\tunlock_buffer(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t\t\n \t\t\text2_xattr_update_super_block(sb);\n \t\t}\n@@ -707,19 +709,21 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \n \terror = 0;\n \tif (old_bh && old_bh != new_bh) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/*\n \t\t * If there was an old block and we are no longer using it,\n \t\t * release the old block.\n \t\t */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,\n-\t\t\t\t\told_bh->b_blocknr);\n \t\tlock_buffer(old_bh);\n \t\tif (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);\n+\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect freed block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(ext2_mb_cache,\n+\t\t\t\t\t\t     hash, old_bh->b_blocknr);\n \t\t\t/* Free the old block. */\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n \t\t\tea_bdebug(old_bh, \""freeing\"");\n \t\t\text2_free_blocks(inode, old_bh->b_blocknr, 1);\n \t\t\tmark_inode_dirty(inode);\n@@ -730,8 +734,6 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t} else {\n \t\t\t/* Decrement the refcount only. */\n \t\t\tle32_add_cpu(&HDR(old_bh)->h_refcount, -1);\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tdquot_free_block_nodirty(inode, 1);\n \t\t\tmark_inode_dirty(inode);\n \t\t\tmark_buffer_dirty(old_bh);\n@@ -757,7 +759,6 @@ void\n ext2_xattr_delete_inode(struct inode *inode)\n {\n \tstruct buffer_head *bh = NULL;\n-\tstruct mb_cache_entry *ce;\n \n \tdown_write(&EXT2_I(inode)->xattr_sem);\n \tif (!EXT2_I(inode)->i_file_acl)\n@@ -777,19 +778,22 @@ ext2_xattr_delete_inode(struct inode *inode)\n \t\t\tEXT2_I(inode)->i_file_acl);\n \t\tgoto cleanup;\n \t}\n-\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);\n \tlock_buffer(bh);\n \tif (HDR(bh)->h_refcount == cpu_to_le32(1)) {\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_free(ce);\n+\t\t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n+\n+\t\t/*\n+\t\t * This must happen under buffer lock for ext2_xattr_set2() to\n+\t\t * reliably detect freed block\n+\t\t */\n+\t\tmb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,\n+\t\t\t\t\t     hash, bh->b_blocknr);\n \t\text2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);\n \t\tget_bh(bh);\n \t\tbforget(bh);\n \t\tunlock_buffer(bh);\n \t} else {\n \t\tle32_add_cpu(&HDR(bh)->h_refcount, -1);\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_release(ce);\n \t\tea_bdebug(bh, \""refcount now=%d\"",\n \t\t\tle32_to_cpu(HDR(bh)->h_refcount));\n \t\tunlock_buffer(bh);\n@@ -805,18 +809,6 @@ ext2_xattr_delete_inode(struct inode *inode)\n \tup_write(&EXT2_I(inode)->xattr_sem);\n }\n \n-/*\n- * ext2_xattr_put_super()\n- *\n- * This is called when a file system is unmounted.\n- */\n-void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-\tmb_cache_shrink(sb->s_bdev);\n-}\n-\n-\n /*\n  * ext2_xattr_cache_insert()\n  *\n@@ -826,28 +818,20 @@ ext2_xattr_put_super(struct super_block *sb)\n  * Returns 0, or a negative error number on failure.\n  */\n static int\n-ext2_xattr_cache_insert(struct buffer_head *bh)\n+ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)\n {\n \t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n-\tstruct mb_cache_entry *ce;\n \tint error;\n \n-\tce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);\n-\tif (!ce)\n-\t\treturn -ENOMEM;\n-\terror = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);\n+\terror = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);\n \tif (error) {\n-\t\tmb_cache_entry_free(ce);\n \t\tif (error == -EBUSY) {\n \t\t\tea_bdebug(bh, \""already in cache (%d cache entries)\"",\n \t\t\t\tatomic_read(&ext2_xattr_cache->c_entry_count));\n \t\t\terror = 0;\n \t\t}\n-\t} else {\n-\t\tea_bdebug(bh, \""inserting [%x] (%d cache entries)\"", (int)hash,\n-\t\t\t  atomic_read(&ext2_xattr_cache->c_entry_count));\n-\t\tmb_cache_entry_release(ce);\n-\t}\n+\t} else\n+\t\tea_bdebug(bh, \""inserting [%x]\"", (int)hash);\n \treturn error;\n }\n \n@@ -903,31 +887,39 @@ static struct buffer_head *\n ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n {\n \t__u32 hash = le32_to_cpu(header->h_hash);\n-\tstruct mb_cache_entry *ce;\n+\tstruct mb2_cache_entry *ce;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tif (!header->h_hash)\n \t\treturn NULL;  /* never share */\n \tea_idebug(inode, \""looking for cached blocks [%x]\"", (int)hash);\n again:\n-\tce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,\n-\t\t\t\t       hash);\n+\tce = mb2_cache_entry_find_first(ext2_mb_cache, hash);\n \twhile (ce) {\n \t\tstruct buffer_head *bh;\n \n-\t\tif (IS_ERR(ce)) {\n-\t\t\tif (PTR_ERR(ce) == -EAGAIN)\n-\t\t\t\tgoto again;\n-\t\t\tbreak;\n-\t\t}\n-\n \t\tbh = sb_bread(inode->i_sb, ce->e_block);\n \t\tif (!bh) {\n \t\t\text2_error(inode->i_sb, \""ext2_xattr_cache_find\"",\n \t\t\t\t\""inode %ld: block %ld read error\"",\n \t\t\t\tinode->i_ino, (unsigned long) ce->e_block);\n \t\t} else {\n \t\t\tlock_buffer(bh);\n-\t\t\tif (le32_to_cpu(HDR(bh)->h_refcount) >\n+\t\t\t/*\n+\t\t\t * We have to be careful about races with freeing or\n+\t\t\t * rehashing of xattr block. Once we hold buffer lock\n+\t\t\t * xattr block's state is stable so we can check\n+\t\t\t * whether the block got freed / rehashed or not.\n+\t\t\t * Since we unhash mbcache entry under buffer lock when\n+\t\t\t * freeing / rehashing xattr block, checking whether\n+\t\t\t * entry is still hashed is reliable.\n+\t\t\t */\n+\t\t\tif (hlist_bl_unhashed(&ce->e_hash_list)) {\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n+\t\t\t\tunlock_buffer(bh);\n+\t\t\t\tbrelse(bh);\n+\t\t\t\tgoto again;\n+\t\t\t} else if (le32_to_cpu(HDR(bh)->h_refcount) >\n \t\t\t\t   EXT2_XATTR_REFCOUNT_MAX) {\n \t\t\t\tea_idebug(inode, \""block %ld refcount %d>%d\"",\n \t\t\t\t\t  (unsigned long) ce->e_block,\n@@ -936,13 +928,14 @@ ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n \t\t\t} else if (!ext2_xattr_cmp(header, HDR(bh))) {\n \t\t\t\tea_bdebug(bh, \""b_count=%d\"",\n \t\t\t\t\t  atomic_read(&(bh->b_count)));\n-\t\t\t\tmb_cache_entry_release(ce);\n+\t\t\t\tmb2_cache_entry_touch(ext2_mb_cache, ce);\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n \t\t\t\treturn bh;\n \t\t\t}\n \t\t\tunlock_buffer(bh);\n \t\t\tbrelse(bh);\n \t\t}\n-\t\tce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);\n+\t\tce = mb2_cache_entry_find_next(ext2_mb_cache, ce);\n \t}\n \treturn NULL;\n }\n@@ -1015,17 +1008,15 @@ static void ext2_xattr_rehash(struct ext2_xattr_header *header,\n \n #undef BLOCK_HASH_SHIFT\n \n-int __init\n-init_ext2_xattr(void)\n+#define HASH_BUCKET_BITS 10\n+\n+struct mb2_cache *ext2_xattr_create_cache(void)\n {\n-\text2_xattr_cache = mb_cache_create(\""ext2_xattr\"", 6);\n-\tif (!ext2_xattr_cache)\n-\t\treturn -ENOMEM;\n-\treturn 0;\n+\treturn mb2_cache_create(HASH_BUCKET_BITS);\n }\n \n-void\n-exit_ext2_xattr(void)\n+void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n-\tmb_cache_destroy(ext2_xattr_cache);\n+\tif (cache)\n+\t\tmb2_cache_destroy(cache);\n }""}<_**next**_>{""sha"": ""6ea38aa9563a00649bf25544eed131bbe8b1d88d"", ""filename"": ""fs/ext2/xattr.h"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 16, ""changes"": 21, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -53,6 +53,8 @@ struct ext2_xattr_entry {\n #define EXT2_XATTR_SIZE(size) \\\n \t(((size) + EXT2_XATTR_ROUND) & ~EXT2_XATTR_ROUND)\n \n+struct mb2_cache;\n+\n # ifdef CONFIG_EXT2_FS_XATTR\n \n extern const struct xattr_handler ext2_xattr_user_handler;\n@@ -65,10 +67,9 @@ extern int ext2_xattr_get(struct inode *, int, const char *, void *, size_t);\n extern int ext2_xattr_set(struct inode *, int, const char *, const void *, size_t, int);\n \n extern void ext2_xattr_delete_inode(struct inode *);\n-extern void ext2_xattr_put_super(struct super_block *);\n \n-extern int init_ext2_xattr(void);\n-extern void exit_ext2_xattr(void);\n+extern struct mb2_cache *ext2_xattr_create_cache(void);\n+extern void ext2_xattr_destroy_cache(struct mb2_cache *cache);\n \n extern const struct xattr_handler *ext2_xattr_handlers[];\n \n@@ -93,19 +94,7 @@ ext2_xattr_delete_inode(struct inode *inode)\n {\n }\n \n-static inline void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-}\n-\n-static inline int\n-init_ext2_xattr(void)\n-{\n-\treturn 0;\n-}\n-\n-static inline void\n-exit_ext2_xattr(void)\n+static inline void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n }\n ""}","ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)
{
	struct inode *inode = d_inode(dentry);
	struct buffer_head *bh = NULL;
	struct ext2_xattr_entry *entry;
 	char *end;
 	size_t rest = buffer_size;
 	int error;
	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	ea_idebug(inode, ""buffer=%p, buffer_size=%ld"",
 		  buffer, (long)buffer_size);

	down_read(&EXT2_I(inode)->xattr_sem);
	error = 0;
	if (!EXT2_I(inode)->i_file_acl)
		goto cleanup;
	ea_idebug(inode, ""reading block %d"", EXT2_I(inode)->i_file_acl);
	bh = sb_bread(inode->i_sb, EXT2_I(inode)->i_file_acl);
	error = -EIO;
	if (!bh)
		goto cleanup;
	ea_bdebug(bh, ""b_count=%d, refcount=%d"",
		atomic_read(&(bh->b_count)), le32_to_cpu(HDR(bh)->h_refcount));
	end = bh->b_data + bh->b_size;
	if (HDR(bh)->h_magic != cpu_to_le32(EXT2_XATTR_MAGIC) ||
	    HDR(bh)->h_blocks != cpu_to_le32(1)) {
bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_list"",
			""inode %ld: bad block %d"", inode->i_ino,
			EXT2_I(inode)->i_file_acl);
		error = -EIO;
		goto cleanup;
	}

	/* check the on-disk data structure */
	entry = FIRST_ENTRY(bh);
	while (!IS_LAST_ENTRY(entry)) {
		struct ext2_xattr_entry *next = EXT2_XATTR_NEXT(entry);

		if ((char *)next >= end)
 			goto bad_block;
 		entry = next;
 	}
	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 
 	/* list the attribute names */
	for (entry = FIRST_ENTRY(bh); !IS_LAST_ENTRY(entry);
	     entry = EXT2_XATTR_NEXT(entry)) {
		const struct xattr_handler *handler =
			ext2_xattr_handler(entry->e_name_index);

		if (handler && (!handler->list || handler->list(dentry))) {
			const char *prefix = handler->prefix ?: handler->name;
			size_t prefix_len = strlen(prefix);
			size_t size = prefix_len + entry->e_name_len + 1;

			if (buffer) {
				if (size > rest) {
					error = -ERANGE;
					goto cleanup;
				}
				memcpy(buffer, prefix, prefix_len);
				buffer += prefix_len;
				memcpy(buffer, entry->e_name, entry->e_name_len);
				buffer += entry->e_name_len;
				*buffer++ = 0;
			}
			rest -= size;
		}
	}
	error = buffer_size - rest;  /* total size */

cleanup:
	brelse(bh);
	up_read(&EXT2_I(inode)->xattr_sem);

	return error;
}
","ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)
{
	struct inode *inode = d_inode(dentry);
	struct buffer_head *bh = NULL;
	struct ext2_xattr_entry *entry;
 	char *end;
 	size_t rest = buffer_size;
 	int error;
 
 	ea_idebug(inode, ""buffer=%p, buffer_size=%ld"",
 		  buffer, (long)buffer_size);

	down_read(&EXT2_I(inode)->xattr_sem);
	error = 0;
	if (!EXT2_I(inode)->i_file_acl)
		goto cleanup;
	ea_idebug(inode, ""reading block %d"", EXT2_I(inode)->i_file_acl);
	bh = sb_bread(inode->i_sb, EXT2_I(inode)->i_file_acl);
	error = -EIO;
	if (!bh)
		goto cleanup;
	ea_bdebug(bh, ""b_count=%d, refcount=%d"",
		atomic_read(&(bh->b_count)), le32_to_cpu(HDR(bh)->h_refcount));
	end = bh->b_data + bh->b_size;
	if (HDR(bh)->h_magic != cpu_to_le32(EXT2_XATTR_MAGIC) ||
	    HDR(bh)->h_blocks != cpu_to_le32(1)) {
bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_list"",
			""inode %ld: bad block %d"", inode->i_ino,
			EXT2_I(inode)->i_file_acl);
		error = -EIO;
		goto cleanup;
	}

	/* check the on-disk data structure */
	entry = FIRST_ENTRY(bh);
	while (!IS_LAST_ENTRY(entry)) {
		struct ext2_xattr_entry *next = EXT2_XATTR_NEXT(entry);

		if ((char *)next >= end)
 			goto bad_block;
 		entry = next;
 	}
	if (ext2_xattr_cache_insert(bh))
 		ea_idebug(inode, ""cache insert failed"");
 
 	/* list the attribute names */
	for (entry = FIRST_ENTRY(bh); !IS_LAST_ENTRY(entry);
	     entry = EXT2_XATTR_NEXT(entry)) {
		const struct xattr_handler *handler =
			ext2_xattr_handler(entry->e_name_index);

		if (handler && (!handler->list || handler->list(dentry))) {
			const char *prefix = handler->prefix ?: handler->name;
			size_t prefix_len = strlen(prefix);
			size_t size = prefix_len + entry->e_name_len + 1;

			if (buffer) {
				if (size > rest) {
					error = -ERANGE;
					goto cleanup;
				}
				memcpy(buffer, prefix, prefix_len);
				buffer += prefix_len;
				memcpy(buffer, entry->e_name, entry->e_name_len);
				buffer += entry->e_name_len;
				*buffer++ = 0;
			}
			rest -= size;
		}
	}
	error = buffer_size - rest;  /* total size */

cleanup:
	brelse(bh);
	up_read(&EXT2_I(inode)->xattr_sem);

	return error;
}
",C,"	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
","	if (ext2_xattr_cache_insert(bh))
",,"@@ -56,7 +56,7 @@
 #include <linux/buffer_head.h>
 #include <linux/init.h>
 #include <linux/slab.h>
-#include <linux/mbcache.h>
+#include <linux/mbcache2.h>
 #include <linux/quotaops.h>
 #include <linux/rwsem.h>
 #include <linux/security.h>
@@ -90,14 +90,12 @@
 static int ext2_xattr_set2(struct inode *, struct buffer_head *,
 			   struct ext2_xattr_header *);
 
-static int ext2_xattr_cache_insert(struct buffer_head *);
+static int ext2_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);
 static struct buffer_head *ext2_xattr_cache_find(struct inode *,
 						 struct ext2_xattr_header *);
 static void ext2_xattr_rehash(struct ext2_xattr_header *,
 			      struct ext2_xattr_entry *);
 
-static struct mb_cache *ext2_xattr_cache;
-
 static const struct xattr_handler *ext2_xattr_handler_map[] = {
 	[EXT2_XATTR_INDEX_USER]		     = &ext2_xattr_user_handler,
 #ifdef CONFIG_EXT2_FS_POSIX_ACL
@@ -152,6 +150,7 @@ ext2_xattr_get(struct inode *inode, int name_index, const char *name,
 	size_t name_len, size;
 	char *end;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	ea_idebug(inode, ""name=%d.%s, buffer=%p, buffer_size=%ld"",
 		  name_index, name, buffer, (long)buffer_size);
@@ -196,7 +195,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_get"",
 			goto found;
 		entry = next;
 	}
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 	error = -ENODATA;
 	goto cleanup;
@@ -209,7 +208,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_get"",
 	    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)
 		goto bad_block;
 
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 	if (buffer) {
 		error = -ERANGE;
@@ -247,6 +246,7 @@ ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)
 	char *end;
 	size_t rest = buffer_size;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	ea_idebug(inode, ""buffer=%p, buffer_size=%ld"",
 		  buffer, (long)buffer_size);
@@ -281,7 +281,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_list"",
 			goto bad_block;
 		entry = next;
 	}
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 
 	/* list the attribute names */
@@ -483,22 +483,23 @@ bad_block:		ext2_error(sb, ""ext2_xattr_set"",
 	/* Here we know that we can set the new attribute. */
 
 	if (header) {
-		struct mb_cache_entry *ce;
-
 		/* assert(header == HDR(bh)); */
-		ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,
-					bh->b_blocknr);
 		lock_buffer(bh);
 		if (header->h_refcount == cpu_to_le32(1)) {
+			__u32 hash = le32_to_cpu(header->h_hash);
+
 			ea_bdebug(bh, ""modifying in-place"");
-			if (ce)
-				mb_cache_entry_free(ce);
+			/*
+			 * This must happen under buffer lock for
+			 * ext2_xattr_set2() to reliably detect modified block
+			 */
+			mb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,
+						     hash, bh->b_blocknr);
+
 			/* keep the buffer locked while modifying it. */
 		} else {
 			int offset;
 
-			if (ce)
-				mb_cache_entry_release(ce);
 			unlock_buffer(bh);
 			ea_bdebug(bh, ""cloning"");
 			header = kmalloc(bh->b_size, GFP_KERNEL);
@@ -626,6 +627,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *new_bh = NULL;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;
 
 	if (header) {
 		new_bh = ext2_xattr_cache_find(inode, header);
@@ -653,7 +655,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 			   don't need to change the reference count. */
 			new_bh = old_bh;
 			get_bh(new_bh);
-			ext2_xattr_cache_insert(new_bh);
+			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
 		} else {
 			/* We need to allocate a new block */
 			ext2_fsblk_t goal = ext2_group_first_block_no(sb,
@@ -674,7 +676,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 			memcpy(new_bh->b_data, header, new_bh->b_size);
 			set_buffer_uptodate(new_bh);
 			unlock_buffer(new_bh);
-			ext2_xattr_cache_insert(new_bh);
+			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
 			
 			ext2_xattr_update_super_block(sb);
 		}
@@ -707,19 +709,21 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 
 	error = 0;
 	if (old_bh && old_bh != new_bh) {
-		struct mb_cache_entry *ce;
-
 		/*
 		 * If there was an old block and we are no longer using it,
 		 * release the old block.
 		 */
-		ce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,
-					old_bh->b_blocknr);
 		lock_buffer(old_bh);
 		if (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {
+			__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);
+
+			/*
+			 * This must happen under buffer lock for
+			 * ext2_xattr_set2() to reliably detect freed block
+			 */
+			mb2_cache_entry_delete_block(ext2_mb_cache,
+						     hash, old_bh->b_blocknr);
 			/* Free the old block. */
-			if (ce)
-				mb_cache_entry_free(ce);
 			ea_bdebug(old_bh, ""freeing"");
 			ext2_free_blocks(inode, old_bh->b_blocknr, 1);
 			mark_inode_dirty(inode);
@@ -730,8 +734,6 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 		} else {
 			/* Decrement the refcount only. */
 			le32_add_cpu(&HDR(old_bh)->h_refcount, -1);
-			if (ce)
-				mb_cache_entry_release(ce);
 			dquot_free_block_nodirty(inode, 1);
 			mark_inode_dirty(inode);
 			mark_buffer_dirty(old_bh);
@@ -757,7 +759,6 @@ void
 ext2_xattr_delete_inode(struct inode *inode)
 {
 	struct buffer_head *bh = NULL;
-	struct mb_cache_entry *ce;
 
 	down_write(&EXT2_I(inode)->xattr_sem);
 	if (!EXT2_I(inode)->i_file_acl)
@@ -777,19 +778,22 @@ ext2_xattr_delete_inode(struct inode *inode)
 			EXT2_I(inode)->i_file_acl);
 		goto cleanup;
 	}
-	ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);
 	lock_buffer(bh);
 	if (HDR(bh)->h_refcount == cpu_to_le32(1)) {
-		if (ce)
-			mb_cache_entry_free(ce);
+		__u32 hash = le32_to_cpu(HDR(bh)->h_hash);
+
+		/*
+		 * This must happen under buffer lock for ext2_xattr_set2() to
+		 * reliably detect freed block
+		 */
+		mb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,
+					     hash, bh->b_blocknr);
 		ext2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);
 		get_bh(bh);
 		bforget(bh);
 		unlock_buffer(bh);
 	} else {
 		le32_add_cpu(&HDR(bh)->h_refcount, -1);
-		if (ce)
-			mb_cache_entry_release(ce);
 		ea_bdebug(bh, ""refcount now=%d"",
 			le32_to_cpu(HDR(bh)->h_refcount));
 		unlock_buffer(bh);
@@ -805,18 +809,6 @@ ext2_xattr_delete_inode(struct inode *inode)
 	up_write(&EXT2_I(inode)->xattr_sem);
 }
 
-/*
- * ext2_xattr_put_super()
- *
- * This is called when a file system is unmounted.
- */
-void
-ext2_xattr_put_super(struct super_block *sb)
-{
-	mb_cache_shrink(sb->s_bdev);
-}
-
-
 /*
  * ext2_xattr_cache_insert()
  *
@@ -826,28 +818,20 @@ ext2_xattr_put_super(struct super_block *sb)
  * Returns 0, or a negative error number on failure.
  */
 static int
-ext2_xattr_cache_insert(struct buffer_head *bh)
+ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)
 {
 	__u32 hash = le32_to_cpu(HDR(bh)->h_hash);
-	struct mb_cache_entry *ce;
 	int error;
 
-	ce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);
-	if (!ce)
-		return -ENOMEM;
-	error = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);
+	error = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);
 	if (error) {
-		mb_cache_entry_free(ce);
 		if (error == -EBUSY) {
 			ea_bdebug(bh, ""already in cache (%d cache entries)"",
 				atomic_read(&ext2_xattr_cache->c_entry_count));
 			error = 0;
 		}
-	} else {
-		ea_bdebug(bh, ""inserting [%x] (%d cache entries)"", (int)hash,
-			  atomic_read(&ext2_xattr_cache->c_entry_count));
-		mb_cache_entry_release(ce);
-	}
+	} else
+		ea_bdebug(bh, ""inserting [%x]"", (int)hash);
 	return error;
 }
 
@@ -903,31 +887,39 @@ static struct buffer_head *
 ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)
 {
 	__u32 hash = le32_to_cpu(header->h_hash);
-	struct mb_cache_entry *ce;
+	struct mb2_cache_entry *ce;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	if (!header->h_hash)
 		return NULL;  /* never share */
 	ea_idebug(inode, ""looking for cached blocks [%x]"", (int)hash);
 again:
-	ce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,
-				       hash);
+	ce = mb2_cache_entry_find_first(ext2_mb_cache, hash);
 	while (ce) {
 		struct buffer_head *bh;
 
-		if (IS_ERR(ce)) {
-			if (PTR_ERR(ce) == -EAGAIN)
-				goto again;
-			break;
-		}
-
 		bh = sb_bread(inode->i_sb, ce->e_block);
 		if (!bh) {
 			ext2_error(inode->i_sb, ""ext2_xattr_cache_find"",
 				""inode %ld: block %ld read error"",
 				inode->i_ino, (unsigned long) ce->e_block);
 		} else {
 			lock_buffer(bh);
-			if (le32_to_cpu(HDR(bh)->h_refcount) >
+			/*
+			 * We have to be careful about races with freeing or
+			 * rehashing of xattr block. Once we hold buffer lock
+			 * xattr block's state is stable so we can check
+			 * whether the block got freed / rehashed or not.
+			 * Since we unhash mbcache entry under buffer lock when
+			 * freeing / rehashing xattr block, checking whether
+			 * entry is still hashed is reliable.
+			 */
+			if (hlist_bl_unhashed(&ce->e_hash_list)) {
+				mb2_cache_entry_put(ext2_mb_cache, ce);
+				unlock_buffer(bh);
+				brelse(bh);
+				goto again;
+			} else if (le32_to_cpu(HDR(bh)->h_refcount) >
 				   EXT2_XATTR_REFCOUNT_MAX) {
 				ea_idebug(inode, ""block %ld refcount %d>%d"",
 					  (unsigned long) ce->e_block,
@@ -936,13 +928,14 @@ ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)
 			} else if (!ext2_xattr_cmp(header, HDR(bh))) {
 				ea_bdebug(bh, ""b_count=%d"",
 					  atomic_read(&(bh->b_count)));
-				mb_cache_entry_release(ce);
+				mb2_cache_entry_touch(ext2_mb_cache, ce);
+				mb2_cache_entry_put(ext2_mb_cache, ce);
 				return bh;
 			}
 			unlock_buffer(bh);
 			brelse(bh);
 		}
-		ce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);
+		ce = mb2_cache_entry_find_next(ext2_mb_cache, ce);
 	}
 	return NULL;
 }
@@ -1015,17 +1008,15 @@ static void ext2_xattr_rehash(struct ext2_xattr_header *header,
 
 #undef BLOCK_HASH_SHIFT
 
-int __init
-init_ext2_xattr(void)
+#define HASH_BUCKET_BITS 10
+
+struct mb2_cache *ext2_xattr_create_cache(void)
 {
-	ext2_xattr_cache = mb_cache_create(""ext2_xattr"", 6);
-	if (!ext2_xattr_cache)
-		return -ENOMEM;
-	return 0;
+	return mb2_cache_create(HASH_BUCKET_BITS);
 }
 
-void
-exit_ext2_xattr(void)
+void ext2_xattr_destroy_cache(struct mb2_cache *cache)
 {
-	mb_cache_destroy(ext2_xattr_cache);
+	if (cache)
+		mb2_cache_destroy(cache);
 }",linux,be0726d33cb8f411945884664924bed3cb8c70ee,82939d7999dfc1f1998c4b1c12e2f19edbdff272,1,"ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)
{
	struct inode *inode = d_inode(dentry);
	struct buffer_head *bh = NULL;
	struct ext2_xattr_entry *entry;
 	char *end;
 	size_t rest = buffer_size;
 	int error;
//fix_flaw_line_below:
//	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	ea_idebug(inode, ""buffer=%p, buffer_size=%ld"",
 		  buffer, (long)buffer_size);

	down_read(&EXT2_I(inode)->xattr_sem);
	error = 0;
	if (!EXT2_I(inode)->i_file_acl)
		goto cleanup;
	ea_idebug(inode, ""reading block %d"", EXT2_I(inode)->i_file_acl);
	bh = sb_bread(inode->i_sb, EXT2_I(inode)->i_file_acl);
	error = -EIO;
	if (!bh)
		goto cleanup;
	ea_bdebug(bh, ""b_count=%d, refcount=%d"",
		atomic_read(&(bh->b_count)), le32_to_cpu(HDR(bh)->h_refcount));
	end = bh->b_data + bh->b_size;
	if (HDR(bh)->h_magic != cpu_to_le32(EXT2_XATTR_MAGIC) ||
	    HDR(bh)->h_blocks != cpu_to_le32(1)) {
bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_list"",
			""inode %ld: bad block %d"", inode->i_ino,
			EXT2_I(inode)->i_file_acl);
		error = -EIO;
		goto cleanup;
	}

	/* check the on-disk data structure */
	entry = FIRST_ENTRY(bh);
	while (!IS_LAST_ENTRY(entry)) {
		struct ext2_xattr_entry *next = EXT2_XATTR_NEXT(entry);

		if ((char *)next >= end)
 			goto bad_block;
 		entry = next;
 	}
//flaw_line_below:
	if (ext2_xattr_cache_insert(bh))
//fix_flaw_line_below:
//	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 
 	/* list the attribute names */
	for (entry = FIRST_ENTRY(bh); !IS_LAST_ENTRY(entry);
	     entry = EXT2_XATTR_NEXT(entry)) {
		const struct xattr_handler *handler =
			ext2_xattr_handler(entry->e_name_index);

		if (handler && (!handler->list || handler->list(dentry))) {
			const char *prefix = handler->prefix ?: handler->name;
			size_t prefix_len = strlen(prefix);
			size_t size = prefix_len + entry->e_name_len + 1;

			if (buffer) {
				if (size > rest) {
					error = -ERANGE;
					goto cleanup;
				}
				memcpy(buffer, prefix, prefix_len);
				buffer += prefix_len;
				memcpy(buffer, entry->e_name, entry->e_name_len);
				buffer += entry->e_name_len;
				*buffer++ = 0;
			}
			rest -= size;
		}
	}
	error = buffer_size - rest;  /* total size */

cleanup:
	brelse(bh);
	up_read(&EXT2_I(inode)->xattr_sem);

	return error;
}
"
5418,183154,,Local,Not required,Partial,CVE-2015-8952,https://www.cvedetails.com/cve/CVE-2015-8952/,CWE-19,Low,,,,2016-10-16,2.1,"The mbcache feature in the ext2 and ext4 filesystem implementations in the Linux kernel before 4.6 mishandles xattr block caching, which allows local users to cause a denial of service (soft lockup) via filesystem operations in environments that use many attributes, as demonstrated by Ceph and Samba.",2018-03-15,DoS ,0,https://github.com/torvalds/linux/commit/be0726d33cb8f411945884664924bed3cb8c70ee,be0726d33cb8f411945884664924bed3cb8c70ee,"ext2: convert to mbcache2

The conversion is generally straightforward. We convert filesystem from
a global cache to per-fs one. Similarly to ext4 the tricky part is that
xattr block corresponding to found mbcache entry can get freed before we
get buffer lock for that block. So we have to check whether the entry is
still valid after getting the buffer lock.

Signed-off-by: Jan Kara <jack@suse.cz>
Signed-off-by: Theodore Ts'o <tytso@mit.edu>",3,fs/ext2/xattr.c,"{""sha"": ""f98ce7e60a0f84f71743e0dfe069c7e96c6bd648"", ""filename"": ""fs/ext2/ext2.h"", ""status"": ""modified"", ""additions"": 3, ""deletions"": 0, ""changes"": 3, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/ext2.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -61,6 +61,8 @@ struct ext2_block_alloc_info {\n #define rsv_start rsv_window._rsv_start\n #define rsv_end rsv_window._rsv_end\n \n+struct mb2_cache;\n+\n /*\n  * second extended-fs super-block data in memory\n  */\n@@ -111,6 +113,7 @@ struct ext2_sb_info {\n \t * of the mount options.\n \t */\n \tspinlock_t s_lock;\n+\tstruct mb2_cache *s_mb_cache;\n };\n \n static inline spinlock_t *""}<_**next**_>{""sha"": ""b78caf25f746220ce635a3bd946bedeaf7e3e750"", ""filename"": ""fs/ext2/super.c"", ""status"": ""modified"", ""additions"": 17, ""deletions"": 8, ""changes"": 25, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/super.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -131,7 +131,10 @@ static void ext2_put_super (struct super_block * sb)\n \n \tdquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);\n \n-\text2_xattr_put_super(sb);\n+\tif (sbi->s_mb_cache) {\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n+\t\tsbi->s_mb_cache = NULL;\n+\t}\n \tif (!(sb->s_flags & MS_RDONLY)) {\n \t\tstruct ext2_super_block *es = sbi->s_es;\n \n@@ -1104,6 +1107,14 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\text2_msg(sb, KERN_ERR, \""error: insufficient memory\"");\n \t\tgoto failed_mount3;\n \t}\n+\n+#ifdef CONFIG_EXT2_FS_XATTR\n+\tsbi->s_mb_cache = ext2_xattr_create_cache();\n+\tif (!sbi->s_mb_cache) {\n+\t\text2_msg(sb, KERN_ERR, \""Failed to create an mb_cache\"");\n+\t\tgoto failed_mount3;\n+\t}\n+#endif\n \t/*\n \t * set up enough so that it can read an inode\n \t */\n@@ -1149,6 +1160,8 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\t\tsb->s_id);\n \tgoto failed_mount;\n failed_mount3:\n+\tif (sbi->s_mb_cache)\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n \tpercpu_counter_destroy(&sbi->s_freeblocks_counter);\n \tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n \tpercpu_counter_destroy(&sbi->s_dirs_counter);\n@@ -1555,28 +1568,24 @@ MODULE_ALIAS_FS(\""ext2\"");\n \n static int __init init_ext2_fs(void)\n {\n-\tint err = init_ext2_xattr();\n-\tif (err)\n-\t\treturn err;\n+\tint err;\n+\n \terr = init_inodecache();\n \tif (err)\n-\t\tgoto out1;\n+\t\treturn err;\n         err = register_filesystem(&ext2_fs_type);\n \tif (err)\n \t\tgoto out;\n \treturn 0;\n out:\n \tdestroy_inodecache();\n-out1:\n-\texit_ext2_xattr();\n \treturn err;\n }\n \n static void __exit exit_ext2_fs(void)\n {\n \tunregister_filesystem(&ext2_fs_type);\n \tdestroy_inodecache();\n-\texit_ext2_xattr();\n }\n \n MODULE_AUTHOR(\""Remy Card and others\"");""}<_**next**_>{""sha"": ""7162b4869bc32515800d8ffc06ac3835ea241c8b"", ""filename"": ""fs/ext2/xattr.c"", ""status"": ""modified"", ""additions"": 67, ""deletions"": 76, ""changes"": 143, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -56,7 +56,7 @@\n #include <linux/buffer_head.h>\n #include <linux/init.h>\n #include <linux/slab.h>\n-#include <linux/mbcache.h>\n+#include <linux/mbcache2.h>\n #include <linux/quotaops.h>\n #include <linux/rwsem.h>\n #include <linux/security.h>\n@@ -90,14 +90,12 @@\n static int ext2_xattr_set2(struct inode *, struct buffer_head *,\n \t\t\t   struct ext2_xattr_header *);\n \n-static int ext2_xattr_cache_insert(struct buffer_head *);\n+static int ext2_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);\n static struct buffer_head *ext2_xattr_cache_find(struct inode *,\n \t\t\t\t\t\t struct ext2_xattr_header *);\n static void ext2_xattr_rehash(struct ext2_xattr_header *,\n \t\t\t      struct ext2_xattr_entry *);\n \n-static struct mb_cache *ext2_xattr_cache;\n-\n static const struct xattr_handler *ext2_xattr_handler_map[] = {\n \t[EXT2_XATTR_INDEX_USER]\t\t     = &ext2_xattr_user_handler,\n #ifdef CONFIG_EXT2_FS_POSIX_ACL\n@@ -152,6 +150,7 @@ ext2_xattr_get(struct inode *inode, int name_index, const char *name,\n \tsize_t name_len, size;\n \tchar *end;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""name=%d.%s, buffer=%p, buffer_size=%ld\"",\n \t\t  name_index, name, buffer, (long)buffer_size);\n@@ -196,7 +195,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t\t\tgoto found;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \terror = -ENODATA;\n \tgoto cleanup;\n@@ -209,7 +208,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)\n \t\tgoto bad_block;\n \n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \tif (buffer) {\n \t\terror = -ERANGE;\n@@ -247,6 +246,7 @@ ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)\n \tchar *end;\n \tsize_t rest = buffer_size;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""buffer=%p, buffer_size=%ld\"",\n \t\t  buffer, (long)buffer_size);\n@@ -281,7 +281,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_list\"",\n \t\t\tgoto bad_block;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \n \t/* list the attribute names */\n@@ -483,22 +483,23 @@ bad_block:\t\text2_error(sb, \""ext2_xattr_set\"",\n \t/* Here we know that we can set the new attribute. */\n \n \tif (header) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/* assert(header == HDR(bh)); */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,\n-\t\t\t\t\tbh->b_blocknr);\n \t\tlock_buffer(bh);\n \t\tif (header->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(header->h_hash);\n+\n \t\t\tea_bdebug(bh, \""modifying in-place\"");\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect modified block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,\n+\t\t\t\t\t\t     hash, bh->b_blocknr);\n+\n \t\t\t/* keep the buffer locked while modifying it. */\n \t\t} else {\n \t\t\tint offset;\n \n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tunlock_buffer(bh);\n \t\t\tea_bdebug(bh, \""cloning\"");\n \t\t\theader = kmalloc(bh->b_size, GFP_KERNEL);\n@@ -626,6 +627,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \tstruct super_block *sb = inode->i_sb;\n \tstruct buffer_head *new_bh = NULL;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;\n \n \tif (header) {\n \t\tnew_bh = ext2_xattr_cache_find(inode, header);\n@@ -653,7 +655,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\t   don't need to change the reference count. */\n \t\t\tnew_bh = old_bh;\n \t\t\tget_bh(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t} else {\n \t\t\t/* We need to allocate a new block */\n \t\t\text2_fsblk_t goal = ext2_group_first_block_no(sb,\n@@ -674,7 +676,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\tmemcpy(new_bh->b_data, header, new_bh->b_size);\n \t\t\tset_buffer_uptodate(new_bh);\n \t\t\tunlock_buffer(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t\t\n \t\t\text2_xattr_update_super_block(sb);\n \t\t}\n@@ -707,19 +709,21 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \n \terror = 0;\n \tif (old_bh && old_bh != new_bh) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/*\n \t\t * If there was an old block and we are no longer using it,\n \t\t * release the old block.\n \t\t */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,\n-\t\t\t\t\told_bh->b_blocknr);\n \t\tlock_buffer(old_bh);\n \t\tif (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);\n+\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect freed block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(ext2_mb_cache,\n+\t\t\t\t\t\t     hash, old_bh->b_blocknr);\n \t\t\t/* Free the old block. */\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n \t\t\tea_bdebug(old_bh, \""freeing\"");\n \t\t\text2_free_blocks(inode, old_bh->b_blocknr, 1);\n \t\t\tmark_inode_dirty(inode);\n@@ -730,8 +734,6 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t} else {\n \t\t\t/* Decrement the refcount only. */\n \t\t\tle32_add_cpu(&HDR(old_bh)->h_refcount, -1);\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tdquot_free_block_nodirty(inode, 1);\n \t\t\tmark_inode_dirty(inode);\n \t\t\tmark_buffer_dirty(old_bh);\n@@ -757,7 +759,6 @@ void\n ext2_xattr_delete_inode(struct inode *inode)\n {\n \tstruct buffer_head *bh = NULL;\n-\tstruct mb_cache_entry *ce;\n \n \tdown_write(&EXT2_I(inode)->xattr_sem);\n \tif (!EXT2_I(inode)->i_file_acl)\n@@ -777,19 +778,22 @@ ext2_xattr_delete_inode(struct inode *inode)\n \t\t\tEXT2_I(inode)->i_file_acl);\n \t\tgoto cleanup;\n \t}\n-\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);\n \tlock_buffer(bh);\n \tif (HDR(bh)->h_refcount == cpu_to_le32(1)) {\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_free(ce);\n+\t\t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n+\n+\t\t/*\n+\t\t * This must happen under buffer lock for ext2_xattr_set2() to\n+\t\t * reliably detect freed block\n+\t\t */\n+\t\tmb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,\n+\t\t\t\t\t     hash, bh->b_blocknr);\n \t\text2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);\n \t\tget_bh(bh);\n \t\tbforget(bh);\n \t\tunlock_buffer(bh);\n \t} else {\n \t\tle32_add_cpu(&HDR(bh)->h_refcount, -1);\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_release(ce);\n \t\tea_bdebug(bh, \""refcount now=%d\"",\n \t\t\tle32_to_cpu(HDR(bh)->h_refcount));\n \t\tunlock_buffer(bh);\n@@ -805,18 +809,6 @@ ext2_xattr_delete_inode(struct inode *inode)\n \tup_write(&EXT2_I(inode)->xattr_sem);\n }\n \n-/*\n- * ext2_xattr_put_super()\n- *\n- * This is called when a file system is unmounted.\n- */\n-void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-\tmb_cache_shrink(sb->s_bdev);\n-}\n-\n-\n /*\n  * ext2_xattr_cache_insert()\n  *\n@@ -826,28 +818,20 @@ ext2_xattr_put_super(struct super_block *sb)\n  * Returns 0, or a negative error number on failure.\n  */\n static int\n-ext2_xattr_cache_insert(struct buffer_head *bh)\n+ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)\n {\n \t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n-\tstruct mb_cache_entry *ce;\n \tint error;\n \n-\tce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);\n-\tif (!ce)\n-\t\treturn -ENOMEM;\n-\terror = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);\n+\terror = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);\n \tif (error) {\n-\t\tmb_cache_entry_free(ce);\n \t\tif (error == -EBUSY) {\n \t\t\tea_bdebug(bh, \""already in cache (%d cache entries)\"",\n \t\t\t\tatomic_read(&ext2_xattr_cache->c_entry_count));\n \t\t\terror = 0;\n \t\t}\n-\t} else {\n-\t\tea_bdebug(bh, \""inserting [%x] (%d cache entries)\"", (int)hash,\n-\t\t\t  atomic_read(&ext2_xattr_cache->c_entry_count));\n-\t\tmb_cache_entry_release(ce);\n-\t}\n+\t} else\n+\t\tea_bdebug(bh, \""inserting [%x]\"", (int)hash);\n \treturn error;\n }\n \n@@ -903,31 +887,39 @@ static struct buffer_head *\n ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n {\n \t__u32 hash = le32_to_cpu(header->h_hash);\n-\tstruct mb_cache_entry *ce;\n+\tstruct mb2_cache_entry *ce;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tif (!header->h_hash)\n \t\treturn NULL;  /* never share */\n \tea_idebug(inode, \""looking for cached blocks [%x]\"", (int)hash);\n again:\n-\tce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,\n-\t\t\t\t       hash);\n+\tce = mb2_cache_entry_find_first(ext2_mb_cache, hash);\n \twhile (ce) {\n \t\tstruct buffer_head *bh;\n \n-\t\tif (IS_ERR(ce)) {\n-\t\t\tif (PTR_ERR(ce) == -EAGAIN)\n-\t\t\t\tgoto again;\n-\t\t\tbreak;\n-\t\t}\n-\n \t\tbh = sb_bread(inode->i_sb, ce->e_block);\n \t\tif (!bh) {\n \t\t\text2_error(inode->i_sb, \""ext2_xattr_cache_find\"",\n \t\t\t\t\""inode %ld: block %ld read error\"",\n \t\t\t\tinode->i_ino, (unsigned long) ce->e_block);\n \t\t} else {\n \t\t\tlock_buffer(bh);\n-\t\t\tif (le32_to_cpu(HDR(bh)->h_refcount) >\n+\t\t\t/*\n+\t\t\t * We have to be careful about races with freeing or\n+\t\t\t * rehashing of xattr block. Once we hold buffer lock\n+\t\t\t * xattr block's state is stable so we can check\n+\t\t\t * whether the block got freed / rehashed or not.\n+\t\t\t * Since we unhash mbcache entry under buffer lock when\n+\t\t\t * freeing / rehashing xattr block, checking whether\n+\t\t\t * entry is still hashed is reliable.\n+\t\t\t */\n+\t\t\tif (hlist_bl_unhashed(&ce->e_hash_list)) {\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n+\t\t\t\tunlock_buffer(bh);\n+\t\t\t\tbrelse(bh);\n+\t\t\t\tgoto again;\n+\t\t\t} else if (le32_to_cpu(HDR(bh)->h_refcount) >\n \t\t\t\t   EXT2_XATTR_REFCOUNT_MAX) {\n \t\t\t\tea_idebug(inode, \""block %ld refcount %d>%d\"",\n \t\t\t\t\t  (unsigned long) ce->e_block,\n@@ -936,13 +928,14 @@ ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n \t\t\t} else if (!ext2_xattr_cmp(header, HDR(bh))) {\n \t\t\t\tea_bdebug(bh, \""b_count=%d\"",\n \t\t\t\t\t  atomic_read(&(bh->b_count)));\n-\t\t\t\tmb_cache_entry_release(ce);\n+\t\t\t\tmb2_cache_entry_touch(ext2_mb_cache, ce);\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n \t\t\t\treturn bh;\n \t\t\t}\n \t\t\tunlock_buffer(bh);\n \t\t\tbrelse(bh);\n \t\t}\n-\t\tce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);\n+\t\tce = mb2_cache_entry_find_next(ext2_mb_cache, ce);\n \t}\n \treturn NULL;\n }\n@@ -1015,17 +1008,15 @@ static void ext2_xattr_rehash(struct ext2_xattr_header *header,\n \n #undef BLOCK_HASH_SHIFT\n \n-int __init\n-init_ext2_xattr(void)\n+#define HASH_BUCKET_BITS 10\n+\n+struct mb2_cache *ext2_xattr_create_cache(void)\n {\n-\text2_xattr_cache = mb_cache_create(\""ext2_xattr\"", 6);\n-\tif (!ext2_xattr_cache)\n-\t\treturn -ENOMEM;\n-\treturn 0;\n+\treturn mb2_cache_create(HASH_BUCKET_BITS);\n }\n \n-void\n-exit_ext2_xattr(void)\n+void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n-\tmb_cache_destroy(ext2_xattr_cache);\n+\tif (cache)\n+\t\tmb2_cache_destroy(cache);\n }""}<_**next**_>{""sha"": ""6ea38aa9563a00649bf25544eed131bbe8b1d88d"", ""filename"": ""fs/ext2/xattr.h"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 16, ""changes"": 21, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -53,6 +53,8 @@ struct ext2_xattr_entry {\n #define EXT2_XATTR_SIZE(size) \\\n \t(((size) + EXT2_XATTR_ROUND) & ~EXT2_XATTR_ROUND)\n \n+struct mb2_cache;\n+\n # ifdef CONFIG_EXT2_FS_XATTR\n \n extern const struct xattr_handler ext2_xattr_user_handler;\n@@ -65,10 +67,9 @@ extern int ext2_xattr_get(struct inode *, int, const char *, void *, size_t);\n extern int ext2_xattr_set(struct inode *, int, const char *, const void *, size_t, int);\n \n extern void ext2_xattr_delete_inode(struct inode *);\n-extern void ext2_xattr_put_super(struct super_block *);\n \n-extern int init_ext2_xattr(void);\n-extern void exit_ext2_xattr(void);\n+extern struct mb2_cache *ext2_xattr_create_cache(void);\n+extern void ext2_xattr_destroy_cache(struct mb2_cache *cache);\n \n extern const struct xattr_handler *ext2_xattr_handlers[];\n \n@@ -93,19 +94,7 @@ ext2_xattr_delete_inode(struct inode *inode)\n {\n }\n \n-static inline void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-}\n-\n-static inline int\n-init_ext2_xattr(void)\n-{\n-\treturn 0;\n-}\n-\n-static inline void\n-exit_ext2_xattr(void)\n+static inline void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n }\n ""}","ext2_xattr_put_super(struct super_block *sb)
","ext2_xattr_put_super(struct super_block *sb)
{
	mb_cache_shrink(sb->s_bdev);
}
",C,,"{
	mb_cache_shrink(sb->s_bdev);
}
",,"@@ -56,7 +56,7 @@
 #include <linux/buffer_head.h>
 #include <linux/init.h>
 #include <linux/slab.h>
-#include <linux/mbcache.h>
+#include <linux/mbcache2.h>
 #include <linux/quotaops.h>
 #include <linux/rwsem.h>
 #include <linux/security.h>
@@ -90,14 +90,12 @@
 static int ext2_xattr_set2(struct inode *, struct buffer_head *,
 			   struct ext2_xattr_header *);
 
-static int ext2_xattr_cache_insert(struct buffer_head *);
+static int ext2_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);
 static struct buffer_head *ext2_xattr_cache_find(struct inode *,
 						 struct ext2_xattr_header *);
 static void ext2_xattr_rehash(struct ext2_xattr_header *,
 			      struct ext2_xattr_entry *);
 
-static struct mb_cache *ext2_xattr_cache;
-
 static const struct xattr_handler *ext2_xattr_handler_map[] = {
 	[EXT2_XATTR_INDEX_USER]		     = &ext2_xattr_user_handler,
 #ifdef CONFIG_EXT2_FS_POSIX_ACL
@@ -152,6 +150,7 @@ ext2_xattr_get(struct inode *inode, int name_index, const char *name,
 	size_t name_len, size;
 	char *end;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	ea_idebug(inode, ""name=%d.%s, buffer=%p, buffer_size=%ld"",
 		  name_index, name, buffer, (long)buffer_size);
@@ -196,7 +195,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_get"",
 			goto found;
 		entry = next;
 	}
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 	error = -ENODATA;
 	goto cleanup;
@@ -209,7 +208,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_get"",
 	    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)
 		goto bad_block;
 
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 	if (buffer) {
 		error = -ERANGE;
@@ -247,6 +246,7 @@ ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)
 	char *end;
 	size_t rest = buffer_size;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	ea_idebug(inode, ""buffer=%p, buffer_size=%ld"",
 		  buffer, (long)buffer_size);
@@ -281,7 +281,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_list"",
 			goto bad_block;
 		entry = next;
 	}
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 
 	/* list the attribute names */
@@ -483,22 +483,23 @@ bad_block:		ext2_error(sb, ""ext2_xattr_set"",
 	/* Here we know that we can set the new attribute. */
 
 	if (header) {
-		struct mb_cache_entry *ce;
-
 		/* assert(header == HDR(bh)); */
-		ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,
-					bh->b_blocknr);
 		lock_buffer(bh);
 		if (header->h_refcount == cpu_to_le32(1)) {
+			__u32 hash = le32_to_cpu(header->h_hash);
+
 			ea_bdebug(bh, ""modifying in-place"");
-			if (ce)
-				mb_cache_entry_free(ce);
+			/*
+			 * This must happen under buffer lock for
+			 * ext2_xattr_set2() to reliably detect modified block
+			 */
+			mb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,
+						     hash, bh->b_blocknr);
+
 			/* keep the buffer locked while modifying it. */
 		} else {
 			int offset;
 
-			if (ce)
-				mb_cache_entry_release(ce);
 			unlock_buffer(bh);
 			ea_bdebug(bh, ""cloning"");
 			header = kmalloc(bh->b_size, GFP_KERNEL);
@@ -626,6 +627,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *new_bh = NULL;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;
 
 	if (header) {
 		new_bh = ext2_xattr_cache_find(inode, header);
@@ -653,7 +655,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 			   don't need to change the reference count. */
 			new_bh = old_bh;
 			get_bh(new_bh);
-			ext2_xattr_cache_insert(new_bh);
+			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
 		} else {
 			/* We need to allocate a new block */
 			ext2_fsblk_t goal = ext2_group_first_block_no(sb,
@@ -674,7 +676,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 			memcpy(new_bh->b_data, header, new_bh->b_size);
 			set_buffer_uptodate(new_bh);
 			unlock_buffer(new_bh);
-			ext2_xattr_cache_insert(new_bh);
+			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
 			
 			ext2_xattr_update_super_block(sb);
 		}
@@ -707,19 +709,21 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 
 	error = 0;
 	if (old_bh && old_bh != new_bh) {
-		struct mb_cache_entry *ce;
-
 		/*
 		 * If there was an old block and we are no longer using it,
 		 * release the old block.
 		 */
-		ce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,
-					old_bh->b_blocknr);
 		lock_buffer(old_bh);
 		if (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {
+			__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);
+
+			/*
+			 * This must happen under buffer lock for
+			 * ext2_xattr_set2() to reliably detect freed block
+			 */
+			mb2_cache_entry_delete_block(ext2_mb_cache,
+						     hash, old_bh->b_blocknr);
 			/* Free the old block. */
-			if (ce)
-				mb_cache_entry_free(ce);
 			ea_bdebug(old_bh, ""freeing"");
 			ext2_free_blocks(inode, old_bh->b_blocknr, 1);
 			mark_inode_dirty(inode);
@@ -730,8 +734,6 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 		} else {
 			/* Decrement the refcount only. */
 			le32_add_cpu(&HDR(old_bh)->h_refcount, -1);
-			if (ce)
-				mb_cache_entry_release(ce);
 			dquot_free_block_nodirty(inode, 1);
 			mark_inode_dirty(inode);
 			mark_buffer_dirty(old_bh);
@@ -757,7 +759,6 @@ void
 ext2_xattr_delete_inode(struct inode *inode)
 {
 	struct buffer_head *bh = NULL;
-	struct mb_cache_entry *ce;
 
 	down_write(&EXT2_I(inode)->xattr_sem);
 	if (!EXT2_I(inode)->i_file_acl)
@@ -777,19 +778,22 @@ ext2_xattr_delete_inode(struct inode *inode)
 			EXT2_I(inode)->i_file_acl);
 		goto cleanup;
 	}
-	ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);
 	lock_buffer(bh);
 	if (HDR(bh)->h_refcount == cpu_to_le32(1)) {
-		if (ce)
-			mb_cache_entry_free(ce);
+		__u32 hash = le32_to_cpu(HDR(bh)->h_hash);
+
+		/*
+		 * This must happen under buffer lock for ext2_xattr_set2() to
+		 * reliably detect freed block
+		 */
+		mb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,
+					     hash, bh->b_blocknr);
 		ext2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);
 		get_bh(bh);
 		bforget(bh);
 		unlock_buffer(bh);
 	} else {
 		le32_add_cpu(&HDR(bh)->h_refcount, -1);
-		if (ce)
-			mb_cache_entry_release(ce);
 		ea_bdebug(bh, ""refcount now=%d"",
 			le32_to_cpu(HDR(bh)->h_refcount));
 		unlock_buffer(bh);
@@ -805,18 +809,6 @@ ext2_xattr_delete_inode(struct inode *inode)
 	up_write(&EXT2_I(inode)->xattr_sem);
 }
 
-/*
- * ext2_xattr_put_super()
- *
- * This is called when a file system is unmounted.
- */
-void
-ext2_xattr_put_super(struct super_block *sb)
-{
-	mb_cache_shrink(sb->s_bdev);
-}
-
-
 /*
  * ext2_xattr_cache_insert()
  *
@@ -826,28 +818,20 @@ ext2_xattr_put_super(struct super_block *sb)
  * Returns 0, or a negative error number on failure.
  */
 static int
-ext2_xattr_cache_insert(struct buffer_head *bh)
+ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)
 {
 	__u32 hash = le32_to_cpu(HDR(bh)->h_hash);
-	struct mb_cache_entry *ce;
 	int error;
 
-	ce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);
-	if (!ce)
-		return -ENOMEM;
-	error = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);
+	error = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);
 	if (error) {
-		mb_cache_entry_free(ce);
 		if (error == -EBUSY) {
 			ea_bdebug(bh, ""already in cache (%d cache entries)"",
 				atomic_read(&ext2_xattr_cache->c_entry_count));
 			error = 0;
 		}
-	} else {
-		ea_bdebug(bh, ""inserting [%x] (%d cache entries)"", (int)hash,
-			  atomic_read(&ext2_xattr_cache->c_entry_count));
-		mb_cache_entry_release(ce);
-	}
+	} else
+		ea_bdebug(bh, ""inserting [%x]"", (int)hash);
 	return error;
 }
 
@@ -903,31 +887,39 @@ static struct buffer_head *
 ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)
 {
 	__u32 hash = le32_to_cpu(header->h_hash);
-	struct mb_cache_entry *ce;
+	struct mb2_cache_entry *ce;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	if (!header->h_hash)
 		return NULL;  /* never share */
 	ea_idebug(inode, ""looking for cached blocks [%x]"", (int)hash);
 again:
-	ce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,
-				       hash);
+	ce = mb2_cache_entry_find_first(ext2_mb_cache, hash);
 	while (ce) {
 		struct buffer_head *bh;
 
-		if (IS_ERR(ce)) {
-			if (PTR_ERR(ce) == -EAGAIN)
-				goto again;
-			break;
-		}
-
 		bh = sb_bread(inode->i_sb, ce->e_block);
 		if (!bh) {
 			ext2_error(inode->i_sb, ""ext2_xattr_cache_find"",
 				""inode %ld: block %ld read error"",
 				inode->i_ino, (unsigned long) ce->e_block);
 		} else {
 			lock_buffer(bh);
-			if (le32_to_cpu(HDR(bh)->h_refcount) >
+			/*
+			 * We have to be careful about races with freeing or
+			 * rehashing of xattr block. Once we hold buffer lock
+			 * xattr block's state is stable so we can check
+			 * whether the block got freed / rehashed or not.
+			 * Since we unhash mbcache entry under buffer lock when
+			 * freeing / rehashing xattr block, checking whether
+			 * entry is still hashed is reliable.
+			 */
+			if (hlist_bl_unhashed(&ce->e_hash_list)) {
+				mb2_cache_entry_put(ext2_mb_cache, ce);
+				unlock_buffer(bh);
+				brelse(bh);
+				goto again;
+			} else if (le32_to_cpu(HDR(bh)->h_refcount) >
 				   EXT2_XATTR_REFCOUNT_MAX) {
 				ea_idebug(inode, ""block %ld refcount %d>%d"",
 					  (unsigned long) ce->e_block,
@@ -936,13 +928,14 @@ ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)
 			} else if (!ext2_xattr_cmp(header, HDR(bh))) {
 				ea_bdebug(bh, ""b_count=%d"",
 					  atomic_read(&(bh->b_count)));
-				mb_cache_entry_release(ce);
+				mb2_cache_entry_touch(ext2_mb_cache, ce);
+				mb2_cache_entry_put(ext2_mb_cache, ce);
 				return bh;
 			}
 			unlock_buffer(bh);
 			brelse(bh);
 		}
-		ce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);
+		ce = mb2_cache_entry_find_next(ext2_mb_cache, ce);
 	}
 	return NULL;
 }
@@ -1015,17 +1008,15 @@ static void ext2_xattr_rehash(struct ext2_xattr_header *header,
 
 #undef BLOCK_HASH_SHIFT
 
-int __init
-init_ext2_xattr(void)
+#define HASH_BUCKET_BITS 10
+
+struct mb2_cache *ext2_xattr_create_cache(void)
 {
-	ext2_xattr_cache = mb_cache_create(""ext2_xattr"", 6);
-	if (!ext2_xattr_cache)
-		return -ENOMEM;
-	return 0;
+	return mb2_cache_create(HASH_BUCKET_BITS);
 }
 
-void
-exit_ext2_xattr(void)
+void ext2_xattr_destroy_cache(struct mb2_cache *cache)
 {
-	mb_cache_destroy(ext2_xattr_cache);
+	if (cache)
+		mb2_cache_destroy(cache);
 }",linux,be0726d33cb8f411945884664924bed3cb8c70ee,82939d7999dfc1f1998c4b1c12e2f19edbdff272,1,"ext2_xattr_put_super(struct super_block *sb)
//flaw_line_below:
{
//flaw_line_below:
	mb_cache_shrink(sb->s_bdev);
//flaw_line_below:
}
"
5419,183155,,Local,Not required,Partial,CVE-2015-8952,https://www.cvedetails.com/cve/CVE-2015-8952/,CWE-19,Low,,,,2016-10-16,2.1,"The mbcache feature in the ext2 and ext4 filesystem implementations in the Linux kernel before 4.6 mishandles xattr block caching, which allows local users to cause a denial of service (soft lockup) via filesystem operations in environments that use many attributes, as demonstrated by Ceph and Samba.",2018-03-15,DoS ,9,https://github.com/torvalds/linux/commit/be0726d33cb8f411945884664924bed3cb8c70ee,be0726d33cb8f411945884664924bed3cb8c70ee,"ext2: convert to mbcache2

The conversion is generally straightforward. We convert filesystem from
a global cache to per-fs one. Similarly to ext4 the tricky part is that
xattr block corresponding to found mbcache entry can get freed before we
get buffer lock for that block. So we have to check whether the entry is
still valid after getting the buffer lock.

Signed-off-by: Jan Kara <jack@suse.cz>
Signed-off-by: Theodore Ts'o <tytso@mit.edu>",7,fs/ext2/xattr.c,"{""sha"": ""f98ce7e60a0f84f71743e0dfe069c7e96c6bd648"", ""filename"": ""fs/ext2/ext2.h"", ""status"": ""modified"", ""additions"": 3, ""deletions"": 0, ""changes"": 3, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/ext2.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -61,6 +61,8 @@ struct ext2_block_alloc_info {\n #define rsv_start rsv_window._rsv_start\n #define rsv_end rsv_window._rsv_end\n \n+struct mb2_cache;\n+\n /*\n  * second extended-fs super-block data in memory\n  */\n@@ -111,6 +113,7 @@ struct ext2_sb_info {\n \t * of the mount options.\n \t */\n \tspinlock_t s_lock;\n+\tstruct mb2_cache *s_mb_cache;\n };\n \n static inline spinlock_t *""}<_**next**_>{""sha"": ""b78caf25f746220ce635a3bd946bedeaf7e3e750"", ""filename"": ""fs/ext2/super.c"", ""status"": ""modified"", ""additions"": 17, ""deletions"": 8, ""changes"": 25, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/super.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -131,7 +131,10 @@ static void ext2_put_super (struct super_block * sb)\n \n \tdquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);\n \n-\text2_xattr_put_super(sb);\n+\tif (sbi->s_mb_cache) {\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n+\t\tsbi->s_mb_cache = NULL;\n+\t}\n \tif (!(sb->s_flags & MS_RDONLY)) {\n \t\tstruct ext2_super_block *es = sbi->s_es;\n \n@@ -1104,6 +1107,14 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\text2_msg(sb, KERN_ERR, \""error: insufficient memory\"");\n \t\tgoto failed_mount3;\n \t}\n+\n+#ifdef CONFIG_EXT2_FS_XATTR\n+\tsbi->s_mb_cache = ext2_xattr_create_cache();\n+\tif (!sbi->s_mb_cache) {\n+\t\text2_msg(sb, KERN_ERR, \""Failed to create an mb_cache\"");\n+\t\tgoto failed_mount3;\n+\t}\n+#endif\n \t/*\n \t * set up enough so that it can read an inode\n \t */\n@@ -1149,6 +1160,8 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\t\tsb->s_id);\n \tgoto failed_mount;\n failed_mount3:\n+\tif (sbi->s_mb_cache)\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n \tpercpu_counter_destroy(&sbi->s_freeblocks_counter);\n \tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n \tpercpu_counter_destroy(&sbi->s_dirs_counter);\n@@ -1555,28 +1568,24 @@ MODULE_ALIAS_FS(\""ext2\"");\n \n static int __init init_ext2_fs(void)\n {\n-\tint err = init_ext2_xattr();\n-\tif (err)\n-\t\treturn err;\n+\tint err;\n+\n \terr = init_inodecache();\n \tif (err)\n-\t\tgoto out1;\n+\t\treturn err;\n         err = register_filesystem(&ext2_fs_type);\n \tif (err)\n \t\tgoto out;\n \treturn 0;\n out:\n \tdestroy_inodecache();\n-out1:\n-\texit_ext2_xattr();\n \treturn err;\n }\n \n static void __exit exit_ext2_fs(void)\n {\n \tunregister_filesystem(&ext2_fs_type);\n \tdestroy_inodecache();\n-\texit_ext2_xattr();\n }\n \n MODULE_AUTHOR(\""Remy Card and others\"");""}<_**next**_>{""sha"": ""7162b4869bc32515800d8ffc06ac3835ea241c8b"", ""filename"": ""fs/ext2/xattr.c"", ""status"": ""modified"", ""additions"": 67, ""deletions"": 76, ""changes"": 143, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -56,7 +56,7 @@\n #include <linux/buffer_head.h>\n #include <linux/init.h>\n #include <linux/slab.h>\n-#include <linux/mbcache.h>\n+#include <linux/mbcache2.h>\n #include <linux/quotaops.h>\n #include <linux/rwsem.h>\n #include <linux/security.h>\n@@ -90,14 +90,12 @@\n static int ext2_xattr_set2(struct inode *, struct buffer_head *,\n \t\t\t   struct ext2_xattr_header *);\n \n-static int ext2_xattr_cache_insert(struct buffer_head *);\n+static int ext2_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);\n static struct buffer_head *ext2_xattr_cache_find(struct inode *,\n \t\t\t\t\t\t struct ext2_xattr_header *);\n static void ext2_xattr_rehash(struct ext2_xattr_header *,\n \t\t\t      struct ext2_xattr_entry *);\n \n-static struct mb_cache *ext2_xattr_cache;\n-\n static const struct xattr_handler *ext2_xattr_handler_map[] = {\n \t[EXT2_XATTR_INDEX_USER]\t\t     = &ext2_xattr_user_handler,\n #ifdef CONFIG_EXT2_FS_POSIX_ACL\n@@ -152,6 +150,7 @@ ext2_xattr_get(struct inode *inode, int name_index, const char *name,\n \tsize_t name_len, size;\n \tchar *end;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""name=%d.%s, buffer=%p, buffer_size=%ld\"",\n \t\t  name_index, name, buffer, (long)buffer_size);\n@@ -196,7 +195,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t\t\tgoto found;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \terror = -ENODATA;\n \tgoto cleanup;\n@@ -209,7 +208,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)\n \t\tgoto bad_block;\n \n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \tif (buffer) {\n \t\terror = -ERANGE;\n@@ -247,6 +246,7 @@ ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)\n \tchar *end;\n \tsize_t rest = buffer_size;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""buffer=%p, buffer_size=%ld\"",\n \t\t  buffer, (long)buffer_size);\n@@ -281,7 +281,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_list\"",\n \t\t\tgoto bad_block;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \n \t/* list the attribute names */\n@@ -483,22 +483,23 @@ bad_block:\t\text2_error(sb, \""ext2_xattr_set\"",\n \t/* Here we know that we can set the new attribute. */\n \n \tif (header) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/* assert(header == HDR(bh)); */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,\n-\t\t\t\t\tbh->b_blocknr);\n \t\tlock_buffer(bh);\n \t\tif (header->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(header->h_hash);\n+\n \t\t\tea_bdebug(bh, \""modifying in-place\"");\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect modified block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,\n+\t\t\t\t\t\t     hash, bh->b_blocknr);\n+\n \t\t\t/* keep the buffer locked while modifying it. */\n \t\t} else {\n \t\t\tint offset;\n \n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tunlock_buffer(bh);\n \t\t\tea_bdebug(bh, \""cloning\"");\n \t\t\theader = kmalloc(bh->b_size, GFP_KERNEL);\n@@ -626,6 +627,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \tstruct super_block *sb = inode->i_sb;\n \tstruct buffer_head *new_bh = NULL;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;\n \n \tif (header) {\n \t\tnew_bh = ext2_xattr_cache_find(inode, header);\n@@ -653,7 +655,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\t   don't need to change the reference count. */\n \t\t\tnew_bh = old_bh;\n \t\t\tget_bh(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t} else {\n \t\t\t/* We need to allocate a new block */\n \t\t\text2_fsblk_t goal = ext2_group_first_block_no(sb,\n@@ -674,7 +676,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\tmemcpy(new_bh->b_data, header, new_bh->b_size);\n \t\t\tset_buffer_uptodate(new_bh);\n \t\t\tunlock_buffer(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t\t\n \t\t\text2_xattr_update_super_block(sb);\n \t\t}\n@@ -707,19 +709,21 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \n \terror = 0;\n \tif (old_bh && old_bh != new_bh) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/*\n \t\t * If there was an old block and we are no longer using it,\n \t\t * release the old block.\n \t\t */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,\n-\t\t\t\t\told_bh->b_blocknr);\n \t\tlock_buffer(old_bh);\n \t\tif (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);\n+\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect freed block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(ext2_mb_cache,\n+\t\t\t\t\t\t     hash, old_bh->b_blocknr);\n \t\t\t/* Free the old block. */\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n \t\t\tea_bdebug(old_bh, \""freeing\"");\n \t\t\text2_free_blocks(inode, old_bh->b_blocknr, 1);\n \t\t\tmark_inode_dirty(inode);\n@@ -730,8 +734,6 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t} else {\n \t\t\t/* Decrement the refcount only. */\n \t\t\tle32_add_cpu(&HDR(old_bh)->h_refcount, -1);\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tdquot_free_block_nodirty(inode, 1);\n \t\t\tmark_inode_dirty(inode);\n \t\t\tmark_buffer_dirty(old_bh);\n@@ -757,7 +759,6 @@ void\n ext2_xattr_delete_inode(struct inode *inode)\n {\n \tstruct buffer_head *bh = NULL;\n-\tstruct mb_cache_entry *ce;\n \n \tdown_write(&EXT2_I(inode)->xattr_sem);\n \tif (!EXT2_I(inode)->i_file_acl)\n@@ -777,19 +778,22 @@ ext2_xattr_delete_inode(struct inode *inode)\n \t\t\tEXT2_I(inode)->i_file_acl);\n \t\tgoto cleanup;\n \t}\n-\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);\n \tlock_buffer(bh);\n \tif (HDR(bh)->h_refcount == cpu_to_le32(1)) {\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_free(ce);\n+\t\t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n+\n+\t\t/*\n+\t\t * This must happen under buffer lock for ext2_xattr_set2() to\n+\t\t * reliably detect freed block\n+\t\t */\n+\t\tmb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,\n+\t\t\t\t\t     hash, bh->b_blocknr);\n \t\text2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);\n \t\tget_bh(bh);\n \t\tbforget(bh);\n \t\tunlock_buffer(bh);\n \t} else {\n \t\tle32_add_cpu(&HDR(bh)->h_refcount, -1);\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_release(ce);\n \t\tea_bdebug(bh, \""refcount now=%d\"",\n \t\t\tle32_to_cpu(HDR(bh)->h_refcount));\n \t\tunlock_buffer(bh);\n@@ -805,18 +809,6 @@ ext2_xattr_delete_inode(struct inode *inode)\n \tup_write(&EXT2_I(inode)->xattr_sem);\n }\n \n-/*\n- * ext2_xattr_put_super()\n- *\n- * This is called when a file system is unmounted.\n- */\n-void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-\tmb_cache_shrink(sb->s_bdev);\n-}\n-\n-\n /*\n  * ext2_xattr_cache_insert()\n  *\n@@ -826,28 +818,20 @@ ext2_xattr_put_super(struct super_block *sb)\n  * Returns 0, or a negative error number on failure.\n  */\n static int\n-ext2_xattr_cache_insert(struct buffer_head *bh)\n+ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)\n {\n \t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n-\tstruct mb_cache_entry *ce;\n \tint error;\n \n-\tce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);\n-\tif (!ce)\n-\t\treturn -ENOMEM;\n-\terror = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);\n+\terror = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);\n \tif (error) {\n-\t\tmb_cache_entry_free(ce);\n \t\tif (error == -EBUSY) {\n \t\t\tea_bdebug(bh, \""already in cache (%d cache entries)\"",\n \t\t\t\tatomic_read(&ext2_xattr_cache->c_entry_count));\n \t\t\terror = 0;\n \t\t}\n-\t} else {\n-\t\tea_bdebug(bh, \""inserting [%x] (%d cache entries)\"", (int)hash,\n-\t\t\t  atomic_read(&ext2_xattr_cache->c_entry_count));\n-\t\tmb_cache_entry_release(ce);\n-\t}\n+\t} else\n+\t\tea_bdebug(bh, \""inserting [%x]\"", (int)hash);\n \treturn error;\n }\n \n@@ -903,31 +887,39 @@ static struct buffer_head *\n ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n {\n \t__u32 hash = le32_to_cpu(header->h_hash);\n-\tstruct mb_cache_entry *ce;\n+\tstruct mb2_cache_entry *ce;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tif (!header->h_hash)\n \t\treturn NULL;  /* never share */\n \tea_idebug(inode, \""looking for cached blocks [%x]\"", (int)hash);\n again:\n-\tce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,\n-\t\t\t\t       hash);\n+\tce = mb2_cache_entry_find_first(ext2_mb_cache, hash);\n \twhile (ce) {\n \t\tstruct buffer_head *bh;\n \n-\t\tif (IS_ERR(ce)) {\n-\t\t\tif (PTR_ERR(ce) == -EAGAIN)\n-\t\t\t\tgoto again;\n-\t\t\tbreak;\n-\t\t}\n-\n \t\tbh = sb_bread(inode->i_sb, ce->e_block);\n \t\tif (!bh) {\n \t\t\text2_error(inode->i_sb, \""ext2_xattr_cache_find\"",\n \t\t\t\t\""inode %ld: block %ld read error\"",\n \t\t\t\tinode->i_ino, (unsigned long) ce->e_block);\n \t\t} else {\n \t\t\tlock_buffer(bh);\n-\t\t\tif (le32_to_cpu(HDR(bh)->h_refcount) >\n+\t\t\t/*\n+\t\t\t * We have to be careful about races with freeing or\n+\t\t\t * rehashing of xattr block. Once we hold buffer lock\n+\t\t\t * xattr block's state is stable so we can check\n+\t\t\t * whether the block got freed / rehashed or not.\n+\t\t\t * Since we unhash mbcache entry under buffer lock when\n+\t\t\t * freeing / rehashing xattr block, checking whether\n+\t\t\t * entry is still hashed is reliable.\n+\t\t\t */\n+\t\t\tif (hlist_bl_unhashed(&ce->e_hash_list)) {\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n+\t\t\t\tunlock_buffer(bh);\n+\t\t\t\tbrelse(bh);\n+\t\t\t\tgoto again;\n+\t\t\t} else if (le32_to_cpu(HDR(bh)->h_refcount) >\n \t\t\t\t   EXT2_XATTR_REFCOUNT_MAX) {\n \t\t\t\tea_idebug(inode, \""block %ld refcount %d>%d\"",\n \t\t\t\t\t  (unsigned long) ce->e_block,\n@@ -936,13 +928,14 @@ ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n \t\t\t} else if (!ext2_xattr_cmp(header, HDR(bh))) {\n \t\t\t\tea_bdebug(bh, \""b_count=%d\"",\n \t\t\t\t\t  atomic_read(&(bh->b_count)));\n-\t\t\t\tmb_cache_entry_release(ce);\n+\t\t\t\tmb2_cache_entry_touch(ext2_mb_cache, ce);\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n \t\t\t\treturn bh;\n \t\t\t}\n \t\t\tunlock_buffer(bh);\n \t\t\tbrelse(bh);\n \t\t}\n-\t\tce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);\n+\t\tce = mb2_cache_entry_find_next(ext2_mb_cache, ce);\n \t}\n \treturn NULL;\n }\n@@ -1015,17 +1008,15 @@ static void ext2_xattr_rehash(struct ext2_xattr_header *header,\n \n #undef BLOCK_HASH_SHIFT\n \n-int __init\n-init_ext2_xattr(void)\n+#define HASH_BUCKET_BITS 10\n+\n+struct mb2_cache *ext2_xattr_create_cache(void)\n {\n-\text2_xattr_cache = mb_cache_create(\""ext2_xattr\"", 6);\n-\tif (!ext2_xattr_cache)\n-\t\treturn -ENOMEM;\n-\treturn 0;\n+\treturn mb2_cache_create(HASH_BUCKET_BITS);\n }\n \n-void\n-exit_ext2_xattr(void)\n+void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n-\tmb_cache_destroy(ext2_xattr_cache);\n+\tif (cache)\n+\t\tmb2_cache_destroy(cache);\n }""}<_**next**_>{""sha"": ""6ea38aa9563a00649bf25544eed131bbe8b1d88d"", ""filename"": ""fs/ext2/xattr.h"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 16, ""changes"": 21, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -53,6 +53,8 @@ struct ext2_xattr_entry {\n #define EXT2_XATTR_SIZE(size) \\\n \t(((size) + EXT2_XATTR_ROUND) & ~EXT2_XATTR_ROUND)\n \n+struct mb2_cache;\n+\n # ifdef CONFIG_EXT2_FS_XATTR\n \n extern const struct xattr_handler ext2_xattr_user_handler;\n@@ -65,10 +67,9 @@ extern int ext2_xattr_get(struct inode *, int, const char *, void *, size_t);\n extern int ext2_xattr_set(struct inode *, int, const char *, const void *, size_t, int);\n \n extern void ext2_xattr_delete_inode(struct inode *);\n-extern void ext2_xattr_put_super(struct super_block *);\n \n-extern int init_ext2_xattr(void);\n-extern void exit_ext2_xattr(void);\n+extern struct mb2_cache *ext2_xattr_create_cache(void);\n+extern void ext2_xattr_destroy_cache(struct mb2_cache *cache);\n \n extern const struct xattr_handler *ext2_xattr_handlers[];\n \n@@ -93,19 +94,7 @@ ext2_xattr_delete_inode(struct inode *inode)\n {\n }\n \n-static inline void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-}\n-\n-static inline int\n-init_ext2_xattr(void)\n-{\n-\treturn 0;\n-}\n-\n-static inline void\n-exit_ext2_xattr(void)\n+static inline void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n }\n ""}","ext2_xattr_set(struct inode *inode, int name_index, const char *name,
	       const void *value, size_t value_len, int flags)
{
	struct super_block *sb = inode->i_sb;
	struct buffer_head *bh = NULL;
	struct ext2_xattr_header *header = NULL;
	struct ext2_xattr_entry *here, *last;
	size_t name_len, free, min_offs = sb->s_blocksize;
	int not_found = 1, error;
	char *end;
	
	/*
	 * header -- Points either into bh, or to a temporarily
	 *           allocated buffer.
	 * here -- The named entry found, or the place for inserting, within
	 *         the block pointed to by header.
	 * last -- Points right after the last named entry within the block
	 *         pointed to by header.
	 * min_offs -- The offset of the first value (values are aligned
	 *             towards the end of the block).
	 * end -- Points right after the block pointed to by header.
	 */
	
	ea_idebug(inode, ""name=%d.%s, value=%p, value_len=%ld"",
		  name_index, name, value, (long)value_len);

	if (value == NULL)
		value_len = 0;
	if (name == NULL)
		return -EINVAL;
	name_len = strlen(name);
	if (name_len > 255 || value_len > sb->s_blocksize)
		return -ERANGE;
	down_write(&EXT2_I(inode)->xattr_sem);
	if (EXT2_I(inode)->i_file_acl) {
		/* The inode already has an extended attribute block. */
		bh = sb_bread(sb, EXT2_I(inode)->i_file_acl);
		error = -EIO;
		if (!bh)
			goto cleanup;
		ea_bdebug(bh, ""b_count=%d, refcount=%d"",
			atomic_read(&(bh->b_count)),
			le32_to_cpu(HDR(bh)->h_refcount));
		header = HDR(bh);
		end = bh->b_data + bh->b_size;
		if (header->h_magic != cpu_to_le32(EXT2_XATTR_MAGIC) ||
		    header->h_blocks != cpu_to_le32(1)) {
bad_block:		ext2_error(sb, ""ext2_xattr_set"",
				""inode %ld: bad block %d"", inode->i_ino, 
				   EXT2_I(inode)->i_file_acl);
			error = -EIO;
			goto cleanup;
		}
		/* Find the named attribute. */
		here = FIRST_ENTRY(bh);
		while (!IS_LAST_ENTRY(here)) {
			struct ext2_xattr_entry *next = EXT2_XATTR_NEXT(here);
			if ((char *)next >= end)
				goto bad_block;
			if (!here->e_value_block && here->e_value_size) {
				size_t offs = le16_to_cpu(here->e_value_offs);
				if (offs < min_offs)
					min_offs = offs;
			}
			not_found = name_index - here->e_name_index;
			if (!not_found)
				not_found = name_len - here->e_name_len;
			if (!not_found)
				not_found = memcmp(name, here->e_name,name_len);
			if (not_found <= 0)
				break;
			here = next;
		}
		last = here;
		/* We still need to compute min_offs and last. */
		while (!IS_LAST_ENTRY(last)) {
			struct ext2_xattr_entry *next = EXT2_XATTR_NEXT(last);
			if ((char *)next >= end)
				goto bad_block;
			if (!last->e_value_block && last->e_value_size) {
				size_t offs = le16_to_cpu(last->e_value_offs);
				if (offs < min_offs)
					min_offs = offs;
			}
			last = next;
		}

		/* Check whether we have enough space left. */
		free = min_offs - ((char*)last - (char*)header) - sizeof(__u32);
	} else {
		/* We will use a new extended attribute block. */
		free = sb->s_blocksize -
			sizeof(struct ext2_xattr_header) - sizeof(__u32);
		here = last = NULL;  /* avoid gcc uninitialized warning. */
	}

	if (not_found) {
		/* Request to remove a nonexistent attribute? */
		error = -ENODATA;
		if (flags & XATTR_REPLACE)
			goto cleanup;
		error = 0;
		if (value == NULL)
			goto cleanup;
	} else {
		/* Request to create an existing attribute? */
		error = -EEXIST;
		if (flags & XATTR_CREATE)
			goto cleanup;
		if (!here->e_value_block && here->e_value_size) {
			size_t size = le32_to_cpu(here->e_value_size);

			if (le16_to_cpu(here->e_value_offs) + size > 
			    sb->s_blocksize || size > sb->s_blocksize)
				goto bad_block;
			free += EXT2_XATTR_SIZE(size);
		}
		free += EXT2_XATTR_LEN(name_len);
	}
	error = -ENOSPC;
	if (free < EXT2_XATTR_LEN(name_len) + EXT2_XATTR_SIZE(value_len))
		goto cleanup;

 	/* Here we know that we can set the new attribute. */
 
 	if (header) {
 		/* assert(header == HDR(bh)); */
 		lock_buffer(bh);
 		if (header->h_refcount == cpu_to_le32(1)) {
			__u32 hash = le32_to_cpu(header->h_hash);

 			ea_bdebug(bh, ""modifying in-place"");
			/*
			 * This must happen under buffer lock for
			 * ext2_xattr_set2() to reliably detect modified block
			 */
			mb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,
						     hash, bh->b_blocknr);

 			/* keep the buffer locked while modifying it. */
 		} else {
 			int offset;
 
 			unlock_buffer(bh);
 			ea_bdebug(bh, ""cloning"");
 			header = kmalloc(bh->b_size, GFP_KERNEL);
			error = -ENOMEM;
			if (header == NULL)
				goto cleanup;
			memcpy(header, HDR(bh), bh->b_size);
			header->h_refcount = cpu_to_le32(1);

			offset = (char *)here - bh->b_data;
			here = ENTRY((char *)header + offset);
			offset = (char *)last - bh->b_data;
			last = ENTRY((char *)header + offset);
		}
	} else {
		/* Allocate a buffer where we construct the new block. */
		header = kzalloc(sb->s_blocksize, GFP_KERNEL);
		error = -ENOMEM;
		if (header == NULL)
			goto cleanup;
		end = (char *)header + sb->s_blocksize;
		header->h_magic = cpu_to_le32(EXT2_XATTR_MAGIC);
		header->h_blocks = header->h_refcount = cpu_to_le32(1);
		last = here = ENTRY(header+1);
	}

	/* Iff we are modifying the block in-place, bh is locked here. */

	if (not_found) {
		/* Insert the new name. */
		size_t size = EXT2_XATTR_LEN(name_len);
		size_t rest = (char *)last - (char *)here;
		memmove((char *)here + size, here, rest);
		memset(here, 0, size);
		here->e_name_index = name_index;
		here->e_name_len = name_len;
		memcpy(here->e_name, name, name_len);
	} else {
		if (!here->e_value_block && here->e_value_size) {
			char *first_val = (char *)header + min_offs;
			size_t offs = le16_to_cpu(here->e_value_offs);
			char *val = (char *)header + offs;
			size_t size = EXT2_XATTR_SIZE(
				le32_to_cpu(here->e_value_size));

			if (size == EXT2_XATTR_SIZE(value_len)) {
				/* The old and the new value have the same
				   size. Just replace. */
				here->e_value_size = cpu_to_le32(value_len);
				memset(val + size - EXT2_XATTR_PAD, 0,
				       EXT2_XATTR_PAD); /* Clear pad bytes. */
				memcpy(val, value, value_len);
				goto skip_replace;
			}

			/* Remove the old value. */
			memmove(first_val + size, first_val, val - first_val);
			memset(first_val, 0, size);
			here->e_value_offs = 0;
			min_offs += size;

			/* Adjust all value offsets. */
			last = ENTRY(header+1);
			while (!IS_LAST_ENTRY(last)) {
				size_t o = le16_to_cpu(last->e_value_offs);
				if (!last->e_value_block && o < offs)
					last->e_value_offs =
						cpu_to_le16(o + size);
				last = EXT2_XATTR_NEXT(last);
			}
		}
		if (value == NULL) {
			/* Remove the old name. */
			size_t size = EXT2_XATTR_LEN(name_len);
			last = ENTRY((char *)last - size);
			memmove(here, (char*)here + size,
				(char*)last - (char*)here);
			memset(last, 0, size);
		}
	}

	if (value != NULL) {
		/* Insert the new value. */
		here->e_value_size = cpu_to_le32(value_len);
		if (value_len) {
			size_t size = EXT2_XATTR_SIZE(value_len);
			char *val = (char *)header + min_offs - size;
			here->e_value_offs =
				cpu_to_le16((char *)val - (char *)header);
			memset(val + size - EXT2_XATTR_PAD, 0,
			       EXT2_XATTR_PAD); /* Clear the pad bytes. */
			memcpy(val, value, value_len);
		}
	}

skip_replace:
	if (IS_LAST_ENTRY(ENTRY(header+1))) {
		/* This block is now empty. */
		if (bh && header == HDR(bh))
			unlock_buffer(bh);  /* we were modifying in-place. */
		error = ext2_xattr_set2(inode, bh, NULL);
	} else {
		ext2_xattr_rehash(header, here);
		if (bh && header == HDR(bh))
			unlock_buffer(bh);  /* we were modifying in-place. */
		error = ext2_xattr_set2(inode, bh, header);
	}

cleanup:
	brelse(bh);
	if (!(bh && header == HDR(bh)))
		kfree(header);
	up_write(&EXT2_I(inode)->xattr_sem);

	return error;
}
","ext2_xattr_set(struct inode *inode, int name_index, const char *name,
	       const void *value, size_t value_len, int flags)
{
	struct super_block *sb = inode->i_sb;
	struct buffer_head *bh = NULL;
	struct ext2_xattr_header *header = NULL;
	struct ext2_xattr_entry *here, *last;
	size_t name_len, free, min_offs = sb->s_blocksize;
	int not_found = 1, error;
	char *end;
	
	/*
	 * header -- Points either into bh, or to a temporarily
	 *           allocated buffer.
	 * here -- The named entry found, or the place for inserting, within
	 *         the block pointed to by header.
	 * last -- Points right after the last named entry within the block
	 *         pointed to by header.
	 * min_offs -- The offset of the first value (values are aligned
	 *             towards the end of the block).
	 * end -- Points right after the block pointed to by header.
	 */
	
	ea_idebug(inode, ""name=%d.%s, value=%p, value_len=%ld"",
		  name_index, name, value, (long)value_len);

	if (value == NULL)
		value_len = 0;
	if (name == NULL)
		return -EINVAL;
	name_len = strlen(name);
	if (name_len > 255 || value_len > sb->s_blocksize)
		return -ERANGE;
	down_write(&EXT2_I(inode)->xattr_sem);
	if (EXT2_I(inode)->i_file_acl) {
		/* The inode already has an extended attribute block. */
		bh = sb_bread(sb, EXT2_I(inode)->i_file_acl);
		error = -EIO;
		if (!bh)
			goto cleanup;
		ea_bdebug(bh, ""b_count=%d, refcount=%d"",
			atomic_read(&(bh->b_count)),
			le32_to_cpu(HDR(bh)->h_refcount));
		header = HDR(bh);
		end = bh->b_data + bh->b_size;
		if (header->h_magic != cpu_to_le32(EXT2_XATTR_MAGIC) ||
		    header->h_blocks != cpu_to_le32(1)) {
bad_block:		ext2_error(sb, ""ext2_xattr_set"",
				""inode %ld: bad block %d"", inode->i_ino, 
				   EXT2_I(inode)->i_file_acl);
			error = -EIO;
			goto cleanup;
		}
		/* Find the named attribute. */
		here = FIRST_ENTRY(bh);
		while (!IS_LAST_ENTRY(here)) {
			struct ext2_xattr_entry *next = EXT2_XATTR_NEXT(here);
			if ((char *)next >= end)
				goto bad_block;
			if (!here->e_value_block && here->e_value_size) {
				size_t offs = le16_to_cpu(here->e_value_offs);
				if (offs < min_offs)
					min_offs = offs;
			}
			not_found = name_index - here->e_name_index;
			if (!not_found)
				not_found = name_len - here->e_name_len;
			if (!not_found)
				not_found = memcmp(name, here->e_name,name_len);
			if (not_found <= 0)
				break;
			here = next;
		}
		last = here;
		/* We still need to compute min_offs and last. */
		while (!IS_LAST_ENTRY(last)) {
			struct ext2_xattr_entry *next = EXT2_XATTR_NEXT(last);
			if ((char *)next >= end)
				goto bad_block;
			if (!last->e_value_block && last->e_value_size) {
				size_t offs = le16_to_cpu(last->e_value_offs);
				if (offs < min_offs)
					min_offs = offs;
			}
			last = next;
		}

		/* Check whether we have enough space left. */
		free = min_offs - ((char*)last - (char*)header) - sizeof(__u32);
	} else {
		/* We will use a new extended attribute block. */
		free = sb->s_blocksize -
			sizeof(struct ext2_xattr_header) - sizeof(__u32);
		here = last = NULL;  /* avoid gcc uninitialized warning. */
	}

	if (not_found) {
		/* Request to remove a nonexistent attribute? */
		error = -ENODATA;
		if (flags & XATTR_REPLACE)
			goto cleanup;
		error = 0;
		if (value == NULL)
			goto cleanup;
	} else {
		/* Request to create an existing attribute? */
		error = -EEXIST;
		if (flags & XATTR_CREATE)
			goto cleanup;
		if (!here->e_value_block && here->e_value_size) {
			size_t size = le32_to_cpu(here->e_value_size);

			if (le16_to_cpu(here->e_value_offs) + size > 
			    sb->s_blocksize || size > sb->s_blocksize)
				goto bad_block;
			free += EXT2_XATTR_SIZE(size);
		}
		free += EXT2_XATTR_LEN(name_len);
	}
	error = -ENOSPC;
	if (free < EXT2_XATTR_LEN(name_len) + EXT2_XATTR_SIZE(value_len))
		goto cleanup;

 	/* Here we know that we can set the new attribute. */
 
 	if (header) {
		struct mb_cache_entry *ce;
 		/* assert(header == HDR(bh)); */
		ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,
					bh->b_blocknr);
 		lock_buffer(bh);
 		if (header->h_refcount == cpu_to_le32(1)) {
 			ea_bdebug(bh, ""modifying in-place"");
			if (ce)
				mb_cache_entry_free(ce);
 			/* keep the buffer locked while modifying it. */
 		} else {
 			int offset;
 
			if (ce)
				mb_cache_entry_release(ce);
 			unlock_buffer(bh);
 			ea_bdebug(bh, ""cloning"");
 			header = kmalloc(bh->b_size, GFP_KERNEL);
			error = -ENOMEM;
			if (header == NULL)
				goto cleanup;
			memcpy(header, HDR(bh), bh->b_size);
			header->h_refcount = cpu_to_le32(1);

			offset = (char *)here - bh->b_data;
			here = ENTRY((char *)header + offset);
			offset = (char *)last - bh->b_data;
			last = ENTRY((char *)header + offset);
		}
	} else {
		/* Allocate a buffer where we construct the new block. */
		header = kzalloc(sb->s_blocksize, GFP_KERNEL);
		error = -ENOMEM;
		if (header == NULL)
			goto cleanup;
		end = (char *)header + sb->s_blocksize;
		header->h_magic = cpu_to_le32(EXT2_XATTR_MAGIC);
		header->h_blocks = header->h_refcount = cpu_to_le32(1);
		last = here = ENTRY(header+1);
	}

	/* Iff we are modifying the block in-place, bh is locked here. */

	if (not_found) {
		/* Insert the new name. */
		size_t size = EXT2_XATTR_LEN(name_len);
		size_t rest = (char *)last - (char *)here;
		memmove((char *)here + size, here, rest);
		memset(here, 0, size);
		here->e_name_index = name_index;
		here->e_name_len = name_len;
		memcpy(here->e_name, name, name_len);
	} else {
		if (!here->e_value_block && here->e_value_size) {
			char *first_val = (char *)header + min_offs;
			size_t offs = le16_to_cpu(here->e_value_offs);
			char *val = (char *)header + offs;
			size_t size = EXT2_XATTR_SIZE(
				le32_to_cpu(here->e_value_size));

			if (size == EXT2_XATTR_SIZE(value_len)) {
				/* The old and the new value have the same
				   size. Just replace. */
				here->e_value_size = cpu_to_le32(value_len);
				memset(val + size - EXT2_XATTR_PAD, 0,
				       EXT2_XATTR_PAD); /* Clear pad bytes. */
				memcpy(val, value, value_len);
				goto skip_replace;
			}

			/* Remove the old value. */
			memmove(first_val + size, first_val, val - first_val);
			memset(first_val, 0, size);
			here->e_value_offs = 0;
			min_offs += size;

			/* Adjust all value offsets. */
			last = ENTRY(header+1);
			while (!IS_LAST_ENTRY(last)) {
				size_t o = le16_to_cpu(last->e_value_offs);
				if (!last->e_value_block && o < offs)
					last->e_value_offs =
						cpu_to_le16(o + size);
				last = EXT2_XATTR_NEXT(last);
			}
		}
		if (value == NULL) {
			/* Remove the old name. */
			size_t size = EXT2_XATTR_LEN(name_len);
			last = ENTRY((char *)last - size);
			memmove(here, (char*)here + size,
				(char*)last - (char*)here);
			memset(last, 0, size);
		}
	}

	if (value != NULL) {
		/* Insert the new value. */
		here->e_value_size = cpu_to_le32(value_len);
		if (value_len) {
			size_t size = EXT2_XATTR_SIZE(value_len);
			char *val = (char *)header + min_offs - size;
			here->e_value_offs =
				cpu_to_le16((char *)val - (char *)header);
			memset(val + size - EXT2_XATTR_PAD, 0,
			       EXT2_XATTR_PAD); /* Clear the pad bytes. */
			memcpy(val, value, value_len);
		}
	}

skip_replace:
	if (IS_LAST_ENTRY(ENTRY(header+1))) {
		/* This block is now empty. */
		if (bh && header == HDR(bh))
			unlock_buffer(bh);  /* we were modifying in-place. */
		error = ext2_xattr_set2(inode, bh, NULL);
	} else {
		ext2_xattr_rehash(header, here);
		if (bh && header == HDR(bh))
			unlock_buffer(bh);  /* we were modifying in-place. */
		error = ext2_xattr_set2(inode, bh, header);
	}

cleanup:
	brelse(bh);
	if (!(bh && header == HDR(bh)))
		kfree(header);
	up_write(&EXT2_I(inode)->xattr_sem);

	return error;
}
",C,"			__u32 hash = le32_to_cpu(header->h_hash);

			/*
			 * This must happen under buffer lock for
			 * ext2_xattr_set2() to reliably detect modified block
			 */
			mb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,
						     hash, bh->b_blocknr);

","		struct mb_cache_entry *ce;
		ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,
					bh->b_blocknr);
			if (ce)
				mb_cache_entry_free(ce);
			if (ce)
				mb_cache_entry_release(ce);
",,"@@ -56,7 +56,7 @@
 #include <linux/buffer_head.h>
 #include <linux/init.h>
 #include <linux/slab.h>
-#include <linux/mbcache.h>
+#include <linux/mbcache2.h>
 #include <linux/quotaops.h>
 #include <linux/rwsem.h>
 #include <linux/security.h>
@@ -90,14 +90,12 @@
 static int ext2_xattr_set2(struct inode *, struct buffer_head *,
 			   struct ext2_xattr_header *);
 
-static int ext2_xattr_cache_insert(struct buffer_head *);
+static int ext2_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);
 static struct buffer_head *ext2_xattr_cache_find(struct inode *,
 						 struct ext2_xattr_header *);
 static void ext2_xattr_rehash(struct ext2_xattr_header *,
 			      struct ext2_xattr_entry *);
 
-static struct mb_cache *ext2_xattr_cache;
-
 static const struct xattr_handler *ext2_xattr_handler_map[] = {
 	[EXT2_XATTR_INDEX_USER]		     = &ext2_xattr_user_handler,
 #ifdef CONFIG_EXT2_FS_POSIX_ACL
@@ -152,6 +150,7 @@ ext2_xattr_get(struct inode *inode, int name_index, const char *name,
 	size_t name_len, size;
 	char *end;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	ea_idebug(inode, ""name=%d.%s, buffer=%p, buffer_size=%ld"",
 		  name_index, name, buffer, (long)buffer_size);
@@ -196,7 +195,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_get"",
 			goto found;
 		entry = next;
 	}
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 	error = -ENODATA;
 	goto cleanup;
@@ -209,7 +208,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_get"",
 	    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)
 		goto bad_block;
 
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 	if (buffer) {
 		error = -ERANGE;
@@ -247,6 +246,7 @@ ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)
 	char *end;
 	size_t rest = buffer_size;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	ea_idebug(inode, ""buffer=%p, buffer_size=%ld"",
 		  buffer, (long)buffer_size);
@@ -281,7 +281,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_list"",
 			goto bad_block;
 		entry = next;
 	}
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 
 	/* list the attribute names */
@@ -483,22 +483,23 @@ bad_block:		ext2_error(sb, ""ext2_xattr_set"",
 	/* Here we know that we can set the new attribute. */
 
 	if (header) {
-		struct mb_cache_entry *ce;
-
 		/* assert(header == HDR(bh)); */
-		ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,
-					bh->b_blocknr);
 		lock_buffer(bh);
 		if (header->h_refcount == cpu_to_le32(1)) {
+			__u32 hash = le32_to_cpu(header->h_hash);
+
 			ea_bdebug(bh, ""modifying in-place"");
-			if (ce)
-				mb_cache_entry_free(ce);
+			/*
+			 * This must happen under buffer lock for
+			 * ext2_xattr_set2() to reliably detect modified block
+			 */
+			mb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,
+						     hash, bh->b_blocknr);
+
 			/* keep the buffer locked while modifying it. */
 		} else {
 			int offset;
 
-			if (ce)
-				mb_cache_entry_release(ce);
 			unlock_buffer(bh);
 			ea_bdebug(bh, ""cloning"");
 			header = kmalloc(bh->b_size, GFP_KERNEL);
@@ -626,6 +627,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *new_bh = NULL;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;
 
 	if (header) {
 		new_bh = ext2_xattr_cache_find(inode, header);
@@ -653,7 +655,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 			   don't need to change the reference count. */
 			new_bh = old_bh;
 			get_bh(new_bh);
-			ext2_xattr_cache_insert(new_bh);
+			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
 		} else {
 			/* We need to allocate a new block */
 			ext2_fsblk_t goal = ext2_group_first_block_no(sb,
@@ -674,7 +676,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 			memcpy(new_bh->b_data, header, new_bh->b_size);
 			set_buffer_uptodate(new_bh);
 			unlock_buffer(new_bh);
-			ext2_xattr_cache_insert(new_bh);
+			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
 			
 			ext2_xattr_update_super_block(sb);
 		}
@@ -707,19 +709,21 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 
 	error = 0;
 	if (old_bh && old_bh != new_bh) {
-		struct mb_cache_entry *ce;
-
 		/*
 		 * If there was an old block and we are no longer using it,
 		 * release the old block.
 		 */
-		ce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,
-					old_bh->b_blocknr);
 		lock_buffer(old_bh);
 		if (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {
+			__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);
+
+			/*
+			 * This must happen under buffer lock for
+			 * ext2_xattr_set2() to reliably detect freed block
+			 */
+			mb2_cache_entry_delete_block(ext2_mb_cache,
+						     hash, old_bh->b_blocknr);
 			/* Free the old block. */
-			if (ce)
-				mb_cache_entry_free(ce);
 			ea_bdebug(old_bh, ""freeing"");
 			ext2_free_blocks(inode, old_bh->b_blocknr, 1);
 			mark_inode_dirty(inode);
@@ -730,8 +734,6 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 		} else {
 			/* Decrement the refcount only. */
 			le32_add_cpu(&HDR(old_bh)->h_refcount, -1);
-			if (ce)
-				mb_cache_entry_release(ce);
 			dquot_free_block_nodirty(inode, 1);
 			mark_inode_dirty(inode);
 			mark_buffer_dirty(old_bh);
@@ -757,7 +759,6 @@ void
 ext2_xattr_delete_inode(struct inode *inode)
 {
 	struct buffer_head *bh = NULL;
-	struct mb_cache_entry *ce;
 
 	down_write(&EXT2_I(inode)->xattr_sem);
 	if (!EXT2_I(inode)->i_file_acl)
@@ -777,19 +778,22 @@ ext2_xattr_delete_inode(struct inode *inode)
 			EXT2_I(inode)->i_file_acl);
 		goto cleanup;
 	}
-	ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);
 	lock_buffer(bh);
 	if (HDR(bh)->h_refcount == cpu_to_le32(1)) {
-		if (ce)
-			mb_cache_entry_free(ce);
+		__u32 hash = le32_to_cpu(HDR(bh)->h_hash);
+
+		/*
+		 * This must happen under buffer lock for ext2_xattr_set2() to
+		 * reliably detect freed block
+		 */
+		mb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,
+					     hash, bh->b_blocknr);
 		ext2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);
 		get_bh(bh);
 		bforget(bh);
 		unlock_buffer(bh);
 	} else {
 		le32_add_cpu(&HDR(bh)->h_refcount, -1);
-		if (ce)
-			mb_cache_entry_release(ce);
 		ea_bdebug(bh, ""refcount now=%d"",
 			le32_to_cpu(HDR(bh)->h_refcount));
 		unlock_buffer(bh);
@@ -805,18 +809,6 @@ ext2_xattr_delete_inode(struct inode *inode)
 	up_write(&EXT2_I(inode)->xattr_sem);
 }
 
-/*
- * ext2_xattr_put_super()
- *
- * This is called when a file system is unmounted.
- */
-void
-ext2_xattr_put_super(struct super_block *sb)
-{
-	mb_cache_shrink(sb->s_bdev);
-}
-
-
 /*
  * ext2_xattr_cache_insert()
  *
@@ -826,28 +818,20 @@ ext2_xattr_put_super(struct super_block *sb)
  * Returns 0, or a negative error number on failure.
  */
 static int
-ext2_xattr_cache_insert(struct buffer_head *bh)
+ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)
 {
 	__u32 hash = le32_to_cpu(HDR(bh)->h_hash);
-	struct mb_cache_entry *ce;
 	int error;
 
-	ce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);
-	if (!ce)
-		return -ENOMEM;
-	error = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);
+	error = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);
 	if (error) {
-		mb_cache_entry_free(ce);
 		if (error == -EBUSY) {
 			ea_bdebug(bh, ""already in cache (%d cache entries)"",
 				atomic_read(&ext2_xattr_cache->c_entry_count));
 			error = 0;
 		}
-	} else {
-		ea_bdebug(bh, ""inserting [%x] (%d cache entries)"", (int)hash,
-			  atomic_read(&ext2_xattr_cache->c_entry_count));
-		mb_cache_entry_release(ce);
-	}
+	} else
+		ea_bdebug(bh, ""inserting [%x]"", (int)hash);
 	return error;
 }
 
@@ -903,31 +887,39 @@ static struct buffer_head *
 ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)
 {
 	__u32 hash = le32_to_cpu(header->h_hash);
-	struct mb_cache_entry *ce;
+	struct mb2_cache_entry *ce;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	if (!header->h_hash)
 		return NULL;  /* never share */
 	ea_idebug(inode, ""looking for cached blocks [%x]"", (int)hash);
 again:
-	ce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,
-				       hash);
+	ce = mb2_cache_entry_find_first(ext2_mb_cache, hash);
 	while (ce) {
 		struct buffer_head *bh;
 
-		if (IS_ERR(ce)) {
-			if (PTR_ERR(ce) == -EAGAIN)
-				goto again;
-			break;
-		}
-
 		bh = sb_bread(inode->i_sb, ce->e_block);
 		if (!bh) {
 			ext2_error(inode->i_sb, ""ext2_xattr_cache_find"",
 				""inode %ld: block %ld read error"",
 				inode->i_ino, (unsigned long) ce->e_block);
 		} else {
 			lock_buffer(bh);
-			if (le32_to_cpu(HDR(bh)->h_refcount) >
+			/*
+			 * We have to be careful about races with freeing or
+			 * rehashing of xattr block. Once we hold buffer lock
+			 * xattr block's state is stable so we can check
+			 * whether the block got freed / rehashed or not.
+			 * Since we unhash mbcache entry under buffer lock when
+			 * freeing / rehashing xattr block, checking whether
+			 * entry is still hashed is reliable.
+			 */
+			if (hlist_bl_unhashed(&ce->e_hash_list)) {
+				mb2_cache_entry_put(ext2_mb_cache, ce);
+				unlock_buffer(bh);
+				brelse(bh);
+				goto again;
+			} else if (le32_to_cpu(HDR(bh)->h_refcount) >
 				   EXT2_XATTR_REFCOUNT_MAX) {
 				ea_idebug(inode, ""block %ld refcount %d>%d"",
 					  (unsigned long) ce->e_block,
@@ -936,13 +928,14 @@ ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)
 			} else if (!ext2_xattr_cmp(header, HDR(bh))) {
 				ea_bdebug(bh, ""b_count=%d"",
 					  atomic_read(&(bh->b_count)));
-				mb_cache_entry_release(ce);
+				mb2_cache_entry_touch(ext2_mb_cache, ce);
+				mb2_cache_entry_put(ext2_mb_cache, ce);
 				return bh;
 			}
 			unlock_buffer(bh);
 			brelse(bh);
 		}
-		ce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);
+		ce = mb2_cache_entry_find_next(ext2_mb_cache, ce);
 	}
 	return NULL;
 }
@@ -1015,17 +1008,15 @@ static void ext2_xattr_rehash(struct ext2_xattr_header *header,
 
 #undef BLOCK_HASH_SHIFT
 
-int __init
-init_ext2_xattr(void)
+#define HASH_BUCKET_BITS 10
+
+struct mb2_cache *ext2_xattr_create_cache(void)
 {
-	ext2_xattr_cache = mb_cache_create(""ext2_xattr"", 6);
-	if (!ext2_xattr_cache)
-		return -ENOMEM;
-	return 0;
+	return mb2_cache_create(HASH_BUCKET_BITS);
 }
 
-void
-exit_ext2_xattr(void)
+void ext2_xattr_destroy_cache(struct mb2_cache *cache)
 {
-	mb_cache_destroy(ext2_xattr_cache);
+	if (cache)
+		mb2_cache_destroy(cache);
 }",linux,be0726d33cb8f411945884664924bed3cb8c70ee,82939d7999dfc1f1998c4b1c12e2f19edbdff272,1,"ext2_xattr_set(struct inode *inode, int name_index, const char *name,
	       const void *value, size_t value_len, int flags)
{
	struct super_block *sb = inode->i_sb;
	struct buffer_head *bh = NULL;
	struct ext2_xattr_header *header = NULL;
	struct ext2_xattr_entry *here, *last;
	size_t name_len, free, min_offs = sb->s_blocksize;
	int not_found = 1, error;
	char *end;
	
	/*
	 * header -- Points either into bh, or to a temporarily
	 *           allocated buffer.
	 * here -- The named entry found, or the place for inserting, within
	 *         the block pointed to by header.
	 * last -- Points right after the last named entry within the block
	 *         pointed to by header.
	 * min_offs -- The offset of the first value (values are aligned
	 *             towards the end of the block).
	 * end -- Points right after the block pointed to by header.
	 */
	
	ea_idebug(inode, ""name=%d.%s, value=%p, value_len=%ld"",
		  name_index, name, value, (long)value_len);

	if (value == NULL)
		value_len = 0;
	if (name == NULL)
		return -EINVAL;
	name_len = strlen(name);
	if (name_len > 255 || value_len > sb->s_blocksize)
		return -ERANGE;
	down_write(&EXT2_I(inode)->xattr_sem);
	if (EXT2_I(inode)->i_file_acl) {
		/* The inode already has an extended attribute block. */
		bh = sb_bread(sb, EXT2_I(inode)->i_file_acl);
		error = -EIO;
		if (!bh)
			goto cleanup;
		ea_bdebug(bh, ""b_count=%d, refcount=%d"",
			atomic_read(&(bh->b_count)),
			le32_to_cpu(HDR(bh)->h_refcount));
		header = HDR(bh);
		end = bh->b_data + bh->b_size;
		if (header->h_magic != cpu_to_le32(EXT2_XATTR_MAGIC) ||
		    header->h_blocks != cpu_to_le32(1)) {
bad_block:		ext2_error(sb, ""ext2_xattr_set"",
				""inode %ld: bad block %d"", inode->i_ino, 
				   EXT2_I(inode)->i_file_acl);
			error = -EIO;
			goto cleanup;
		}
		/* Find the named attribute. */
		here = FIRST_ENTRY(bh);
		while (!IS_LAST_ENTRY(here)) {
			struct ext2_xattr_entry *next = EXT2_XATTR_NEXT(here);
			if ((char *)next >= end)
				goto bad_block;
			if (!here->e_value_block && here->e_value_size) {
				size_t offs = le16_to_cpu(here->e_value_offs);
				if (offs < min_offs)
					min_offs = offs;
			}
			not_found = name_index - here->e_name_index;
			if (!not_found)
				not_found = name_len - here->e_name_len;
			if (!not_found)
				not_found = memcmp(name, here->e_name,name_len);
			if (not_found <= 0)
				break;
			here = next;
		}
		last = here;
		/* We still need to compute min_offs and last. */
		while (!IS_LAST_ENTRY(last)) {
			struct ext2_xattr_entry *next = EXT2_XATTR_NEXT(last);
			if ((char *)next >= end)
				goto bad_block;
			if (!last->e_value_block && last->e_value_size) {
				size_t offs = le16_to_cpu(last->e_value_offs);
				if (offs < min_offs)
					min_offs = offs;
			}
			last = next;
		}

		/* Check whether we have enough space left. */
		free = min_offs - ((char*)last - (char*)header) - sizeof(__u32);
	} else {
		/* We will use a new extended attribute block. */
		free = sb->s_blocksize -
			sizeof(struct ext2_xattr_header) - sizeof(__u32);
		here = last = NULL;  /* avoid gcc uninitialized warning. */
	}

	if (not_found) {
		/* Request to remove a nonexistent attribute? */
		error = -ENODATA;
		if (flags & XATTR_REPLACE)
			goto cleanup;
		error = 0;
		if (value == NULL)
			goto cleanup;
	} else {
		/* Request to create an existing attribute? */
		error = -EEXIST;
		if (flags & XATTR_CREATE)
			goto cleanup;
		if (!here->e_value_block && here->e_value_size) {
			size_t size = le32_to_cpu(here->e_value_size);

			if (le16_to_cpu(here->e_value_offs) + size > 
			    sb->s_blocksize || size > sb->s_blocksize)
				goto bad_block;
			free += EXT2_XATTR_SIZE(size);
		}
		free += EXT2_XATTR_LEN(name_len);
	}
	error = -ENOSPC;
	if (free < EXT2_XATTR_LEN(name_len) + EXT2_XATTR_SIZE(value_len))
		goto cleanup;

 	/* Here we know that we can set the new attribute. */
 
 	if (header) {
//flaw_line_below:
		struct mb_cache_entry *ce;
//flaw_line_below:

 		/* assert(header == HDR(bh)); */
//flaw_line_below:
		ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,
//flaw_line_below:
					bh->b_blocknr);
 		lock_buffer(bh);
 		if (header->h_refcount == cpu_to_le32(1)) {
//fix_flaw_line_below:
//			__u32 hash = le32_to_cpu(header->h_hash);
//fix_flaw_line_below:
//
 			ea_bdebug(bh, ""modifying in-place"");
//flaw_line_below:
			if (ce)
//flaw_line_below:
				mb_cache_entry_free(ce);
//fix_flaw_line_below:
//			/*
//fix_flaw_line_below:
//			 * This must happen under buffer lock for
//fix_flaw_line_below:
//			 * ext2_xattr_set2() to reliably detect modified block
//fix_flaw_line_below:
//			 */
//fix_flaw_line_below:
//			mb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,
//fix_flaw_line_below:
//						     hash, bh->b_blocknr);
//fix_flaw_line_below:
//
 			/* keep the buffer locked while modifying it. */
 		} else {
 			int offset;
 
//flaw_line_below:
			if (ce)
//flaw_line_below:
				mb_cache_entry_release(ce);
 			unlock_buffer(bh);
 			ea_bdebug(bh, ""cloning"");
 			header = kmalloc(bh->b_size, GFP_KERNEL);
			error = -ENOMEM;
			if (header == NULL)
				goto cleanup;
			memcpy(header, HDR(bh), bh->b_size);
			header->h_refcount = cpu_to_le32(1);

			offset = (char *)here - bh->b_data;
			here = ENTRY((char *)header + offset);
			offset = (char *)last - bh->b_data;
			last = ENTRY((char *)header + offset);
		}
	} else {
		/* Allocate a buffer where we construct the new block. */
		header = kzalloc(sb->s_blocksize, GFP_KERNEL);
		error = -ENOMEM;
		if (header == NULL)
			goto cleanup;
		end = (char *)header + sb->s_blocksize;
		header->h_magic = cpu_to_le32(EXT2_XATTR_MAGIC);
		header->h_blocks = header->h_refcount = cpu_to_le32(1);
		last = here = ENTRY(header+1);
	}

	/* Iff we are modifying the block in-place, bh is locked here. */

	if (not_found) {
		/* Insert the new name. */
		size_t size = EXT2_XATTR_LEN(name_len);
		size_t rest = (char *)last - (char *)here;
		memmove((char *)here + size, here, rest);
		memset(here, 0, size);
		here->e_name_index = name_index;
		here->e_name_len = name_len;
		memcpy(here->e_name, name, name_len);
	} else {
		if (!here->e_value_block && here->e_value_size) {
			char *first_val = (char *)header + min_offs;
			size_t offs = le16_to_cpu(here->e_value_offs);
			char *val = (char *)header + offs;
			size_t size = EXT2_XATTR_SIZE(
				le32_to_cpu(here->e_value_size));

			if (size == EXT2_XATTR_SIZE(value_len)) {
				/* The old and the new value have the same
				   size. Just replace. */
				here->e_value_size = cpu_to_le32(value_len);
				memset(val + size - EXT2_XATTR_PAD, 0,
				       EXT2_XATTR_PAD); /* Clear pad bytes. */
				memcpy(val, value, value_len);
				goto skip_replace;
			}

			/* Remove the old value. */
			memmove(first_val + size, first_val, val - first_val);
			memset(first_val, 0, size);
			here->e_value_offs = 0;
			min_offs += size;

			/* Adjust all value offsets. */
			last = ENTRY(header+1);
			while (!IS_LAST_ENTRY(last)) {
				size_t o = le16_to_cpu(last->e_value_offs);
				if (!last->e_value_block && o < offs)
					last->e_value_offs =
						cpu_to_le16(o + size);
				last = EXT2_XATTR_NEXT(last);
			}
		}
		if (value == NULL) {
			/* Remove the old name. */
			size_t size = EXT2_XATTR_LEN(name_len);
			last = ENTRY((char *)last - size);
			memmove(here, (char*)here + size,
				(char*)last - (char*)here);
			memset(last, 0, size);
		}
	}

	if (value != NULL) {
		/* Insert the new value. */
		here->e_value_size = cpu_to_le32(value_len);
		if (value_len) {
			size_t size = EXT2_XATTR_SIZE(value_len);
			char *val = (char *)header + min_offs - size;
			here->e_value_offs =
				cpu_to_le16((char *)val - (char *)header);
			memset(val + size - EXT2_XATTR_PAD, 0,
			       EXT2_XATTR_PAD); /* Clear the pad bytes. */
			memcpy(val, value, value_len);
		}
	}

skip_replace:
	if (IS_LAST_ENTRY(ENTRY(header+1))) {
		/* This block is now empty. */
		if (bh && header == HDR(bh))
			unlock_buffer(bh);  /* we were modifying in-place. */
		error = ext2_xattr_set2(inode, bh, NULL);
	} else {
		ext2_xattr_rehash(header, here);
		if (bh && header == HDR(bh))
			unlock_buffer(bh);  /* we were modifying in-place. */
		error = ext2_xattr_set2(inode, bh, header);
	}

cleanup:
	brelse(bh);
	if (!(bh && header == HDR(bh)))
		kfree(header);
	up_write(&EXT2_I(inode)->xattr_sem);

	return error;
}
"
5420,183156,,Local,Not required,Partial,CVE-2015-8952,https://www.cvedetails.com/cve/CVE-2015-8952/,CWE-19,Low,,,,2016-10-16,2.1,"The mbcache feature in the ext2 and ext4 filesystem implementations in the Linux kernel before 4.6 mishandles xattr block caching, which allows local users to cause a denial of service (soft lockup) via filesystem operations in environments that use many attributes, as demonstrated by Ceph and Samba.",2018-03-15,DoS ,11,https://github.com/torvalds/linux/commit/be0726d33cb8f411945884664924bed3cb8c70ee,be0726d33cb8f411945884664924bed3cb8c70ee,"ext2: convert to mbcache2

The conversion is generally straightforward. We convert filesystem from
a global cache to per-fs one. Similarly to ext4 the tricky part is that
xattr block corresponding to found mbcache entry can get freed before we
get buffer lock for that block. So we have to check whether the entry is
still valid after getting the buffer lock.

Signed-off-by: Jan Kara <jack@suse.cz>
Signed-off-by: Theodore Ts'o <tytso@mit.edu>",9,fs/ext2/xattr.c,"{""sha"": ""f98ce7e60a0f84f71743e0dfe069c7e96c6bd648"", ""filename"": ""fs/ext2/ext2.h"", ""status"": ""modified"", ""additions"": 3, ""deletions"": 0, ""changes"": 3, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/ext2.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -61,6 +61,8 @@ struct ext2_block_alloc_info {\n #define rsv_start rsv_window._rsv_start\n #define rsv_end rsv_window._rsv_end\n \n+struct mb2_cache;\n+\n /*\n  * second extended-fs super-block data in memory\n  */\n@@ -111,6 +113,7 @@ struct ext2_sb_info {\n \t * of the mount options.\n \t */\n \tspinlock_t s_lock;\n+\tstruct mb2_cache *s_mb_cache;\n };\n \n static inline spinlock_t *""}<_**next**_>{""sha"": ""b78caf25f746220ce635a3bd946bedeaf7e3e750"", ""filename"": ""fs/ext2/super.c"", ""status"": ""modified"", ""additions"": 17, ""deletions"": 8, ""changes"": 25, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/super.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -131,7 +131,10 @@ static void ext2_put_super (struct super_block * sb)\n \n \tdquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);\n \n-\text2_xattr_put_super(sb);\n+\tif (sbi->s_mb_cache) {\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n+\t\tsbi->s_mb_cache = NULL;\n+\t}\n \tif (!(sb->s_flags & MS_RDONLY)) {\n \t\tstruct ext2_super_block *es = sbi->s_es;\n \n@@ -1104,6 +1107,14 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\text2_msg(sb, KERN_ERR, \""error: insufficient memory\"");\n \t\tgoto failed_mount3;\n \t}\n+\n+#ifdef CONFIG_EXT2_FS_XATTR\n+\tsbi->s_mb_cache = ext2_xattr_create_cache();\n+\tif (!sbi->s_mb_cache) {\n+\t\text2_msg(sb, KERN_ERR, \""Failed to create an mb_cache\"");\n+\t\tgoto failed_mount3;\n+\t}\n+#endif\n \t/*\n \t * set up enough so that it can read an inode\n \t */\n@@ -1149,6 +1160,8 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\t\tsb->s_id);\n \tgoto failed_mount;\n failed_mount3:\n+\tif (sbi->s_mb_cache)\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n \tpercpu_counter_destroy(&sbi->s_freeblocks_counter);\n \tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n \tpercpu_counter_destroy(&sbi->s_dirs_counter);\n@@ -1555,28 +1568,24 @@ MODULE_ALIAS_FS(\""ext2\"");\n \n static int __init init_ext2_fs(void)\n {\n-\tint err = init_ext2_xattr();\n-\tif (err)\n-\t\treturn err;\n+\tint err;\n+\n \terr = init_inodecache();\n \tif (err)\n-\t\tgoto out1;\n+\t\treturn err;\n         err = register_filesystem(&ext2_fs_type);\n \tif (err)\n \t\tgoto out;\n \treturn 0;\n out:\n \tdestroy_inodecache();\n-out1:\n-\texit_ext2_xattr();\n \treturn err;\n }\n \n static void __exit exit_ext2_fs(void)\n {\n \tunregister_filesystem(&ext2_fs_type);\n \tdestroy_inodecache();\n-\texit_ext2_xattr();\n }\n \n MODULE_AUTHOR(\""Remy Card and others\"");""}<_**next**_>{""sha"": ""7162b4869bc32515800d8ffc06ac3835ea241c8b"", ""filename"": ""fs/ext2/xattr.c"", ""status"": ""modified"", ""additions"": 67, ""deletions"": 76, ""changes"": 143, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -56,7 +56,7 @@\n #include <linux/buffer_head.h>\n #include <linux/init.h>\n #include <linux/slab.h>\n-#include <linux/mbcache.h>\n+#include <linux/mbcache2.h>\n #include <linux/quotaops.h>\n #include <linux/rwsem.h>\n #include <linux/security.h>\n@@ -90,14 +90,12 @@\n static int ext2_xattr_set2(struct inode *, struct buffer_head *,\n \t\t\t   struct ext2_xattr_header *);\n \n-static int ext2_xattr_cache_insert(struct buffer_head *);\n+static int ext2_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);\n static struct buffer_head *ext2_xattr_cache_find(struct inode *,\n \t\t\t\t\t\t struct ext2_xattr_header *);\n static void ext2_xattr_rehash(struct ext2_xattr_header *,\n \t\t\t      struct ext2_xattr_entry *);\n \n-static struct mb_cache *ext2_xattr_cache;\n-\n static const struct xattr_handler *ext2_xattr_handler_map[] = {\n \t[EXT2_XATTR_INDEX_USER]\t\t     = &ext2_xattr_user_handler,\n #ifdef CONFIG_EXT2_FS_POSIX_ACL\n@@ -152,6 +150,7 @@ ext2_xattr_get(struct inode *inode, int name_index, const char *name,\n \tsize_t name_len, size;\n \tchar *end;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""name=%d.%s, buffer=%p, buffer_size=%ld\"",\n \t\t  name_index, name, buffer, (long)buffer_size);\n@@ -196,7 +195,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t\t\tgoto found;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \terror = -ENODATA;\n \tgoto cleanup;\n@@ -209,7 +208,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)\n \t\tgoto bad_block;\n \n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \tif (buffer) {\n \t\terror = -ERANGE;\n@@ -247,6 +246,7 @@ ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)\n \tchar *end;\n \tsize_t rest = buffer_size;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""buffer=%p, buffer_size=%ld\"",\n \t\t  buffer, (long)buffer_size);\n@@ -281,7 +281,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_list\"",\n \t\t\tgoto bad_block;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \n \t/* list the attribute names */\n@@ -483,22 +483,23 @@ bad_block:\t\text2_error(sb, \""ext2_xattr_set\"",\n \t/* Here we know that we can set the new attribute. */\n \n \tif (header) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/* assert(header == HDR(bh)); */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,\n-\t\t\t\t\tbh->b_blocknr);\n \t\tlock_buffer(bh);\n \t\tif (header->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(header->h_hash);\n+\n \t\t\tea_bdebug(bh, \""modifying in-place\"");\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect modified block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,\n+\t\t\t\t\t\t     hash, bh->b_blocknr);\n+\n \t\t\t/* keep the buffer locked while modifying it. */\n \t\t} else {\n \t\t\tint offset;\n \n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tunlock_buffer(bh);\n \t\t\tea_bdebug(bh, \""cloning\"");\n \t\t\theader = kmalloc(bh->b_size, GFP_KERNEL);\n@@ -626,6 +627,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \tstruct super_block *sb = inode->i_sb;\n \tstruct buffer_head *new_bh = NULL;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;\n \n \tif (header) {\n \t\tnew_bh = ext2_xattr_cache_find(inode, header);\n@@ -653,7 +655,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\t   don't need to change the reference count. */\n \t\t\tnew_bh = old_bh;\n \t\t\tget_bh(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t} else {\n \t\t\t/* We need to allocate a new block */\n \t\t\text2_fsblk_t goal = ext2_group_first_block_no(sb,\n@@ -674,7 +676,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\tmemcpy(new_bh->b_data, header, new_bh->b_size);\n \t\t\tset_buffer_uptodate(new_bh);\n \t\t\tunlock_buffer(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t\t\n \t\t\text2_xattr_update_super_block(sb);\n \t\t}\n@@ -707,19 +709,21 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \n \terror = 0;\n \tif (old_bh && old_bh != new_bh) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/*\n \t\t * If there was an old block and we are no longer using it,\n \t\t * release the old block.\n \t\t */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,\n-\t\t\t\t\told_bh->b_blocknr);\n \t\tlock_buffer(old_bh);\n \t\tif (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);\n+\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect freed block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(ext2_mb_cache,\n+\t\t\t\t\t\t     hash, old_bh->b_blocknr);\n \t\t\t/* Free the old block. */\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n \t\t\tea_bdebug(old_bh, \""freeing\"");\n \t\t\text2_free_blocks(inode, old_bh->b_blocknr, 1);\n \t\t\tmark_inode_dirty(inode);\n@@ -730,8 +734,6 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t} else {\n \t\t\t/* Decrement the refcount only. */\n \t\t\tle32_add_cpu(&HDR(old_bh)->h_refcount, -1);\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tdquot_free_block_nodirty(inode, 1);\n \t\t\tmark_inode_dirty(inode);\n \t\t\tmark_buffer_dirty(old_bh);\n@@ -757,7 +759,6 @@ void\n ext2_xattr_delete_inode(struct inode *inode)\n {\n \tstruct buffer_head *bh = NULL;\n-\tstruct mb_cache_entry *ce;\n \n \tdown_write(&EXT2_I(inode)->xattr_sem);\n \tif (!EXT2_I(inode)->i_file_acl)\n@@ -777,19 +778,22 @@ ext2_xattr_delete_inode(struct inode *inode)\n \t\t\tEXT2_I(inode)->i_file_acl);\n \t\tgoto cleanup;\n \t}\n-\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);\n \tlock_buffer(bh);\n \tif (HDR(bh)->h_refcount == cpu_to_le32(1)) {\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_free(ce);\n+\t\t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n+\n+\t\t/*\n+\t\t * This must happen under buffer lock for ext2_xattr_set2() to\n+\t\t * reliably detect freed block\n+\t\t */\n+\t\tmb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,\n+\t\t\t\t\t     hash, bh->b_blocknr);\n \t\text2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);\n \t\tget_bh(bh);\n \t\tbforget(bh);\n \t\tunlock_buffer(bh);\n \t} else {\n \t\tle32_add_cpu(&HDR(bh)->h_refcount, -1);\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_release(ce);\n \t\tea_bdebug(bh, \""refcount now=%d\"",\n \t\t\tle32_to_cpu(HDR(bh)->h_refcount));\n \t\tunlock_buffer(bh);\n@@ -805,18 +809,6 @@ ext2_xattr_delete_inode(struct inode *inode)\n \tup_write(&EXT2_I(inode)->xattr_sem);\n }\n \n-/*\n- * ext2_xattr_put_super()\n- *\n- * This is called when a file system is unmounted.\n- */\n-void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-\tmb_cache_shrink(sb->s_bdev);\n-}\n-\n-\n /*\n  * ext2_xattr_cache_insert()\n  *\n@@ -826,28 +818,20 @@ ext2_xattr_put_super(struct super_block *sb)\n  * Returns 0, or a negative error number on failure.\n  */\n static int\n-ext2_xattr_cache_insert(struct buffer_head *bh)\n+ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)\n {\n \t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n-\tstruct mb_cache_entry *ce;\n \tint error;\n \n-\tce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);\n-\tif (!ce)\n-\t\treturn -ENOMEM;\n-\terror = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);\n+\terror = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);\n \tif (error) {\n-\t\tmb_cache_entry_free(ce);\n \t\tif (error == -EBUSY) {\n \t\t\tea_bdebug(bh, \""already in cache (%d cache entries)\"",\n \t\t\t\tatomic_read(&ext2_xattr_cache->c_entry_count));\n \t\t\terror = 0;\n \t\t}\n-\t} else {\n-\t\tea_bdebug(bh, \""inserting [%x] (%d cache entries)\"", (int)hash,\n-\t\t\t  atomic_read(&ext2_xattr_cache->c_entry_count));\n-\t\tmb_cache_entry_release(ce);\n-\t}\n+\t} else\n+\t\tea_bdebug(bh, \""inserting [%x]\"", (int)hash);\n \treturn error;\n }\n \n@@ -903,31 +887,39 @@ static struct buffer_head *\n ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n {\n \t__u32 hash = le32_to_cpu(header->h_hash);\n-\tstruct mb_cache_entry *ce;\n+\tstruct mb2_cache_entry *ce;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tif (!header->h_hash)\n \t\treturn NULL;  /* never share */\n \tea_idebug(inode, \""looking for cached blocks [%x]\"", (int)hash);\n again:\n-\tce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,\n-\t\t\t\t       hash);\n+\tce = mb2_cache_entry_find_first(ext2_mb_cache, hash);\n \twhile (ce) {\n \t\tstruct buffer_head *bh;\n \n-\t\tif (IS_ERR(ce)) {\n-\t\t\tif (PTR_ERR(ce) == -EAGAIN)\n-\t\t\t\tgoto again;\n-\t\t\tbreak;\n-\t\t}\n-\n \t\tbh = sb_bread(inode->i_sb, ce->e_block);\n \t\tif (!bh) {\n \t\t\text2_error(inode->i_sb, \""ext2_xattr_cache_find\"",\n \t\t\t\t\""inode %ld: block %ld read error\"",\n \t\t\t\tinode->i_ino, (unsigned long) ce->e_block);\n \t\t} else {\n \t\t\tlock_buffer(bh);\n-\t\t\tif (le32_to_cpu(HDR(bh)->h_refcount) >\n+\t\t\t/*\n+\t\t\t * We have to be careful about races with freeing or\n+\t\t\t * rehashing of xattr block. Once we hold buffer lock\n+\t\t\t * xattr block's state is stable so we can check\n+\t\t\t * whether the block got freed / rehashed or not.\n+\t\t\t * Since we unhash mbcache entry under buffer lock when\n+\t\t\t * freeing / rehashing xattr block, checking whether\n+\t\t\t * entry is still hashed is reliable.\n+\t\t\t */\n+\t\t\tif (hlist_bl_unhashed(&ce->e_hash_list)) {\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n+\t\t\t\tunlock_buffer(bh);\n+\t\t\t\tbrelse(bh);\n+\t\t\t\tgoto again;\n+\t\t\t} else if (le32_to_cpu(HDR(bh)->h_refcount) >\n \t\t\t\t   EXT2_XATTR_REFCOUNT_MAX) {\n \t\t\t\tea_idebug(inode, \""block %ld refcount %d>%d\"",\n \t\t\t\t\t  (unsigned long) ce->e_block,\n@@ -936,13 +928,14 @@ ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n \t\t\t} else if (!ext2_xattr_cmp(header, HDR(bh))) {\n \t\t\t\tea_bdebug(bh, \""b_count=%d\"",\n \t\t\t\t\t  atomic_read(&(bh->b_count)));\n-\t\t\t\tmb_cache_entry_release(ce);\n+\t\t\t\tmb2_cache_entry_touch(ext2_mb_cache, ce);\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n \t\t\t\treturn bh;\n \t\t\t}\n \t\t\tunlock_buffer(bh);\n \t\t\tbrelse(bh);\n \t\t}\n-\t\tce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);\n+\t\tce = mb2_cache_entry_find_next(ext2_mb_cache, ce);\n \t}\n \treturn NULL;\n }\n@@ -1015,17 +1008,15 @@ static void ext2_xattr_rehash(struct ext2_xattr_header *header,\n \n #undef BLOCK_HASH_SHIFT\n \n-int __init\n-init_ext2_xattr(void)\n+#define HASH_BUCKET_BITS 10\n+\n+struct mb2_cache *ext2_xattr_create_cache(void)\n {\n-\text2_xattr_cache = mb_cache_create(\""ext2_xattr\"", 6);\n-\tif (!ext2_xattr_cache)\n-\t\treturn -ENOMEM;\n-\treturn 0;\n+\treturn mb2_cache_create(HASH_BUCKET_BITS);\n }\n \n-void\n-exit_ext2_xattr(void)\n+void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n-\tmb_cache_destroy(ext2_xattr_cache);\n+\tif (cache)\n+\t\tmb2_cache_destroy(cache);\n }""}<_**next**_>{""sha"": ""6ea38aa9563a00649bf25544eed131bbe8b1d88d"", ""filename"": ""fs/ext2/xattr.h"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 16, ""changes"": 21, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -53,6 +53,8 @@ struct ext2_xattr_entry {\n #define EXT2_XATTR_SIZE(size) \\\n \t(((size) + EXT2_XATTR_ROUND) & ~EXT2_XATTR_ROUND)\n \n+struct mb2_cache;\n+\n # ifdef CONFIG_EXT2_FS_XATTR\n \n extern const struct xattr_handler ext2_xattr_user_handler;\n@@ -65,10 +67,9 @@ extern int ext2_xattr_get(struct inode *, int, const char *, void *, size_t);\n extern int ext2_xattr_set(struct inode *, int, const char *, const void *, size_t, int);\n \n extern void ext2_xattr_delete_inode(struct inode *);\n-extern void ext2_xattr_put_super(struct super_block *);\n \n-extern int init_ext2_xattr(void);\n-extern void exit_ext2_xattr(void);\n+extern struct mb2_cache *ext2_xattr_create_cache(void);\n+extern void ext2_xattr_destroy_cache(struct mb2_cache *cache);\n \n extern const struct xattr_handler *ext2_xattr_handlers[];\n \n@@ -93,19 +94,7 @@ ext2_xattr_delete_inode(struct inode *inode)\n {\n }\n \n-static inline void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-}\n-\n-static inline int\n-init_ext2_xattr(void)\n-{\n-\treturn 0;\n-}\n-\n-static inline void\n-exit_ext2_xattr(void)\n+static inline void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n }\n ""}","ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
		struct ext2_xattr_header *header)
{
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *new_bh = NULL;
 	int error;
	struct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;
 
 	if (header) {
 		new_bh = ext2_xattr_cache_find(inode, header);
		if (new_bh) {
			/* We found an identical block in the cache. */
			if (new_bh == old_bh) {
				ea_bdebug(new_bh, ""keeping this block"");
			} else {
				/* The old block is released after updating
				   the inode.  */
				ea_bdebug(new_bh, ""reusing block"");

				error = dquot_alloc_block(inode, 1);
				if (error) {
					unlock_buffer(new_bh);
					goto cleanup;
				}
				le32_add_cpu(&HDR(new_bh)->h_refcount, 1);
				ea_bdebug(new_bh, ""refcount now=%d"",
					le32_to_cpu(HDR(new_bh)->h_refcount));
			}
			unlock_buffer(new_bh);
		} else if (old_bh && header == HDR(old_bh)) {
			/* Keep this block. No need to lock the block as we
 			   don't need to change the reference count. */
 			new_bh = old_bh;
 			get_bh(new_bh);
			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
 		} else {
 			/* We need to allocate a new block */
 			ext2_fsblk_t goal = ext2_group_first_block_no(sb,
						EXT2_I(inode)->i_block_group);
			int block = ext2_new_block(inode, goal, &error);
			if (error)
				goto cleanup;
			ea_idebug(inode, ""creating block %d"", block);

			new_bh = sb_getblk(sb, block);
			if (unlikely(!new_bh)) {
				ext2_free_blocks(inode, block, 1);
				mark_inode_dirty(inode);
				error = -ENOMEM;
				goto cleanup;
			}
			lock_buffer(new_bh);
 			memcpy(new_bh->b_data, header, new_bh->b_size);
 			set_buffer_uptodate(new_bh);
 			unlock_buffer(new_bh);
			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
 			
 			ext2_xattr_update_super_block(sb);
 		}
		mark_buffer_dirty(new_bh);
		if (IS_SYNC(inode)) {
			sync_dirty_buffer(new_bh);
			error = -EIO;
			if (buffer_req(new_bh) && !buffer_uptodate(new_bh))
				goto cleanup;
		}
	}

	/* Update the inode. */
	EXT2_I(inode)->i_file_acl = new_bh ? new_bh->b_blocknr : 0;
	inode->i_ctime = CURRENT_TIME_SEC;
	if (IS_SYNC(inode)) {
		error = sync_inode_metadata(inode, 1);
		/* In case sync failed due to ENOSPC the inode was actually
		 * written (only some dirty data were not) so we just proceed
		 * as if nothing happened and cleanup the unused block */
		if (error && error != -ENOSPC) {
			if (new_bh && new_bh != old_bh) {
				dquot_free_block_nodirty(inode, 1);
				mark_inode_dirty(inode);
			}
			goto cleanup;
		}
	} else
		mark_inode_dirty(inode);
 
 	error = 0;
 	if (old_bh && old_bh != new_bh) {
 		/*
 		 * If there was an old block and we are no longer using it,
 		 * release the old block.
 		 */
 		lock_buffer(old_bh);
 		if (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {
			__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);

			/*
			 * This must happen under buffer lock for
			 * ext2_xattr_set2() to reliably detect freed block
			 */
			mb2_cache_entry_delete_block(ext2_mb_cache,
						     hash, old_bh->b_blocknr);
 			/* Free the old block. */
 			ea_bdebug(old_bh, ""freeing"");
 			ext2_free_blocks(inode, old_bh->b_blocknr, 1);
 			mark_inode_dirty(inode);
			/* We let our caller release old_bh, so we
			 * need to duplicate the buffer before. */
			get_bh(old_bh);
			bforget(old_bh);
 		} else {
 			/* Decrement the refcount only. */
 			le32_add_cpu(&HDR(old_bh)->h_refcount, -1);
 			dquot_free_block_nodirty(inode, 1);
 			mark_inode_dirty(inode);
 			mark_buffer_dirty(old_bh);
			ea_bdebug(old_bh, ""refcount now=%d"",
				le32_to_cpu(HDR(old_bh)->h_refcount));
		}
		unlock_buffer(old_bh);
	}

cleanup:
	brelse(new_bh);

	return error;
}
","ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
		struct ext2_xattr_header *header)
{
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *new_bh = NULL;
 	int error;
 
 	if (header) {
 		new_bh = ext2_xattr_cache_find(inode, header);
		if (new_bh) {
			/* We found an identical block in the cache. */
			if (new_bh == old_bh) {
				ea_bdebug(new_bh, ""keeping this block"");
			} else {
				/* The old block is released after updating
				   the inode.  */
				ea_bdebug(new_bh, ""reusing block"");

				error = dquot_alloc_block(inode, 1);
				if (error) {
					unlock_buffer(new_bh);
					goto cleanup;
				}
				le32_add_cpu(&HDR(new_bh)->h_refcount, 1);
				ea_bdebug(new_bh, ""refcount now=%d"",
					le32_to_cpu(HDR(new_bh)->h_refcount));
			}
			unlock_buffer(new_bh);
		} else if (old_bh && header == HDR(old_bh)) {
			/* Keep this block. No need to lock the block as we
 			   don't need to change the reference count. */
 			new_bh = old_bh;
 			get_bh(new_bh);
			ext2_xattr_cache_insert(new_bh);
 		} else {
 			/* We need to allocate a new block */
 			ext2_fsblk_t goal = ext2_group_first_block_no(sb,
						EXT2_I(inode)->i_block_group);
			int block = ext2_new_block(inode, goal, &error);
			if (error)
				goto cleanup;
			ea_idebug(inode, ""creating block %d"", block);

			new_bh = sb_getblk(sb, block);
			if (unlikely(!new_bh)) {
				ext2_free_blocks(inode, block, 1);
				mark_inode_dirty(inode);
				error = -ENOMEM;
				goto cleanup;
			}
			lock_buffer(new_bh);
 			memcpy(new_bh->b_data, header, new_bh->b_size);
 			set_buffer_uptodate(new_bh);
 			unlock_buffer(new_bh);
			ext2_xattr_cache_insert(new_bh);
 			
 			ext2_xattr_update_super_block(sb);
 		}
		mark_buffer_dirty(new_bh);
		if (IS_SYNC(inode)) {
			sync_dirty_buffer(new_bh);
			error = -EIO;
			if (buffer_req(new_bh) && !buffer_uptodate(new_bh))
				goto cleanup;
		}
	}

	/* Update the inode. */
	EXT2_I(inode)->i_file_acl = new_bh ? new_bh->b_blocknr : 0;
	inode->i_ctime = CURRENT_TIME_SEC;
	if (IS_SYNC(inode)) {
		error = sync_inode_metadata(inode, 1);
		/* In case sync failed due to ENOSPC the inode was actually
		 * written (only some dirty data were not) so we just proceed
		 * as if nothing happened and cleanup the unused block */
		if (error && error != -ENOSPC) {
			if (new_bh && new_bh != old_bh) {
				dquot_free_block_nodirty(inode, 1);
				mark_inode_dirty(inode);
			}
			goto cleanup;
		}
	} else
		mark_inode_dirty(inode);
 
 	error = 0;
 	if (old_bh && old_bh != new_bh) {
		struct mb_cache_entry *ce;
 		/*
 		 * If there was an old block and we are no longer using it,
 		 * release the old block.
 		 */
		ce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,
					old_bh->b_blocknr);
 		lock_buffer(old_bh);
 		if (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {
 			/* Free the old block. */
			if (ce)
				mb_cache_entry_free(ce);
 			ea_bdebug(old_bh, ""freeing"");
 			ext2_free_blocks(inode, old_bh->b_blocknr, 1);
 			mark_inode_dirty(inode);
			/* We let our caller release old_bh, so we
			 * need to duplicate the buffer before. */
			get_bh(old_bh);
			bforget(old_bh);
 		} else {
 			/* Decrement the refcount only. */
 			le32_add_cpu(&HDR(old_bh)->h_refcount, -1);
			if (ce)
				mb_cache_entry_release(ce);
 			dquot_free_block_nodirty(inode, 1);
 			mark_inode_dirty(inode);
 			mark_buffer_dirty(old_bh);
			ea_bdebug(old_bh, ""refcount now=%d"",
				le32_to_cpu(HDR(old_bh)->h_refcount));
		}
		unlock_buffer(old_bh);
	}

cleanup:
	brelse(new_bh);

	return error;
}
",C,"	struct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;
			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
			__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);

			/*
			 * This must happen under buffer lock for
			 * ext2_xattr_set2() to reliably detect freed block
			 */
			mb2_cache_entry_delete_block(ext2_mb_cache,
						     hash, old_bh->b_blocknr);
","			ext2_xattr_cache_insert(new_bh);
			ext2_xattr_cache_insert(new_bh);
		struct mb_cache_entry *ce;
		ce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,
					old_bh->b_blocknr);
			if (ce)
				mb_cache_entry_free(ce);
			if (ce)
				mb_cache_entry_release(ce);
",,"@@ -56,7 +56,7 @@
 #include <linux/buffer_head.h>
 #include <linux/init.h>
 #include <linux/slab.h>
-#include <linux/mbcache.h>
+#include <linux/mbcache2.h>
 #include <linux/quotaops.h>
 #include <linux/rwsem.h>
 #include <linux/security.h>
@@ -90,14 +90,12 @@
 static int ext2_xattr_set2(struct inode *, struct buffer_head *,
 			   struct ext2_xattr_header *);
 
-static int ext2_xattr_cache_insert(struct buffer_head *);
+static int ext2_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);
 static struct buffer_head *ext2_xattr_cache_find(struct inode *,
 						 struct ext2_xattr_header *);
 static void ext2_xattr_rehash(struct ext2_xattr_header *,
 			      struct ext2_xattr_entry *);
 
-static struct mb_cache *ext2_xattr_cache;
-
 static const struct xattr_handler *ext2_xattr_handler_map[] = {
 	[EXT2_XATTR_INDEX_USER]		     = &ext2_xattr_user_handler,
 #ifdef CONFIG_EXT2_FS_POSIX_ACL
@@ -152,6 +150,7 @@ ext2_xattr_get(struct inode *inode, int name_index, const char *name,
 	size_t name_len, size;
 	char *end;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	ea_idebug(inode, ""name=%d.%s, buffer=%p, buffer_size=%ld"",
 		  name_index, name, buffer, (long)buffer_size);
@@ -196,7 +195,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_get"",
 			goto found;
 		entry = next;
 	}
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 	error = -ENODATA;
 	goto cleanup;
@@ -209,7 +208,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_get"",
 	    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)
 		goto bad_block;
 
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 	if (buffer) {
 		error = -ERANGE;
@@ -247,6 +246,7 @@ ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)
 	char *end;
 	size_t rest = buffer_size;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	ea_idebug(inode, ""buffer=%p, buffer_size=%ld"",
 		  buffer, (long)buffer_size);
@@ -281,7 +281,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_list"",
 			goto bad_block;
 		entry = next;
 	}
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 
 	/* list the attribute names */
@@ -483,22 +483,23 @@ bad_block:		ext2_error(sb, ""ext2_xattr_set"",
 	/* Here we know that we can set the new attribute. */
 
 	if (header) {
-		struct mb_cache_entry *ce;
-
 		/* assert(header == HDR(bh)); */
-		ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,
-					bh->b_blocknr);
 		lock_buffer(bh);
 		if (header->h_refcount == cpu_to_le32(1)) {
+			__u32 hash = le32_to_cpu(header->h_hash);
+
 			ea_bdebug(bh, ""modifying in-place"");
-			if (ce)
-				mb_cache_entry_free(ce);
+			/*
+			 * This must happen under buffer lock for
+			 * ext2_xattr_set2() to reliably detect modified block
+			 */
+			mb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,
+						     hash, bh->b_blocknr);
+
 			/* keep the buffer locked while modifying it. */
 		} else {
 			int offset;
 
-			if (ce)
-				mb_cache_entry_release(ce);
 			unlock_buffer(bh);
 			ea_bdebug(bh, ""cloning"");
 			header = kmalloc(bh->b_size, GFP_KERNEL);
@@ -626,6 +627,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *new_bh = NULL;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;
 
 	if (header) {
 		new_bh = ext2_xattr_cache_find(inode, header);
@@ -653,7 +655,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 			   don't need to change the reference count. */
 			new_bh = old_bh;
 			get_bh(new_bh);
-			ext2_xattr_cache_insert(new_bh);
+			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
 		} else {
 			/* We need to allocate a new block */
 			ext2_fsblk_t goal = ext2_group_first_block_no(sb,
@@ -674,7 +676,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 			memcpy(new_bh->b_data, header, new_bh->b_size);
 			set_buffer_uptodate(new_bh);
 			unlock_buffer(new_bh);
-			ext2_xattr_cache_insert(new_bh);
+			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
 			
 			ext2_xattr_update_super_block(sb);
 		}
@@ -707,19 +709,21 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 
 	error = 0;
 	if (old_bh && old_bh != new_bh) {
-		struct mb_cache_entry *ce;
-
 		/*
 		 * If there was an old block and we are no longer using it,
 		 * release the old block.
 		 */
-		ce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,
-					old_bh->b_blocknr);
 		lock_buffer(old_bh);
 		if (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {
+			__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);
+
+			/*
+			 * This must happen under buffer lock for
+			 * ext2_xattr_set2() to reliably detect freed block
+			 */
+			mb2_cache_entry_delete_block(ext2_mb_cache,
+						     hash, old_bh->b_blocknr);
 			/* Free the old block. */
-			if (ce)
-				mb_cache_entry_free(ce);
 			ea_bdebug(old_bh, ""freeing"");
 			ext2_free_blocks(inode, old_bh->b_blocknr, 1);
 			mark_inode_dirty(inode);
@@ -730,8 +734,6 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 		} else {
 			/* Decrement the refcount only. */
 			le32_add_cpu(&HDR(old_bh)->h_refcount, -1);
-			if (ce)
-				mb_cache_entry_release(ce);
 			dquot_free_block_nodirty(inode, 1);
 			mark_inode_dirty(inode);
 			mark_buffer_dirty(old_bh);
@@ -757,7 +759,6 @@ void
 ext2_xattr_delete_inode(struct inode *inode)
 {
 	struct buffer_head *bh = NULL;
-	struct mb_cache_entry *ce;
 
 	down_write(&EXT2_I(inode)->xattr_sem);
 	if (!EXT2_I(inode)->i_file_acl)
@@ -777,19 +778,22 @@ ext2_xattr_delete_inode(struct inode *inode)
 			EXT2_I(inode)->i_file_acl);
 		goto cleanup;
 	}
-	ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);
 	lock_buffer(bh);
 	if (HDR(bh)->h_refcount == cpu_to_le32(1)) {
-		if (ce)
-			mb_cache_entry_free(ce);
+		__u32 hash = le32_to_cpu(HDR(bh)->h_hash);
+
+		/*
+		 * This must happen under buffer lock for ext2_xattr_set2() to
+		 * reliably detect freed block
+		 */
+		mb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,
+					     hash, bh->b_blocknr);
 		ext2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);
 		get_bh(bh);
 		bforget(bh);
 		unlock_buffer(bh);
 	} else {
 		le32_add_cpu(&HDR(bh)->h_refcount, -1);
-		if (ce)
-			mb_cache_entry_release(ce);
 		ea_bdebug(bh, ""refcount now=%d"",
 			le32_to_cpu(HDR(bh)->h_refcount));
 		unlock_buffer(bh);
@@ -805,18 +809,6 @@ ext2_xattr_delete_inode(struct inode *inode)
 	up_write(&EXT2_I(inode)->xattr_sem);
 }
 
-/*
- * ext2_xattr_put_super()
- *
- * This is called when a file system is unmounted.
- */
-void
-ext2_xattr_put_super(struct super_block *sb)
-{
-	mb_cache_shrink(sb->s_bdev);
-}
-
-
 /*
  * ext2_xattr_cache_insert()
  *
@@ -826,28 +818,20 @@ ext2_xattr_put_super(struct super_block *sb)
  * Returns 0, or a negative error number on failure.
  */
 static int
-ext2_xattr_cache_insert(struct buffer_head *bh)
+ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)
 {
 	__u32 hash = le32_to_cpu(HDR(bh)->h_hash);
-	struct mb_cache_entry *ce;
 	int error;
 
-	ce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);
-	if (!ce)
-		return -ENOMEM;
-	error = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);
+	error = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);
 	if (error) {
-		mb_cache_entry_free(ce);
 		if (error == -EBUSY) {
 			ea_bdebug(bh, ""already in cache (%d cache entries)"",
 				atomic_read(&ext2_xattr_cache->c_entry_count));
 			error = 0;
 		}
-	} else {
-		ea_bdebug(bh, ""inserting [%x] (%d cache entries)"", (int)hash,
-			  atomic_read(&ext2_xattr_cache->c_entry_count));
-		mb_cache_entry_release(ce);
-	}
+	} else
+		ea_bdebug(bh, ""inserting [%x]"", (int)hash);
 	return error;
 }
 
@@ -903,31 +887,39 @@ static struct buffer_head *
 ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)
 {
 	__u32 hash = le32_to_cpu(header->h_hash);
-	struct mb_cache_entry *ce;
+	struct mb2_cache_entry *ce;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	if (!header->h_hash)
 		return NULL;  /* never share */
 	ea_idebug(inode, ""looking for cached blocks [%x]"", (int)hash);
 again:
-	ce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,
-				       hash);
+	ce = mb2_cache_entry_find_first(ext2_mb_cache, hash);
 	while (ce) {
 		struct buffer_head *bh;
 
-		if (IS_ERR(ce)) {
-			if (PTR_ERR(ce) == -EAGAIN)
-				goto again;
-			break;
-		}
-
 		bh = sb_bread(inode->i_sb, ce->e_block);
 		if (!bh) {
 			ext2_error(inode->i_sb, ""ext2_xattr_cache_find"",
 				""inode %ld: block %ld read error"",
 				inode->i_ino, (unsigned long) ce->e_block);
 		} else {
 			lock_buffer(bh);
-			if (le32_to_cpu(HDR(bh)->h_refcount) >
+			/*
+			 * We have to be careful about races with freeing or
+			 * rehashing of xattr block. Once we hold buffer lock
+			 * xattr block's state is stable so we can check
+			 * whether the block got freed / rehashed or not.
+			 * Since we unhash mbcache entry under buffer lock when
+			 * freeing / rehashing xattr block, checking whether
+			 * entry is still hashed is reliable.
+			 */
+			if (hlist_bl_unhashed(&ce->e_hash_list)) {
+				mb2_cache_entry_put(ext2_mb_cache, ce);
+				unlock_buffer(bh);
+				brelse(bh);
+				goto again;
+			} else if (le32_to_cpu(HDR(bh)->h_refcount) >
 				   EXT2_XATTR_REFCOUNT_MAX) {
 				ea_idebug(inode, ""block %ld refcount %d>%d"",
 					  (unsigned long) ce->e_block,
@@ -936,13 +928,14 @@ ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)
 			} else if (!ext2_xattr_cmp(header, HDR(bh))) {
 				ea_bdebug(bh, ""b_count=%d"",
 					  atomic_read(&(bh->b_count)));
-				mb_cache_entry_release(ce);
+				mb2_cache_entry_touch(ext2_mb_cache, ce);
+				mb2_cache_entry_put(ext2_mb_cache, ce);
 				return bh;
 			}
 			unlock_buffer(bh);
 			brelse(bh);
 		}
-		ce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);
+		ce = mb2_cache_entry_find_next(ext2_mb_cache, ce);
 	}
 	return NULL;
 }
@@ -1015,17 +1008,15 @@ static void ext2_xattr_rehash(struct ext2_xattr_header *header,
 
 #undef BLOCK_HASH_SHIFT
 
-int __init
-init_ext2_xattr(void)
+#define HASH_BUCKET_BITS 10
+
+struct mb2_cache *ext2_xattr_create_cache(void)
 {
-	ext2_xattr_cache = mb_cache_create(""ext2_xattr"", 6);
-	if (!ext2_xattr_cache)
-		return -ENOMEM;
-	return 0;
+	return mb2_cache_create(HASH_BUCKET_BITS);
 }
 
-void
-exit_ext2_xattr(void)
+void ext2_xattr_destroy_cache(struct mb2_cache *cache)
 {
-	mb_cache_destroy(ext2_xattr_cache);
+	if (cache)
+		mb2_cache_destroy(cache);
 }",linux,be0726d33cb8f411945884664924bed3cb8c70ee,82939d7999dfc1f1998c4b1c12e2f19edbdff272,1,"ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
		struct ext2_xattr_header *header)
{
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *new_bh = NULL;
 	int error;
//fix_flaw_line_below:
//	struct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;
 
 	if (header) {
 		new_bh = ext2_xattr_cache_find(inode, header);
		if (new_bh) {
			/* We found an identical block in the cache. */
			if (new_bh == old_bh) {
				ea_bdebug(new_bh, ""keeping this block"");
			} else {
				/* The old block is released after updating
				   the inode.  */
				ea_bdebug(new_bh, ""reusing block"");

				error = dquot_alloc_block(inode, 1);
				if (error) {
					unlock_buffer(new_bh);
					goto cleanup;
				}
				le32_add_cpu(&HDR(new_bh)->h_refcount, 1);
				ea_bdebug(new_bh, ""refcount now=%d"",
					le32_to_cpu(HDR(new_bh)->h_refcount));
			}
			unlock_buffer(new_bh);
		} else if (old_bh && header == HDR(old_bh)) {
			/* Keep this block. No need to lock the block as we
 			   don't need to change the reference count. */
 			new_bh = old_bh;
 			get_bh(new_bh);
//flaw_line_below:
			ext2_xattr_cache_insert(new_bh);
//fix_flaw_line_below:
//			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
 		} else {
 			/* We need to allocate a new block */
 			ext2_fsblk_t goal = ext2_group_first_block_no(sb,
						EXT2_I(inode)->i_block_group);
			int block = ext2_new_block(inode, goal, &error);
			if (error)
				goto cleanup;
			ea_idebug(inode, ""creating block %d"", block);

			new_bh = sb_getblk(sb, block);
			if (unlikely(!new_bh)) {
				ext2_free_blocks(inode, block, 1);
				mark_inode_dirty(inode);
				error = -ENOMEM;
				goto cleanup;
			}
			lock_buffer(new_bh);
 			memcpy(new_bh->b_data, header, new_bh->b_size);
 			set_buffer_uptodate(new_bh);
 			unlock_buffer(new_bh);
//flaw_line_below:
			ext2_xattr_cache_insert(new_bh);
//fix_flaw_line_below:
//			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
 			
 			ext2_xattr_update_super_block(sb);
 		}
		mark_buffer_dirty(new_bh);
		if (IS_SYNC(inode)) {
			sync_dirty_buffer(new_bh);
			error = -EIO;
			if (buffer_req(new_bh) && !buffer_uptodate(new_bh))
				goto cleanup;
		}
	}

	/* Update the inode. */
	EXT2_I(inode)->i_file_acl = new_bh ? new_bh->b_blocknr : 0;
	inode->i_ctime = CURRENT_TIME_SEC;
	if (IS_SYNC(inode)) {
		error = sync_inode_metadata(inode, 1);
		/* In case sync failed due to ENOSPC the inode was actually
		 * written (only some dirty data were not) so we just proceed
		 * as if nothing happened and cleanup the unused block */
		if (error && error != -ENOSPC) {
			if (new_bh && new_bh != old_bh) {
				dquot_free_block_nodirty(inode, 1);
				mark_inode_dirty(inode);
			}
			goto cleanup;
		}
	} else
		mark_inode_dirty(inode);
 
 	error = 0;
 	if (old_bh && old_bh != new_bh) {
//flaw_line_below:
		struct mb_cache_entry *ce;
//flaw_line_below:

 		/*
 		 * If there was an old block and we are no longer using it,
 		 * release the old block.
 		 */
//flaw_line_below:
		ce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,
//flaw_line_below:
					old_bh->b_blocknr);
 		lock_buffer(old_bh);
 		if (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {
//fix_flaw_line_below:
//			__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);
//fix_flaw_line_below:
//
//fix_flaw_line_below:
//			/*
//fix_flaw_line_below:
//			 * This must happen under buffer lock for
//fix_flaw_line_below:
//			 * ext2_xattr_set2() to reliably detect freed block
//fix_flaw_line_below:
//			 */
//fix_flaw_line_below:
//			mb2_cache_entry_delete_block(ext2_mb_cache,
//fix_flaw_line_below:
//						     hash, old_bh->b_blocknr);
 			/* Free the old block. */
//flaw_line_below:
			if (ce)
//flaw_line_below:
				mb_cache_entry_free(ce);
 			ea_bdebug(old_bh, ""freeing"");
 			ext2_free_blocks(inode, old_bh->b_blocknr, 1);
 			mark_inode_dirty(inode);
			/* We let our caller release old_bh, so we
			 * need to duplicate the buffer before. */
			get_bh(old_bh);
			bforget(old_bh);
 		} else {
 			/* Decrement the refcount only. */
 			le32_add_cpu(&HDR(old_bh)->h_refcount, -1);
//flaw_line_below:
			if (ce)
//flaw_line_below:
				mb_cache_entry_release(ce);
 			dquot_free_block_nodirty(inode, 1);
 			mark_inode_dirty(inode);
 			mark_buffer_dirty(old_bh);
			ea_bdebug(old_bh, ""refcount now=%d"",
				le32_to_cpu(HDR(old_bh)->h_refcount));
		}
		unlock_buffer(old_bh);
	}

cleanup:
	brelse(new_bh);

	return error;
}
"
5421,183157,,Local,Not required,Partial,CVE-2015-8952,https://www.cvedetails.com/cve/CVE-2015-8952/,CWE-19,Low,,,,2016-10-16,2.1,"The mbcache feature in the ext2 and ext4 filesystem implementations in the Linux kernel before 4.6 mishandles xattr block caching, which allows local users to cause a denial of service (soft lockup) via filesystem operations in environments that use many attributes, as demonstrated by Ceph and Samba.",2018-03-15,DoS ,4,https://github.com/torvalds/linux/commit/be0726d33cb8f411945884664924bed3cb8c70ee,be0726d33cb8f411945884664924bed3cb8c70ee,"ext2: convert to mbcache2

The conversion is generally straightforward. We convert filesystem from
a global cache to per-fs one. Similarly to ext4 the tricky part is that
xattr block corresponding to found mbcache entry can get freed before we
get buffer lock for that block. So we have to check whether the entry is
still valid after getting the buffer lock.

Signed-off-by: Jan Kara <jack@suse.cz>
Signed-off-by: Theodore Ts'o <tytso@mit.edu>",4,fs/ext2/xattr.c,"{""sha"": ""f98ce7e60a0f84f71743e0dfe069c7e96c6bd648"", ""filename"": ""fs/ext2/ext2.h"", ""status"": ""modified"", ""additions"": 3, ""deletions"": 0, ""changes"": 3, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/ext2.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/ext2.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -61,6 +61,8 @@ struct ext2_block_alloc_info {\n #define rsv_start rsv_window._rsv_start\n #define rsv_end rsv_window._rsv_end\n \n+struct mb2_cache;\n+\n /*\n  * second extended-fs super-block data in memory\n  */\n@@ -111,6 +113,7 @@ struct ext2_sb_info {\n \t * of the mount options.\n \t */\n \tspinlock_t s_lock;\n+\tstruct mb2_cache *s_mb_cache;\n };\n \n static inline spinlock_t *""}<_**next**_>{""sha"": ""b78caf25f746220ce635a3bd946bedeaf7e3e750"", ""filename"": ""fs/ext2/super.c"", ""status"": ""modified"", ""additions"": 17, ""deletions"": 8, ""changes"": 25, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/super.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/super.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -131,7 +131,10 @@ static void ext2_put_super (struct super_block * sb)\n \n \tdquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);\n \n-\text2_xattr_put_super(sb);\n+\tif (sbi->s_mb_cache) {\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n+\t\tsbi->s_mb_cache = NULL;\n+\t}\n \tif (!(sb->s_flags & MS_RDONLY)) {\n \t\tstruct ext2_super_block *es = sbi->s_es;\n \n@@ -1104,6 +1107,14 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\text2_msg(sb, KERN_ERR, \""error: insufficient memory\"");\n \t\tgoto failed_mount3;\n \t}\n+\n+#ifdef CONFIG_EXT2_FS_XATTR\n+\tsbi->s_mb_cache = ext2_xattr_create_cache();\n+\tif (!sbi->s_mb_cache) {\n+\t\text2_msg(sb, KERN_ERR, \""Failed to create an mb_cache\"");\n+\t\tgoto failed_mount3;\n+\t}\n+#endif\n \t/*\n \t * set up enough so that it can read an inode\n \t */\n@@ -1149,6 +1160,8 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)\n \t\t\tsb->s_id);\n \tgoto failed_mount;\n failed_mount3:\n+\tif (sbi->s_mb_cache)\n+\t\text2_xattr_destroy_cache(sbi->s_mb_cache);\n \tpercpu_counter_destroy(&sbi->s_freeblocks_counter);\n \tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n \tpercpu_counter_destroy(&sbi->s_dirs_counter);\n@@ -1555,28 +1568,24 @@ MODULE_ALIAS_FS(\""ext2\"");\n \n static int __init init_ext2_fs(void)\n {\n-\tint err = init_ext2_xattr();\n-\tif (err)\n-\t\treturn err;\n+\tint err;\n+\n \terr = init_inodecache();\n \tif (err)\n-\t\tgoto out1;\n+\t\treturn err;\n         err = register_filesystem(&ext2_fs_type);\n \tif (err)\n \t\tgoto out;\n \treturn 0;\n out:\n \tdestroy_inodecache();\n-out1:\n-\texit_ext2_xattr();\n \treturn err;\n }\n \n static void __exit exit_ext2_fs(void)\n {\n \tunregister_filesystem(&ext2_fs_type);\n \tdestroy_inodecache();\n-\texit_ext2_xattr();\n }\n \n MODULE_AUTHOR(\""Remy Card and others\"");""}<_**next**_>{""sha"": ""7162b4869bc32515800d8ffc06ac3835ea241c8b"", ""filename"": ""fs/ext2/xattr.c"", ""status"": ""modified"", ""additions"": 67, ""deletions"": 76, ""changes"": 143, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.c?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -56,7 +56,7 @@\n #include <linux/buffer_head.h>\n #include <linux/init.h>\n #include <linux/slab.h>\n-#include <linux/mbcache.h>\n+#include <linux/mbcache2.h>\n #include <linux/quotaops.h>\n #include <linux/rwsem.h>\n #include <linux/security.h>\n@@ -90,14 +90,12 @@\n static int ext2_xattr_set2(struct inode *, struct buffer_head *,\n \t\t\t   struct ext2_xattr_header *);\n \n-static int ext2_xattr_cache_insert(struct buffer_head *);\n+static int ext2_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);\n static struct buffer_head *ext2_xattr_cache_find(struct inode *,\n \t\t\t\t\t\t struct ext2_xattr_header *);\n static void ext2_xattr_rehash(struct ext2_xattr_header *,\n \t\t\t      struct ext2_xattr_entry *);\n \n-static struct mb_cache *ext2_xattr_cache;\n-\n static const struct xattr_handler *ext2_xattr_handler_map[] = {\n \t[EXT2_XATTR_INDEX_USER]\t\t     = &ext2_xattr_user_handler,\n #ifdef CONFIG_EXT2_FS_POSIX_ACL\n@@ -152,6 +150,7 @@ ext2_xattr_get(struct inode *inode, int name_index, const char *name,\n \tsize_t name_len, size;\n \tchar *end;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""name=%d.%s, buffer=%p, buffer_size=%ld\"",\n \t\t  name_index, name, buffer, (long)buffer_size);\n@@ -196,7 +195,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t\t\tgoto found;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \terror = -ENODATA;\n \tgoto cleanup;\n@@ -209,7 +208,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_get\"",\n \t    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)\n \t\tgoto bad_block;\n \n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \tif (buffer) {\n \t\terror = -ERANGE;\n@@ -247,6 +246,7 @@ ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)\n \tchar *end;\n \tsize_t rest = buffer_size;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tea_idebug(inode, \""buffer=%p, buffer_size=%ld\"",\n \t\t  buffer, (long)buffer_size);\n@@ -281,7 +281,7 @@ bad_block:\text2_error(inode->i_sb, \""ext2_xattr_list\"",\n \t\t\tgoto bad_block;\n \t\tentry = next;\n \t}\n-\tif (ext2_xattr_cache_insert(bh))\n+\tif (ext2_xattr_cache_insert(ext2_mb_cache, bh))\n \t\tea_idebug(inode, \""cache insert failed\"");\n \n \t/* list the attribute names */\n@@ -483,22 +483,23 @@ bad_block:\t\text2_error(sb, \""ext2_xattr_set\"",\n \t/* Here we know that we can set the new attribute. */\n \n \tif (header) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/* assert(header == HDR(bh)); */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,\n-\t\t\t\t\tbh->b_blocknr);\n \t\tlock_buffer(bh);\n \t\tif (header->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(header->h_hash);\n+\n \t\t\tea_bdebug(bh, \""modifying in-place\"");\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect modified block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,\n+\t\t\t\t\t\t     hash, bh->b_blocknr);\n+\n \t\t\t/* keep the buffer locked while modifying it. */\n \t\t} else {\n \t\t\tint offset;\n \n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tunlock_buffer(bh);\n \t\t\tea_bdebug(bh, \""cloning\"");\n \t\t\theader = kmalloc(bh->b_size, GFP_KERNEL);\n@@ -626,6 +627,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \tstruct super_block *sb = inode->i_sb;\n \tstruct buffer_head *new_bh = NULL;\n \tint error;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;\n \n \tif (header) {\n \t\tnew_bh = ext2_xattr_cache_find(inode, header);\n@@ -653,7 +655,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\t   don't need to change the reference count. */\n \t\t\tnew_bh = old_bh;\n \t\t\tget_bh(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t} else {\n \t\t\t/* We need to allocate a new block */\n \t\t\text2_fsblk_t goal = ext2_group_first_block_no(sb,\n@@ -674,7 +676,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t\tmemcpy(new_bh->b_data, header, new_bh->b_size);\n \t\t\tset_buffer_uptodate(new_bh);\n \t\t\tunlock_buffer(new_bh);\n-\t\t\text2_xattr_cache_insert(new_bh);\n+\t\t\text2_xattr_cache_insert(ext2_mb_cache, new_bh);\n \t\t\t\n \t\t\text2_xattr_update_super_block(sb);\n \t\t}\n@@ -707,19 +709,21 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \n \terror = 0;\n \tif (old_bh && old_bh != new_bh) {\n-\t\tstruct mb_cache_entry *ce;\n-\n \t\t/*\n \t\t * If there was an old block and we are no longer using it,\n \t\t * release the old block.\n \t\t */\n-\t\tce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,\n-\t\t\t\t\told_bh->b_blocknr);\n \t\tlock_buffer(old_bh);\n \t\tif (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {\n+\t\t\t__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);\n+\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext2_xattr_set2() to reliably detect freed block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(ext2_mb_cache,\n+\t\t\t\t\t\t     hash, old_bh->b_blocknr);\n \t\t\t/* Free the old block. */\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_free(ce);\n \t\t\tea_bdebug(old_bh, \""freeing\"");\n \t\t\text2_free_blocks(inode, old_bh->b_blocknr, 1);\n \t\t\tmark_inode_dirty(inode);\n@@ -730,8 +734,6 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,\n \t\t} else {\n \t\t\t/* Decrement the refcount only. */\n \t\t\tle32_add_cpu(&HDR(old_bh)->h_refcount, -1);\n-\t\t\tif (ce)\n-\t\t\t\tmb_cache_entry_release(ce);\n \t\t\tdquot_free_block_nodirty(inode, 1);\n \t\t\tmark_inode_dirty(inode);\n \t\t\tmark_buffer_dirty(old_bh);\n@@ -757,7 +759,6 @@ void\n ext2_xattr_delete_inode(struct inode *inode)\n {\n \tstruct buffer_head *bh = NULL;\n-\tstruct mb_cache_entry *ce;\n \n \tdown_write(&EXT2_I(inode)->xattr_sem);\n \tif (!EXT2_I(inode)->i_file_acl)\n@@ -777,19 +778,22 @@ ext2_xattr_delete_inode(struct inode *inode)\n \t\t\tEXT2_I(inode)->i_file_acl);\n \t\tgoto cleanup;\n \t}\n-\tce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);\n \tlock_buffer(bh);\n \tif (HDR(bh)->h_refcount == cpu_to_le32(1)) {\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_free(ce);\n+\t\t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n+\n+\t\t/*\n+\t\t * This must happen under buffer lock for ext2_xattr_set2() to\n+\t\t * reliably detect freed block\n+\t\t */\n+\t\tmb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,\n+\t\t\t\t\t     hash, bh->b_blocknr);\n \t\text2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);\n \t\tget_bh(bh);\n \t\tbforget(bh);\n \t\tunlock_buffer(bh);\n \t} else {\n \t\tle32_add_cpu(&HDR(bh)->h_refcount, -1);\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_release(ce);\n \t\tea_bdebug(bh, \""refcount now=%d\"",\n \t\t\tle32_to_cpu(HDR(bh)->h_refcount));\n \t\tunlock_buffer(bh);\n@@ -805,18 +809,6 @@ ext2_xattr_delete_inode(struct inode *inode)\n \tup_write(&EXT2_I(inode)->xattr_sem);\n }\n \n-/*\n- * ext2_xattr_put_super()\n- *\n- * This is called when a file system is unmounted.\n- */\n-void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-\tmb_cache_shrink(sb->s_bdev);\n-}\n-\n-\n /*\n  * ext2_xattr_cache_insert()\n  *\n@@ -826,28 +818,20 @@ ext2_xattr_put_super(struct super_block *sb)\n  * Returns 0, or a negative error number on failure.\n  */\n static int\n-ext2_xattr_cache_insert(struct buffer_head *bh)\n+ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)\n {\n \t__u32 hash = le32_to_cpu(HDR(bh)->h_hash);\n-\tstruct mb_cache_entry *ce;\n \tint error;\n \n-\tce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);\n-\tif (!ce)\n-\t\treturn -ENOMEM;\n-\terror = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);\n+\terror = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);\n \tif (error) {\n-\t\tmb_cache_entry_free(ce);\n \t\tif (error == -EBUSY) {\n \t\t\tea_bdebug(bh, \""already in cache (%d cache entries)\"",\n \t\t\t\tatomic_read(&ext2_xattr_cache->c_entry_count));\n \t\t\terror = 0;\n \t\t}\n-\t} else {\n-\t\tea_bdebug(bh, \""inserting [%x] (%d cache entries)\"", (int)hash,\n-\t\t\t  atomic_read(&ext2_xattr_cache->c_entry_count));\n-\t\tmb_cache_entry_release(ce);\n-\t}\n+\t} else\n+\t\tea_bdebug(bh, \""inserting [%x]\"", (int)hash);\n \treturn error;\n }\n \n@@ -903,31 +887,39 @@ static struct buffer_head *\n ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n {\n \t__u32 hash = le32_to_cpu(header->h_hash);\n-\tstruct mb_cache_entry *ce;\n+\tstruct mb2_cache_entry *ce;\n+\tstruct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;\n \n \tif (!header->h_hash)\n \t\treturn NULL;  /* never share */\n \tea_idebug(inode, \""looking for cached blocks [%x]\"", (int)hash);\n again:\n-\tce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,\n-\t\t\t\t       hash);\n+\tce = mb2_cache_entry_find_first(ext2_mb_cache, hash);\n \twhile (ce) {\n \t\tstruct buffer_head *bh;\n \n-\t\tif (IS_ERR(ce)) {\n-\t\t\tif (PTR_ERR(ce) == -EAGAIN)\n-\t\t\t\tgoto again;\n-\t\t\tbreak;\n-\t\t}\n-\n \t\tbh = sb_bread(inode->i_sb, ce->e_block);\n \t\tif (!bh) {\n \t\t\text2_error(inode->i_sb, \""ext2_xattr_cache_find\"",\n \t\t\t\t\""inode %ld: block %ld read error\"",\n \t\t\t\tinode->i_ino, (unsigned long) ce->e_block);\n \t\t} else {\n \t\t\tlock_buffer(bh);\n-\t\t\tif (le32_to_cpu(HDR(bh)->h_refcount) >\n+\t\t\t/*\n+\t\t\t * We have to be careful about races with freeing or\n+\t\t\t * rehashing of xattr block. Once we hold buffer lock\n+\t\t\t * xattr block's state is stable so we can check\n+\t\t\t * whether the block got freed / rehashed or not.\n+\t\t\t * Since we unhash mbcache entry under buffer lock when\n+\t\t\t * freeing / rehashing xattr block, checking whether\n+\t\t\t * entry is still hashed is reliable.\n+\t\t\t */\n+\t\t\tif (hlist_bl_unhashed(&ce->e_hash_list)) {\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n+\t\t\t\tunlock_buffer(bh);\n+\t\t\t\tbrelse(bh);\n+\t\t\t\tgoto again;\n+\t\t\t} else if (le32_to_cpu(HDR(bh)->h_refcount) >\n \t\t\t\t   EXT2_XATTR_REFCOUNT_MAX) {\n \t\t\t\tea_idebug(inode, \""block %ld refcount %d>%d\"",\n \t\t\t\t\t  (unsigned long) ce->e_block,\n@@ -936,13 +928,14 @@ ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)\n \t\t\t} else if (!ext2_xattr_cmp(header, HDR(bh))) {\n \t\t\t\tea_bdebug(bh, \""b_count=%d\"",\n \t\t\t\t\t  atomic_read(&(bh->b_count)));\n-\t\t\t\tmb_cache_entry_release(ce);\n+\t\t\t\tmb2_cache_entry_touch(ext2_mb_cache, ce);\n+\t\t\t\tmb2_cache_entry_put(ext2_mb_cache, ce);\n \t\t\t\treturn bh;\n \t\t\t}\n \t\t\tunlock_buffer(bh);\n \t\t\tbrelse(bh);\n \t\t}\n-\t\tce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);\n+\t\tce = mb2_cache_entry_find_next(ext2_mb_cache, ce);\n \t}\n \treturn NULL;\n }\n@@ -1015,17 +1008,15 @@ static void ext2_xattr_rehash(struct ext2_xattr_header *header,\n \n #undef BLOCK_HASH_SHIFT\n \n-int __init\n-init_ext2_xattr(void)\n+#define HASH_BUCKET_BITS 10\n+\n+struct mb2_cache *ext2_xattr_create_cache(void)\n {\n-\text2_xattr_cache = mb_cache_create(\""ext2_xattr\"", 6);\n-\tif (!ext2_xattr_cache)\n-\t\treturn -ENOMEM;\n-\treturn 0;\n+\treturn mb2_cache_create(HASH_BUCKET_BITS);\n }\n \n-void\n-exit_ext2_xattr(void)\n+void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n-\tmb_cache_destroy(ext2_xattr_cache);\n+\tif (cache)\n+\t\tmb2_cache_destroy(cache);\n }""}<_**next**_>{""sha"": ""6ea38aa9563a00649bf25544eed131bbe8b1d88d"", ""filename"": ""fs/ext2/xattr.h"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 16, ""changes"": 21, ""blob_url"": ""https://github.com/torvalds/linux/blob/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/be0726d33cb8f411945884664924bed3cb8c70ee/fs/ext2/xattr.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext2/xattr.h?ref=be0726d33cb8f411945884664924bed3cb8c70ee"", ""patch"": ""@@ -53,6 +53,8 @@ struct ext2_xattr_entry {\n #define EXT2_XATTR_SIZE(size) \\\n \t(((size) + EXT2_XATTR_ROUND) & ~EXT2_XATTR_ROUND)\n \n+struct mb2_cache;\n+\n # ifdef CONFIG_EXT2_FS_XATTR\n \n extern const struct xattr_handler ext2_xattr_user_handler;\n@@ -65,10 +67,9 @@ extern int ext2_xattr_get(struct inode *, int, const char *, void *, size_t);\n extern int ext2_xattr_set(struct inode *, int, const char *, const void *, size_t, int);\n \n extern void ext2_xattr_delete_inode(struct inode *);\n-extern void ext2_xattr_put_super(struct super_block *);\n \n-extern int init_ext2_xattr(void);\n-extern void exit_ext2_xattr(void);\n+extern struct mb2_cache *ext2_xattr_create_cache(void);\n+extern void ext2_xattr_destroy_cache(struct mb2_cache *cache);\n \n extern const struct xattr_handler *ext2_xattr_handlers[];\n \n@@ -93,19 +94,7 @@ ext2_xattr_delete_inode(struct inode *inode)\n {\n }\n \n-static inline void\n-ext2_xattr_put_super(struct super_block *sb)\n-{\n-}\n-\n-static inline int\n-init_ext2_xattr(void)\n-{\n-\treturn 0;\n-}\n-\n-static inline void\n-exit_ext2_xattr(void)\n+static inline void ext2_xattr_destroy_cache(struct mb2_cache *cache)\n {\n }\n ""}","init_ext2_xattr(void)
#define HASH_BUCKET_BITS 10

struct mb2_cache *ext2_xattr_create_cache(void)
 {
	return mb2_cache_create(HASH_BUCKET_BITS);
 }
","init_ext2_xattr(void)
 {
	ext2_xattr_cache = mb_cache_create(""ext2_xattr"", 6);
	if (!ext2_xattr_cache)
		return -ENOMEM;
	return 0;
 }
",C,"#define HASH_BUCKET_BITS 10

struct mb2_cache *ext2_xattr_create_cache(void)
	return mb2_cache_create(HASH_BUCKET_BITS);
","	ext2_xattr_cache = mb_cache_create(""ext2_xattr"", 6);
	if (!ext2_xattr_cache)
		return -ENOMEM;
	return 0;
",,"@@ -56,7 +56,7 @@
 #include <linux/buffer_head.h>
 #include <linux/init.h>
 #include <linux/slab.h>
-#include <linux/mbcache.h>
+#include <linux/mbcache2.h>
 #include <linux/quotaops.h>
 #include <linux/rwsem.h>
 #include <linux/security.h>
@@ -90,14 +90,12 @@
 static int ext2_xattr_set2(struct inode *, struct buffer_head *,
 			   struct ext2_xattr_header *);
 
-static int ext2_xattr_cache_insert(struct buffer_head *);
+static int ext2_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);
 static struct buffer_head *ext2_xattr_cache_find(struct inode *,
 						 struct ext2_xattr_header *);
 static void ext2_xattr_rehash(struct ext2_xattr_header *,
 			      struct ext2_xattr_entry *);
 
-static struct mb_cache *ext2_xattr_cache;
-
 static const struct xattr_handler *ext2_xattr_handler_map[] = {
 	[EXT2_XATTR_INDEX_USER]		     = &ext2_xattr_user_handler,
 #ifdef CONFIG_EXT2_FS_POSIX_ACL
@@ -152,6 +150,7 @@ ext2_xattr_get(struct inode *inode, int name_index, const char *name,
 	size_t name_len, size;
 	char *end;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	ea_idebug(inode, ""name=%d.%s, buffer=%p, buffer_size=%ld"",
 		  name_index, name, buffer, (long)buffer_size);
@@ -196,7 +195,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_get"",
 			goto found;
 		entry = next;
 	}
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 	error = -ENODATA;
 	goto cleanup;
@@ -209,7 +208,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_get"",
 	    le16_to_cpu(entry->e_value_offs) + size > inode->i_sb->s_blocksize)
 		goto bad_block;
 
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 	if (buffer) {
 		error = -ERANGE;
@@ -247,6 +246,7 @@ ext2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)
 	char *end;
 	size_t rest = buffer_size;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	ea_idebug(inode, ""buffer=%p, buffer_size=%ld"",
 		  buffer, (long)buffer_size);
@@ -281,7 +281,7 @@ bad_block:	ext2_error(inode->i_sb, ""ext2_xattr_list"",
 			goto bad_block;
 		entry = next;
 	}
-	if (ext2_xattr_cache_insert(bh))
+	if (ext2_xattr_cache_insert(ext2_mb_cache, bh))
 		ea_idebug(inode, ""cache insert failed"");
 
 	/* list the attribute names */
@@ -483,22 +483,23 @@ bad_block:		ext2_error(sb, ""ext2_xattr_set"",
 	/* Here we know that we can set the new attribute. */
 
 	if (header) {
-		struct mb_cache_entry *ce;
-
 		/* assert(header == HDR(bh)); */
-		ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev,
-					bh->b_blocknr);
 		lock_buffer(bh);
 		if (header->h_refcount == cpu_to_le32(1)) {
+			__u32 hash = le32_to_cpu(header->h_hash);
+
 			ea_bdebug(bh, ""modifying in-place"");
-			if (ce)
-				mb_cache_entry_free(ce);
+			/*
+			 * This must happen under buffer lock for
+			 * ext2_xattr_set2() to reliably detect modified block
+			 */
+			mb2_cache_entry_delete_block(EXT2_SB(sb)->s_mb_cache,
+						     hash, bh->b_blocknr);
+
 			/* keep the buffer locked while modifying it. */
 		} else {
 			int offset;
 
-			if (ce)
-				mb_cache_entry_release(ce);
 			unlock_buffer(bh);
 			ea_bdebug(bh, ""cloning"");
 			header = kmalloc(bh->b_size, GFP_KERNEL);
@@ -626,6 +627,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *new_bh = NULL;
 	int error;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(sb)->s_mb_cache;
 
 	if (header) {
 		new_bh = ext2_xattr_cache_find(inode, header);
@@ -653,7 +655,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 			   don't need to change the reference count. */
 			new_bh = old_bh;
 			get_bh(new_bh);
-			ext2_xattr_cache_insert(new_bh);
+			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
 		} else {
 			/* We need to allocate a new block */
 			ext2_fsblk_t goal = ext2_group_first_block_no(sb,
@@ -674,7 +676,7 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 			memcpy(new_bh->b_data, header, new_bh->b_size);
 			set_buffer_uptodate(new_bh);
 			unlock_buffer(new_bh);
-			ext2_xattr_cache_insert(new_bh);
+			ext2_xattr_cache_insert(ext2_mb_cache, new_bh);
 			
 			ext2_xattr_update_super_block(sb);
 		}
@@ -707,19 +709,21 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 
 	error = 0;
 	if (old_bh && old_bh != new_bh) {
-		struct mb_cache_entry *ce;
-
 		/*
 		 * If there was an old block and we are no longer using it,
 		 * release the old block.
 		 */
-		ce = mb_cache_entry_get(ext2_xattr_cache, old_bh->b_bdev,
-					old_bh->b_blocknr);
 		lock_buffer(old_bh);
 		if (HDR(old_bh)->h_refcount == cpu_to_le32(1)) {
+			__u32 hash = le32_to_cpu(HDR(old_bh)->h_hash);
+
+			/*
+			 * This must happen under buffer lock for
+			 * ext2_xattr_set2() to reliably detect freed block
+			 */
+			mb2_cache_entry_delete_block(ext2_mb_cache,
+						     hash, old_bh->b_blocknr);
 			/* Free the old block. */
-			if (ce)
-				mb_cache_entry_free(ce);
 			ea_bdebug(old_bh, ""freeing"");
 			ext2_free_blocks(inode, old_bh->b_blocknr, 1);
 			mark_inode_dirty(inode);
@@ -730,8 +734,6 @@ ext2_xattr_set2(struct inode *inode, struct buffer_head *old_bh,
 		} else {
 			/* Decrement the refcount only. */
 			le32_add_cpu(&HDR(old_bh)->h_refcount, -1);
-			if (ce)
-				mb_cache_entry_release(ce);
 			dquot_free_block_nodirty(inode, 1);
 			mark_inode_dirty(inode);
 			mark_buffer_dirty(old_bh);
@@ -757,7 +759,6 @@ void
 ext2_xattr_delete_inode(struct inode *inode)
 {
 	struct buffer_head *bh = NULL;
-	struct mb_cache_entry *ce;
 
 	down_write(&EXT2_I(inode)->xattr_sem);
 	if (!EXT2_I(inode)->i_file_acl)
@@ -777,19 +778,22 @@ ext2_xattr_delete_inode(struct inode *inode)
 			EXT2_I(inode)->i_file_acl);
 		goto cleanup;
 	}
-	ce = mb_cache_entry_get(ext2_xattr_cache, bh->b_bdev, bh->b_blocknr);
 	lock_buffer(bh);
 	if (HDR(bh)->h_refcount == cpu_to_le32(1)) {
-		if (ce)
-			mb_cache_entry_free(ce);
+		__u32 hash = le32_to_cpu(HDR(bh)->h_hash);
+
+		/*
+		 * This must happen under buffer lock for ext2_xattr_set2() to
+		 * reliably detect freed block
+		 */
+		mb2_cache_entry_delete_block(EXT2_SB(inode->i_sb)->s_mb_cache,
+					     hash, bh->b_blocknr);
 		ext2_free_blocks(inode, EXT2_I(inode)->i_file_acl, 1);
 		get_bh(bh);
 		bforget(bh);
 		unlock_buffer(bh);
 	} else {
 		le32_add_cpu(&HDR(bh)->h_refcount, -1);
-		if (ce)
-			mb_cache_entry_release(ce);
 		ea_bdebug(bh, ""refcount now=%d"",
 			le32_to_cpu(HDR(bh)->h_refcount));
 		unlock_buffer(bh);
@@ -805,18 +809,6 @@ ext2_xattr_delete_inode(struct inode *inode)
 	up_write(&EXT2_I(inode)->xattr_sem);
 }
 
-/*
- * ext2_xattr_put_super()
- *
- * This is called when a file system is unmounted.
- */
-void
-ext2_xattr_put_super(struct super_block *sb)
-{
-	mb_cache_shrink(sb->s_bdev);
-}
-
-
 /*
  * ext2_xattr_cache_insert()
  *
@@ -826,28 +818,20 @@ ext2_xattr_put_super(struct super_block *sb)
  * Returns 0, or a negative error number on failure.
  */
 static int
-ext2_xattr_cache_insert(struct buffer_head *bh)
+ext2_xattr_cache_insert(struct mb2_cache *cache, struct buffer_head *bh)
 {
 	__u32 hash = le32_to_cpu(HDR(bh)->h_hash);
-	struct mb_cache_entry *ce;
 	int error;
 
-	ce = mb_cache_entry_alloc(ext2_xattr_cache, GFP_NOFS);
-	if (!ce)
-		return -ENOMEM;
-	error = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);
+	error = mb2_cache_entry_create(cache, GFP_NOFS, hash, bh->b_blocknr);
 	if (error) {
-		mb_cache_entry_free(ce);
 		if (error == -EBUSY) {
 			ea_bdebug(bh, ""already in cache (%d cache entries)"",
 				atomic_read(&ext2_xattr_cache->c_entry_count));
 			error = 0;
 		}
-	} else {
-		ea_bdebug(bh, ""inserting [%x] (%d cache entries)"", (int)hash,
-			  atomic_read(&ext2_xattr_cache->c_entry_count));
-		mb_cache_entry_release(ce);
-	}
+	} else
+		ea_bdebug(bh, ""inserting [%x]"", (int)hash);
 	return error;
 }
 
@@ -903,31 +887,39 @@ static struct buffer_head *
 ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)
 {
 	__u32 hash = le32_to_cpu(header->h_hash);
-	struct mb_cache_entry *ce;
+	struct mb2_cache_entry *ce;
+	struct mb2_cache *ext2_mb_cache = EXT2_SB(inode->i_sb)->s_mb_cache;
 
 	if (!header->h_hash)
 		return NULL;  /* never share */
 	ea_idebug(inode, ""looking for cached blocks [%x]"", (int)hash);
 again:
-	ce = mb_cache_entry_find_first(ext2_xattr_cache, inode->i_sb->s_bdev,
-				       hash);
+	ce = mb2_cache_entry_find_first(ext2_mb_cache, hash);
 	while (ce) {
 		struct buffer_head *bh;
 
-		if (IS_ERR(ce)) {
-			if (PTR_ERR(ce) == -EAGAIN)
-				goto again;
-			break;
-		}
-
 		bh = sb_bread(inode->i_sb, ce->e_block);
 		if (!bh) {
 			ext2_error(inode->i_sb, ""ext2_xattr_cache_find"",
 				""inode %ld: block %ld read error"",
 				inode->i_ino, (unsigned long) ce->e_block);
 		} else {
 			lock_buffer(bh);
-			if (le32_to_cpu(HDR(bh)->h_refcount) >
+			/*
+			 * We have to be careful about races with freeing or
+			 * rehashing of xattr block. Once we hold buffer lock
+			 * xattr block's state is stable so we can check
+			 * whether the block got freed / rehashed or not.
+			 * Since we unhash mbcache entry under buffer lock when
+			 * freeing / rehashing xattr block, checking whether
+			 * entry is still hashed is reliable.
+			 */
+			if (hlist_bl_unhashed(&ce->e_hash_list)) {
+				mb2_cache_entry_put(ext2_mb_cache, ce);
+				unlock_buffer(bh);
+				brelse(bh);
+				goto again;
+			} else if (le32_to_cpu(HDR(bh)->h_refcount) >
 				   EXT2_XATTR_REFCOUNT_MAX) {
 				ea_idebug(inode, ""block %ld refcount %d>%d"",
 					  (unsigned long) ce->e_block,
@@ -936,13 +928,14 @@ ext2_xattr_cache_find(struct inode *inode, struct ext2_xattr_header *header)
 			} else if (!ext2_xattr_cmp(header, HDR(bh))) {
 				ea_bdebug(bh, ""b_count=%d"",
 					  atomic_read(&(bh->b_count)));
-				mb_cache_entry_release(ce);
+				mb2_cache_entry_touch(ext2_mb_cache, ce);
+				mb2_cache_entry_put(ext2_mb_cache, ce);
 				return bh;
 			}
 			unlock_buffer(bh);
 			brelse(bh);
 		}
-		ce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);
+		ce = mb2_cache_entry_find_next(ext2_mb_cache, ce);
 	}
 	return NULL;
 }
@@ -1015,17 +1008,15 @@ static void ext2_xattr_rehash(struct ext2_xattr_header *header,
 
 #undef BLOCK_HASH_SHIFT
 
-int __init
-init_ext2_xattr(void)
+#define HASH_BUCKET_BITS 10
+
+struct mb2_cache *ext2_xattr_create_cache(void)
 {
-	ext2_xattr_cache = mb_cache_create(""ext2_xattr"", 6);
-	if (!ext2_xattr_cache)
-		return -ENOMEM;
-	return 0;
+	return mb2_cache_create(HASH_BUCKET_BITS);
 }
 
-void
-exit_ext2_xattr(void)
+void ext2_xattr_destroy_cache(struct mb2_cache *cache)
 {
-	mb_cache_destroy(ext2_xattr_cache);
+	if (cache)
+		mb2_cache_destroy(cache);
 }",linux,be0726d33cb8f411945884664924bed3cb8c70ee,82939d7999dfc1f1998c4b1c12e2f19edbdff272,1,"init_ext2_xattr(void)
//fix_flaw_line_below:
//#define HASH_BUCKET_BITS 10
//fix_flaw_line_below:
//
//fix_flaw_line_below:
//struct mb2_cache *ext2_xattr_create_cache(void)
 {
//flaw_line_below:
	ext2_xattr_cache = mb_cache_create(""ext2_xattr"", 6);
//flaw_line_below:
	if (!ext2_xattr_cache)
//flaw_line_below:
		return -ENOMEM;
//flaw_line_below:
	return 0;
//fix_flaw_line_below:
//	return mb2_cache_create(HASH_BUCKET_BITS);
 }
"
5422,183158,,Local,Not required,Partial,CVE-2015-8952,https://www.cvedetails.com/cve/CVE-2015-8952/,CWE-19,Low,,,,2016-10-16,2.1,"The mbcache feature in the ext2 and ext4 filesystem implementations in the Linux kernel before 4.6 mishandles xattr block caching, which allows local users to cause a denial of service (soft lockup) via filesystem operations in environments that use many attributes, as demonstrated by Ceph and Samba.",2018-03-15,DoS ,5,https://github.com/torvalds/linux/commit/82939d7999dfc1f1998c4b1c12e2f19edbdff272,82939d7999dfc1f1998c4b1c12e2f19edbdff272,"ext4: convert to mbcache2

The conversion is generally straightforward. The only tricky part is
that xattr block corresponding to found mbcache entry can get freed
before we get buffer lock for that block. So we have to check whether
the entry is still valid after getting buffer lock.

Signed-off-by: Jan Kara <jack@suse.cz>
Signed-off-by: Theodore Ts'o <tytso@mit.edu>",1,fs/ext4/super.c,"{""sha"": ""9ac9e62569ef8fdf981021b58d37ab99d0150882"", ""filename"": ""fs/ext4/ext4.h"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 1, ""changes"": 2, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/ext4.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/ext4.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/ext4.h?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -1468,7 +1468,7 @@ struct ext4_sb_info {\n \tstruct list_head s_es_list;\t/* List of inodes with reclaimable extents */\n \tlong s_es_nr_inode;\n \tstruct ext4_es_stats s_es_stats;\n-\tstruct mb_cache *s_mb_cache;\n+\tstruct mb2_cache *s_mb_cache;\n \tspinlock_t s_es_lock ____cacheline_aligned_in_smp;\n \n \t/* Ratelimit ext4 messages. */""}<_**next**_>{""sha"": ""ecc37e1034358d769ab29971e9d2301fb9e2b3bc"", ""filename"": ""fs/ext4/super.c"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 2, ""changes"": 7, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/super.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/super.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/super.c?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -844,7 +844,6 @@ static void ext4_put_super(struct super_block *sb)\n \text4_release_system_zone(sb);\n \text4_mb_release(sb);\n \text4_ext_release(sb);\n-\text4_xattr_put_super(sb);\n \n \tif (!(sb->s_flags & MS_RDONLY)) {\n \t\text4_clear_feature_journal_needs_recovery(sb);\n@@ -3797,7 +3796,7 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n \n no_journal:\n \tif (ext4_mballoc_ready) {\n-\t\tsbi->s_mb_cache = ext4_xattr_create_cache(sb->s_id);\n+\t\tsbi->s_mb_cache = ext4_xattr_create_cache();\n \t\tif (!sbi->s_mb_cache) {\n \t\t\text4_msg(sb, KERN_ERR, \""Failed to create an mb_cache\"");\n \t\t\tgoto failed_mount_wq;\n@@ -4027,6 +4026,10 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n \tif (EXT4_SB(sb)->rsv_conversion_wq)\n \t\tdestroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);\n failed_mount_wq:\n+\tif (sbi->s_mb_cache) {\n+\t\text4_xattr_destroy_cache(sbi->s_mb_cache);\n+\t\tsbi->s_mb_cache = NULL;\n+\t}\n \tif (sbi->s_journal) {\n \t\tjbd2_journal_destroy(sbi->s_journal);\n \t\tsbi->s_journal = NULL;""}<_**next**_>{""sha"": ""fe9f8d6ab6c91b60689abadefd5435c31893fcae"", ""filename"": ""fs/ext4/xattr.c"", ""status"": ""modified"", ""additions"": 67, ""deletions"": 69, ""changes"": 136, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/xattr.c?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -53,7 +53,7 @@\n #include <linux/init.h>\n #include <linux/fs.h>\n #include <linux/slab.h>\n-#include <linux/mbcache.h>\n+#include <linux/mbcache2.h>\n #include <linux/quotaops.h>\n #include \""ext4_jbd2.h\""\n #include \""ext4.h\""\n@@ -78,10 +78,10 @@\n # define ea_bdebug(bh, fmt, ...)\tno_printk(fmt, ##__VA_ARGS__)\n #endif\n \n-static void ext4_xattr_cache_insert(struct mb_cache *, struct buffer_head *);\n+static void ext4_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);\n static struct buffer_head *ext4_xattr_cache_find(struct inode *,\n \t\t\t\t\t\t struct ext4_xattr_header *,\n-\t\t\t\t\t\t struct mb_cache_entry **);\n+\t\t\t\t\t\t struct mb2_cache_entry **);\n static void ext4_xattr_rehash(struct ext4_xattr_header *,\n \t\t\t      struct ext4_xattr_entry *);\n static int ext4_xattr_list(struct dentry *dentry, char *buffer,\n@@ -276,7 +276,7 @@ ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,\n \tstruct ext4_xattr_entry *entry;\n \tsize_t size;\n \tint error;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tea_idebug(inode, \""name=%d.%s, buffer=%p, buffer_size=%ld\"",\n \t\t  name_index, name, buffer, (long)buffer_size);\n@@ -428,7 +428,7 @@ ext4_xattr_block_list(struct dentry *dentry, char *buffer, size_t buffer_size)\n \tstruct inode *inode = d_inode(dentry);\n \tstruct buffer_head *bh = NULL;\n \tint error;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tea_idebug(inode, \""buffer=%p, buffer_size=%ld\"",\n \t\t  buffer, (long)buffer_size);\n@@ -545,30 +545,31 @@ static void\n ext4_xattr_release_block(handle_t *handle, struct inode *inode,\n \t\t\t struct buffer_head *bh)\n {\n-\tstruct mb_cache_entry *ce = NULL;\n \tint error = 0;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n-\tce = mb_cache_entry_get(ext4_mb_cache, bh->b_bdev, bh->b_blocknr);\n \tBUFFER_TRACE(bh, \""get_write_access\"");\n \terror = ext4_journal_get_write_access(handle, bh);\n \tif (error)\n \t\tgoto out;\n \n \tlock_buffer(bh);\n \tif (BHDR(bh)->h_refcount == cpu_to_le32(1)) {\n+\t\t__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);\n+\n \t\tea_bdebug(bh, \""refcount now=0; freeing\"");\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_free(ce);\n+\t\t/*\n+\t\t * This must happen under buffer lock for\n+\t\t * ext4_xattr_block_set() to reliably detect freed block\n+\t\t */\n+\t\tmb2_cache_entry_delete_block(EXT4_GET_MB_CACHE(inode), hash,\n+\t\t\t\t\t     bh->b_blocknr);\n \t\tget_bh(bh);\n \t\tunlock_buffer(bh);\n \t\text4_free_blocks(handle, inode, bh, 0, 1,\n \t\t\t\t EXT4_FREE_BLOCKS_METADATA |\n \t\t\t\t EXT4_FREE_BLOCKS_FORGET);\n \t} else {\n \t\tle32_add_cpu(&BHDR(bh)->h_refcount, -1);\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_release(ce);\n \t\t/*\n \t\t * Beware of this ugliness: Releasing of xattr block references\n \t\t * from different inodes can race and so we have to protect\n@@ -781,28 +782,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \tstruct super_block *sb = inode->i_sb;\n \tstruct buffer_head *new_bh = NULL;\n \tstruct ext4_xattr_search *s = &bs->s;\n-\tstruct mb_cache_entry *ce = NULL;\n+\tstruct mb2_cache_entry *ce = NULL;\n \tint error = 0;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n #define header(x) ((struct ext4_xattr_header *)(x))\n \n \tif (i->value && i->value_len > sb->s_blocksize)\n \t\treturn -ENOSPC;\n \tif (s->base) {\n-\t\tce = mb_cache_entry_get(ext4_mb_cache, bs->bh->b_bdev,\n-\t\t\t\t\tbs->bh->b_blocknr);\n \t\tBUFFER_TRACE(bs->bh, \""get_write_access\"");\n \t\terror = ext4_journal_get_write_access(handle, bs->bh);\n \t\tif (error)\n \t\t\tgoto cleanup;\n \t\tlock_buffer(bs->bh);\n \n \t\tif (header(s->base)->h_refcount == cpu_to_le32(1)) {\n-\t\t\tif (ce) {\n-\t\t\t\tmb_cache_entry_free(ce);\n-\t\t\t\tce = NULL;\n-\t\t\t}\n+\t\t\t__u32 hash = le32_to_cpu(BHDR(bs->bh)->h_hash);\n+\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext4_xattr_block_set() to reliably detect modified\n+\t\t\t * block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(ext4_mb_cache, hash,\n+\t\t\t\t\t\t     bs->bh->b_blocknr);\n \t\t\tea_bdebug(bs->bh, \""modifying in-place\"");\n \t\t\terror = ext4_xattr_set_entry(i, s);\n \t\t\tif (!error) {\n@@ -826,10 +830,6 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\tint offset = (char *)s->here - bs->bh->b_data;\n \n \t\t\tunlock_buffer(bs->bh);\n-\t\t\tif (ce) {\n-\t\t\t\tmb_cache_entry_release(ce);\n-\t\t\t\tce = NULL;\n-\t\t\t}\n \t\t\tea_bdebug(bs->bh, \""cloning\"");\n \t\t\ts->base = kmalloc(bs->bh->b_size, GFP_NOFS);\n \t\t\terror = -ENOMEM;\n@@ -884,6 +884,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\t\tif (error)\n \t\t\t\t\tgoto cleanup_dquot;\n \t\t\t\tlock_buffer(new_bh);\n+\t\t\t\t/*\n+\t\t\t\t * We have to be careful about races with\n+\t\t\t\t * freeing or rehashing of xattr block. Once we\n+\t\t\t\t * hold buffer lock xattr block's state is\n+\t\t\t\t * stable so we can check whether the block got\n+\t\t\t\t * freed / rehashed or not.  Since we unhash\n+\t\t\t\t * mbcache entry under buffer lock when freeing\n+\t\t\t\t * / rehashing xattr block, checking whether\n+\t\t\t\t * entry is still hashed is reliable.\n+\t\t\t\t */\n+\t\t\t\tif (hlist_bl_unhashed(&ce->e_hash_list)) {\n+\t\t\t\t\t/*\n+\t\t\t\t\t * Undo everything and check mbcache\n+\t\t\t\t\t * again.\n+\t\t\t\t\t */\n+\t\t\t\t\tunlock_buffer(new_bh);\n+\t\t\t\t\tdquot_free_block(inode,\n+\t\t\t\t\t\t\t EXT4_C2B(EXT4_SB(sb),\n+\t\t\t\t\t\t\t\t  1));\n+\t\t\t\t\tbrelse(new_bh);\n+\t\t\t\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n+\t\t\t\t\tce = NULL;\n+\t\t\t\t\tnew_bh = NULL;\n+\t\t\t\t\tgoto inserted;\n+\t\t\t\t}\n \t\t\t\tle32_add_cpu(&BHDR(new_bh)->h_refcount, 1);\n \t\t\t\tea_bdebug(new_bh, \""reusing; refcount now=%d\"",\n \t\t\t\t\tle32_to_cpu(BHDR(new_bh)->h_refcount));\n@@ -894,7 +919,8 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\t\tif (error)\n \t\t\t\t\tgoto cleanup_dquot;\n \t\t\t}\n-\t\t\tmb_cache_entry_release(ce);\n+\t\t\tmb2_cache_entry_touch(ext4_mb_cache, ce);\n+\t\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n \t\t\tce = NULL;\n \t\t} else if (bs->bh && s->base == bs->bh->b_data) {\n \t\t\t/* We were modifying this block in-place. */\n@@ -959,7 +985,7 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \n cleanup:\n \tif (ce)\n-\t\tmb_cache_entry_release(ce);\n+\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n \tbrelse(new_bh);\n \tif (!(bs->bh && s->base == bs->bh->b_data))\n \t\tkfree(s->base);\n@@ -1511,17 +1537,6 @@ ext4_xattr_delete_inode(handle_t *handle, struct inode *inode)\n \tbrelse(bh);\n }\n \n-/*\n- * ext4_xattr_put_super()\n- *\n- * This is called when a file system is unmounted.\n- */\n-void\n-ext4_xattr_put_super(struct super_block *sb)\n-{\n-\tmb_cache_shrink(sb->s_bdev);\n-}\n-\n /*\n  * ext4_xattr_cache_insert()\n  *\n@@ -1531,28 +1546,18 @@ ext4_xattr_put_super(struct super_block *sb)\n  * Returns 0, or a negative error number on failure.\n  */\n static void\n-ext4_xattr_cache_insert(struct mb_cache *ext4_mb_cache, struct buffer_head *bh)\n+ext4_xattr_cache_insert(struct mb2_cache *ext4_mb_cache, struct buffer_head *bh)\n {\n \t__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);\n-\tstruct mb_cache_entry *ce;\n \tint error;\n \n-\tce = mb_cache_entry_alloc(ext4_mb_cache, GFP_NOFS);\n-\tif (!ce) {\n-\t\tea_bdebug(bh, \""out of memory\"");\n-\t\treturn;\n-\t}\n-\terror = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);\n+\terror = mb2_cache_entry_create(ext4_mb_cache, GFP_NOFS, hash,\n+\t\t\t\t       bh->b_blocknr);\n \tif (error) {\n-\t\tmb_cache_entry_free(ce);\n-\t\tif (error == -EBUSY) {\n+\t\tif (error == -EBUSY)\n \t\t\tea_bdebug(bh, \""already in cache\"");\n-\t\t\terror = 0;\n-\t\t}\n-\t} else {\n+\t} else\n \t\tea_bdebug(bh, \""inserting [%x]\"", (int)hash);\n-\t\tmb_cache_entry_release(ce);\n-\t}\n }\n \n /*\n@@ -1605,26 +1610,19 @@ ext4_xattr_cmp(struct ext4_xattr_header *header1,\n  */\n static struct buffer_head *\n ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,\n-\t\t      struct mb_cache_entry **pce)\n+\t\t      struct mb2_cache_entry **pce)\n {\n \t__u32 hash = le32_to_cpu(header->h_hash);\n-\tstruct mb_cache_entry *ce;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache_entry *ce;\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tif (!header->h_hash)\n \t\treturn NULL;  /* never share */\n \tea_idebug(inode, \""looking for cached blocks [%x]\"", (int)hash);\n-again:\n-\tce = mb_cache_entry_find_first(ext4_mb_cache, inode->i_sb->s_bdev,\n-\t\t\t\t       hash);\n+\tce = mb2_cache_entry_find_first(ext4_mb_cache, hash);\n \twhile (ce) {\n \t\tstruct buffer_head *bh;\n \n-\t\tif (IS_ERR(ce)) {\n-\t\t\tif (PTR_ERR(ce) == -EAGAIN)\n-\t\t\t\tgoto again;\n-\t\t\tbreak;\n-\t\t}\n \t\tbh = sb_bread(inode->i_sb, ce->e_block);\n \t\tif (!bh) {\n \t\t\tEXT4_ERROR_INODE(inode, \""block %lu read error\"",\n@@ -1640,7 +1638,7 @@ ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,\n \t\t\treturn bh;\n \t\t}\n \t\tbrelse(bh);\n-\t\tce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);\n+\t\tce = mb2_cache_entry_find_next(ext4_mb_cache, ce);\n \t}\n \treturn NULL;\n }\n@@ -1715,15 +1713,15 @@ static void ext4_xattr_rehash(struct ext4_xattr_header *header,\n \n #define\tHASH_BUCKET_BITS\t10\n \n-struct mb_cache *\n-ext4_xattr_create_cache(char *name)\n+struct mb2_cache *\n+ext4_xattr_create_cache(void)\n {\n-\treturn mb_cache_create(name, HASH_BUCKET_BITS);\n+\treturn mb2_cache_create(HASH_BUCKET_BITS);\n }\n \n-void ext4_xattr_destroy_cache(struct mb_cache *cache)\n+void ext4_xattr_destroy_cache(struct mb2_cache *cache)\n {\n \tif (cache)\n-\t\tmb_cache_destroy(cache);\n+\t\tmb2_cache_destroy(cache);\n }\n ""}<_**next**_>{""sha"": ""10b0f7323ed6fcd628efee26998d0f1be7652c48"", ""filename"": ""fs/ext4/xattr.h"", ""status"": ""modified"", ""additions"": 2, ""deletions"": 3, ""changes"": 5, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/xattr.h?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -108,7 +108,6 @@ extern int ext4_xattr_set(struct inode *, int, const char *, const void *, size_\n extern int ext4_xattr_set_handle(handle_t *, struct inode *, int, const char *, const void *, size_t, int);\n \n extern void ext4_xattr_delete_inode(handle_t *, struct inode *);\n-extern void ext4_xattr_put_super(struct super_block *);\n \n extern int ext4_expand_extra_isize_ea(struct inode *inode, int new_extra_isize,\n \t\t\t    struct ext4_inode *raw_inode, handle_t *handle);\n@@ -124,8 +123,8 @@ extern int ext4_xattr_ibody_inline_set(handle_t *handle, struct inode *inode,\n \t\t\t\t       struct ext4_xattr_info *i,\n \t\t\t\t       struct ext4_xattr_ibody_find *is);\n \n-extern struct mb_cache *ext4_xattr_create_cache(char *name);\n-extern void ext4_xattr_destroy_cache(struct mb_cache *);\n+extern struct mb2_cache *ext4_xattr_create_cache(void);\n+extern void ext4_xattr_destroy_cache(struct mb2_cache *);\n \n #ifdef CONFIG_EXT4_FS_SECURITY\n extern int ext4_init_security(handle_t *handle, struct inode *inode,""}","static int ext4_fill_super(struct super_block *sb, void *data, int silent)
{
	char *orig_data = kstrdup(data, GFP_KERNEL);
	struct buffer_head *bh;
	struct ext4_super_block *es = NULL;
	struct ext4_sb_info *sbi;
	ext4_fsblk_t block;
	ext4_fsblk_t sb_block = get_sb_block(&data);
	ext4_fsblk_t logical_sb_block;
	unsigned long offset = 0;
	unsigned long journal_devnum = 0;
	unsigned long def_mount_opts;
	struct inode *root;
	const char *descr;
	int ret = -ENOMEM;
	int blocksize, clustersize;
	unsigned int db_count;
	unsigned int i;
	int needs_recovery, has_huge_files, has_bigalloc;
	__u64 blocks_count;
	int err = 0;
	unsigned int journal_ioprio = DEFAULT_JOURNAL_IOPRIO;
	ext4_group_t first_not_zeroed;

	sbi = kzalloc(sizeof(*sbi), GFP_KERNEL);
	if (!sbi)
		goto out_free_orig;

	sbi->s_blockgroup_lock =
		kzalloc(sizeof(struct blockgroup_lock), GFP_KERNEL);
	if (!sbi->s_blockgroup_lock) {
		kfree(sbi);
		goto out_free_orig;
	}
	sb->s_fs_info = sbi;
	sbi->s_sb = sb;
	sbi->s_inode_readahead_blks = EXT4_DEF_INODE_READAHEAD_BLKS;
	sbi->s_sb_block = sb_block;
	if (sb->s_bdev->bd_part)
		sbi->s_sectors_written_start =
			part_stat_read(sb->s_bdev->bd_part, sectors[1]);

	/* Cleanup superblock name */
	strreplace(sb->s_id, '/', '!');

	/* -EINVAL is default */
	ret = -EINVAL;
	blocksize = sb_min_blocksize(sb, EXT4_MIN_BLOCK_SIZE);
	if (!blocksize) {
		ext4_msg(sb, KERN_ERR, ""unable to set blocksize"");
		goto out_fail;
	}

	/*
	 * The ext4 superblock will not be buffer aligned for other than 1kB
	 * block sizes.  We need to calculate the offset from buffer start.
	 */
	if (blocksize != EXT4_MIN_BLOCK_SIZE) {
		logical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;
		offset = do_div(logical_sb_block, blocksize);
	} else {
		logical_sb_block = sb_block;
	}

	if (!(bh = sb_bread_unmovable(sb, logical_sb_block))) {
		ext4_msg(sb, KERN_ERR, ""unable to read superblock"");
		goto out_fail;
	}
	/*
	 * Note: s_es must be initialized as soon as possible because
	 *       some ext4 macro-instructions depend on its value
	 */
	es = (struct ext4_super_block *) (bh->b_data + offset);
	sbi->s_es = es;
	sb->s_magic = le16_to_cpu(es->s_magic);
	if (sb->s_magic != EXT4_SUPER_MAGIC)
		goto cantfind_ext4;
	sbi->s_kbytes_written = le64_to_cpu(es->s_kbytes_written);

	/* Warn if metadata_csum and gdt_csum are both set. */
	if (ext4_has_feature_metadata_csum(sb) &&
	    ext4_has_feature_gdt_csum(sb))
		ext4_warning(sb, ""metadata_csum and uninit_bg are ""
			     ""redundant flags; please run fsck."");

	/* Check for a known checksum algorithm */
	if (!ext4_verify_csum_type(sb, es)) {
		ext4_msg(sb, KERN_ERR, ""VFS: Found ext4 filesystem with ""
			 ""unknown checksum algorithm."");
		silent = 1;
		goto cantfind_ext4;
	}

	/* Load the checksum driver */
	if (ext4_has_feature_metadata_csum(sb)) {
		sbi->s_chksum_driver = crypto_alloc_shash(""crc32c"", 0, 0);
		if (IS_ERR(sbi->s_chksum_driver)) {
			ext4_msg(sb, KERN_ERR, ""Cannot load crc32c driver."");
			ret = PTR_ERR(sbi->s_chksum_driver);
			sbi->s_chksum_driver = NULL;
			goto failed_mount;
		}
	}

	/* Check superblock checksum */
	if (!ext4_superblock_csum_verify(sb, es)) {
		ext4_msg(sb, KERN_ERR, ""VFS: Found ext4 filesystem with ""
			 ""invalid superblock checksum.  Run e2fsck?"");
		silent = 1;
		ret = -EFSBADCRC;
		goto cantfind_ext4;
	}

	/* Precompute checksum seed for all metadata */
	if (ext4_has_feature_csum_seed(sb))
		sbi->s_csum_seed = le32_to_cpu(es->s_checksum_seed);
	else if (ext4_has_metadata_csum(sb))
		sbi->s_csum_seed = ext4_chksum(sbi, ~0, es->s_uuid,
					       sizeof(es->s_uuid));

	/* Set defaults before we parse the mount options */
	def_mount_opts = le32_to_cpu(es->s_default_mount_opts);
	set_opt(sb, INIT_INODE_TABLE);
	if (def_mount_opts & EXT4_DEFM_DEBUG)
		set_opt(sb, DEBUG);
	if (def_mount_opts & EXT4_DEFM_BSDGROUPS)
		set_opt(sb, GRPID);
	if (def_mount_opts & EXT4_DEFM_UID16)
		set_opt(sb, NO_UID32);
	/* xattr user namespace & acls are now defaulted on */
	set_opt(sb, XATTR_USER);
#ifdef CONFIG_EXT4_FS_POSIX_ACL
	set_opt(sb, POSIX_ACL);
#endif
	/* don't forget to enable journal_csum when metadata_csum is enabled. */
	if (ext4_has_metadata_csum(sb))
		set_opt(sb, JOURNAL_CHECKSUM);

	if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_DATA)
		set_opt(sb, JOURNAL_DATA);
	else if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_ORDERED)
		set_opt(sb, ORDERED_DATA);
	else if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_WBACK)
		set_opt(sb, WRITEBACK_DATA);

	if (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_PANIC)
		set_opt(sb, ERRORS_PANIC);
	else if (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_CONTINUE)
		set_opt(sb, ERRORS_CONT);
	else
		set_opt(sb, ERRORS_RO);
	/* block_validity enabled by default; disable with noblock_validity */
	set_opt(sb, BLOCK_VALIDITY);
	if (def_mount_opts & EXT4_DEFM_DISCARD)
		set_opt(sb, DISCARD);

	sbi->s_resuid = make_kuid(&init_user_ns, le16_to_cpu(es->s_def_resuid));
	sbi->s_resgid = make_kgid(&init_user_ns, le16_to_cpu(es->s_def_resgid));
	sbi->s_commit_interval = JBD2_DEFAULT_MAX_COMMIT_AGE * HZ;
	sbi->s_min_batch_time = EXT4_DEF_MIN_BATCH_TIME;
	sbi->s_max_batch_time = EXT4_DEF_MAX_BATCH_TIME;

	if ((def_mount_opts & EXT4_DEFM_NOBARRIER) == 0)
		set_opt(sb, BARRIER);

	/*
	 * enable delayed allocation by default
	 * Use -o nodelalloc to turn it off
	 */
	if (!IS_EXT3_SB(sb) && !IS_EXT2_SB(sb) &&
	    ((def_mount_opts & EXT4_DEFM_NODELALLOC) == 0))
		set_opt(sb, DELALLOC);

	/*
	 * set default s_li_wait_mult for lazyinit, for the case there is
	 * no mount option specified.
	 */
	sbi->s_li_wait_mult = EXT4_DEF_LI_WAIT_MULT;

	if (!parse_options((char *) sbi->s_es->s_mount_opts, sb,
			   &journal_devnum, &journal_ioprio, 0)) {
		ext4_msg(sb, KERN_WARNING,
			 ""failed to parse options in superblock: %s"",
			 sbi->s_es->s_mount_opts);
	}
	sbi->s_def_mount_opt = sbi->s_mount_opt;
	if (!parse_options((char *) data, sb, &journal_devnum,
			   &journal_ioprio, 0))
		goto failed_mount;

	if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA) {
		printk_once(KERN_WARNING ""EXT4-fs: Warning: mounting ""
			    ""with data=journal disables delayed ""
			    ""allocation and O_DIRECT support!\n"");
		if (test_opt2(sb, EXPLICIT_DELALLOC)) {
			ext4_msg(sb, KERN_ERR, ""can't mount with ""
				 ""both data=journal and delalloc"");
			goto failed_mount;
		}
		if (test_opt(sb, DIOREAD_NOLOCK)) {
			ext4_msg(sb, KERN_ERR, ""can't mount with ""
				 ""both data=journal and dioread_nolock"");
			goto failed_mount;
		}
		if (test_opt(sb, DAX)) {
			ext4_msg(sb, KERN_ERR, ""can't mount with ""
				 ""both data=journal and dax"");
			goto failed_mount;
		}
		if (test_opt(sb, DELALLOC))
			clear_opt(sb, DELALLOC);
	} else {
		sb->s_iflags |= SB_I_CGROUPWB;
	}

	sb->s_flags = (sb->s_flags & ~MS_POSIXACL) |
		(test_opt(sb, POSIX_ACL) ? MS_POSIXACL : 0);

	if (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV &&
	    (ext4_has_compat_features(sb) ||
	     ext4_has_ro_compat_features(sb) ||
	     ext4_has_incompat_features(sb)))
		ext4_msg(sb, KERN_WARNING,
		       ""feature flags set on rev 0 fs, ""
		       ""running e2fsck is recommended"");

	if (es->s_creator_os == cpu_to_le32(EXT4_OS_HURD)) {
		set_opt2(sb, HURD_COMPAT);
		if (ext4_has_feature_64bit(sb)) {
			ext4_msg(sb, KERN_ERR,
				 ""The Hurd can't support 64-bit file systems"");
			goto failed_mount;
		}
	}

	if (IS_EXT2_SB(sb)) {
		if (ext2_feature_set_ok(sb))
			ext4_msg(sb, KERN_INFO, ""mounting ext2 file system ""
				 ""using the ext4 subsystem"");
		else {
			ext4_msg(sb, KERN_ERR, ""couldn't mount as ext2 due ""
				 ""to feature incompatibilities"");
			goto failed_mount;
		}
	}

	if (IS_EXT3_SB(sb)) {
		if (ext3_feature_set_ok(sb))
			ext4_msg(sb, KERN_INFO, ""mounting ext3 file system ""
				 ""using the ext4 subsystem"");
		else {
			ext4_msg(sb, KERN_ERR, ""couldn't mount as ext3 due ""
				 ""to feature incompatibilities"");
			goto failed_mount;
		}
	}

	/*
	 * Check feature flags regardless of the revision level, since we
	 * previously didn't change the revision level when setting the flags,
	 * so there is a chance incompat flags are set on a rev 0 filesystem.
	 */
	if (!ext4_feature_set_ok(sb, (sb->s_flags & MS_RDONLY)))
		goto failed_mount;

	blocksize = BLOCK_SIZE << le32_to_cpu(es->s_log_block_size);
	if (blocksize < EXT4_MIN_BLOCK_SIZE ||
	    blocksize > EXT4_MAX_BLOCK_SIZE) {
		ext4_msg(sb, KERN_ERR,
		       ""Unsupported filesystem blocksize %d"", blocksize);
		goto failed_mount;
	}

	if (sbi->s_mount_opt & EXT4_MOUNT_DAX) {
		if (blocksize != PAGE_SIZE) {
			ext4_msg(sb, KERN_ERR,
					""error: unsupported blocksize for dax"");
			goto failed_mount;
		}
		if (!sb->s_bdev->bd_disk->fops->direct_access) {
			ext4_msg(sb, KERN_ERR,
					""error: device does not support dax"");
			goto failed_mount;
		}
	}

	if (ext4_has_feature_encrypt(sb) && es->s_encryption_level) {
		ext4_msg(sb, KERN_ERR, ""Unsupported encryption level %d"",
			 es->s_encryption_level);
		goto failed_mount;
	}

	if (sb->s_blocksize != blocksize) {
		/* Validate the filesystem blocksize */
		if (!sb_set_blocksize(sb, blocksize)) {
			ext4_msg(sb, KERN_ERR, ""bad block size %d"",
					blocksize);
			goto failed_mount;
		}

		brelse(bh);
		logical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;
		offset = do_div(logical_sb_block, blocksize);
		bh = sb_bread_unmovable(sb, logical_sb_block);
		if (!bh) {
			ext4_msg(sb, KERN_ERR,
			       ""Can't read superblock on 2nd try"");
			goto failed_mount;
		}
		es = (struct ext4_super_block *)(bh->b_data + offset);
		sbi->s_es = es;
		if (es->s_magic != cpu_to_le16(EXT4_SUPER_MAGIC)) {
			ext4_msg(sb, KERN_ERR,
			       ""Magic mismatch, very weird!"");
			goto failed_mount;
		}
	}

	has_huge_files = ext4_has_feature_huge_file(sb);
	sbi->s_bitmap_maxbytes = ext4_max_bitmap_size(sb->s_blocksize_bits,
						      has_huge_files);
	sb->s_maxbytes = ext4_max_size(sb->s_blocksize_bits, has_huge_files);

	if (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV) {
		sbi->s_inode_size = EXT4_GOOD_OLD_INODE_SIZE;
		sbi->s_first_ino = EXT4_GOOD_OLD_FIRST_INO;
	} else {
		sbi->s_inode_size = le16_to_cpu(es->s_inode_size);
		sbi->s_first_ino = le32_to_cpu(es->s_first_ino);
		if ((sbi->s_inode_size < EXT4_GOOD_OLD_INODE_SIZE) ||
		    (!is_power_of_2(sbi->s_inode_size)) ||
		    (sbi->s_inode_size > blocksize)) {
			ext4_msg(sb, KERN_ERR,
			       ""unsupported inode size: %d"",
			       sbi->s_inode_size);
			goto failed_mount;
		}
		if (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE)
			sb->s_time_gran = 1 << (EXT4_EPOCH_BITS - 2);
	}

	sbi->s_desc_size = le16_to_cpu(es->s_desc_size);
	if (ext4_has_feature_64bit(sb)) {
		if (sbi->s_desc_size < EXT4_MIN_DESC_SIZE_64BIT ||
		    sbi->s_desc_size > EXT4_MAX_DESC_SIZE ||
		    !is_power_of_2(sbi->s_desc_size)) {
			ext4_msg(sb, KERN_ERR,
			       ""unsupported descriptor size %lu"",
			       sbi->s_desc_size);
			goto failed_mount;
		}
	} else
		sbi->s_desc_size = EXT4_MIN_DESC_SIZE;

	sbi->s_blocks_per_group = le32_to_cpu(es->s_blocks_per_group);
	sbi->s_inodes_per_group = le32_to_cpu(es->s_inodes_per_group);
	if (EXT4_INODE_SIZE(sb) == 0 || EXT4_INODES_PER_GROUP(sb) == 0)
		goto cantfind_ext4;

	sbi->s_inodes_per_block = blocksize / EXT4_INODE_SIZE(sb);
	if (sbi->s_inodes_per_block == 0)
		goto cantfind_ext4;
	sbi->s_itb_per_group = sbi->s_inodes_per_group /
					sbi->s_inodes_per_block;
	sbi->s_desc_per_block = blocksize / EXT4_DESC_SIZE(sb);
	sbi->s_sbh = bh;
	sbi->s_mount_state = le16_to_cpu(es->s_state);
	sbi->s_addr_per_block_bits = ilog2(EXT4_ADDR_PER_BLOCK(sb));
	sbi->s_desc_per_block_bits = ilog2(EXT4_DESC_PER_BLOCK(sb));

	for (i = 0; i < 4; i++)
		sbi->s_hash_seed[i] = le32_to_cpu(es->s_hash_seed[i]);
	sbi->s_def_hash_version = es->s_def_hash_version;
	if (ext4_has_feature_dir_index(sb)) {
		i = le32_to_cpu(es->s_flags);
		if (i & EXT2_FLAGS_UNSIGNED_HASH)
			sbi->s_hash_unsigned = 3;
		else if ((i & EXT2_FLAGS_SIGNED_HASH) == 0) {
#ifdef __CHAR_UNSIGNED__
			if (!(sb->s_flags & MS_RDONLY))
				es->s_flags |=
					cpu_to_le32(EXT2_FLAGS_UNSIGNED_HASH);
			sbi->s_hash_unsigned = 3;
#else
			if (!(sb->s_flags & MS_RDONLY))
				es->s_flags |=
					cpu_to_le32(EXT2_FLAGS_SIGNED_HASH);
#endif
		}
	}

	/* Handle clustersize */
	clustersize = BLOCK_SIZE << le32_to_cpu(es->s_log_cluster_size);
	has_bigalloc = ext4_has_feature_bigalloc(sb);
	if (has_bigalloc) {
		if (clustersize < blocksize) {
			ext4_msg(sb, KERN_ERR,
				 ""cluster size (%d) smaller than ""
				 ""block size (%d)"", clustersize, blocksize);
			goto failed_mount;
		}
		sbi->s_cluster_bits = le32_to_cpu(es->s_log_cluster_size) -
			le32_to_cpu(es->s_log_block_size);
		sbi->s_clusters_per_group =
			le32_to_cpu(es->s_clusters_per_group);
		if (sbi->s_clusters_per_group > blocksize * 8) {
			ext4_msg(sb, KERN_ERR,
				 ""#clusters per group too big: %lu"",
				 sbi->s_clusters_per_group);
			goto failed_mount;
		}
		if (sbi->s_blocks_per_group !=
		    (sbi->s_clusters_per_group * (clustersize / blocksize))) {
			ext4_msg(sb, KERN_ERR, ""blocks per group (%lu) and ""
				 ""clusters per group (%lu) inconsistent"",
				 sbi->s_blocks_per_group,
				 sbi->s_clusters_per_group);
			goto failed_mount;
		}
	} else {
		if (clustersize != blocksize) {
			ext4_warning(sb, ""fragment/cluster size (%d) != ""
				     ""block size (%d)"", clustersize,
				     blocksize);
			clustersize = blocksize;
		}
		if (sbi->s_blocks_per_group > blocksize * 8) {
			ext4_msg(sb, KERN_ERR,
				 ""#blocks per group too big: %lu"",
				 sbi->s_blocks_per_group);
			goto failed_mount;
		}
		sbi->s_clusters_per_group = sbi->s_blocks_per_group;
		sbi->s_cluster_bits = 0;
	}
	sbi->s_cluster_ratio = clustersize / blocksize;

	if (sbi->s_inodes_per_group > blocksize * 8) {
		ext4_msg(sb, KERN_ERR,
		       ""#inodes per group too big: %lu"",
		       sbi->s_inodes_per_group);
		goto failed_mount;
	}

	/* Do we have standard group size of clustersize * 8 blocks ? */
	if (sbi->s_blocks_per_group == clustersize << 3)
		set_opt2(sb, STD_GROUP_SIZE);

	/*
	 * Test whether we have more sectors than will fit in sector_t,
	 * and whether the max offset is addressable by the page cache.
	 */
	err = generic_check_addressable(sb->s_blocksize_bits,
					ext4_blocks_count(es));
	if (err) {
		ext4_msg(sb, KERN_ERR, ""filesystem""
			 "" too large to mount safely on this system"");
		if (sizeof(sector_t) < 8)
			ext4_msg(sb, KERN_WARNING, ""CONFIG_LBDAF not enabled"");
		goto failed_mount;
	}

	if (EXT4_BLOCKS_PER_GROUP(sb) == 0)
		goto cantfind_ext4;

	/* check blocks count against device size */
	blocks_count = sb->s_bdev->bd_inode->i_size >> sb->s_blocksize_bits;
	if (blocks_count && ext4_blocks_count(es) > blocks_count) {
		ext4_msg(sb, KERN_WARNING, ""bad geometry: block count %llu ""
		       ""exceeds size of device (%llu blocks)"",
		       ext4_blocks_count(es), blocks_count);
		goto failed_mount;
	}

	/*
	 * It makes no sense for the first data block to be beyond the end
	 * of the filesystem.
	 */
	if (le32_to_cpu(es->s_first_data_block) >= ext4_blocks_count(es)) {
		ext4_msg(sb, KERN_WARNING, ""bad geometry: first data ""
			 ""block %u is beyond end of filesystem (%llu)"",
			 le32_to_cpu(es->s_first_data_block),
			 ext4_blocks_count(es));
		goto failed_mount;
	}
	blocks_count = (ext4_blocks_count(es) -
			le32_to_cpu(es->s_first_data_block) +
			EXT4_BLOCKS_PER_GROUP(sb) - 1);
	do_div(blocks_count, EXT4_BLOCKS_PER_GROUP(sb));
	if (blocks_count > ((uint64_t)1<<32) - EXT4_DESC_PER_BLOCK(sb)) {
		ext4_msg(sb, KERN_WARNING, ""groups count too large: %u ""
		       ""(block count %llu, first data block %u, ""
		       ""blocks per group %lu)"", sbi->s_groups_count,
		       ext4_blocks_count(es),
		       le32_to_cpu(es->s_first_data_block),
		       EXT4_BLOCKS_PER_GROUP(sb));
		goto failed_mount;
	}
	sbi->s_groups_count = blocks_count;
	sbi->s_blockfile_groups = min_t(ext4_group_t, sbi->s_groups_count,
			(EXT4_MAX_BLOCK_FILE_PHYS / EXT4_BLOCKS_PER_GROUP(sb)));
	db_count = (sbi->s_groups_count + EXT4_DESC_PER_BLOCK(sb) - 1) /
		   EXT4_DESC_PER_BLOCK(sb);
	sbi->s_group_desc = ext4_kvmalloc(db_count *
					  sizeof(struct buffer_head *),
					  GFP_KERNEL);
	if (sbi->s_group_desc == NULL) {
		ext4_msg(sb, KERN_ERR, ""not enough memory"");
		ret = -ENOMEM;
		goto failed_mount;
	}

	bgl_lock_init(sbi->s_blockgroup_lock);

	for (i = 0; i < db_count; i++) {
		block = descriptor_loc(sb, logical_sb_block, i);
		sbi->s_group_desc[i] = sb_bread_unmovable(sb, block);
		if (!sbi->s_group_desc[i]) {
			ext4_msg(sb, KERN_ERR,
			       ""can't read group descriptor %d"", i);
			db_count = i;
			goto failed_mount2;
		}
	}
	if (!ext4_check_descriptors(sb, &first_not_zeroed)) {
		ext4_msg(sb, KERN_ERR, ""group descriptors corrupted!"");
		ret = -EFSCORRUPTED;
		goto failed_mount2;
	}

	sbi->s_gdb_count = db_count;
	get_random_bytes(&sbi->s_next_generation, sizeof(u32));
	spin_lock_init(&sbi->s_next_gen_lock);

	setup_timer(&sbi->s_err_report, print_daily_error_info,
		(unsigned long) sb);

	/* Register extent status tree shrinker */
	if (ext4_es_register_shrinker(sbi))
		goto failed_mount3;

	sbi->s_stripe = ext4_get_stripe_size(sbi);
	sbi->s_extent_max_zeroout_kb = 32;

	/*
	 * set up enough so that it can read an inode
	 */
	sb->s_op = &ext4_sops;
	sb->s_export_op = &ext4_export_ops;
	sb->s_xattr = ext4_xattr_handlers;
#ifdef CONFIG_QUOTA
	sb->dq_op = &ext4_quota_operations;
	if (ext4_has_feature_quota(sb))
		sb->s_qcop = &dquot_quotactl_sysfile_ops;
	else
		sb->s_qcop = &ext4_qctl_operations;
	sb->s_quota_types = QTYPE_MASK_USR | QTYPE_MASK_GRP | QTYPE_MASK_PRJ;
#endif
	memcpy(sb->s_uuid, es->s_uuid, sizeof(es->s_uuid));

	INIT_LIST_HEAD(&sbi->s_orphan); /* unlinked but open files */
	mutex_init(&sbi->s_orphan_lock);

	sb->s_root = NULL;

	needs_recovery = (es->s_last_orphan != 0 ||
			  ext4_has_feature_journal_needs_recovery(sb));

	if (ext4_has_feature_mmp(sb) && !(sb->s_flags & MS_RDONLY))
		if (ext4_multi_mount_protect(sb, le64_to_cpu(es->s_mmp_block)))
			goto failed_mount3a;

	/*
	 * The first inode we look at is the journal inode.  Don't try
	 * root first: it may be modified in the journal!
	 */
	if (!test_opt(sb, NOLOAD) && ext4_has_feature_journal(sb)) {
		if (ext4_load_journal(sb, es, journal_devnum))
			goto failed_mount3a;
	} else if (test_opt(sb, NOLOAD) && !(sb->s_flags & MS_RDONLY) &&
		   ext4_has_feature_journal_needs_recovery(sb)) {
		ext4_msg(sb, KERN_ERR, ""required journal recovery ""
		       ""suppressed and not mounted read-only"");
		goto failed_mount_wq;
	} else {
		/* Nojournal mode, all journal mount options are illegal */
		if (test_opt2(sb, EXPLICIT_JOURNAL_CHECKSUM)) {
			ext4_msg(sb, KERN_ERR, ""can't mount with ""
				 ""journal_checksum, fs mounted w/o journal"");
			goto failed_mount_wq;
		}
		if (test_opt(sb, JOURNAL_ASYNC_COMMIT)) {
			ext4_msg(sb, KERN_ERR, ""can't mount with ""
				 ""journal_async_commit, fs mounted w/o journal"");
			goto failed_mount_wq;
		}
		if (sbi->s_commit_interval != JBD2_DEFAULT_MAX_COMMIT_AGE*HZ) {
			ext4_msg(sb, KERN_ERR, ""can't mount with ""
				 ""commit=%lu, fs mounted w/o journal"",
				 sbi->s_commit_interval / HZ);
			goto failed_mount_wq;
		}
		if (EXT4_MOUNT_DATA_FLAGS &
		    (sbi->s_mount_opt ^ sbi->s_def_mount_opt)) {
			ext4_msg(sb, KERN_ERR, ""can't mount with ""
				 ""data=, fs mounted w/o journal"");
			goto failed_mount_wq;
		}
		sbi->s_def_mount_opt &= EXT4_MOUNT_JOURNAL_CHECKSUM;
		clear_opt(sb, JOURNAL_CHECKSUM);
		clear_opt(sb, DATA_FLAGS);
		sbi->s_journal = NULL;
		needs_recovery = 0;
		goto no_journal;
	}

	if (ext4_has_feature_64bit(sb) &&
	    !jbd2_journal_set_features(EXT4_SB(sb)->s_journal, 0, 0,
				       JBD2_FEATURE_INCOMPAT_64BIT)) {
		ext4_msg(sb, KERN_ERR, ""Failed to set 64-bit journal feature"");
		goto failed_mount_wq;
	}

	if (!set_journal_csum_feature_set(sb)) {
		ext4_msg(sb, KERN_ERR, ""Failed to set journal checksum ""
			 ""feature set"");
		goto failed_mount_wq;
	}

	/* We have now updated the journal if required, so we can
	 * validate the data journaling mode. */
	switch (test_opt(sb, DATA_FLAGS)) {
	case 0:
		/* No mode set, assume a default based on the journal
		 * capabilities: ORDERED_DATA if the journal can
		 * cope, else JOURNAL_DATA
		 */
		if (jbd2_journal_check_available_features
		    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE))
			set_opt(sb, ORDERED_DATA);
		else
			set_opt(sb, JOURNAL_DATA);
		break;

	case EXT4_MOUNT_ORDERED_DATA:
	case EXT4_MOUNT_WRITEBACK_DATA:
		if (!jbd2_journal_check_available_features
		    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE)) {
			ext4_msg(sb, KERN_ERR, ""Journal does not support ""
			       ""requested data journaling mode"");
			goto failed_mount_wq;
		}
	default:
		break;
	}
	set_task_ioprio(sbi->s_journal->j_task, journal_ioprio);

	sbi->s_journal->j_commit_callback = ext4_journal_commit_callback;
 
 no_journal:
 	if (ext4_mballoc_ready) {
		sbi->s_mb_cache = ext4_xattr_create_cache();
 		if (!sbi->s_mb_cache) {
 			ext4_msg(sb, KERN_ERR, ""Failed to create an mb_cache"");
 			goto failed_mount_wq;
		}
	}

	if ((DUMMY_ENCRYPTION_ENABLED(sbi) || ext4_has_feature_encrypt(sb)) &&
	    (blocksize != PAGE_CACHE_SIZE)) {
		ext4_msg(sb, KERN_ERR,
			 ""Unsupported blocksize for fs encryption"");
		goto failed_mount_wq;
	}

	if (DUMMY_ENCRYPTION_ENABLED(sbi) && !(sb->s_flags & MS_RDONLY) &&
	    !ext4_has_feature_encrypt(sb)) {
		ext4_set_feature_encrypt(sb);
		ext4_commit_super(sb, 1);
	}

	/*
	 * Get the # of file system overhead blocks from the
	 * superblock if present.
	 */
	if (es->s_overhead_clusters)
		sbi->s_overhead = le32_to_cpu(es->s_overhead_clusters);
	else {
		err = ext4_calculate_overhead(sb);
		if (err)
			goto failed_mount_wq;
	}

	/*
	 * The maximum number of concurrent works can be high and
	 * concurrency isn't really necessary.  Limit it to 1.
	 */
	EXT4_SB(sb)->rsv_conversion_wq =
		alloc_workqueue(""ext4-rsv-conversion"", WQ_MEM_RECLAIM | WQ_UNBOUND, 1);
	if (!EXT4_SB(sb)->rsv_conversion_wq) {
		printk(KERN_ERR ""EXT4-fs: failed to create workqueue\n"");
		ret = -ENOMEM;
		goto failed_mount4;
	}

	/*
	 * The jbd2_journal_load will have done any necessary log recovery,
	 * so we can safely mount the rest of the filesystem now.
	 */

	root = ext4_iget(sb, EXT4_ROOT_INO);
	if (IS_ERR(root)) {
		ext4_msg(sb, KERN_ERR, ""get root inode failed"");
		ret = PTR_ERR(root);
		root = NULL;
		goto failed_mount4;
	}
	if (!S_ISDIR(root->i_mode) || !root->i_blocks || !root->i_size) {
		ext4_msg(sb, KERN_ERR, ""corrupt root inode, run e2fsck"");
		iput(root);
		goto failed_mount4;
	}
	sb->s_root = d_make_root(root);
	if (!sb->s_root) {
		ext4_msg(sb, KERN_ERR, ""get root dentry failed"");
		ret = -ENOMEM;
		goto failed_mount4;
	}

	if (ext4_setup_super(sb, es, sb->s_flags & MS_RDONLY))
		sb->s_flags |= MS_RDONLY;

	/* determine the minimum size of new large inodes, if present */
	if (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE) {
		sbi->s_want_extra_isize = sizeof(struct ext4_inode) -
						     EXT4_GOOD_OLD_INODE_SIZE;
		if (ext4_has_feature_extra_isize(sb)) {
			if (sbi->s_want_extra_isize <
			    le16_to_cpu(es->s_want_extra_isize))
				sbi->s_want_extra_isize =
					le16_to_cpu(es->s_want_extra_isize);
			if (sbi->s_want_extra_isize <
			    le16_to_cpu(es->s_min_extra_isize))
				sbi->s_want_extra_isize =
					le16_to_cpu(es->s_min_extra_isize);
		}
	}
	/* Check if enough inode space is available */
	if (EXT4_GOOD_OLD_INODE_SIZE + sbi->s_want_extra_isize >
							sbi->s_inode_size) {
		sbi->s_want_extra_isize = sizeof(struct ext4_inode) -
						       EXT4_GOOD_OLD_INODE_SIZE;
		ext4_msg(sb, KERN_INFO, ""required extra inode space not""
			 ""available"");
	}

	ext4_set_resv_clusters(sb);

	err = ext4_setup_system_zone(sb);
	if (err) {
		ext4_msg(sb, KERN_ERR, ""failed to initialize system ""
			 ""zone (%d)"", err);
		goto failed_mount4a;
	}

	ext4_ext_init(sb);
	err = ext4_mb_init(sb);
	if (err) {
		ext4_msg(sb, KERN_ERR, ""failed to initialize mballoc (%d)"",
			 err);
		goto failed_mount5;
	}

	block = ext4_count_free_clusters(sb);
	ext4_free_blocks_count_set(sbi->s_es, 
				   EXT4_C2B(sbi, block));
	err = percpu_counter_init(&sbi->s_freeclusters_counter, block,
				  GFP_KERNEL);
	if (!err) {
		unsigned long freei = ext4_count_free_inodes(sb);
		sbi->s_es->s_free_inodes_count = cpu_to_le32(freei);
		err = percpu_counter_init(&sbi->s_freeinodes_counter, freei,
					  GFP_KERNEL);
	}
	if (!err)
		err = percpu_counter_init(&sbi->s_dirs_counter,
					  ext4_count_dirs(sb), GFP_KERNEL);
	if (!err)
		err = percpu_counter_init(&sbi->s_dirtyclusters_counter, 0,
					  GFP_KERNEL);
	if (err) {
		ext4_msg(sb, KERN_ERR, ""insufficient memory"");
		goto failed_mount6;
	}

	if (ext4_has_feature_flex_bg(sb))
		if (!ext4_fill_flex_info(sb)) {
			ext4_msg(sb, KERN_ERR,
			       ""unable to initialize ""
			       ""flex_bg meta info!"");
			goto failed_mount6;
		}

	err = ext4_register_li_request(sb, first_not_zeroed);
	if (err)
		goto failed_mount6;

	err = ext4_register_sysfs(sb);
	if (err)
		goto failed_mount7;

#ifdef CONFIG_QUOTA
	/* Enable quota usage during mount. */
	if (ext4_has_feature_quota(sb) && !(sb->s_flags & MS_RDONLY)) {
		err = ext4_enable_quotas(sb);
		if (err)
			goto failed_mount8;
	}
#endif  /* CONFIG_QUOTA */

	EXT4_SB(sb)->s_mount_state |= EXT4_ORPHAN_FS;
	ext4_orphan_cleanup(sb, es);
	EXT4_SB(sb)->s_mount_state &= ~EXT4_ORPHAN_FS;
	if (needs_recovery) {
		ext4_msg(sb, KERN_INFO, ""recovery complete"");
		ext4_mark_recovery_complete(sb, es);
	}
	if (EXT4_SB(sb)->s_journal) {
		if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA)
			descr = "" journalled data mode"";
		else if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_ORDERED_DATA)
			descr = "" ordered data mode"";
		else
			descr = "" writeback data mode"";
	} else
		descr = ""out journal"";

	if (test_opt(sb, DISCARD)) {
		struct request_queue *q = bdev_get_queue(sb->s_bdev);
		if (!blk_queue_discard(q))
			ext4_msg(sb, KERN_WARNING,
				 ""mounting with \""discard\"" option, but ""
				 ""the device does not support discard"");
	}

	if (___ratelimit(&ext4_mount_msg_ratelimit, ""EXT4-fs mount""))
		ext4_msg(sb, KERN_INFO, ""mounted filesystem with%s. ""
			 ""Opts: %s%s%s"", descr, sbi->s_es->s_mount_opts,
			 *sbi->s_es->s_mount_opts ? ""; "" : """", orig_data);

	if (es->s_error_count)
		mod_timer(&sbi->s_err_report, jiffies + 300*HZ); /* 5 minutes */

	/* Enable message ratelimiting. Default is 10 messages per 5 secs. */
	ratelimit_state_init(&sbi->s_err_ratelimit_state, 5 * HZ, 10);
	ratelimit_state_init(&sbi->s_warning_ratelimit_state, 5 * HZ, 10);
	ratelimit_state_init(&sbi->s_msg_ratelimit_state, 5 * HZ, 10);

	kfree(orig_data);
	return 0;

cantfind_ext4:
	if (!silent)
		ext4_msg(sb, KERN_ERR, ""VFS: Can't find ext4 filesystem"");
	goto failed_mount;

#ifdef CONFIG_QUOTA
failed_mount8:
	ext4_unregister_sysfs(sb);
#endif
failed_mount7:
	ext4_unregister_li_request(sb);
failed_mount6:
	ext4_mb_release(sb);
	if (sbi->s_flex_groups)
		kvfree(sbi->s_flex_groups);
	percpu_counter_destroy(&sbi->s_freeclusters_counter);
	percpu_counter_destroy(&sbi->s_freeinodes_counter);
	percpu_counter_destroy(&sbi->s_dirs_counter);
	percpu_counter_destroy(&sbi->s_dirtyclusters_counter);
failed_mount5:
	ext4_ext_release(sb);
	ext4_release_system_zone(sb);
failed_mount4a:
	dput(sb->s_root);
	sb->s_root = NULL;
failed_mount4:
	ext4_msg(sb, KERN_ERR, ""mount failed"");
 	if (EXT4_SB(sb)->rsv_conversion_wq)
 		destroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);
 failed_mount_wq:
	if (sbi->s_mb_cache) {
		ext4_xattr_destroy_cache(sbi->s_mb_cache);
		sbi->s_mb_cache = NULL;
	}
 	if (sbi->s_journal) {
 		jbd2_journal_destroy(sbi->s_journal);
 		sbi->s_journal = NULL;
	}
failed_mount3a:
	ext4_es_unregister_shrinker(sbi);
failed_mount3:
	del_timer_sync(&sbi->s_err_report);
	if (sbi->s_mmp_tsk)
		kthread_stop(sbi->s_mmp_tsk);
failed_mount2:
	for (i = 0; i < db_count; i++)
		brelse(sbi->s_group_desc[i]);
	kvfree(sbi->s_group_desc);
failed_mount:
	if (sbi->s_chksum_driver)
		crypto_free_shash(sbi->s_chksum_driver);
#ifdef CONFIG_QUOTA
	for (i = 0; i < EXT4_MAXQUOTAS; i++)
		kfree(sbi->s_qf_names[i]);
#endif
	ext4_blkdev_remove(sbi);
	brelse(bh);
out_fail:
	sb->s_fs_info = NULL;
	kfree(sbi->s_blockgroup_lock);
	kfree(sbi);
out_free_orig:
	kfree(orig_data);
	return err ? err : ret;
}
","static int ext4_fill_super(struct super_block *sb, void *data, int silent)
{
	char *orig_data = kstrdup(data, GFP_KERNEL);
	struct buffer_head *bh;
	struct ext4_super_block *es = NULL;
	struct ext4_sb_info *sbi;
	ext4_fsblk_t block;
	ext4_fsblk_t sb_block = get_sb_block(&data);
	ext4_fsblk_t logical_sb_block;
	unsigned long offset = 0;
	unsigned long journal_devnum = 0;
	unsigned long def_mount_opts;
	struct inode *root;
	const char *descr;
	int ret = -ENOMEM;
	int blocksize, clustersize;
	unsigned int db_count;
	unsigned int i;
	int needs_recovery, has_huge_files, has_bigalloc;
	__u64 blocks_count;
	int err = 0;
	unsigned int journal_ioprio = DEFAULT_JOURNAL_IOPRIO;
	ext4_group_t first_not_zeroed;

	sbi = kzalloc(sizeof(*sbi), GFP_KERNEL);
	if (!sbi)
		goto out_free_orig;

	sbi->s_blockgroup_lock =
		kzalloc(sizeof(struct blockgroup_lock), GFP_KERNEL);
	if (!sbi->s_blockgroup_lock) {
		kfree(sbi);
		goto out_free_orig;
	}
	sb->s_fs_info = sbi;
	sbi->s_sb = sb;
	sbi->s_inode_readahead_blks = EXT4_DEF_INODE_READAHEAD_BLKS;
	sbi->s_sb_block = sb_block;
	if (sb->s_bdev->bd_part)
		sbi->s_sectors_written_start =
			part_stat_read(sb->s_bdev->bd_part, sectors[1]);

	/* Cleanup superblock name */
	strreplace(sb->s_id, '/', '!');

	/* -EINVAL is default */
	ret = -EINVAL;
	blocksize = sb_min_blocksize(sb, EXT4_MIN_BLOCK_SIZE);
	if (!blocksize) {
		ext4_msg(sb, KERN_ERR, ""unable to set blocksize"");
		goto out_fail;
	}

	/*
	 * The ext4 superblock will not be buffer aligned for other than 1kB
	 * block sizes.  We need to calculate the offset from buffer start.
	 */
	if (blocksize != EXT4_MIN_BLOCK_SIZE) {
		logical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;
		offset = do_div(logical_sb_block, blocksize);
	} else {
		logical_sb_block = sb_block;
	}

	if (!(bh = sb_bread_unmovable(sb, logical_sb_block))) {
		ext4_msg(sb, KERN_ERR, ""unable to read superblock"");
		goto out_fail;
	}
	/*
	 * Note: s_es must be initialized as soon as possible because
	 *       some ext4 macro-instructions depend on its value
	 */
	es = (struct ext4_super_block *) (bh->b_data + offset);
	sbi->s_es = es;
	sb->s_magic = le16_to_cpu(es->s_magic);
	if (sb->s_magic != EXT4_SUPER_MAGIC)
		goto cantfind_ext4;
	sbi->s_kbytes_written = le64_to_cpu(es->s_kbytes_written);

	/* Warn if metadata_csum and gdt_csum are both set. */
	if (ext4_has_feature_metadata_csum(sb) &&
	    ext4_has_feature_gdt_csum(sb))
		ext4_warning(sb, ""metadata_csum and uninit_bg are ""
			     ""redundant flags; please run fsck."");

	/* Check for a known checksum algorithm */
	if (!ext4_verify_csum_type(sb, es)) {
		ext4_msg(sb, KERN_ERR, ""VFS: Found ext4 filesystem with ""
			 ""unknown checksum algorithm."");
		silent = 1;
		goto cantfind_ext4;
	}

	/* Load the checksum driver */
	if (ext4_has_feature_metadata_csum(sb)) {
		sbi->s_chksum_driver = crypto_alloc_shash(""crc32c"", 0, 0);
		if (IS_ERR(sbi->s_chksum_driver)) {
			ext4_msg(sb, KERN_ERR, ""Cannot load crc32c driver."");
			ret = PTR_ERR(sbi->s_chksum_driver);
			sbi->s_chksum_driver = NULL;
			goto failed_mount;
		}
	}

	/* Check superblock checksum */
	if (!ext4_superblock_csum_verify(sb, es)) {
		ext4_msg(sb, KERN_ERR, ""VFS: Found ext4 filesystem with ""
			 ""invalid superblock checksum.  Run e2fsck?"");
		silent = 1;
		ret = -EFSBADCRC;
		goto cantfind_ext4;
	}

	/* Precompute checksum seed for all metadata */
	if (ext4_has_feature_csum_seed(sb))
		sbi->s_csum_seed = le32_to_cpu(es->s_checksum_seed);
	else if (ext4_has_metadata_csum(sb))
		sbi->s_csum_seed = ext4_chksum(sbi, ~0, es->s_uuid,
					       sizeof(es->s_uuid));

	/* Set defaults before we parse the mount options */
	def_mount_opts = le32_to_cpu(es->s_default_mount_opts);
	set_opt(sb, INIT_INODE_TABLE);
	if (def_mount_opts & EXT4_DEFM_DEBUG)
		set_opt(sb, DEBUG);
	if (def_mount_opts & EXT4_DEFM_BSDGROUPS)
		set_opt(sb, GRPID);
	if (def_mount_opts & EXT4_DEFM_UID16)
		set_opt(sb, NO_UID32);
	/* xattr user namespace & acls are now defaulted on */
	set_opt(sb, XATTR_USER);
#ifdef CONFIG_EXT4_FS_POSIX_ACL
	set_opt(sb, POSIX_ACL);
#endif
	/* don't forget to enable journal_csum when metadata_csum is enabled. */
	if (ext4_has_metadata_csum(sb))
		set_opt(sb, JOURNAL_CHECKSUM);

	if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_DATA)
		set_opt(sb, JOURNAL_DATA);
	else if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_ORDERED)
		set_opt(sb, ORDERED_DATA);
	else if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_WBACK)
		set_opt(sb, WRITEBACK_DATA);

	if (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_PANIC)
		set_opt(sb, ERRORS_PANIC);
	else if (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_CONTINUE)
		set_opt(sb, ERRORS_CONT);
	else
		set_opt(sb, ERRORS_RO);
	/* block_validity enabled by default; disable with noblock_validity */
	set_opt(sb, BLOCK_VALIDITY);
	if (def_mount_opts & EXT4_DEFM_DISCARD)
		set_opt(sb, DISCARD);

	sbi->s_resuid = make_kuid(&init_user_ns, le16_to_cpu(es->s_def_resuid));
	sbi->s_resgid = make_kgid(&init_user_ns, le16_to_cpu(es->s_def_resgid));
	sbi->s_commit_interval = JBD2_DEFAULT_MAX_COMMIT_AGE * HZ;
	sbi->s_min_batch_time = EXT4_DEF_MIN_BATCH_TIME;
	sbi->s_max_batch_time = EXT4_DEF_MAX_BATCH_TIME;

	if ((def_mount_opts & EXT4_DEFM_NOBARRIER) == 0)
		set_opt(sb, BARRIER);

	/*
	 * enable delayed allocation by default
	 * Use -o nodelalloc to turn it off
	 */
	if (!IS_EXT3_SB(sb) && !IS_EXT2_SB(sb) &&
	    ((def_mount_opts & EXT4_DEFM_NODELALLOC) == 0))
		set_opt(sb, DELALLOC);

	/*
	 * set default s_li_wait_mult for lazyinit, for the case there is
	 * no mount option specified.
	 */
	sbi->s_li_wait_mult = EXT4_DEF_LI_WAIT_MULT;

	if (!parse_options((char *) sbi->s_es->s_mount_opts, sb,
			   &journal_devnum, &journal_ioprio, 0)) {
		ext4_msg(sb, KERN_WARNING,
			 ""failed to parse options in superblock: %s"",
			 sbi->s_es->s_mount_opts);
	}
	sbi->s_def_mount_opt = sbi->s_mount_opt;
	if (!parse_options((char *) data, sb, &journal_devnum,
			   &journal_ioprio, 0))
		goto failed_mount;

	if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA) {
		printk_once(KERN_WARNING ""EXT4-fs: Warning: mounting ""
			    ""with data=journal disables delayed ""
			    ""allocation and O_DIRECT support!\n"");
		if (test_opt2(sb, EXPLICIT_DELALLOC)) {
			ext4_msg(sb, KERN_ERR, ""can't mount with ""
				 ""both data=journal and delalloc"");
			goto failed_mount;
		}
		if (test_opt(sb, DIOREAD_NOLOCK)) {
			ext4_msg(sb, KERN_ERR, ""can't mount with ""
				 ""both data=journal and dioread_nolock"");
			goto failed_mount;
		}
		if (test_opt(sb, DAX)) {
			ext4_msg(sb, KERN_ERR, ""can't mount with ""
				 ""both data=journal and dax"");
			goto failed_mount;
		}
		if (test_opt(sb, DELALLOC))
			clear_opt(sb, DELALLOC);
	} else {
		sb->s_iflags |= SB_I_CGROUPWB;
	}

	sb->s_flags = (sb->s_flags & ~MS_POSIXACL) |
		(test_opt(sb, POSIX_ACL) ? MS_POSIXACL : 0);

	if (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV &&
	    (ext4_has_compat_features(sb) ||
	     ext4_has_ro_compat_features(sb) ||
	     ext4_has_incompat_features(sb)))
		ext4_msg(sb, KERN_WARNING,
		       ""feature flags set on rev 0 fs, ""
		       ""running e2fsck is recommended"");

	if (es->s_creator_os == cpu_to_le32(EXT4_OS_HURD)) {
		set_opt2(sb, HURD_COMPAT);
		if (ext4_has_feature_64bit(sb)) {
			ext4_msg(sb, KERN_ERR,
				 ""The Hurd can't support 64-bit file systems"");
			goto failed_mount;
		}
	}

	if (IS_EXT2_SB(sb)) {
		if (ext2_feature_set_ok(sb))
			ext4_msg(sb, KERN_INFO, ""mounting ext2 file system ""
				 ""using the ext4 subsystem"");
		else {
			ext4_msg(sb, KERN_ERR, ""couldn't mount as ext2 due ""
				 ""to feature incompatibilities"");
			goto failed_mount;
		}
	}

	if (IS_EXT3_SB(sb)) {
		if (ext3_feature_set_ok(sb))
			ext4_msg(sb, KERN_INFO, ""mounting ext3 file system ""
				 ""using the ext4 subsystem"");
		else {
			ext4_msg(sb, KERN_ERR, ""couldn't mount as ext3 due ""
				 ""to feature incompatibilities"");
			goto failed_mount;
		}
	}

	/*
	 * Check feature flags regardless of the revision level, since we
	 * previously didn't change the revision level when setting the flags,
	 * so there is a chance incompat flags are set on a rev 0 filesystem.
	 */
	if (!ext4_feature_set_ok(sb, (sb->s_flags & MS_RDONLY)))
		goto failed_mount;

	blocksize = BLOCK_SIZE << le32_to_cpu(es->s_log_block_size);
	if (blocksize < EXT4_MIN_BLOCK_SIZE ||
	    blocksize > EXT4_MAX_BLOCK_SIZE) {
		ext4_msg(sb, KERN_ERR,
		       ""Unsupported filesystem blocksize %d"", blocksize);
		goto failed_mount;
	}

	if (sbi->s_mount_opt & EXT4_MOUNT_DAX) {
		if (blocksize != PAGE_SIZE) {
			ext4_msg(sb, KERN_ERR,
					""error: unsupported blocksize for dax"");
			goto failed_mount;
		}
		if (!sb->s_bdev->bd_disk->fops->direct_access) {
			ext4_msg(sb, KERN_ERR,
					""error: device does not support dax"");
			goto failed_mount;
		}
	}

	if (ext4_has_feature_encrypt(sb) && es->s_encryption_level) {
		ext4_msg(sb, KERN_ERR, ""Unsupported encryption level %d"",
			 es->s_encryption_level);
		goto failed_mount;
	}

	if (sb->s_blocksize != blocksize) {
		/* Validate the filesystem blocksize */
		if (!sb_set_blocksize(sb, blocksize)) {
			ext4_msg(sb, KERN_ERR, ""bad block size %d"",
					blocksize);
			goto failed_mount;
		}

		brelse(bh);
		logical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;
		offset = do_div(logical_sb_block, blocksize);
		bh = sb_bread_unmovable(sb, logical_sb_block);
		if (!bh) {
			ext4_msg(sb, KERN_ERR,
			       ""Can't read superblock on 2nd try"");
			goto failed_mount;
		}
		es = (struct ext4_super_block *)(bh->b_data + offset);
		sbi->s_es = es;
		if (es->s_magic != cpu_to_le16(EXT4_SUPER_MAGIC)) {
			ext4_msg(sb, KERN_ERR,
			       ""Magic mismatch, very weird!"");
			goto failed_mount;
		}
	}

	has_huge_files = ext4_has_feature_huge_file(sb);
	sbi->s_bitmap_maxbytes = ext4_max_bitmap_size(sb->s_blocksize_bits,
						      has_huge_files);
	sb->s_maxbytes = ext4_max_size(sb->s_blocksize_bits, has_huge_files);

	if (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV) {
		sbi->s_inode_size = EXT4_GOOD_OLD_INODE_SIZE;
		sbi->s_first_ino = EXT4_GOOD_OLD_FIRST_INO;
	} else {
		sbi->s_inode_size = le16_to_cpu(es->s_inode_size);
		sbi->s_first_ino = le32_to_cpu(es->s_first_ino);
		if ((sbi->s_inode_size < EXT4_GOOD_OLD_INODE_SIZE) ||
		    (!is_power_of_2(sbi->s_inode_size)) ||
		    (sbi->s_inode_size > blocksize)) {
			ext4_msg(sb, KERN_ERR,
			       ""unsupported inode size: %d"",
			       sbi->s_inode_size);
			goto failed_mount;
		}
		if (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE)
			sb->s_time_gran = 1 << (EXT4_EPOCH_BITS - 2);
	}

	sbi->s_desc_size = le16_to_cpu(es->s_desc_size);
	if (ext4_has_feature_64bit(sb)) {
		if (sbi->s_desc_size < EXT4_MIN_DESC_SIZE_64BIT ||
		    sbi->s_desc_size > EXT4_MAX_DESC_SIZE ||
		    !is_power_of_2(sbi->s_desc_size)) {
			ext4_msg(sb, KERN_ERR,
			       ""unsupported descriptor size %lu"",
			       sbi->s_desc_size);
			goto failed_mount;
		}
	} else
		sbi->s_desc_size = EXT4_MIN_DESC_SIZE;

	sbi->s_blocks_per_group = le32_to_cpu(es->s_blocks_per_group);
	sbi->s_inodes_per_group = le32_to_cpu(es->s_inodes_per_group);
	if (EXT4_INODE_SIZE(sb) == 0 || EXT4_INODES_PER_GROUP(sb) == 0)
		goto cantfind_ext4;

	sbi->s_inodes_per_block = blocksize / EXT4_INODE_SIZE(sb);
	if (sbi->s_inodes_per_block == 0)
		goto cantfind_ext4;
	sbi->s_itb_per_group = sbi->s_inodes_per_group /
					sbi->s_inodes_per_block;
	sbi->s_desc_per_block = blocksize / EXT4_DESC_SIZE(sb);
	sbi->s_sbh = bh;
	sbi->s_mount_state = le16_to_cpu(es->s_state);
	sbi->s_addr_per_block_bits = ilog2(EXT4_ADDR_PER_BLOCK(sb));
	sbi->s_desc_per_block_bits = ilog2(EXT4_DESC_PER_BLOCK(sb));

	for (i = 0; i < 4; i++)
		sbi->s_hash_seed[i] = le32_to_cpu(es->s_hash_seed[i]);
	sbi->s_def_hash_version = es->s_def_hash_version;
	if (ext4_has_feature_dir_index(sb)) {
		i = le32_to_cpu(es->s_flags);
		if (i & EXT2_FLAGS_UNSIGNED_HASH)
			sbi->s_hash_unsigned = 3;
		else if ((i & EXT2_FLAGS_SIGNED_HASH) == 0) {
#ifdef __CHAR_UNSIGNED__
			if (!(sb->s_flags & MS_RDONLY))
				es->s_flags |=
					cpu_to_le32(EXT2_FLAGS_UNSIGNED_HASH);
			sbi->s_hash_unsigned = 3;
#else
			if (!(sb->s_flags & MS_RDONLY))
				es->s_flags |=
					cpu_to_le32(EXT2_FLAGS_SIGNED_HASH);
#endif
		}
	}

	/* Handle clustersize */
	clustersize = BLOCK_SIZE << le32_to_cpu(es->s_log_cluster_size);
	has_bigalloc = ext4_has_feature_bigalloc(sb);
	if (has_bigalloc) {
		if (clustersize < blocksize) {
			ext4_msg(sb, KERN_ERR,
				 ""cluster size (%d) smaller than ""
				 ""block size (%d)"", clustersize, blocksize);
			goto failed_mount;
		}
		sbi->s_cluster_bits = le32_to_cpu(es->s_log_cluster_size) -
			le32_to_cpu(es->s_log_block_size);
		sbi->s_clusters_per_group =
			le32_to_cpu(es->s_clusters_per_group);
		if (sbi->s_clusters_per_group > blocksize * 8) {
			ext4_msg(sb, KERN_ERR,
				 ""#clusters per group too big: %lu"",
				 sbi->s_clusters_per_group);
			goto failed_mount;
		}
		if (sbi->s_blocks_per_group !=
		    (sbi->s_clusters_per_group * (clustersize / blocksize))) {
			ext4_msg(sb, KERN_ERR, ""blocks per group (%lu) and ""
				 ""clusters per group (%lu) inconsistent"",
				 sbi->s_blocks_per_group,
				 sbi->s_clusters_per_group);
			goto failed_mount;
		}
	} else {
		if (clustersize != blocksize) {
			ext4_warning(sb, ""fragment/cluster size (%d) != ""
				     ""block size (%d)"", clustersize,
				     blocksize);
			clustersize = blocksize;
		}
		if (sbi->s_blocks_per_group > blocksize * 8) {
			ext4_msg(sb, KERN_ERR,
				 ""#blocks per group too big: %lu"",
				 sbi->s_blocks_per_group);
			goto failed_mount;
		}
		sbi->s_clusters_per_group = sbi->s_blocks_per_group;
		sbi->s_cluster_bits = 0;
	}
	sbi->s_cluster_ratio = clustersize / blocksize;

	if (sbi->s_inodes_per_group > blocksize * 8) {
		ext4_msg(sb, KERN_ERR,
		       ""#inodes per group too big: %lu"",
		       sbi->s_inodes_per_group);
		goto failed_mount;
	}

	/* Do we have standard group size of clustersize * 8 blocks ? */
	if (sbi->s_blocks_per_group == clustersize << 3)
		set_opt2(sb, STD_GROUP_SIZE);

	/*
	 * Test whether we have more sectors than will fit in sector_t,
	 * and whether the max offset is addressable by the page cache.
	 */
	err = generic_check_addressable(sb->s_blocksize_bits,
					ext4_blocks_count(es));
	if (err) {
		ext4_msg(sb, KERN_ERR, ""filesystem""
			 "" too large to mount safely on this system"");
		if (sizeof(sector_t) < 8)
			ext4_msg(sb, KERN_WARNING, ""CONFIG_LBDAF not enabled"");
		goto failed_mount;
	}

	if (EXT4_BLOCKS_PER_GROUP(sb) == 0)
		goto cantfind_ext4;

	/* check blocks count against device size */
	blocks_count = sb->s_bdev->bd_inode->i_size >> sb->s_blocksize_bits;
	if (blocks_count && ext4_blocks_count(es) > blocks_count) {
		ext4_msg(sb, KERN_WARNING, ""bad geometry: block count %llu ""
		       ""exceeds size of device (%llu blocks)"",
		       ext4_blocks_count(es), blocks_count);
		goto failed_mount;
	}

	/*
	 * It makes no sense for the first data block to be beyond the end
	 * of the filesystem.
	 */
	if (le32_to_cpu(es->s_first_data_block) >= ext4_blocks_count(es)) {
		ext4_msg(sb, KERN_WARNING, ""bad geometry: first data ""
			 ""block %u is beyond end of filesystem (%llu)"",
			 le32_to_cpu(es->s_first_data_block),
			 ext4_blocks_count(es));
		goto failed_mount;
	}
	blocks_count = (ext4_blocks_count(es) -
			le32_to_cpu(es->s_first_data_block) +
			EXT4_BLOCKS_PER_GROUP(sb) - 1);
	do_div(blocks_count, EXT4_BLOCKS_PER_GROUP(sb));
	if (blocks_count > ((uint64_t)1<<32) - EXT4_DESC_PER_BLOCK(sb)) {
		ext4_msg(sb, KERN_WARNING, ""groups count too large: %u ""
		       ""(block count %llu, first data block %u, ""
		       ""blocks per group %lu)"", sbi->s_groups_count,
		       ext4_blocks_count(es),
		       le32_to_cpu(es->s_first_data_block),
		       EXT4_BLOCKS_PER_GROUP(sb));
		goto failed_mount;
	}
	sbi->s_groups_count = blocks_count;
	sbi->s_blockfile_groups = min_t(ext4_group_t, sbi->s_groups_count,
			(EXT4_MAX_BLOCK_FILE_PHYS / EXT4_BLOCKS_PER_GROUP(sb)));
	db_count = (sbi->s_groups_count + EXT4_DESC_PER_BLOCK(sb) - 1) /
		   EXT4_DESC_PER_BLOCK(sb);
	sbi->s_group_desc = ext4_kvmalloc(db_count *
					  sizeof(struct buffer_head *),
					  GFP_KERNEL);
	if (sbi->s_group_desc == NULL) {
		ext4_msg(sb, KERN_ERR, ""not enough memory"");
		ret = -ENOMEM;
		goto failed_mount;
	}

	bgl_lock_init(sbi->s_blockgroup_lock);

	for (i = 0; i < db_count; i++) {
		block = descriptor_loc(sb, logical_sb_block, i);
		sbi->s_group_desc[i] = sb_bread_unmovable(sb, block);
		if (!sbi->s_group_desc[i]) {
			ext4_msg(sb, KERN_ERR,
			       ""can't read group descriptor %d"", i);
			db_count = i;
			goto failed_mount2;
		}
	}
	if (!ext4_check_descriptors(sb, &first_not_zeroed)) {
		ext4_msg(sb, KERN_ERR, ""group descriptors corrupted!"");
		ret = -EFSCORRUPTED;
		goto failed_mount2;
	}

	sbi->s_gdb_count = db_count;
	get_random_bytes(&sbi->s_next_generation, sizeof(u32));
	spin_lock_init(&sbi->s_next_gen_lock);

	setup_timer(&sbi->s_err_report, print_daily_error_info,
		(unsigned long) sb);

	/* Register extent status tree shrinker */
	if (ext4_es_register_shrinker(sbi))
		goto failed_mount3;

	sbi->s_stripe = ext4_get_stripe_size(sbi);
	sbi->s_extent_max_zeroout_kb = 32;

	/*
	 * set up enough so that it can read an inode
	 */
	sb->s_op = &ext4_sops;
	sb->s_export_op = &ext4_export_ops;
	sb->s_xattr = ext4_xattr_handlers;
#ifdef CONFIG_QUOTA
	sb->dq_op = &ext4_quota_operations;
	if (ext4_has_feature_quota(sb))
		sb->s_qcop = &dquot_quotactl_sysfile_ops;
	else
		sb->s_qcop = &ext4_qctl_operations;
	sb->s_quota_types = QTYPE_MASK_USR | QTYPE_MASK_GRP | QTYPE_MASK_PRJ;
#endif
	memcpy(sb->s_uuid, es->s_uuid, sizeof(es->s_uuid));

	INIT_LIST_HEAD(&sbi->s_orphan); /* unlinked but open files */
	mutex_init(&sbi->s_orphan_lock);

	sb->s_root = NULL;

	needs_recovery = (es->s_last_orphan != 0 ||
			  ext4_has_feature_journal_needs_recovery(sb));

	if (ext4_has_feature_mmp(sb) && !(sb->s_flags & MS_RDONLY))
		if (ext4_multi_mount_protect(sb, le64_to_cpu(es->s_mmp_block)))
			goto failed_mount3a;

	/*
	 * The first inode we look at is the journal inode.  Don't try
	 * root first: it may be modified in the journal!
	 */
	if (!test_opt(sb, NOLOAD) && ext4_has_feature_journal(sb)) {
		if (ext4_load_journal(sb, es, journal_devnum))
			goto failed_mount3a;
	} else if (test_opt(sb, NOLOAD) && !(sb->s_flags & MS_RDONLY) &&
		   ext4_has_feature_journal_needs_recovery(sb)) {
		ext4_msg(sb, KERN_ERR, ""required journal recovery ""
		       ""suppressed and not mounted read-only"");
		goto failed_mount_wq;
	} else {
		/* Nojournal mode, all journal mount options are illegal */
		if (test_opt2(sb, EXPLICIT_JOURNAL_CHECKSUM)) {
			ext4_msg(sb, KERN_ERR, ""can't mount with ""
				 ""journal_checksum, fs mounted w/o journal"");
			goto failed_mount_wq;
		}
		if (test_opt(sb, JOURNAL_ASYNC_COMMIT)) {
			ext4_msg(sb, KERN_ERR, ""can't mount with ""
				 ""journal_async_commit, fs mounted w/o journal"");
			goto failed_mount_wq;
		}
		if (sbi->s_commit_interval != JBD2_DEFAULT_MAX_COMMIT_AGE*HZ) {
			ext4_msg(sb, KERN_ERR, ""can't mount with ""
				 ""commit=%lu, fs mounted w/o journal"",
				 sbi->s_commit_interval / HZ);
			goto failed_mount_wq;
		}
		if (EXT4_MOUNT_DATA_FLAGS &
		    (sbi->s_mount_opt ^ sbi->s_def_mount_opt)) {
			ext4_msg(sb, KERN_ERR, ""can't mount with ""
				 ""data=, fs mounted w/o journal"");
			goto failed_mount_wq;
		}
		sbi->s_def_mount_opt &= EXT4_MOUNT_JOURNAL_CHECKSUM;
		clear_opt(sb, JOURNAL_CHECKSUM);
		clear_opt(sb, DATA_FLAGS);
		sbi->s_journal = NULL;
		needs_recovery = 0;
		goto no_journal;
	}

	if (ext4_has_feature_64bit(sb) &&
	    !jbd2_journal_set_features(EXT4_SB(sb)->s_journal, 0, 0,
				       JBD2_FEATURE_INCOMPAT_64BIT)) {
		ext4_msg(sb, KERN_ERR, ""Failed to set 64-bit journal feature"");
		goto failed_mount_wq;
	}

	if (!set_journal_csum_feature_set(sb)) {
		ext4_msg(sb, KERN_ERR, ""Failed to set journal checksum ""
			 ""feature set"");
		goto failed_mount_wq;
	}

	/* We have now updated the journal if required, so we can
	 * validate the data journaling mode. */
	switch (test_opt(sb, DATA_FLAGS)) {
	case 0:
		/* No mode set, assume a default based on the journal
		 * capabilities: ORDERED_DATA if the journal can
		 * cope, else JOURNAL_DATA
		 */
		if (jbd2_journal_check_available_features
		    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE))
			set_opt(sb, ORDERED_DATA);
		else
			set_opt(sb, JOURNAL_DATA);
		break;

	case EXT4_MOUNT_ORDERED_DATA:
	case EXT4_MOUNT_WRITEBACK_DATA:
		if (!jbd2_journal_check_available_features
		    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE)) {
			ext4_msg(sb, KERN_ERR, ""Journal does not support ""
			       ""requested data journaling mode"");
			goto failed_mount_wq;
		}
	default:
		break;
	}
	set_task_ioprio(sbi->s_journal->j_task, journal_ioprio);

	sbi->s_journal->j_commit_callback = ext4_journal_commit_callback;
 
 no_journal:
 	if (ext4_mballoc_ready) {
		sbi->s_mb_cache = ext4_xattr_create_cache(sb->s_id);
 		if (!sbi->s_mb_cache) {
 			ext4_msg(sb, KERN_ERR, ""Failed to create an mb_cache"");
 			goto failed_mount_wq;
		}
	}

	if ((DUMMY_ENCRYPTION_ENABLED(sbi) || ext4_has_feature_encrypt(sb)) &&
	    (blocksize != PAGE_CACHE_SIZE)) {
		ext4_msg(sb, KERN_ERR,
			 ""Unsupported blocksize for fs encryption"");
		goto failed_mount_wq;
	}

	if (DUMMY_ENCRYPTION_ENABLED(sbi) && !(sb->s_flags & MS_RDONLY) &&
	    !ext4_has_feature_encrypt(sb)) {
		ext4_set_feature_encrypt(sb);
		ext4_commit_super(sb, 1);
	}

	/*
	 * Get the # of file system overhead blocks from the
	 * superblock if present.
	 */
	if (es->s_overhead_clusters)
		sbi->s_overhead = le32_to_cpu(es->s_overhead_clusters);
	else {
		err = ext4_calculate_overhead(sb);
		if (err)
			goto failed_mount_wq;
	}

	/*
	 * The maximum number of concurrent works can be high and
	 * concurrency isn't really necessary.  Limit it to 1.
	 */
	EXT4_SB(sb)->rsv_conversion_wq =
		alloc_workqueue(""ext4-rsv-conversion"", WQ_MEM_RECLAIM | WQ_UNBOUND, 1);
	if (!EXT4_SB(sb)->rsv_conversion_wq) {
		printk(KERN_ERR ""EXT4-fs: failed to create workqueue\n"");
		ret = -ENOMEM;
		goto failed_mount4;
	}

	/*
	 * The jbd2_journal_load will have done any necessary log recovery,
	 * so we can safely mount the rest of the filesystem now.
	 */

	root = ext4_iget(sb, EXT4_ROOT_INO);
	if (IS_ERR(root)) {
		ext4_msg(sb, KERN_ERR, ""get root inode failed"");
		ret = PTR_ERR(root);
		root = NULL;
		goto failed_mount4;
	}
	if (!S_ISDIR(root->i_mode) || !root->i_blocks || !root->i_size) {
		ext4_msg(sb, KERN_ERR, ""corrupt root inode, run e2fsck"");
		iput(root);
		goto failed_mount4;
	}
	sb->s_root = d_make_root(root);
	if (!sb->s_root) {
		ext4_msg(sb, KERN_ERR, ""get root dentry failed"");
		ret = -ENOMEM;
		goto failed_mount4;
	}

	if (ext4_setup_super(sb, es, sb->s_flags & MS_RDONLY))
		sb->s_flags |= MS_RDONLY;

	/* determine the minimum size of new large inodes, if present */
	if (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE) {
		sbi->s_want_extra_isize = sizeof(struct ext4_inode) -
						     EXT4_GOOD_OLD_INODE_SIZE;
		if (ext4_has_feature_extra_isize(sb)) {
			if (sbi->s_want_extra_isize <
			    le16_to_cpu(es->s_want_extra_isize))
				sbi->s_want_extra_isize =
					le16_to_cpu(es->s_want_extra_isize);
			if (sbi->s_want_extra_isize <
			    le16_to_cpu(es->s_min_extra_isize))
				sbi->s_want_extra_isize =
					le16_to_cpu(es->s_min_extra_isize);
		}
	}
	/* Check if enough inode space is available */
	if (EXT4_GOOD_OLD_INODE_SIZE + sbi->s_want_extra_isize >
							sbi->s_inode_size) {
		sbi->s_want_extra_isize = sizeof(struct ext4_inode) -
						       EXT4_GOOD_OLD_INODE_SIZE;
		ext4_msg(sb, KERN_INFO, ""required extra inode space not""
			 ""available"");
	}

	ext4_set_resv_clusters(sb);

	err = ext4_setup_system_zone(sb);
	if (err) {
		ext4_msg(sb, KERN_ERR, ""failed to initialize system ""
			 ""zone (%d)"", err);
		goto failed_mount4a;
	}

	ext4_ext_init(sb);
	err = ext4_mb_init(sb);
	if (err) {
		ext4_msg(sb, KERN_ERR, ""failed to initialize mballoc (%d)"",
			 err);
		goto failed_mount5;
	}

	block = ext4_count_free_clusters(sb);
	ext4_free_blocks_count_set(sbi->s_es, 
				   EXT4_C2B(sbi, block));
	err = percpu_counter_init(&sbi->s_freeclusters_counter, block,
				  GFP_KERNEL);
	if (!err) {
		unsigned long freei = ext4_count_free_inodes(sb);
		sbi->s_es->s_free_inodes_count = cpu_to_le32(freei);
		err = percpu_counter_init(&sbi->s_freeinodes_counter, freei,
					  GFP_KERNEL);
	}
	if (!err)
		err = percpu_counter_init(&sbi->s_dirs_counter,
					  ext4_count_dirs(sb), GFP_KERNEL);
	if (!err)
		err = percpu_counter_init(&sbi->s_dirtyclusters_counter, 0,
					  GFP_KERNEL);
	if (err) {
		ext4_msg(sb, KERN_ERR, ""insufficient memory"");
		goto failed_mount6;
	}

	if (ext4_has_feature_flex_bg(sb))
		if (!ext4_fill_flex_info(sb)) {
			ext4_msg(sb, KERN_ERR,
			       ""unable to initialize ""
			       ""flex_bg meta info!"");
			goto failed_mount6;
		}

	err = ext4_register_li_request(sb, first_not_zeroed);
	if (err)
		goto failed_mount6;

	err = ext4_register_sysfs(sb);
	if (err)
		goto failed_mount7;

#ifdef CONFIG_QUOTA
	/* Enable quota usage during mount. */
	if (ext4_has_feature_quota(sb) && !(sb->s_flags & MS_RDONLY)) {
		err = ext4_enable_quotas(sb);
		if (err)
			goto failed_mount8;
	}
#endif  /* CONFIG_QUOTA */

	EXT4_SB(sb)->s_mount_state |= EXT4_ORPHAN_FS;
	ext4_orphan_cleanup(sb, es);
	EXT4_SB(sb)->s_mount_state &= ~EXT4_ORPHAN_FS;
	if (needs_recovery) {
		ext4_msg(sb, KERN_INFO, ""recovery complete"");
		ext4_mark_recovery_complete(sb, es);
	}
	if (EXT4_SB(sb)->s_journal) {
		if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA)
			descr = "" journalled data mode"";
		else if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_ORDERED_DATA)
			descr = "" ordered data mode"";
		else
			descr = "" writeback data mode"";
	} else
		descr = ""out journal"";

	if (test_opt(sb, DISCARD)) {
		struct request_queue *q = bdev_get_queue(sb->s_bdev);
		if (!blk_queue_discard(q))
			ext4_msg(sb, KERN_WARNING,
				 ""mounting with \""discard\"" option, but ""
				 ""the device does not support discard"");
	}

	if (___ratelimit(&ext4_mount_msg_ratelimit, ""EXT4-fs mount""))
		ext4_msg(sb, KERN_INFO, ""mounted filesystem with%s. ""
			 ""Opts: %s%s%s"", descr, sbi->s_es->s_mount_opts,
			 *sbi->s_es->s_mount_opts ? ""; "" : """", orig_data);

	if (es->s_error_count)
		mod_timer(&sbi->s_err_report, jiffies + 300*HZ); /* 5 minutes */

	/* Enable message ratelimiting. Default is 10 messages per 5 secs. */
	ratelimit_state_init(&sbi->s_err_ratelimit_state, 5 * HZ, 10);
	ratelimit_state_init(&sbi->s_warning_ratelimit_state, 5 * HZ, 10);
	ratelimit_state_init(&sbi->s_msg_ratelimit_state, 5 * HZ, 10);

	kfree(orig_data);
	return 0;

cantfind_ext4:
	if (!silent)
		ext4_msg(sb, KERN_ERR, ""VFS: Can't find ext4 filesystem"");
	goto failed_mount;

#ifdef CONFIG_QUOTA
failed_mount8:
	ext4_unregister_sysfs(sb);
#endif
failed_mount7:
	ext4_unregister_li_request(sb);
failed_mount6:
	ext4_mb_release(sb);
	if (sbi->s_flex_groups)
		kvfree(sbi->s_flex_groups);
	percpu_counter_destroy(&sbi->s_freeclusters_counter);
	percpu_counter_destroy(&sbi->s_freeinodes_counter);
	percpu_counter_destroy(&sbi->s_dirs_counter);
	percpu_counter_destroy(&sbi->s_dirtyclusters_counter);
failed_mount5:
	ext4_ext_release(sb);
	ext4_release_system_zone(sb);
failed_mount4a:
	dput(sb->s_root);
	sb->s_root = NULL;
failed_mount4:
	ext4_msg(sb, KERN_ERR, ""mount failed"");
 	if (EXT4_SB(sb)->rsv_conversion_wq)
 		destroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);
 failed_mount_wq:
 	if (sbi->s_journal) {
 		jbd2_journal_destroy(sbi->s_journal);
 		sbi->s_journal = NULL;
	}
failed_mount3a:
	ext4_es_unregister_shrinker(sbi);
failed_mount3:
	del_timer_sync(&sbi->s_err_report);
	if (sbi->s_mmp_tsk)
		kthread_stop(sbi->s_mmp_tsk);
failed_mount2:
	for (i = 0; i < db_count; i++)
		brelse(sbi->s_group_desc[i]);
	kvfree(sbi->s_group_desc);
failed_mount:
	if (sbi->s_chksum_driver)
		crypto_free_shash(sbi->s_chksum_driver);
#ifdef CONFIG_QUOTA
	for (i = 0; i < EXT4_MAXQUOTAS; i++)
		kfree(sbi->s_qf_names[i]);
#endif
	ext4_blkdev_remove(sbi);
	brelse(bh);
out_fail:
	sb->s_fs_info = NULL;
	kfree(sbi->s_blockgroup_lock);
	kfree(sbi);
out_free_orig:
	kfree(orig_data);
	return err ? err : ret;
}
",C,"		sbi->s_mb_cache = ext4_xattr_create_cache();
	if (sbi->s_mb_cache) {
		ext4_xattr_destroy_cache(sbi->s_mb_cache);
		sbi->s_mb_cache = NULL;
	}
","		sbi->s_mb_cache = ext4_xattr_create_cache(sb->s_id);
",,"@@ -844,7 +844,6 @@ static void ext4_put_super(struct super_block *sb)
 	ext4_release_system_zone(sb);
 	ext4_mb_release(sb);
 	ext4_ext_release(sb);
-	ext4_xattr_put_super(sb);
 
 	if (!(sb->s_flags & MS_RDONLY)) {
 		ext4_clear_feature_journal_needs_recovery(sb);
@@ -3797,7 +3796,7 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)
 
 no_journal:
 	if (ext4_mballoc_ready) {
-		sbi->s_mb_cache = ext4_xattr_create_cache(sb->s_id);
+		sbi->s_mb_cache = ext4_xattr_create_cache();
 		if (!sbi->s_mb_cache) {
 			ext4_msg(sb, KERN_ERR, ""Failed to create an mb_cache"");
 			goto failed_mount_wq;
@@ -4027,6 +4026,10 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)
 	if (EXT4_SB(sb)->rsv_conversion_wq)
 		destroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);
 failed_mount_wq:
+	if (sbi->s_mb_cache) {
+		ext4_xattr_destroy_cache(sbi->s_mb_cache);
+		sbi->s_mb_cache = NULL;
+	}
 	if (sbi->s_journal) {
 		jbd2_journal_destroy(sbi->s_journal);
 		sbi->s_journal = NULL;",linux,82939d7999dfc1f1998c4b1c12e2f19edbdff272,f9a61eb4e2471c56a63cd804c7474128138c38ac,1,"static int ext4_fill_super(struct super_block *sb, void *data, int silent)
{
	char *orig_data = kstrdup(data, GFP_KERNEL);
	struct buffer_head *bh;
	struct ext4_super_block *es = NULL;
	struct ext4_sb_info *sbi;
	ext4_fsblk_t block;
	ext4_fsblk_t sb_block = get_sb_block(&data);
	ext4_fsblk_t logical_sb_block;
	unsigned long offset = 0;
	unsigned long journal_devnum = 0;
	unsigned long def_mount_opts;
	struct inode *root;
	const char *descr;
	int ret = -ENOMEM;
	int blocksize, clustersize;
	unsigned int db_count;
	unsigned int i;
	int needs_recovery, has_huge_files, has_bigalloc;
	__u64 blocks_count;
	int err = 0;
	unsigned int journal_ioprio = DEFAULT_JOURNAL_IOPRIO;
	ext4_group_t first_not_zeroed;

	sbi = kzalloc(sizeof(*sbi), GFP_KERNEL);
	if (!sbi)
		goto out_free_orig;

	sbi->s_blockgroup_lock =
		kzalloc(sizeof(struct blockgroup_lock), GFP_KERNEL);
	if (!sbi->s_blockgroup_lock) {
		kfree(sbi);
		goto out_free_orig;
	}
	sb->s_fs_info = sbi;
	sbi->s_sb = sb;
	sbi->s_inode_readahead_blks = EXT4_DEF_INODE_READAHEAD_BLKS;
	sbi->s_sb_block = sb_block;
	if (sb->s_bdev->bd_part)
		sbi->s_sectors_written_start =
			part_stat_read(sb->s_bdev->bd_part, sectors[1]);

	/* Cleanup superblock name */
	strreplace(sb->s_id, '/', '!');

	/* -EINVAL is default */
	ret = -EINVAL;
	blocksize = sb_min_blocksize(sb, EXT4_MIN_BLOCK_SIZE);
	if (!blocksize) {
		ext4_msg(sb, KERN_ERR, ""unable to set blocksize"");
		goto out_fail;
	}

	/*
	 * The ext4 superblock will not be buffer aligned for other than 1kB
	 * block sizes.  We need to calculate the offset from buffer start.
	 */
	if (blocksize != EXT4_MIN_BLOCK_SIZE) {
		logical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;
		offset = do_div(logical_sb_block, blocksize);
	} else {
		logical_sb_block = sb_block;
	}

	if (!(bh = sb_bread_unmovable(sb, logical_sb_block))) {
		ext4_msg(sb, KERN_ERR, ""unable to read superblock"");
		goto out_fail;
	}
	/*
	 * Note: s_es must be initialized as soon as possible because
	 *       some ext4 macro-instructions depend on its value
	 */
	es = (struct ext4_super_block *) (bh->b_data + offset);
	sbi->s_es = es;
	sb->s_magic = le16_to_cpu(es->s_magic);
	if (sb->s_magic != EXT4_SUPER_MAGIC)
		goto cantfind_ext4;
	sbi->s_kbytes_written = le64_to_cpu(es->s_kbytes_written);

	/* Warn if metadata_csum and gdt_csum are both set. */
	if (ext4_has_feature_metadata_csum(sb) &&
	    ext4_has_feature_gdt_csum(sb))
		ext4_warning(sb, ""metadata_csum and uninit_bg are ""
			     ""redundant flags; please run fsck."");

	/* Check for a known checksum algorithm */
	if (!ext4_verify_csum_type(sb, es)) {
		ext4_msg(sb, KERN_ERR, ""VFS: Found ext4 filesystem with ""
			 ""unknown checksum algorithm."");
		silent = 1;
		goto cantfind_ext4;
	}

	/* Load the checksum driver */
	if (ext4_has_feature_metadata_csum(sb)) {
		sbi->s_chksum_driver = crypto_alloc_shash(""crc32c"", 0, 0);
		if (IS_ERR(sbi->s_chksum_driver)) {
			ext4_msg(sb, KERN_ERR, ""Cannot load crc32c driver."");
			ret = PTR_ERR(sbi->s_chksum_driver);
			sbi->s_chksum_driver = NULL;
			goto failed_mount;
		}
	}

	/* Check superblock checksum */
	if (!ext4_superblock_csum_verify(sb, es)) {
		ext4_msg(sb, KERN_ERR, ""VFS: Found ext4 filesystem with ""
			 ""invalid superblock checksum.  Run e2fsck?"");
		silent = 1;
		ret = -EFSBADCRC;
		goto cantfind_ext4;
	}

	/* Precompute checksum seed for all metadata */
	if (ext4_has_feature_csum_seed(sb))
		sbi->s_csum_seed = le32_to_cpu(es->s_checksum_seed);
	else if (ext4_has_metadata_csum(sb))
		sbi->s_csum_seed = ext4_chksum(sbi, ~0, es->s_uuid,
					       sizeof(es->s_uuid));

	/* Set defaults before we parse the mount options */
	def_mount_opts = le32_to_cpu(es->s_default_mount_opts);
	set_opt(sb, INIT_INODE_TABLE);
	if (def_mount_opts & EXT4_DEFM_DEBUG)
		set_opt(sb, DEBUG);
	if (def_mount_opts & EXT4_DEFM_BSDGROUPS)
		set_opt(sb, GRPID);
	if (def_mount_opts & EXT4_DEFM_UID16)
		set_opt(sb, NO_UID32);
	/* xattr user namespace & acls are now defaulted on */
	set_opt(sb, XATTR_USER);
#ifdef CONFIG_EXT4_FS_POSIX_ACL
	set_opt(sb, POSIX_ACL);
#endif
	/* don't forget to enable journal_csum when metadata_csum is enabled. */
	if (ext4_has_metadata_csum(sb))
		set_opt(sb, JOURNAL_CHECKSUM);

	if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_DATA)
		set_opt(sb, JOURNAL_DATA);
	else if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_ORDERED)
		set_opt(sb, ORDERED_DATA);
	else if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_WBACK)
		set_opt(sb, WRITEBACK_DATA);

	if (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_PANIC)
		set_opt(sb, ERRORS_PANIC);
	else if (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_CONTINUE)
		set_opt(sb, ERRORS_CONT);
	else
		set_opt(sb, ERRORS_RO);
	/* block_validity enabled by default; disable with noblock_validity */
	set_opt(sb, BLOCK_VALIDITY);
	if (def_mount_opts & EXT4_DEFM_DISCARD)
		set_opt(sb, DISCARD);

	sbi->s_resuid = make_kuid(&init_user_ns, le16_to_cpu(es->s_def_resuid));
	sbi->s_resgid = make_kgid(&init_user_ns, le16_to_cpu(es->s_def_resgid));
	sbi->s_commit_interval = JBD2_DEFAULT_MAX_COMMIT_AGE * HZ;
	sbi->s_min_batch_time = EXT4_DEF_MIN_BATCH_TIME;
	sbi->s_max_batch_time = EXT4_DEF_MAX_BATCH_TIME;

	if ((def_mount_opts & EXT4_DEFM_NOBARRIER) == 0)
		set_opt(sb, BARRIER);

	/*
	 * enable delayed allocation by default
	 * Use -o nodelalloc to turn it off
	 */
	if (!IS_EXT3_SB(sb) && !IS_EXT2_SB(sb) &&
	    ((def_mount_opts & EXT4_DEFM_NODELALLOC) == 0))
		set_opt(sb, DELALLOC);

	/*
	 * set default s_li_wait_mult for lazyinit, for the case there is
	 * no mount option specified.
	 */
	sbi->s_li_wait_mult = EXT4_DEF_LI_WAIT_MULT;

	if (!parse_options((char *) sbi->s_es->s_mount_opts, sb,
			   &journal_devnum, &journal_ioprio, 0)) {
		ext4_msg(sb, KERN_WARNING,
			 ""failed to parse options in superblock: %s"",
			 sbi->s_es->s_mount_opts);
	}
	sbi->s_def_mount_opt = sbi->s_mount_opt;
	if (!parse_options((char *) data, sb, &journal_devnum,
			   &journal_ioprio, 0))
		goto failed_mount;

	if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA) {
		printk_once(KERN_WARNING ""EXT4-fs: Warning: mounting ""
			    ""with data=journal disables delayed ""
			    ""allocation and O_DIRECT support!\n"");
		if (test_opt2(sb, EXPLICIT_DELALLOC)) {
			ext4_msg(sb, KERN_ERR, ""can't mount with ""
				 ""both data=journal and delalloc"");
			goto failed_mount;
		}
		if (test_opt(sb, DIOREAD_NOLOCK)) {
			ext4_msg(sb, KERN_ERR, ""can't mount with ""
				 ""both data=journal and dioread_nolock"");
			goto failed_mount;
		}
		if (test_opt(sb, DAX)) {
			ext4_msg(sb, KERN_ERR, ""can't mount with ""
				 ""both data=journal and dax"");
			goto failed_mount;
		}
		if (test_opt(sb, DELALLOC))
			clear_opt(sb, DELALLOC);
	} else {
		sb->s_iflags |= SB_I_CGROUPWB;
	}

	sb->s_flags = (sb->s_flags & ~MS_POSIXACL) |
		(test_opt(sb, POSIX_ACL) ? MS_POSIXACL : 0);

	if (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV &&
	    (ext4_has_compat_features(sb) ||
	     ext4_has_ro_compat_features(sb) ||
	     ext4_has_incompat_features(sb)))
		ext4_msg(sb, KERN_WARNING,
		       ""feature flags set on rev 0 fs, ""
		       ""running e2fsck is recommended"");

	if (es->s_creator_os == cpu_to_le32(EXT4_OS_HURD)) {
		set_opt2(sb, HURD_COMPAT);
		if (ext4_has_feature_64bit(sb)) {
			ext4_msg(sb, KERN_ERR,
				 ""The Hurd can't support 64-bit file systems"");
			goto failed_mount;
		}
	}

	if (IS_EXT2_SB(sb)) {
		if (ext2_feature_set_ok(sb))
			ext4_msg(sb, KERN_INFO, ""mounting ext2 file system ""
				 ""using the ext4 subsystem"");
		else {
			ext4_msg(sb, KERN_ERR, ""couldn't mount as ext2 due ""
				 ""to feature incompatibilities"");
			goto failed_mount;
		}
	}

	if (IS_EXT3_SB(sb)) {
		if (ext3_feature_set_ok(sb))
			ext4_msg(sb, KERN_INFO, ""mounting ext3 file system ""
				 ""using the ext4 subsystem"");
		else {
			ext4_msg(sb, KERN_ERR, ""couldn't mount as ext3 due ""
				 ""to feature incompatibilities"");
			goto failed_mount;
		}
	}

	/*
	 * Check feature flags regardless of the revision level, since we
	 * previously didn't change the revision level when setting the flags,
	 * so there is a chance incompat flags are set on a rev 0 filesystem.
	 */
	if (!ext4_feature_set_ok(sb, (sb->s_flags & MS_RDONLY)))
		goto failed_mount;

	blocksize = BLOCK_SIZE << le32_to_cpu(es->s_log_block_size);
	if (blocksize < EXT4_MIN_BLOCK_SIZE ||
	    blocksize > EXT4_MAX_BLOCK_SIZE) {
		ext4_msg(sb, KERN_ERR,
		       ""Unsupported filesystem blocksize %d"", blocksize);
		goto failed_mount;
	}

	if (sbi->s_mount_opt & EXT4_MOUNT_DAX) {
		if (blocksize != PAGE_SIZE) {
			ext4_msg(sb, KERN_ERR,
					""error: unsupported blocksize for dax"");
			goto failed_mount;
		}
		if (!sb->s_bdev->bd_disk->fops->direct_access) {
			ext4_msg(sb, KERN_ERR,
					""error: device does not support dax"");
			goto failed_mount;
		}
	}

	if (ext4_has_feature_encrypt(sb) && es->s_encryption_level) {
		ext4_msg(sb, KERN_ERR, ""Unsupported encryption level %d"",
			 es->s_encryption_level);
		goto failed_mount;
	}

	if (sb->s_blocksize != blocksize) {
		/* Validate the filesystem blocksize */
		if (!sb_set_blocksize(sb, blocksize)) {
			ext4_msg(sb, KERN_ERR, ""bad block size %d"",
					blocksize);
			goto failed_mount;
		}

		brelse(bh);
		logical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;
		offset = do_div(logical_sb_block, blocksize);
		bh = sb_bread_unmovable(sb, logical_sb_block);
		if (!bh) {
			ext4_msg(sb, KERN_ERR,
			       ""Can't read superblock on 2nd try"");
			goto failed_mount;
		}
		es = (struct ext4_super_block *)(bh->b_data + offset);
		sbi->s_es = es;
		if (es->s_magic != cpu_to_le16(EXT4_SUPER_MAGIC)) {
			ext4_msg(sb, KERN_ERR,
			       ""Magic mismatch, very weird!"");
			goto failed_mount;
		}
	}

	has_huge_files = ext4_has_feature_huge_file(sb);
	sbi->s_bitmap_maxbytes = ext4_max_bitmap_size(sb->s_blocksize_bits,
						      has_huge_files);
	sb->s_maxbytes = ext4_max_size(sb->s_blocksize_bits, has_huge_files);

	if (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV) {
		sbi->s_inode_size = EXT4_GOOD_OLD_INODE_SIZE;
		sbi->s_first_ino = EXT4_GOOD_OLD_FIRST_INO;
	} else {
		sbi->s_inode_size = le16_to_cpu(es->s_inode_size);
		sbi->s_first_ino = le32_to_cpu(es->s_first_ino);
		if ((sbi->s_inode_size < EXT4_GOOD_OLD_INODE_SIZE) ||
		    (!is_power_of_2(sbi->s_inode_size)) ||
		    (sbi->s_inode_size > blocksize)) {
			ext4_msg(sb, KERN_ERR,
			       ""unsupported inode size: %d"",
			       sbi->s_inode_size);
			goto failed_mount;
		}
		if (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE)
			sb->s_time_gran = 1 << (EXT4_EPOCH_BITS - 2);
	}

	sbi->s_desc_size = le16_to_cpu(es->s_desc_size);
	if (ext4_has_feature_64bit(sb)) {
		if (sbi->s_desc_size < EXT4_MIN_DESC_SIZE_64BIT ||
		    sbi->s_desc_size > EXT4_MAX_DESC_SIZE ||
		    !is_power_of_2(sbi->s_desc_size)) {
			ext4_msg(sb, KERN_ERR,
			       ""unsupported descriptor size %lu"",
			       sbi->s_desc_size);
			goto failed_mount;
		}
	} else
		sbi->s_desc_size = EXT4_MIN_DESC_SIZE;

	sbi->s_blocks_per_group = le32_to_cpu(es->s_blocks_per_group);
	sbi->s_inodes_per_group = le32_to_cpu(es->s_inodes_per_group);
	if (EXT4_INODE_SIZE(sb) == 0 || EXT4_INODES_PER_GROUP(sb) == 0)
		goto cantfind_ext4;

	sbi->s_inodes_per_block = blocksize / EXT4_INODE_SIZE(sb);
	if (sbi->s_inodes_per_block == 0)
		goto cantfind_ext4;
	sbi->s_itb_per_group = sbi->s_inodes_per_group /
					sbi->s_inodes_per_block;
	sbi->s_desc_per_block = blocksize / EXT4_DESC_SIZE(sb);
	sbi->s_sbh = bh;
	sbi->s_mount_state = le16_to_cpu(es->s_state);
	sbi->s_addr_per_block_bits = ilog2(EXT4_ADDR_PER_BLOCK(sb));
	sbi->s_desc_per_block_bits = ilog2(EXT4_DESC_PER_BLOCK(sb));

	for (i = 0; i < 4; i++)
		sbi->s_hash_seed[i] = le32_to_cpu(es->s_hash_seed[i]);
	sbi->s_def_hash_version = es->s_def_hash_version;
	if (ext4_has_feature_dir_index(sb)) {
		i = le32_to_cpu(es->s_flags);
		if (i & EXT2_FLAGS_UNSIGNED_HASH)
			sbi->s_hash_unsigned = 3;
		else if ((i & EXT2_FLAGS_SIGNED_HASH) == 0) {
#ifdef __CHAR_UNSIGNED__
			if (!(sb->s_flags & MS_RDONLY))
				es->s_flags |=
					cpu_to_le32(EXT2_FLAGS_UNSIGNED_HASH);
			sbi->s_hash_unsigned = 3;
#else
			if (!(sb->s_flags & MS_RDONLY))
				es->s_flags |=
					cpu_to_le32(EXT2_FLAGS_SIGNED_HASH);
#endif
		}
	}

	/* Handle clustersize */
	clustersize = BLOCK_SIZE << le32_to_cpu(es->s_log_cluster_size);
	has_bigalloc = ext4_has_feature_bigalloc(sb);
	if (has_bigalloc) {
		if (clustersize < blocksize) {
			ext4_msg(sb, KERN_ERR,
				 ""cluster size (%d) smaller than ""
				 ""block size (%d)"", clustersize, blocksize);
			goto failed_mount;
		}
		sbi->s_cluster_bits = le32_to_cpu(es->s_log_cluster_size) -
			le32_to_cpu(es->s_log_block_size);
		sbi->s_clusters_per_group =
			le32_to_cpu(es->s_clusters_per_group);
		if (sbi->s_clusters_per_group > blocksize * 8) {
			ext4_msg(sb, KERN_ERR,
				 ""#clusters per group too big: %lu"",
				 sbi->s_clusters_per_group);
			goto failed_mount;
		}
		if (sbi->s_blocks_per_group !=
		    (sbi->s_clusters_per_group * (clustersize / blocksize))) {
			ext4_msg(sb, KERN_ERR, ""blocks per group (%lu) and ""
				 ""clusters per group (%lu) inconsistent"",
				 sbi->s_blocks_per_group,
				 sbi->s_clusters_per_group);
			goto failed_mount;
		}
	} else {
		if (clustersize != blocksize) {
			ext4_warning(sb, ""fragment/cluster size (%d) != ""
				     ""block size (%d)"", clustersize,
				     blocksize);
			clustersize = blocksize;
		}
		if (sbi->s_blocks_per_group > blocksize * 8) {
			ext4_msg(sb, KERN_ERR,
				 ""#blocks per group too big: %lu"",
				 sbi->s_blocks_per_group);
			goto failed_mount;
		}
		sbi->s_clusters_per_group = sbi->s_blocks_per_group;
		sbi->s_cluster_bits = 0;
	}
	sbi->s_cluster_ratio = clustersize / blocksize;

	if (sbi->s_inodes_per_group > blocksize * 8) {
		ext4_msg(sb, KERN_ERR,
		       ""#inodes per group too big: %lu"",
		       sbi->s_inodes_per_group);
		goto failed_mount;
	}

	/* Do we have standard group size of clustersize * 8 blocks ? */
	if (sbi->s_blocks_per_group == clustersize << 3)
		set_opt2(sb, STD_GROUP_SIZE);

	/*
	 * Test whether we have more sectors than will fit in sector_t,
	 * and whether the max offset is addressable by the page cache.
	 */
	err = generic_check_addressable(sb->s_blocksize_bits,
					ext4_blocks_count(es));
	if (err) {
		ext4_msg(sb, KERN_ERR, ""filesystem""
			 "" too large to mount safely on this system"");
		if (sizeof(sector_t) < 8)
			ext4_msg(sb, KERN_WARNING, ""CONFIG_LBDAF not enabled"");
		goto failed_mount;
	}

	if (EXT4_BLOCKS_PER_GROUP(sb) == 0)
		goto cantfind_ext4;

	/* check blocks count against device size */
	blocks_count = sb->s_bdev->bd_inode->i_size >> sb->s_blocksize_bits;
	if (blocks_count && ext4_blocks_count(es) > blocks_count) {
		ext4_msg(sb, KERN_WARNING, ""bad geometry: block count %llu ""
		       ""exceeds size of device (%llu blocks)"",
		       ext4_blocks_count(es), blocks_count);
		goto failed_mount;
	}

	/*
	 * It makes no sense for the first data block to be beyond the end
	 * of the filesystem.
	 */
	if (le32_to_cpu(es->s_first_data_block) >= ext4_blocks_count(es)) {
		ext4_msg(sb, KERN_WARNING, ""bad geometry: first data ""
			 ""block %u is beyond end of filesystem (%llu)"",
			 le32_to_cpu(es->s_first_data_block),
			 ext4_blocks_count(es));
		goto failed_mount;
	}
	blocks_count = (ext4_blocks_count(es) -
			le32_to_cpu(es->s_first_data_block) +
			EXT4_BLOCKS_PER_GROUP(sb) - 1);
	do_div(blocks_count, EXT4_BLOCKS_PER_GROUP(sb));
	if (blocks_count > ((uint64_t)1<<32) - EXT4_DESC_PER_BLOCK(sb)) {
		ext4_msg(sb, KERN_WARNING, ""groups count too large: %u ""
		       ""(block count %llu, first data block %u, ""
		       ""blocks per group %lu)"", sbi->s_groups_count,
		       ext4_blocks_count(es),
		       le32_to_cpu(es->s_first_data_block),
		       EXT4_BLOCKS_PER_GROUP(sb));
		goto failed_mount;
	}
	sbi->s_groups_count = blocks_count;
	sbi->s_blockfile_groups = min_t(ext4_group_t, sbi->s_groups_count,
			(EXT4_MAX_BLOCK_FILE_PHYS / EXT4_BLOCKS_PER_GROUP(sb)));
	db_count = (sbi->s_groups_count + EXT4_DESC_PER_BLOCK(sb) - 1) /
		   EXT4_DESC_PER_BLOCK(sb);
	sbi->s_group_desc = ext4_kvmalloc(db_count *
					  sizeof(struct buffer_head *),
					  GFP_KERNEL);
	if (sbi->s_group_desc == NULL) {
		ext4_msg(sb, KERN_ERR, ""not enough memory"");
		ret = -ENOMEM;
		goto failed_mount;
	}

	bgl_lock_init(sbi->s_blockgroup_lock);

	for (i = 0; i < db_count; i++) {
		block = descriptor_loc(sb, logical_sb_block, i);
		sbi->s_group_desc[i] = sb_bread_unmovable(sb, block);
		if (!sbi->s_group_desc[i]) {
			ext4_msg(sb, KERN_ERR,
			       ""can't read group descriptor %d"", i);
			db_count = i;
			goto failed_mount2;
		}
	}
	if (!ext4_check_descriptors(sb, &first_not_zeroed)) {
		ext4_msg(sb, KERN_ERR, ""group descriptors corrupted!"");
		ret = -EFSCORRUPTED;
		goto failed_mount2;
	}

	sbi->s_gdb_count = db_count;
	get_random_bytes(&sbi->s_next_generation, sizeof(u32));
	spin_lock_init(&sbi->s_next_gen_lock);

	setup_timer(&sbi->s_err_report, print_daily_error_info,
		(unsigned long) sb);

	/* Register extent status tree shrinker */
	if (ext4_es_register_shrinker(sbi))
		goto failed_mount3;

	sbi->s_stripe = ext4_get_stripe_size(sbi);
	sbi->s_extent_max_zeroout_kb = 32;

	/*
	 * set up enough so that it can read an inode
	 */
	sb->s_op = &ext4_sops;
	sb->s_export_op = &ext4_export_ops;
	sb->s_xattr = ext4_xattr_handlers;
#ifdef CONFIG_QUOTA
	sb->dq_op = &ext4_quota_operations;
	if (ext4_has_feature_quota(sb))
		sb->s_qcop = &dquot_quotactl_sysfile_ops;
	else
		sb->s_qcop = &ext4_qctl_operations;
	sb->s_quota_types = QTYPE_MASK_USR | QTYPE_MASK_GRP | QTYPE_MASK_PRJ;
#endif
	memcpy(sb->s_uuid, es->s_uuid, sizeof(es->s_uuid));

	INIT_LIST_HEAD(&sbi->s_orphan); /* unlinked but open files */
	mutex_init(&sbi->s_orphan_lock);

	sb->s_root = NULL;

	needs_recovery = (es->s_last_orphan != 0 ||
			  ext4_has_feature_journal_needs_recovery(sb));

	if (ext4_has_feature_mmp(sb) && !(sb->s_flags & MS_RDONLY))
		if (ext4_multi_mount_protect(sb, le64_to_cpu(es->s_mmp_block)))
			goto failed_mount3a;

	/*
	 * The first inode we look at is the journal inode.  Don't try
	 * root first: it may be modified in the journal!
	 */
	if (!test_opt(sb, NOLOAD) && ext4_has_feature_journal(sb)) {
		if (ext4_load_journal(sb, es, journal_devnum))
			goto failed_mount3a;
	} else if (test_opt(sb, NOLOAD) && !(sb->s_flags & MS_RDONLY) &&
		   ext4_has_feature_journal_needs_recovery(sb)) {
		ext4_msg(sb, KERN_ERR, ""required journal recovery ""
		       ""suppressed and not mounted read-only"");
		goto failed_mount_wq;
	} else {
		/* Nojournal mode, all journal mount options are illegal */
		if (test_opt2(sb, EXPLICIT_JOURNAL_CHECKSUM)) {
			ext4_msg(sb, KERN_ERR, ""can't mount with ""
				 ""journal_checksum, fs mounted w/o journal"");
			goto failed_mount_wq;
		}
		if (test_opt(sb, JOURNAL_ASYNC_COMMIT)) {
			ext4_msg(sb, KERN_ERR, ""can't mount with ""
				 ""journal_async_commit, fs mounted w/o journal"");
			goto failed_mount_wq;
		}
		if (sbi->s_commit_interval != JBD2_DEFAULT_MAX_COMMIT_AGE*HZ) {
			ext4_msg(sb, KERN_ERR, ""can't mount with ""
				 ""commit=%lu, fs mounted w/o journal"",
				 sbi->s_commit_interval / HZ);
			goto failed_mount_wq;
		}
		if (EXT4_MOUNT_DATA_FLAGS &
		    (sbi->s_mount_opt ^ sbi->s_def_mount_opt)) {
			ext4_msg(sb, KERN_ERR, ""can't mount with ""
				 ""data=, fs mounted w/o journal"");
			goto failed_mount_wq;
		}
		sbi->s_def_mount_opt &= EXT4_MOUNT_JOURNAL_CHECKSUM;
		clear_opt(sb, JOURNAL_CHECKSUM);
		clear_opt(sb, DATA_FLAGS);
		sbi->s_journal = NULL;
		needs_recovery = 0;
		goto no_journal;
	}

	if (ext4_has_feature_64bit(sb) &&
	    !jbd2_journal_set_features(EXT4_SB(sb)->s_journal, 0, 0,
				       JBD2_FEATURE_INCOMPAT_64BIT)) {
		ext4_msg(sb, KERN_ERR, ""Failed to set 64-bit journal feature"");
		goto failed_mount_wq;
	}

	if (!set_journal_csum_feature_set(sb)) {
		ext4_msg(sb, KERN_ERR, ""Failed to set journal checksum ""
			 ""feature set"");
		goto failed_mount_wq;
	}

	/* We have now updated the journal if required, so we can
	 * validate the data journaling mode. */
	switch (test_opt(sb, DATA_FLAGS)) {
	case 0:
		/* No mode set, assume a default based on the journal
		 * capabilities: ORDERED_DATA if the journal can
		 * cope, else JOURNAL_DATA
		 */
		if (jbd2_journal_check_available_features
		    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE))
			set_opt(sb, ORDERED_DATA);
		else
			set_opt(sb, JOURNAL_DATA);
		break;

	case EXT4_MOUNT_ORDERED_DATA:
	case EXT4_MOUNT_WRITEBACK_DATA:
		if (!jbd2_journal_check_available_features
		    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE)) {
			ext4_msg(sb, KERN_ERR, ""Journal does not support ""
			       ""requested data journaling mode"");
			goto failed_mount_wq;
		}
	default:
		break;
	}
	set_task_ioprio(sbi->s_journal->j_task, journal_ioprio);

	sbi->s_journal->j_commit_callback = ext4_journal_commit_callback;
 
 no_journal:
 	if (ext4_mballoc_ready) {
//flaw_line_below:
		sbi->s_mb_cache = ext4_xattr_create_cache(sb->s_id);
//fix_flaw_line_below:
//		sbi->s_mb_cache = ext4_xattr_create_cache();
 		if (!sbi->s_mb_cache) {
 			ext4_msg(sb, KERN_ERR, ""Failed to create an mb_cache"");
 			goto failed_mount_wq;
		}
	}

	if ((DUMMY_ENCRYPTION_ENABLED(sbi) || ext4_has_feature_encrypt(sb)) &&
	    (blocksize != PAGE_CACHE_SIZE)) {
		ext4_msg(sb, KERN_ERR,
			 ""Unsupported blocksize for fs encryption"");
		goto failed_mount_wq;
	}

	if (DUMMY_ENCRYPTION_ENABLED(sbi) && !(sb->s_flags & MS_RDONLY) &&
	    !ext4_has_feature_encrypt(sb)) {
		ext4_set_feature_encrypt(sb);
		ext4_commit_super(sb, 1);
	}

	/*
	 * Get the # of file system overhead blocks from the
	 * superblock if present.
	 */
	if (es->s_overhead_clusters)
		sbi->s_overhead = le32_to_cpu(es->s_overhead_clusters);
	else {
		err = ext4_calculate_overhead(sb);
		if (err)
			goto failed_mount_wq;
	}

	/*
	 * The maximum number of concurrent works can be high and
	 * concurrency isn't really necessary.  Limit it to 1.
	 */
	EXT4_SB(sb)->rsv_conversion_wq =
		alloc_workqueue(""ext4-rsv-conversion"", WQ_MEM_RECLAIM | WQ_UNBOUND, 1);
	if (!EXT4_SB(sb)->rsv_conversion_wq) {
		printk(KERN_ERR ""EXT4-fs: failed to create workqueue\n"");
		ret = -ENOMEM;
		goto failed_mount4;
	}

	/*
	 * The jbd2_journal_load will have done any necessary log recovery,
	 * so we can safely mount the rest of the filesystem now.
	 */

	root = ext4_iget(sb, EXT4_ROOT_INO);
	if (IS_ERR(root)) {
		ext4_msg(sb, KERN_ERR, ""get root inode failed"");
		ret = PTR_ERR(root);
		root = NULL;
		goto failed_mount4;
	}
	if (!S_ISDIR(root->i_mode) || !root->i_blocks || !root->i_size) {
		ext4_msg(sb, KERN_ERR, ""corrupt root inode, run e2fsck"");
		iput(root);
		goto failed_mount4;
	}
	sb->s_root = d_make_root(root);
	if (!sb->s_root) {
		ext4_msg(sb, KERN_ERR, ""get root dentry failed"");
		ret = -ENOMEM;
		goto failed_mount4;
	}

	if (ext4_setup_super(sb, es, sb->s_flags & MS_RDONLY))
		sb->s_flags |= MS_RDONLY;

	/* determine the minimum size of new large inodes, if present */
	if (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE) {
		sbi->s_want_extra_isize = sizeof(struct ext4_inode) -
						     EXT4_GOOD_OLD_INODE_SIZE;
		if (ext4_has_feature_extra_isize(sb)) {
			if (sbi->s_want_extra_isize <
			    le16_to_cpu(es->s_want_extra_isize))
				sbi->s_want_extra_isize =
					le16_to_cpu(es->s_want_extra_isize);
			if (sbi->s_want_extra_isize <
			    le16_to_cpu(es->s_min_extra_isize))
				sbi->s_want_extra_isize =
					le16_to_cpu(es->s_min_extra_isize);
		}
	}
	/* Check if enough inode space is available */
	if (EXT4_GOOD_OLD_INODE_SIZE + sbi->s_want_extra_isize >
							sbi->s_inode_size) {
		sbi->s_want_extra_isize = sizeof(struct ext4_inode) -
						       EXT4_GOOD_OLD_INODE_SIZE;
		ext4_msg(sb, KERN_INFO, ""required extra inode space not""
			 ""available"");
	}

	ext4_set_resv_clusters(sb);

	err = ext4_setup_system_zone(sb);
	if (err) {
		ext4_msg(sb, KERN_ERR, ""failed to initialize system ""
			 ""zone (%d)"", err);
		goto failed_mount4a;
	}

	ext4_ext_init(sb);
	err = ext4_mb_init(sb);
	if (err) {
		ext4_msg(sb, KERN_ERR, ""failed to initialize mballoc (%d)"",
			 err);
		goto failed_mount5;
	}

	block = ext4_count_free_clusters(sb);
	ext4_free_blocks_count_set(sbi->s_es, 
				   EXT4_C2B(sbi, block));
	err = percpu_counter_init(&sbi->s_freeclusters_counter, block,
				  GFP_KERNEL);
	if (!err) {
		unsigned long freei = ext4_count_free_inodes(sb);
		sbi->s_es->s_free_inodes_count = cpu_to_le32(freei);
		err = percpu_counter_init(&sbi->s_freeinodes_counter, freei,
					  GFP_KERNEL);
	}
	if (!err)
		err = percpu_counter_init(&sbi->s_dirs_counter,
					  ext4_count_dirs(sb), GFP_KERNEL);
	if (!err)
		err = percpu_counter_init(&sbi->s_dirtyclusters_counter, 0,
					  GFP_KERNEL);
	if (err) {
		ext4_msg(sb, KERN_ERR, ""insufficient memory"");
		goto failed_mount6;
	}

	if (ext4_has_feature_flex_bg(sb))
		if (!ext4_fill_flex_info(sb)) {
			ext4_msg(sb, KERN_ERR,
			       ""unable to initialize ""
			       ""flex_bg meta info!"");
			goto failed_mount6;
		}

	err = ext4_register_li_request(sb, first_not_zeroed);
	if (err)
		goto failed_mount6;

	err = ext4_register_sysfs(sb);
	if (err)
		goto failed_mount7;

#ifdef CONFIG_QUOTA
	/* Enable quota usage during mount. */
	if (ext4_has_feature_quota(sb) && !(sb->s_flags & MS_RDONLY)) {
		err = ext4_enable_quotas(sb);
		if (err)
			goto failed_mount8;
	}
#endif  /* CONFIG_QUOTA */

	EXT4_SB(sb)->s_mount_state |= EXT4_ORPHAN_FS;
	ext4_orphan_cleanup(sb, es);
	EXT4_SB(sb)->s_mount_state &= ~EXT4_ORPHAN_FS;
	if (needs_recovery) {
		ext4_msg(sb, KERN_INFO, ""recovery complete"");
		ext4_mark_recovery_complete(sb, es);
	}
	if (EXT4_SB(sb)->s_journal) {
		if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA)
			descr = "" journalled data mode"";
		else if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_ORDERED_DATA)
			descr = "" ordered data mode"";
		else
			descr = "" writeback data mode"";
	} else
		descr = ""out journal"";

	if (test_opt(sb, DISCARD)) {
		struct request_queue *q = bdev_get_queue(sb->s_bdev);
		if (!blk_queue_discard(q))
			ext4_msg(sb, KERN_WARNING,
				 ""mounting with \""discard\"" option, but ""
				 ""the device does not support discard"");
	}

	if (___ratelimit(&ext4_mount_msg_ratelimit, ""EXT4-fs mount""))
		ext4_msg(sb, KERN_INFO, ""mounted filesystem with%s. ""
			 ""Opts: %s%s%s"", descr, sbi->s_es->s_mount_opts,
			 *sbi->s_es->s_mount_opts ? ""; "" : """", orig_data);

	if (es->s_error_count)
		mod_timer(&sbi->s_err_report, jiffies + 300*HZ); /* 5 minutes */

	/* Enable message ratelimiting. Default is 10 messages per 5 secs. */
	ratelimit_state_init(&sbi->s_err_ratelimit_state, 5 * HZ, 10);
	ratelimit_state_init(&sbi->s_warning_ratelimit_state, 5 * HZ, 10);
	ratelimit_state_init(&sbi->s_msg_ratelimit_state, 5 * HZ, 10);

	kfree(orig_data);
	return 0;

cantfind_ext4:
	if (!silent)
		ext4_msg(sb, KERN_ERR, ""VFS: Can't find ext4 filesystem"");
	goto failed_mount;

#ifdef CONFIG_QUOTA
failed_mount8:
	ext4_unregister_sysfs(sb);
#endif
failed_mount7:
	ext4_unregister_li_request(sb);
failed_mount6:
	ext4_mb_release(sb);
	if (sbi->s_flex_groups)
		kvfree(sbi->s_flex_groups);
	percpu_counter_destroy(&sbi->s_freeclusters_counter);
	percpu_counter_destroy(&sbi->s_freeinodes_counter);
	percpu_counter_destroy(&sbi->s_dirs_counter);
	percpu_counter_destroy(&sbi->s_dirtyclusters_counter);
failed_mount5:
	ext4_ext_release(sb);
	ext4_release_system_zone(sb);
failed_mount4a:
	dput(sb->s_root);
	sb->s_root = NULL;
failed_mount4:
	ext4_msg(sb, KERN_ERR, ""mount failed"");
 	if (EXT4_SB(sb)->rsv_conversion_wq)
 		destroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);
 failed_mount_wq:
//fix_flaw_line_below:
//	if (sbi->s_mb_cache) {
//fix_flaw_line_below:
//		ext4_xattr_destroy_cache(sbi->s_mb_cache);
//fix_flaw_line_below:
//		sbi->s_mb_cache = NULL;
//fix_flaw_line_below:
//	}
 	if (sbi->s_journal) {
 		jbd2_journal_destroy(sbi->s_journal);
 		sbi->s_journal = NULL;
	}
failed_mount3a:
	ext4_es_unregister_shrinker(sbi);
failed_mount3:
	del_timer_sync(&sbi->s_err_report);
	if (sbi->s_mmp_tsk)
		kthread_stop(sbi->s_mmp_tsk);
failed_mount2:
	for (i = 0; i < db_count; i++)
		brelse(sbi->s_group_desc[i]);
	kvfree(sbi->s_group_desc);
failed_mount:
	if (sbi->s_chksum_driver)
		crypto_free_shash(sbi->s_chksum_driver);
#ifdef CONFIG_QUOTA
	for (i = 0; i < EXT4_MAXQUOTAS; i++)
		kfree(sbi->s_qf_names[i]);
#endif
	ext4_blkdev_remove(sbi);
	brelse(bh);
out_fail:
	sb->s_fs_info = NULL;
	kfree(sbi->s_blockgroup_lock);
	kfree(sbi);
out_free_orig:
	kfree(orig_data);
	return err ? err : ret;
}
"
5423,183159,,Local,Not required,Partial,CVE-2015-8952,https://www.cvedetails.com/cve/CVE-2015-8952/,CWE-19,Low,,,,2016-10-16,2.1,"The mbcache feature in the ext2 and ext4 filesystem implementations in the Linux kernel before 4.6 mishandles xattr block caching, which allows local users to cause a denial of service (soft lockup) via filesystem operations in environments that use many attributes, as demonstrated by Ceph and Samba.",2018-03-15,DoS ,0,https://github.com/torvalds/linux/commit/82939d7999dfc1f1998c4b1c12e2f19edbdff272,82939d7999dfc1f1998c4b1c12e2f19edbdff272,"ext4: convert to mbcache2

The conversion is generally straightforward. The only tricky part is
that xattr block corresponding to found mbcache entry can get freed
before we get buffer lock for that block. So we have to check whether
the entry is still valid after getting buffer lock.

Signed-off-by: Jan Kara <jack@suse.cz>
Signed-off-by: Theodore Ts'o <tytso@mit.edu>",1,fs/ext4/super.c,"{""sha"": ""9ac9e62569ef8fdf981021b58d37ab99d0150882"", ""filename"": ""fs/ext4/ext4.h"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 1, ""changes"": 2, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/ext4.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/ext4.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/ext4.h?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -1468,7 +1468,7 @@ struct ext4_sb_info {\n \tstruct list_head s_es_list;\t/* List of inodes with reclaimable extents */\n \tlong s_es_nr_inode;\n \tstruct ext4_es_stats s_es_stats;\n-\tstruct mb_cache *s_mb_cache;\n+\tstruct mb2_cache *s_mb_cache;\n \tspinlock_t s_es_lock ____cacheline_aligned_in_smp;\n \n \t/* Ratelimit ext4 messages. */""}<_**next**_>{""sha"": ""ecc37e1034358d769ab29971e9d2301fb9e2b3bc"", ""filename"": ""fs/ext4/super.c"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 2, ""changes"": 7, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/super.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/super.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/super.c?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -844,7 +844,6 @@ static void ext4_put_super(struct super_block *sb)\n \text4_release_system_zone(sb);\n \text4_mb_release(sb);\n \text4_ext_release(sb);\n-\text4_xattr_put_super(sb);\n \n \tif (!(sb->s_flags & MS_RDONLY)) {\n \t\text4_clear_feature_journal_needs_recovery(sb);\n@@ -3797,7 +3796,7 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n \n no_journal:\n \tif (ext4_mballoc_ready) {\n-\t\tsbi->s_mb_cache = ext4_xattr_create_cache(sb->s_id);\n+\t\tsbi->s_mb_cache = ext4_xattr_create_cache();\n \t\tif (!sbi->s_mb_cache) {\n \t\t\text4_msg(sb, KERN_ERR, \""Failed to create an mb_cache\"");\n \t\t\tgoto failed_mount_wq;\n@@ -4027,6 +4026,10 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n \tif (EXT4_SB(sb)->rsv_conversion_wq)\n \t\tdestroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);\n failed_mount_wq:\n+\tif (sbi->s_mb_cache) {\n+\t\text4_xattr_destroy_cache(sbi->s_mb_cache);\n+\t\tsbi->s_mb_cache = NULL;\n+\t}\n \tif (sbi->s_journal) {\n \t\tjbd2_journal_destroy(sbi->s_journal);\n \t\tsbi->s_journal = NULL;""}<_**next**_>{""sha"": ""fe9f8d6ab6c91b60689abadefd5435c31893fcae"", ""filename"": ""fs/ext4/xattr.c"", ""status"": ""modified"", ""additions"": 67, ""deletions"": 69, ""changes"": 136, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/xattr.c?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -53,7 +53,7 @@\n #include <linux/init.h>\n #include <linux/fs.h>\n #include <linux/slab.h>\n-#include <linux/mbcache.h>\n+#include <linux/mbcache2.h>\n #include <linux/quotaops.h>\n #include \""ext4_jbd2.h\""\n #include \""ext4.h\""\n@@ -78,10 +78,10 @@\n # define ea_bdebug(bh, fmt, ...)\tno_printk(fmt, ##__VA_ARGS__)\n #endif\n \n-static void ext4_xattr_cache_insert(struct mb_cache *, struct buffer_head *);\n+static void ext4_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);\n static struct buffer_head *ext4_xattr_cache_find(struct inode *,\n \t\t\t\t\t\t struct ext4_xattr_header *,\n-\t\t\t\t\t\t struct mb_cache_entry **);\n+\t\t\t\t\t\t struct mb2_cache_entry **);\n static void ext4_xattr_rehash(struct ext4_xattr_header *,\n \t\t\t      struct ext4_xattr_entry *);\n static int ext4_xattr_list(struct dentry *dentry, char *buffer,\n@@ -276,7 +276,7 @@ ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,\n \tstruct ext4_xattr_entry *entry;\n \tsize_t size;\n \tint error;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tea_idebug(inode, \""name=%d.%s, buffer=%p, buffer_size=%ld\"",\n \t\t  name_index, name, buffer, (long)buffer_size);\n@@ -428,7 +428,7 @@ ext4_xattr_block_list(struct dentry *dentry, char *buffer, size_t buffer_size)\n \tstruct inode *inode = d_inode(dentry);\n \tstruct buffer_head *bh = NULL;\n \tint error;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tea_idebug(inode, \""buffer=%p, buffer_size=%ld\"",\n \t\t  buffer, (long)buffer_size);\n@@ -545,30 +545,31 @@ static void\n ext4_xattr_release_block(handle_t *handle, struct inode *inode,\n \t\t\t struct buffer_head *bh)\n {\n-\tstruct mb_cache_entry *ce = NULL;\n \tint error = 0;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n-\tce = mb_cache_entry_get(ext4_mb_cache, bh->b_bdev, bh->b_blocknr);\n \tBUFFER_TRACE(bh, \""get_write_access\"");\n \terror = ext4_journal_get_write_access(handle, bh);\n \tif (error)\n \t\tgoto out;\n \n \tlock_buffer(bh);\n \tif (BHDR(bh)->h_refcount == cpu_to_le32(1)) {\n+\t\t__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);\n+\n \t\tea_bdebug(bh, \""refcount now=0; freeing\"");\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_free(ce);\n+\t\t/*\n+\t\t * This must happen under buffer lock for\n+\t\t * ext4_xattr_block_set() to reliably detect freed block\n+\t\t */\n+\t\tmb2_cache_entry_delete_block(EXT4_GET_MB_CACHE(inode), hash,\n+\t\t\t\t\t     bh->b_blocknr);\n \t\tget_bh(bh);\n \t\tunlock_buffer(bh);\n \t\text4_free_blocks(handle, inode, bh, 0, 1,\n \t\t\t\t EXT4_FREE_BLOCKS_METADATA |\n \t\t\t\t EXT4_FREE_BLOCKS_FORGET);\n \t} else {\n \t\tle32_add_cpu(&BHDR(bh)->h_refcount, -1);\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_release(ce);\n \t\t/*\n \t\t * Beware of this ugliness: Releasing of xattr block references\n \t\t * from different inodes can race and so we have to protect\n@@ -781,28 +782,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \tstruct super_block *sb = inode->i_sb;\n \tstruct buffer_head *new_bh = NULL;\n \tstruct ext4_xattr_search *s = &bs->s;\n-\tstruct mb_cache_entry *ce = NULL;\n+\tstruct mb2_cache_entry *ce = NULL;\n \tint error = 0;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n #define header(x) ((struct ext4_xattr_header *)(x))\n \n \tif (i->value && i->value_len > sb->s_blocksize)\n \t\treturn -ENOSPC;\n \tif (s->base) {\n-\t\tce = mb_cache_entry_get(ext4_mb_cache, bs->bh->b_bdev,\n-\t\t\t\t\tbs->bh->b_blocknr);\n \t\tBUFFER_TRACE(bs->bh, \""get_write_access\"");\n \t\terror = ext4_journal_get_write_access(handle, bs->bh);\n \t\tif (error)\n \t\t\tgoto cleanup;\n \t\tlock_buffer(bs->bh);\n \n \t\tif (header(s->base)->h_refcount == cpu_to_le32(1)) {\n-\t\t\tif (ce) {\n-\t\t\t\tmb_cache_entry_free(ce);\n-\t\t\t\tce = NULL;\n-\t\t\t}\n+\t\t\t__u32 hash = le32_to_cpu(BHDR(bs->bh)->h_hash);\n+\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext4_xattr_block_set() to reliably detect modified\n+\t\t\t * block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(ext4_mb_cache, hash,\n+\t\t\t\t\t\t     bs->bh->b_blocknr);\n \t\t\tea_bdebug(bs->bh, \""modifying in-place\"");\n \t\t\terror = ext4_xattr_set_entry(i, s);\n \t\t\tif (!error) {\n@@ -826,10 +830,6 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\tint offset = (char *)s->here - bs->bh->b_data;\n \n \t\t\tunlock_buffer(bs->bh);\n-\t\t\tif (ce) {\n-\t\t\t\tmb_cache_entry_release(ce);\n-\t\t\t\tce = NULL;\n-\t\t\t}\n \t\t\tea_bdebug(bs->bh, \""cloning\"");\n \t\t\ts->base = kmalloc(bs->bh->b_size, GFP_NOFS);\n \t\t\terror = -ENOMEM;\n@@ -884,6 +884,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\t\tif (error)\n \t\t\t\t\tgoto cleanup_dquot;\n \t\t\t\tlock_buffer(new_bh);\n+\t\t\t\t/*\n+\t\t\t\t * We have to be careful about races with\n+\t\t\t\t * freeing or rehashing of xattr block. Once we\n+\t\t\t\t * hold buffer lock xattr block's state is\n+\t\t\t\t * stable so we can check whether the block got\n+\t\t\t\t * freed / rehashed or not.  Since we unhash\n+\t\t\t\t * mbcache entry under buffer lock when freeing\n+\t\t\t\t * / rehashing xattr block, checking whether\n+\t\t\t\t * entry is still hashed is reliable.\n+\t\t\t\t */\n+\t\t\t\tif (hlist_bl_unhashed(&ce->e_hash_list)) {\n+\t\t\t\t\t/*\n+\t\t\t\t\t * Undo everything and check mbcache\n+\t\t\t\t\t * again.\n+\t\t\t\t\t */\n+\t\t\t\t\tunlock_buffer(new_bh);\n+\t\t\t\t\tdquot_free_block(inode,\n+\t\t\t\t\t\t\t EXT4_C2B(EXT4_SB(sb),\n+\t\t\t\t\t\t\t\t  1));\n+\t\t\t\t\tbrelse(new_bh);\n+\t\t\t\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n+\t\t\t\t\tce = NULL;\n+\t\t\t\t\tnew_bh = NULL;\n+\t\t\t\t\tgoto inserted;\n+\t\t\t\t}\n \t\t\t\tle32_add_cpu(&BHDR(new_bh)->h_refcount, 1);\n \t\t\t\tea_bdebug(new_bh, \""reusing; refcount now=%d\"",\n \t\t\t\t\tle32_to_cpu(BHDR(new_bh)->h_refcount));\n@@ -894,7 +919,8 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\t\tif (error)\n \t\t\t\t\tgoto cleanup_dquot;\n \t\t\t}\n-\t\t\tmb_cache_entry_release(ce);\n+\t\t\tmb2_cache_entry_touch(ext4_mb_cache, ce);\n+\t\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n \t\t\tce = NULL;\n \t\t} else if (bs->bh && s->base == bs->bh->b_data) {\n \t\t\t/* We were modifying this block in-place. */\n@@ -959,7 +985,7 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \n cleanup:\n \tif (ce)\n-\t\tmb_cache_entry_release(ce);\n+\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n \tbrelse(new_bh);\n \tif (!(bs->bh && s->base == bs->bh->b_data))\n \t\tkfree(s->base);\n@@ -1511,17 +1537,6 @@ ext4_xattr_delete_inode(handle_t *handle, struct inode *inode)\n \tbrelse(bh);\n }\n \n-/*\n- * ext4_xattr_put_super()\n- *\n- * This is called when a file system is unmounted.\n- */\n-void\n-ext4_xattr_put_super(struct super_block *sb)\n-{\n-\tmb_cache_shrink(sb->s_bdev);\n-}\n-\n /*\n  * ext4_xattr_cache_insert()\n  *\n@@ -1531,28 +1546,18 @@ ext4_xattr_put_super(struct super_block *sb)\n  * Returns 0, or a negative error number on failure.\n  */\n static void\n-ext4_xattr_cache_insert(struct mb_cache *ext4_mb_cache, struct buffer_head *bh)\n+ext4_xattr_cache_insert(struct mb2_cache *ext4_mb_cache, struct buffer_head *bh)\n {\n \t__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);\n-\tstruct mb_cache_entry *ce;\n \tint error;\n \n-\tce = mb_cache_entry_alloc(ext4_mb_cache, GFP_NOFS);\n-\tif (!ce) {\n-\t\tea_bdebug(bh, \""out of memory\"");\n-\t\treturn;\n-\t}\n-\terror = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);\n+\terror = mb2_cache_entry_create(ext4_mb_cache, GFP_NOFS, hash,\n+\t\t\t\t       bh->b_blocknr);\n \tif (error) {\n-\t\tmb_cache_entry_free(ce);\n-\t\tif (error == -EBUSY) {\n+\t\tif (error == -EBUSY)\n \t\t\tea_bdebug(bh, \""already in cache\"");\n-\t\t\terror = 0;\n-\t\t}\n-\t} else {\n+\t} else\n \t\tea_bdebug(bh, \""inserting [%x]\"", (int)hash);\n-\t\tmb_cache_entry_release(ce);\n-\t}\n }\n \n /*\n@@ -1605,26 +1610,19 @@ ext4_xattr_cmp(struct ext4_xattr_header *header1,\n  */\n static struct buffer_head *\n ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,\n-\t\t      struct mb_cache_entry **pce)\n+\t\t      struct mb2_cache_entry **pce)\n {\n \t__u32 hash = le32_to_cpu(header->h_hash);\n-\tstruct mb_cache_entry *ce;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache_entry *ce;\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tif (!header->h_hash)\n \t\treturn NULL;  /* never share */\n \tea_idebug(inode, \""looking for cached blocks [%x]\"", (int)hash);\n-again:\n-\tce = mb_cache_entry_find_first(ext4_mb_cache, inode->i_sb->s_bdev,\n-\t\t\t\t       hash);\n+\tce = mb2_cache_entry_find_first(ext4_mb_cache, hash);\n \twhile (ce) {\n \t\tstruct buffer_head *bh;\n \n-\t\tif (IS_ERR(ce)) {\n-\t\t\tif (PTR_ERR(ce) == -EAGAIN)\n-\t\t\t\tgoto again;\n-\t\t\tbreak;\n-\t\t}\n \t\tbh = sb_bread(inode->i_sb, ce->e_block);\n \t\tif (!bh) {\n \t\t\tEXT4_ERROR_INODE(inode, \""block %lu read error\"",\n@@ -1640,7 +1638,7 @@ ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,\n \t\t\treturn bh;\n \t\t}\n \t\tbrelse(bh);\n-\t\tce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);\n+\t\tce = mb2_cache_entry_find_next(ext4_mb_cache, ce);\n \t}\n \treturn NULL;\n }\n@@ -1715,15 +1713,15 @@ static void ext4_xattr_rehash(struct ext4_xattr_header *header,\n \n #define\tHASH_BUCKET_BITS\t10\n \n-struct mb_cache *\n-ext4_xattr_create_cache(char *name)\n+struct mb2_cache *\n+ext4_xattr_create_cache(void)\n {\n-\treturn mb_cache_create(name, HASH_BUCKET_BITS);\n+\treturn mb2_cache_create(HASH_BUCKET_BITS);\n }\n \n-void ext4_xattr_destroy_cache(struct mb_cache *cache)\n+void ext4_xattr_destroy_cache(struct mb2_cache *cache)\n {\n \tif (cache)\n-\t\tmb_cache_destroy(cache);\n+\t\tmb2_cache_destroy(cache);\n }\n ""}<_**next**_>{""sha"": ""10b0f7323ed6fcd628efee26998d0f1be7652c48"", ""filename"": ""fs/ext4/xattr.h"", ""status"": ""modified"", ""additions"": 2, ""deletions"": 3, ""changes"": 5, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/xattr.h?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -108,7 +108,6 @@ extern int ext4_xattr_set(struct inode *, int, const char *, const void *, size_\n extern int ext4_xattr_set_handle(handle_t *, struct inode *, int, const char *, const void *, size_t, int);\n \n extern void ext4_xattr_delete_inode(handle_t *, struct inode *);\n-extern void ext4_xattr_put_super(struct super_block *);\n \n extern int ext4_expand_extra_isize_ea(struct inode *inode, int new_extra_isize,\n \t\t\t    struct ext4_inode *raw_inode, handle_t *handle);\n@@ -124,8 +123,8 @@ extern int ext4_xattr_ibody_inline_set(handle_t *handle, struct inode *inode,\n \t\t\t\t       struct ext4_xattr_info *i,\n \t\t\t\t       struct ext4_xattr_ibody_find *is);\n \n-extern struct mb_cache *ext4_xattr_create_cache(char *name);\n-extern void ext4_xattr_destroy_cache(struct mb_cache *);\n+extern struct mb2_cache *ext4_xattr_create_cache(void);\n+extern void ext4_xattr_destroy_cache(struct mb2_cache *);\n \n #ifdef CONFIG_EXT4_FS_SECURITY\n extern int ext4_init_security(handle_t *handle, struct inode *inode,""}","static void ext4_put_super(struct super_block *sb)
{
	struct ext4_sb_info *sbi = EXT4_SB(sb);
	struct ext4_super_block *es = sbi->s_es;
	int i, err;

	ext4_unregister_li_request(sb);
	dquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);

	flush_workqueue(sbi->rsv_conversion_wq);
	destroy_workqueue(sbi->rsv_conversion_wq);

	if (sbi->s_journal) {
		err = jbd2_journal_destroy(sbi->s_journal);
		sbi->s_journal = NULL;
		if (err < 0)
			ext4_abort(sb, ""Couldn't clean up the journal"");
	}

	ext4_unregister_sysfs(sb);
	ext4_es_unregister_shrinker(sbi);
	del_timer_sync(&sbi->s_err_report);
 	ext4_release_system_zone(sb);
 	ext4_mb_release(sb);
 	ext4_ext_release(sb);
 
 	if (!(sb->s_flags & MS_RDONLY)) {
 		ext4_clear_feature_journal_needs_recovery(sb);
		es->s_state = cpu_to_le16(sbi->s_mount_state);
	}
	if (!(sb->s_flags & MS_RDONLY))
		ext4_commit_super(sb, 1);

	for (i = 0; i < sbi->s_gdb_count; i++)
		brelse(sbi->s_group_desc[i]);
	kvfree(sbi->s_group_desc);
	kvfree(sbi->s_flex_groups);
	percpu_counter_destroy(&sbi->s_freeclusters_counter);
	percpu_counter_destroy(&sbi->s_freeinodes_counter);
	percpu_counter_destroy(&sbi->s_dirs_counter);
	percpu_counter_destroy(&sbi->s_dirtyclusters_counter);
	brelse(sbi->s_sbh);
#ifdef CONFIG_QUOTA
	for (i = 0; i < EXT4_MAXQUOTAS; i++)
		kfree(sbi->s_qf_names[i]);
#endif

	/* Debugging code just in case the in-memory inode orphan list
	 * isn't empty.  The on-disk one can be non-empty if we've
	 * detected an error and taken the fs readonly, but the
	 * in-memory list had better be clean by this point. */
	if (!list_empty(&sbi->s_orphan))
		dump_orphan_list(sb, sbi);
	J_ASSERT(list_empty(&sbi->s_orphan));

	sync_blockdev(sb->s_bdev);
	invalidate_bdev(sb->s_bdev);
	if (sbi->journal_bdev && sbi->journal_bdev != sb->s_bdev) {
		/*
		 * Invalidate the journal device's buffers.  We don't want them
		 * floating about in memory - the physical journal device may
		 * hotswapped, and it breaks the `ro-after' testing code.
		 */
		sync_blockdev(sbi->journal_bdev);
		invalidate_bdev(sbi->journal_bdev);
		ext4_blkdev_remove(sbi);
	}
	if (sbi->s_mb_cache) {
		ext4_xattr_destroy_cache(sbi->s_mb_cache);
		sbi->s_mb_cache = NULL;
	}
	if (sbi->s_mmp_tsk)
		kthread_stop(sbi->s_mmp_tsk);
	sb->s_fs_info = NULL;
	/*
	 * Now that we are completely done shutting down the
	 * superblock, we need to actually destroy the kobject.
	 */
	kobject_put(&sbi->s_kobj);
	wait_for_completion(&sbi->s_kobj_unregister);
	if (sbi->s_chksum_driver)
		crypto_free_shash(sbi->s_chksum_driver);
	kfree(sbi->s_blockgroup_lock);
	kfree(sbi);
}
","static void ext4_put_super(struct super_block *sb)
{
	struct ext4_sb_info *sbi = EXT4_SB(sb);
	struct ext4_super_block *es = sbi->s_es;
	int i, err;

	ext4_unregister_li_request(sb);
	dquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);

	flush_workqueue(sbi->rsv_conversion_wq);
	destroy_workqueue(sbi->rsv_conversion_wq);

	if (sbi->s_journal) {
		err = jbd2_journal_destroy(sbi->s_journal);
		sbi->s_journal = NULL;
		if (err < 0)
			ext4_abort(sb, ""Couldn't clean up the journal"");
	}

	ext4_unregister_sysfs(sb);
	ext4_es_unregister_shrinker(sbi);
	del_timer_sync(&sbi->s_err_report);
 	ext4_release_system_zone(sb);
 	ext4_mb_release(sb);
 	ext4_ext_release(sb);
	ext4_xattr_put_super(sb);
 
 	if (!(sb->s_flags & MS_RDONLY)) {
 		ext4_clear_feature_journal_needs_recovery(sb);
		es->s_state = cpu_to_le16(sbi->s_mount_state);
	}
	if (!(sb->s_flags & MS_RDONLY))
		ext4_commit_super(sb, 1);

	for (i = 0; i < sbi->s_gdb_count; i++)
		brelse(sbi->s_group_desc[i]);
	kvfree(sbi->s_group_desc);
	kvfree(sbi->s_flex_groups);
	percpu_counter_destroy(&sbi->s_freeclusters_counter);
	percpu_counter_destroy(&sbi->s_freeinodes_counter);
	percpu_counter_destroy(&sbi->s_dirs_counter);
	percpu_counter_destroy(&sbi->s_dirtyclusters_counter);
	brelse(sbi->s_sbh);
#ifdef CONFIG_QUOTA
	for (i = 0; i < EXT4_MAXQUOTAS; i++)
		kfree(sbi->s_qf_names[i]);
#endif

	/* Debugging code just in case the in-memory inode orphan list
	 * isn't empty.  The on-disk one can be non-empty if we've
	 * detected an error and taken the fs readonly, but the
	 * in-memory list had better be clean by this point. */
	if (!list_empty(&sbi->s_orphan))
		dump_orphan_list(sb, sbi);
	J_ASSERT(list_empty(&sbi->s_orphan));

	sync_blockdev(sb->s_bdev);
	invalidate_bdev(sb->s_bdev);
	if (sbi->journal_bdev && sbi->journal_bdev != sb->s_bdev) {
		/*
		 * Invalidate the journal device's buffers.  We don't want them
		 * floating about in memory - the physical journal device may
		 * hotswapped, and it breaks the `ro-after' testing code.
		 */
		sync_blockdev(sbi->journal_bdev);
		invalidate_bdev(sbi->journal_bdev);
		ext4_blkdev_remove(sbi);
	}
	if (sbi->s_mb_cache) {
		ext4_xattr_destroy_cache(sbi->s_mb_cache);
		sbi->s_mb_cache = NULL;
	}
	if (sbi->s_mmp_tsk)
		kthread_stop(sbi->s_mmp_tsk);
	sb->s_fs_info = NULL;
	/*
	 * Now that we are completely done shutting down the
	 * superblock, we need to actually destroy the kobject.
	 */
	kobject_put(&sbi->s_kobj);
	wait_for_completion(&sbi->s_kobj_unregister);
	if (sbi->s_chksum_driver)
		crypto_free_shash(sbi->s_chksum_driver);
	kfree(sbi->s_blockgroup_lock);
	kfree(sbi);
}
",C,,"	ext4_xattr_put_super(sb);
",,"@@ -844,7 +844,6 @@ static void ext4_put_super(struct super_block *sb)
 	ext4_release_system_zone(sb);
 	ext4_mb_release(sb);
 	ext4_ext_release(sb);
-	ext4_xattr_put_super(sb);
 
 	if (!(sb->s_flags & MS_RDONLY)) {
 		ext4_clear_feature_journal_needs_recovery(sb);
@@ -3797,7 +3796,7 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)
 
 no_journal:
 	if (ext4_mballoc_ready) {
-		sbi->s_mb_cache = ext4_xattr_create_cache(sb->s_id);
+		sbi->s_mb_cache = ext4_xattr_create_cache();
 		if (!sbi->s_mb_cache) {
 			ext4_msg(sb, KERN_ERR, ""Failed to create an mb_cache"");
 			goto failed_mount_wq;
@@ -4027,6 +4026,10 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)
 	if (EXT4_SB(sb)->rsv_conversion_wq)
 		destroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);
 failed_mount_wq:
+	if (sbi->s_mb_cache) {
+		ext4_xattr_destroy_cache(sbi->s_mb_cache);
+		sbi->s_mb_cache = NULL;
+	}
 	if (sbi->s_journal) {
 		jbd2_journal_destroy(sbi->s_journal);
 		sbi->s_journal = NULL;",linux,82939d7999dfc1f1998c4b1c12e2f19edbdff272,f9a61eb4e2471c56a63cd804c7474128138c38ac,1,"static void ext4_put_super(struct super_block *sb)
{
	struct ext4_sb_info *sbi = EXT4_SB(sb);
	struct ext4_super_block *es = sbi->s_es;
	int i, err;

	ext4_unregister_li_request(sb);
	dquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);

	flush_workqueue(sbi->rsv_conversion_wq);
	destroy_workqueue(sbi->rsv_conversion_wq);

	if (sbi->s_journal) {
		err = jbd2_journal_destroy(sbi->s_journal);
		sbi->s_journal = NULL;
		if (err < 0)
			ext4_abort(sb, ""Couldn't clean up the journal"");
	}

	ext4_unregister_sysfs(sb);
	ext4_es_unregister_shrinker(sbi);
	del_timer_sync(&sbi->s_err_report);
 	ext4_release_system_zone(sb);
 	ext4_mb_release(sb);
 	ext4_ext_release(sb);
//flaw_line_below:
	ext4_xattr_put_super(sb);
 
 	if (!(sb->s_flags & MS_RDONLY)) {
 		ext4_clear_feature_journal_needs_recovery(sb);
		es->s_state = cpu_to_le16(sbi->s_mount_state);
	}
	if (!(sb->s_flags & MS_RDONLY))
		ext4_commit_super(sb, 1);

	for (i = 0; i < sbi->s_gdb_count; i++)
		brelse(sbi->s_group_desc[i]);
	kvfree(sbi->s_group_desc);
	kvfree(sbi->s_flex_groups);
	percpu_counter_destroy(&sbi->s_freeclusters_counter);
	percpu_counter_destroy(&sbi->s_freeinodes_counter);
	percpu_counter_destroy(&sbi->s_dirs_counter);
	percpu_counter_destroy(&sbi->s_dirtyclusters_counter);
	brelse(sbi->s_sbh);
#ifdef CONFIG_QUOTA
	for (i = 0; i < EXT4_MAXQUOTAS; i++)
		kfree(sbi->s_qf_names[i]);
#endif

	/* Debugging code just in case the in-memory inode orphan list
	 * isn't empty.  The on-disk one can be non-empty if we've
	 * detected an error and taken the fs readonly, but the
	 * in-memory list had better be clean by this point. */
	if (!list_empty(&sbi->s_orphan))
		dump_orphan_list(sb, sbi);
	J_ASSERT(list_empty(&sbi->s_orphan));

	sync_blockdev(sb->s_bdev);
	invalidate_bdev(sb->s_bdev);
	if (sbi->journal_bdev && sbi->journal_bdev != sb->s_bdev) {
		/*
		 * Invalidate the journal device's buffers.  We don't want them
		 * floating about in memory - the physical journal device may
		 * hotswapped, and it breaks the `ro-after' testing code.
		 */
		sync_blockdev(sbi->journal_bdev);
		invalidate_bdev(sbi->journal_bdev);
		ext4_blkdev_remove(sbi);
	}
	if (sbi->s_mb_cache) {
		ext4_xattr_destroy_cache(sbi->s_mb_cache);
		sbi->s_mb_cache = NULL;
	}
	if (sbi->s_mmp_tsk)
		kthread_stop(sbi->s_mmp_tsk);
	sb->s_fs_info = NULL;
	/*
	 * Now that we are completely done shutting down the
	 * superblock, we need to actually destroy the kobject.
	 */
	kobject_put(&sbi->s_kobj);
	wait_for_completion(&sbi->s_kobj_unregister);
	if (sbi->s_chksum_driver)
		crypto_free_shash(sbi->s_chksum_driver);
	kfree(sbi->s_blockgroup_lock);
	kfree(sbi);
}
"
5424,183160,,Local,Not required,Partial,CVE-2015-8952,https://www.cvedetails.com/cve/CVE-2015-8952/,CWE-19,Low,,,,2016-10-16,2.1,"The mbcache feature in the ext2 and ext4 filesystem implementations in the Linux kernel before 4.6 mishandles xattr block caching, which allows local users to cause a denial of service (soft lockup) via filesystem operations in environments that use many attributes, as demonstrated by Ceph and Samba.",2018-03-15,DoS ,1,https://github.com/torvalds/linux/commit/82939d7999dfc1f1998c4b1c12e2f19edbdff272,82939d7999dfc1f1998c4b1c12e2f19edbdff272,"ext4: convert to mbcache2

The conversion is generally straightforward. The only tricky part is
that xattr block corresponding to found mbcache entry can get freed
before we get buffer lock for that block. So we have to check whether
the entry is still valid after getting buffer lock.

Signed-off-by: Jan Kara <jack@suse.cz>
Signed-off-by: Theodore Ts'o <tytso@mit.edu>",1,fs/ext4/xattr.c,"{""sha"": ""9ac9e62569ef8fdf981021b58d37ab99d0150882"", ""filename"": ""fs/ext4/ext4.h"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 1, ""changes"": 2, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/ext4.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/ext4.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/ext4.h?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -1468,7 +1468,7 @@ struct ext4_sb_info {\n \tstruct list_head s_es_list;\t/* List of inodes with reclaimable extents */\n \tlong s_es_nr_inode;\n \tstruct ext4_es_stats s_es_stats;\n-\tstruct mb_cache *s_mb_cache;\n+\tstruct mb2_cache *s_mb_cache;\n \tspinlock_t s_es_lock ____cacheline_aligned_in_smp;\n \n \t/* Ratelimit ext4 messages. */""}<_**next**_>{""sha"": ""ecc37e1034358d769ab29971e9d2301fb9e2b3bc"", ""filename"": ""fs/ext4/super.c"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 2, ""changes"": 7, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/super.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/super.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/super.c?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -844,7 +844,6 @@ static void ext4_put_super(struct super_block *sb)\n \text4_release_system_zone(sb);\n \text4_mb_release(sb);\n \text4_ext_release(sb);\n-\text4_xattr_put_super(sb);\n \n \tif (!(sb->s_flags & MS_RDONLY)) {\n \t\text4_clear_feature_journal_needs_recovery(sb);\n@@ -3797,7 +3796,7 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n \n no_journal:\n \tif (ext4_mballoc_ready) {\n-\t\tsbi->s_mb_cache = ext4_xattr_create_cache(sb->s_id);\n+\t\tsbi->s_mb_cache = ext4_xattr_create_cache();\n \t\tif (!sbi->s_mb_cache) {\n \t\t\text4_msg(sb, KERN_ERR, \""Failed to create an mb_cache\"");\n \t\t\tgoto failed_mount_wq;\n@@ -4027,6 +4026,10 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n \tif (EXT4_SB(sb)->rsv_conversion_wq)\n \t\tdestroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);\n failed_mount_wq:\n+\tif (sbi->s_mb_cache) {\n+\t\text4_xattr_destroy_cache(sbi->s_mb_cache);\n+\t\tsbi->s_mb_cache = NULL;\n+\t}\n \tif (sbi->s_journal) {\n \t\tjbd2_journal_destroy(sbi->s_journal);\n \t\tsbi->s_journal = NULL;""}<_**next**_>{""sha"": ""fe9f8d6ab6c91b60689abadefd5435c31893fcae"", ""filename"": ""fs/ext4/xattr.c"", ""status"": ""modified"", ""additions"": 67, ""deletions"": 69, ""changes"": 136, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/xattr.c?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -53,7 +53,7 @@\n #include <linux/init.h>\n #include <linux/fs.h>\n #include <linux/slab.h>\n-#include <linux/mbcache.h>\n+#include <linux/mbcache2.h>\n #include <linux/quotaops.h>\n #include \""ext4_jbd2.h\""\n #include \""ext4.h\""\n@@ -78,10 +78,10 @@\n # define ea_bdebug(bh, fmt, ...)\tno_printk(fmt, ##__VA_ARGS__)\n #endif\n \n-static void ext4_xattr_cache_insert(struct mb_cache *, struct buffer_head *);\n+static void ext4_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);\n static struct buffer_head *ext4_xattr_cache_find(struct inode *,\n \t\t\t\t\t\t struct ext4_xattr_header *,\n-\t\t\t\t\t\t struct mb_cache_entry **);\n+\t\t\t\t\t\t struct mb2_cache_entry **);\n static void ext4_xattr_rehash(struct ext4_xattr_header *,\n \t\t\t      struct ext4_xattr_entry *);\n static int ext4_xattr_list(struct dentry *dentry, char *buffer,\n@@ -276,7 +276,7 @@ ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,\n \tstruct ext4_xattr_entry *entry;\n \tsize_t size;\n \tint error;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tea_idebug(inode, \""name=%d.%s, buffer=%p, buffer_size=%ld\"",\n \t\t  name_index, name, buffer, (long)buffer_size);\n@@ -428,7 +428,7 @@ ext4_xattr_block_list(struct dentry *dentry, char *buffer, size_t buffer_size)\n \tstruct inode *inode = d_inode(dentry);\n \tstruct buffer_head *bh = NULL;\n \tint error;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tea_idebug(inode, \""buffer=%p, buffer_size=%ld\"",\n \t\t  buffer, (long)buffer_size);\n@@ -545,30 +545,31 @@ static void\n ext4_xattr_release_block(handle_t *handle, struct inode *inode,\n \t\t\t struct buffer_head *bh)\n {\n-\tstruct mb_cache_entry *ce = NULL;\n \tint error = 0;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n-\tce = mb_cache_entry_get(ext4_mb_cache, bh->b_bdev, bh->b_blocknr);\n \tBUFFER_TRACE(bh, \""get_write_access\"");\n \terror = ext4_journal_get_write_access(handle, bh);\n \tif (error)\n \t\tgoto out;\n \n \tlock_buffer(bh);\n \tif (BHDR(bh)->h_refcount == cpu_to_le32(1)) {\n+\t\t__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);\n+\n \t\tea_bdebug(bh, \""refcount now=0; freeing\"");\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_free(ce);\n+\t\t/*\n+\t\t * This must happen under buffer lock for\n+\t\t * ext4_xattr_block_set() to reliably detect freed block\n+\t\t */\n+\t\tmb2_cache_entry_delete_block(EXT4_GET_MB_CACHE(inode), hash,\n+\t\t\t\t\t     bh->b_blocknr);\n \t\tget_bh(bh);\n \t\tunlock_buffer(bh);\n \t\text4_free_blocks(handle, inode, bh, 0, 1,\n \t\t\t\t EXT4_FREE_BLOCKS_METADATA |\n \t\t\t\t EXT4_FREE_BLOCKS_FORGET);\n \t} else {\n \t\tle32_add_cpu(&BHDR(bh)->h_refcount, -1);\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_release(ce);\n \t\t/*\n \t\t * Beware of this ugliness: Releasing of xattr block references\n \t\t * from different inodes can race and so we have to protect\n@@ -781,28 +782,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \tstruct super_block *sb = inode->i_sb;\n \tstruct buffer_head *new_bh = NULL;\n \tstruct ext4_xattr_search *s = &bs->s;\n-\tstruct mb_cache_entry *ce = NULL;\n+\tstruct mb2_cache_entry *ce = NULL;\n \tint error = 0;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n #define header(x) ((struct ext4_xattr_header *)(x))\n \n \tif (i->value && i->value_len > sb->s_blocksize)\n \t\treturn -ENOSPC;\n \tif (s->base) {\n-\t\tce = mb_cache_entry_get(ext4_mb_cache, bs->bh->b_bdev,\n-\t\t\t\t\tbs->bh->b_blocknr);\n \t\tBUFFER_TRACE(bs->bh, \""get_write_access\"");\n \t\terror = ext4_journal_get_write_access(handle, bs->bh);\n \t\tif (error)\n \t\t\tgoto cleanup;\n \t\tlock_buffer(bs->bh);\n \n \t\tif (header(s->base)->h_refcount == cpu_to_le32(1)) {\n-\t\t\tif (ce) {\n-\t\t\t\tmb_cache_entry_free(ce);\n-\t\t\t\tce = NULL;\n-\t\t\t}\n+\t\t\t__u32 hash = le32_to_cpu(BHDR(bs->bh)->h_hash);\n+\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext4_xattr_block_set() to reliably detect modified\n+\t\t\t * block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(ext4_mb_cache, hash,\n+\t\t\t\t\t\t     bs->bh->b_blocknr);\n \t\t\tea_bdebug(bs->bh, \""modifying in-place\"");\n \t\t\terror = ext4_xattr_set_entry(i, s);\n \t\t\tif (!error) {\n@@ -826,10 +830,6 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\tint offset = (char *)s->here - bs->bh->b_data;\n \n \t\t\tunlock_buffer(bs->bh);\n-\t\t\tif (ce) {\n-\t\t\t\tmb_cache_entry_release(ce);\n-\t\t\t\tce = NULL;\n-\t\t\t}\n \t\t\tea_bdebug(bs->bh, \""cloning\"");\n \t\t\ts->base = kmalloc(bs->bh->b_size, GFP_NOFS);\n \t\t\terror = -ENOMEM;\n@@ -884,6 +884,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\t\tif (error)\n \t\t\t\t\tgoto cleanup_dquot;\n \t\t\t\tlock_buffer(new_bh);\n+\t\t\t\t/*\n+\t\t\t\t * We have to be careful about races with\n+\t\t\t\t * freeing or rehashing of xattr block. Once we\n+\t\t\t\t * hold buffer lock xattr block's state is\n+\t\t\t\t * stable so we can check whether the block got\n+\t\t\t\t * freed / rehashed or not.  Since we unhash\n+\t\t\t\t * mbcache entry under buffer lock when freeing\n+\t\t\t\t * / rehashing xattr block, checking whether\n+\t\t\t\t * entry is still hashed is reliable.\n+\t\t\t\t */\n+\t\t\t\tif (hlist_bl_unhashed(&ce->e_hash_list)) {\n+\t\t\t\t\t/*\n+\t\t\t\t\t * Undo everything and check mbcache\n+\t\t\t\t\t * again.\n+\t\t\t\t\t */\n+\t\t\t\t\tunlock_buffer(new_bh);\n+\t\t\t\t\tdquot_free_block(inode,\n+\t\t\t\t\t\t\t EXT4_C2B(EXT4_SB(sb),\n+\t\t\t\t\t\t\t\t  1));\n+\t\t\t\t\tbrelse(new_bh);\n+\t\t\t\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n+\t\t\t\t\tce = NULL;\n+\t\t\t\t\tnew_bh = NULL;\n+\t\t\t\t\tgoto inserted;\n+\t\t\t\t}\n \t\t\t\tle32_add_cpu(&BHDR(new_bh)->h_refcount, 1);\n \t\t\t\tea_bdebug(new_bh, \""reusing; refcount now=%d\"",\n \t\t\t\t\tle32_to_cpu(BHDR(new_bh)->h_refcount));\n@@ -894,7 +919,8 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\t\tif (error)\n \t\t\t\t\tgoto cleanup_dquot;\n \t\t\t}\n-\t\t\tmb_cache_entry_release(ce);\n+\t\t\tmb2_cache_entry_touch(ext4_mb_cache, ce);\n+\t\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n \t\t\tce = NULL;\n \t\t} else if (bs->bh && s->base == bs->bh->b_data) {\n \t\t\t/* We were modifying this block in-place. */\n@@ -959,7 +985,7 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \n cleanup:\n \tif (ce)\n-\t\tmb_cache_entry_release(ce);\n+\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n \tbrelse(new_bh);\n \tif (!(bs->bh && s->base == bs->bh->b_data))\n \t\tkfree(s->base);\n@@ -1511,17 +1537,6 @@ ext4_xattr_delete_inode(handle_t *handle, struct inode *inode)\n \tbrelse(bh);\n }\n \n-/*\n- * ext4_xattr_put_super()\n- *\n- * This is called when a file system is unmounted.\n- */\n-void\n-ext4_xattr_put_super(struct super_block *sb)\n-{\n-\tmb_cache_shrink(sb->s_bdev);\n-}\n-\n /*\n  * ext4_xattr_cache_insert()\n  *\n@@ -1531,28 +1546,18 @@ ext4_xattr_put_super(struct super_block *sb)\n  * Returns 0, or a negative error number on failure.\n  */\n static void\n-ext4_xattr_cache_insert(struct mb_cache *ext4_mb_cache, struct buffer_head *bh)\n+ext4_xattr_cache_insert(struct mb2_cache *ext4_mb_cache, struct buffer_head *bh)\n {\n \t__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);\n-\tstruct mb_cache_entry *ce;\n \tint error;\n \n-\tce = mb_cache_entry_alloc(ext4_mb_cache, GFP_NOFS);\n-\tif (!ce) {\n-\t\tea_bdebug(bh, \""out of memory\"");\n-\t\treturn;\n-\t}\n-\terror = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);\n+\terror = mb2_cache_entry_create(ext4_mb_cache, GFP_NOFS, hash,\n+\t\t\t\t       bh->b_blocknr);\n \tif (error) {\n-\t\tmb_cache_entry_free(ce);\n-\t\tif (error == -EBUSY) {\n+\t\tif (error == -EBUSY)\n \t\t\tea_bdebug(bh, \""already in cache\"");\n-\t\t\terror = 0;\n-\t\t}\n-\t} else {\n+\t} else\n \t\tea_bdebug(bh, \""inserting [%x]\"", (int)hash);\n-\t\tmb_cache_entry_release(ce);\n-\t}\n }\n \n /*\n@@ -1605,26 +1610,19 @@ ext4_xattr_cmp(struct ext4_xattr_header *header1,\n  */\n static struct buffer_head *\n ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,\n-\t\t      struct mb_cache_entry **pce)\n+\t\t      struct mb2_cache_entry **pce)\n {\n \t__u32 hash = le32_to_cpu(header->h_hash);\n-\tstruct mb_cache_entry *ce;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache_entry *ce;\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tif (!header->h_hash)\n \t\treturn NULL;  /* never share */\n \tea_idebug(inode, \""looking for cached blocks [%x]\"", (int)hash);\n-again:\n-\tce = mb_cache_entry_find_first(ext4_mb_cache, inode->i_sb->s_bdev,\n-\t\t\t\t       hash);\n+\tce = mb2_cache_entry_find_first(ext4_mb_cache, hash);\n \twhile (ce) {\n \t\tstruct buffer_head *bh;\n \n-\t\tif (IS_ERR(ce)) {\n-\t\t\tif (PTR_ERR(ce) == -EAGAIN)\n-\t\t\t\tgoto again;\n-\t\t\tbreak;\n-\t\t}\n \t\tbh = sb_bread(inode->i_sb, ce->e_block);\n \t\tif (!bh) {\n \t\t\tEXT4_ERROR_INODE(inode, \""block %lu read error\"",\n@@ -1640,7 +1638,7 @@ ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,\n \t\t\treturn bh;\n \t\t}\n \t\tbrelse(bh);\n-\t\tce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);\n+\t\tce = mb2_cache_entry_find_next(ext4_mb_cache, ce);\n \t}\n \treturn NULL;\n }\n@@ -1715,15 +1713,15 @@ static void ext4_xattr_rehash(struct ext4_xattr_header *header,\n \n #define\tHASH_BUCKET_BITS\t10\n \n-struct mb_cache *\n-ext4_xattr_create_cache(char *name)\n+struct mb2_cache *\n+ext4_xattr_create_cache(void)\n {\n-\treturn mb_cache_create(name, HASH_BUCKET_BITS);\n+\treturn mb2_cache_create(HASH_BUCKET_BITS);\n }\n \n-void ext4_xattr_destroy_cache(struct mb_cache *cache)\n+void ext4_xattr_destroy_cache(struct mb2_cache *cache)\n {\n \tif (cache)\n-\t\tmb_cache_destroy(cache);\n+\t\tmb2_cache_destroy(cache);\n }\n ""}<_**next**_>{""sha"": ""10b0f7323ed6fcd628efee26998d0f1be7652c48"", ""filename"": ""fs/ext4/xattr.h"", ""status"": ""modified"", ""additions"": 2, ""deletions"": 3, ""changes"": 5, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/xattr.h?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -108,7 +108,6 @@ extern int ext4_xattr_set(struct inode *, int, const char *, const void *, size_\n extern int ext4_xattr_set_handle(handle_t *, struct inode *, int, const char *, const void *, size_t, int);\n \n extern void ext4_xattr_delete_inode(handle_t *, struct inode *);\n-extern void ext4_xattr_put_super(struct super_block *);\n \n extern int ext4_expand_extra_isize_ea(struct inode *inode, int new_extra_isize,\n \t\t\t    struct ext4_inode *raw_inode, handle_t *handle);\n@@ -124,8 +123,8 @@ extern int ext4_xattr_ibody_inline_set(handle_t *handle, struct inode *inode,\n \t\t\t\t       struct ext4_xattr_info *i,\n \t\t\t\t       struct ext4_xattr_ibody_find *is);\n \n-extern struct mb_cache *ext4_xattr_create_cache(char *name);\n-extern void ext4_xattr_destroy_cache(struct mb_cache *);\n+extern struct mb2_cache *ext4_xattr_create_cache(void);\n+extern void ext4_xattr_destroy_cache(struct mb2_cache *);\n \n #ifdef CONFIG_EXT4_FS_SECURITY\n extern int ext4_init_security(handle_t *handle, struct inode *inode,""}","ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,
		     void *buffer, size_t buffer_size)
{
	struct buffer_head *bh = NULL;
 	struct ext4_xattr_entry *entry;
 	size_t size;
 	int error;
	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	ea_idebug(inode, ""name=%d.%s, buffer=%p, buffer_size=%ld"",
 		  name_index, name, buffer, (long)buffer_size);

	error = -ENODATA;
	if (!EXT4_I(inode)->i_file_acl)
		goto cleanup;
	ea_idebug(inode, ""reading block %llu"",
		  (unsigned long long)EXT4_I(inode)->i_file_acl);
	bh = sb_bread(inode->i_sb, EXT4_I(inode)->i_file_acl);
	if (!bh)
		goto cleanup;
	ea_bdebug(bh, ""b_count=%d, refcount=%d"",
		atomic_read(&(bh->b_count)), le32_to_cpu(BHDR(bh)->h_refcount));
	if (ext4_xattr_check_block(inode, bh)) {
bad_block:
		EXT4_ERROR_INODE(inode, ""bad block %llu"",
				 EXT4_I(inode)->i_file_acl);
		error = -EFSCORRUPTED;
		goto cleanup;
	}
	ext4_xattr_cache_insert(ext4_mb_cache, bh);
	entry = BFIRST(bh);
	error = ext4_xattr_find_entry(&entry, name_index, name, bh->b_size, 1);
	if (error == -EFSCORRUPTED)
		goto bad_block;
	if (error)
		goto cleanup;
	size = le32_to_cpu(entry->e_value_size);
	if (buffer) {
		error = -ERANGE;
		if (size > buffer_size)
			goto cleanup;
		memcpy(buffer, bh->b_data + le16_to_cpu(entry->e_value_offs),
		       size);
	}
	error = size;

cleanup:
	brelse(bh);
	return error;
}
","ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,
		     void *buffer, size_t buffer_size)
{
	struct buffer_head *bh = NULL;
 	struct ext4_xattr_entry *entry;
 	size_t size;
 	int error;
	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	ea_idebug(inode, ""name=%d.%s, buffer=%p, buffer_size=%ld"",
 		  name_index, name, buffer, (long)buffer_size);

	error = -ENODATA;
	if (!EXT4_I(inode)->i_file_acl)
		goto cleanup;
	ea_idebug(inode, ""reading block %llu"",
		  (unsigned long long)EXT4_I(inode)->i_file_acl);
	bh = sb_bread(inode->i_sb, EXT4_I(inode)->i_file_acl);
	if (!bh)
		goto cleanup;
	ea_bdebug(bh, ""b_count=%d, refcount=%d"",
		atomic_read(&(bh->b_count)), le32_to_cpu(BHDR(bh)->h_refcount));
	if (ext4_xattr_check_block(inode, bh)) {
bad_block:
		EXT4_ERROR_INODE(inode, ""bad block %llu"",
				 EXT4_I(inode)->i_file_acl);
		error = -EFSCORRUPTED;
		goto cleanup;
	}
	ext4_xattr_cache_insert(ext4_mb_cache, bh);
	entry = BFIRST(bh);
	error = ext4_xattr_find_entry(&entry, name_index, name, bh->b_size, 1);
	if (error == -EFSCORRUPTED)
		goto bad_block;
	if (error)
		goto cleanup;
	size = le32_to_cpu(entry->e_value_size);
	if (buffer) {
		error = -ERANGE;
		if (size > buffer_size)
			goto cleanup;
		memcpy(buffer, bh->b_data + le16_to_cpu(entry->e_value_offs),
		       size);
	}
	error = size;

cleanup:
	brelse(bh);
	return error;
}
",C,"	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
","	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
",,"@@ -53,7 +53,7 @@
 #include <linux/init.h>
 #include <linux/fs.h>
 #include <linux/slab.h>
-#include <linux/mbcache.h>
+#include <linux/mbcache2.h>
 #include <linux/quotaops.h>
 #include ""ext4_jbd2.h""
 #include ""ext4.h""
@@ -78,10 +78,10 @@
 # define ea_bdebug(bh, fmt, ...)	no_printk(fmt, ##__VA_ARGS__)
 #endif
 
-static void ext4_xattr_cache_insert(struct mb_cache *, struct buffer_head *);
+static void ext4_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);
 static struct buffer_head *ext4_xattr_cache_find(struct inode *,
 						 struct ext4_xattr_header *,
-						 struct mb_cache_entry **);
+						 struct mb2_cache_entry **);
 static void ext4_xattr_rehash(struct ext4_xattr_header *,
 			      struct ext4_xattr_entry *);
 static int ext4_xattr_list(struct dentry *dentry, char *buffer,
@@ -276,7 +276,7 @@ ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,
 	struct ext4_xattr_entry *entry;
 	size_t size;
 	int error;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	ea_idebug(inode, ""name=%d.%s, buffer=%p, buffer_size=%ld"",
 		  name_index, name, buffer, (long)buffer_size);
@@ -428,7 +428,7 @@ ext4_xattr_block_list(struct dentry *dentry, char *buffer, size_t buffer_size)
 	struct inode *inode = d_inode(dentry);
 	struct buffer_head *bh = NULL;
 	int error;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	ea_idebug(inode, ""buffer=%p, buffer_size=%ld"",
 		  buffer, (long)buffer_size);
@@ -545,30 +545,31 @@ static void
 ext4_xattr_release_block(handle_t *handle, struct inode *inode,
 			 struct buffer_head *bh)
 {
-	struct mb_cache_entry *ce = NULL;
 	int error = 0;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
-	ce = mb_cache_entry_get(ext4_mb_cache, bh->b_bdev, bh->b_blocknr);
 	BUFFER_TRACE(bh, ""get_write_access"");
 	error = ext4_journal_get_write_access(handle, bh);
 	if (error)
 		goto out;
 
 	lock_buffer(bh);
 	if (BHDR(bh)->h_refcount == cpu_to_le32(1)) {
+		__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);
+
 		ea_bdebug(bh, ""refcount now=0; freeing"");
-		if (ce)
-			mb_cache_entry_free(ce);
+		/*
+		 * This must happen under buffer lock for
+		 * ext4_xattr_block_set() to reliably detect freed block
+		 */
+		mb2_cache_entry_delete_block(EXT4_GET_MB_CACHE(inode), hash,
+					     bh->b_blocknr);
 		get_bh(bh);
 		unlock_buffer(bh);
 		ext4_free_blocks(handle, inode, bh, 0, 1,
 				 EXT4_FREE_BLOCKS_METADATA |
 				 EXT4_FREE_BLOCKS_FORGET);
 	} else {
 		le32_add_cpu(&BHDR(bh)->h_refcount, -1);
-		if (ce)
-			mb_cache_entry_release(ce);
 		/*
 		 * Beware of this ugliness: Releasing of xattr block references
 		 * from different inodes can race and so we have to protect
@@ -781,28 +782,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *new_bh = NULL;
 	struct ext4_xattr_search *s = &bs->s;
-	struct mb_cache_entry *ce = NULL;
+	struct mb2_cache_entry *ce = NULL;
 	int error = 0;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 #define header(x) ((struct ext4_xattr_header *)(x))
 
 	if (i->value && i->value_len > sb->s_blocksize)
 		return -ENOSPC;
 	if (s->base) {
-		ce = mb_cache_entry_get(ext4_mb_cache, bs->bh->b_bdev,
-					bs->bh->b_blocknr);
 		BUFFER_TRACE(bs->bh, ""get_write_access"");
 		error = ext4_journal_get_write_access(handle, bs->bh);
 		if (error)
 			goto cleanup;
 		lock_buffer(bs->bh);
 
 		if (header(s->base)->h_refcount == cpu_to_le32(1)) {
-			if (ce) {
-				mb_cache_entry_free(ce);
-				ce = NULL;
-			}
+			__u32 hash = le32_to_cpu(BHDR(bs->bh)->h_hash);
+
+			/*
+			 * This must happen under buffer lock for
+			 * ext4_xattr_block_set() to reliably detect modified
+			 * block
+			 */
+			mb2_cache_entry_delete_block(ext4_mb_cache, hash,
+						     bs->bh->b_blocknr);
 			ea_bdebug(bs->bh, ""modifying in-place"");
 			error = ext4_xattr_set_entry(i, s);
 			if (!error) {
@@ -826,10 +830,6 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 			int offset = (char *)s->here - bs->bh->b_data;
 
 			unlock_buffer(bs->bh);
-			if (ce) {
-				mb_cache_entry_release(ce);
-				ce = NULL;
-			}
 			ea_bdebug(bs->bh, ""cloning"");
 			s->base = kmalloc(bs->bh->b_size, GFP_NOFS);
 			error = -ENOMEM;
@@ -884,6 +884,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 				if (error)
 					goto cleanup_dquot;
 				lock_buffer(new_bh);
+				/*
+				 * We have to be careful about races with
+				 * freeing or rehashing of xattr block. Once we
+				 * hold buffer lock xattr block's state is
+				 * stable so we can check whether the block got
+				 * freed / rehashed or not.  Since we unhash
+				 * mbcache entry under buffer lock when freeing
+				 * / rehashing xattr block, checking whether
+				 * entry is still hashed is reliable.
+				 */
+				if (hlist_bl_unhashed(&ce->e_hash_list)) {
+					/*
+					 * Undo everything and check mbcache
+					 * again.
+					 */
+					unlock_buffer(new_bh);
+					dquot_free_block(inode,
+							 EXT4_C2B(EXT4_SB(sb),
+								  1));
+					brelse(new_bh);
+					mb2_cache_entry_put(ext4_mb_cache, ce);
+					ce = NULL;
+					new_bh = NULL;
+					goto inserted;
+				}
 				le32_add_cpu(&BHDR(new_bh)->h_refcount, 1);
 				ea_bdebug(new_bh, ""reusing; refcount now=%d"",
 					le32_to_cpu(BHDR(new_bh)->h_refcount));
@@ -894,7 +919,8 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 				if (error)
 					goto cleanup_dquot;
 			}
-			mb_cache_entry_release(ce);
+			mb2_cache_entry_touch(ext4_mb_cache, ce);
+			mb2_cache_entry_put(ext4_mb_cache, ce);
 			ce = NULL;
 		} else if (bs->bh && s->base == bs->bh->b_data) {
 			/* We were modifying this block in-place. */
@@ -959,7 +985,7 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 
 cleanup:
 	if (ce)
-		mb_cache_entry_release(ce);
+		mb2_cache_entry_put(ext4_mb_cache, ce);
 	brelse(new_bh);
 	if (!(bs->bh && s->base == bs->bh->b_data))
 		kfree(s->base);
@@ -1511,17 +1537,6 @@ ext4_xattr_delete_inode(handle_t *handle, struct inode *inode)
 	brelse(bh);
 }
 
-/*
- * ext4_xattr_put_super()
- *
- * This is called when a file system is unmounted.
- */
-void
-ext4_xattr_put_super(struct super_block *sb)
-{
-	mb_cache_shrink(sb->s_bdev);
-}
-
 /*
  * ext4_xattr_cache_insert()
  *
@@ -1531,28 +1546,18 @@ ext4_xattr_put_super(struct super_block *sb)
  * Returns 0, or a negative error number on failure.
  */
 static void
-ext4_xattr_cache_insert(struct mb_cache *ext4_mb_cache, struct buffer_head *bh)
+ext4_xattr_cache_insert(struct mb2_cache *ext4_mb_cache, struct buffer_head *bh)
 {
 	__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);
-	struct mb_cache_entry *ce;
 	int error;
 
-	ce = mb_cache_entry_alloc(ext4_mb_cache, GFP_NOFS);
-	if (!ce) {
-		ea_bdebug(bh, ""out of memory"");
-		return;
-	}
-	error = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);
+	error = mb2_cache_entry_create(ext4_mb_cache, GFP_NOFS, hash,
+				       bh->b_blocknr);
 	if (error) {
-		mb_cache_entry_free(ce);
-		if (error == -EBUSY) {
+		if (error == -EBUSY)
 			ea_bdebug(bh, ""already in cache"");
-			error = 0;
-		}
-	} else {
+	} else
 		ea_bdebug(bh, ""inserting [%x]"", (int)hash);
-		mb_cache_entry_release(ce);
-	}
 }
 
 /*
@@ -1605,26 +1610,19 @@ ext4_xattr_cmp(struct ext4_xattr_header *header1,
  */
 static struct buffer_head *
 ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,
-		      struct mb_cache_entry **pce)
+		      struct mb2_cache_entry **pce)
 {
 	__u32 hash = le32_to_cpu(header->h_hash);
-	struct mb_cache_entry *ce;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache_entry *ce;
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	if (!header->h_hash)
 		return NULL;  /* never share */
 	ea_idebug(inode, ""looking for cached blocks [%x]"", (int)hash);
-again:
-	ce = mb_cache_entry_find_first(ext4_mb_cache, inode->i_sb->s_bdev,
-				       hash);
+	ce = mb2_cache_entry_find_first(ext4_mb_cache, hash);
 	while (ce) {
 		struct buffer_head *bh;
 
-		if (IS_ERR(ce)) {
-			if (PTR_ERR(ce) == -EAGAIN)
-				goto again;
-			break;
-		}
 		bh = sb_bread(inode->i_sb, ce->e_block);
 		if (!bh) {
 			EXT4_ERROR_INODE(inode, ""block %lu read error"",
@@ -1640,7 +1638,7 @@ ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,
 			return bh;
 		}
 		brelse(bh);
-		ce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);
+		ce = mb2_cache_entry_find_next(ext4_mb_cache, ce);
 	}
 	return NULL;
 }
@@ -1715,15 +1713,15 @@ static void ext4_xattr_rehash(struct ext4_xattr_header *header,
 
 #define	HASH_BUCKET_BITS	10
 
-struct mb_cache *
-ext4_xattr_create_cache(char *name)
+struct mb2_cache *
+ext4_xattr_create_cache(void)
 {
-	return mb_cache_create(name, HASH_BUCKET_BITS);
+	return mb2_cache_create(HASH_BUCKET_BITS);
 }
 
-void ext4_xattr_destroy_cache(struct mb_cache *cache)
+void ext4_xattr_destroy_cache(struct mb2_cache *cache)
 {
 	if (cache)
-		mb_cache_destroy(cache);
+		mb2_cache_destroy(cache);
 }
 ",linux,82939d7999dfc1f1998c4b1c12e2f19edbdff272,f9a61eb4e2471c56a63cd804c7474128138c38ac,1,"ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,
		     void *buffer, size_t buffer_size)
{
	struct buffer_head *bh = NULL;
 	struct ext4_xattr_entry *entry;
 	size_t size;
 	int error;
//flaw_line_below:
	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
//fix_flaw_line_below:
//	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	ea_idebug(inode, ""name=%d.%s, buffer=%p, buffer_size=%ld"",
 		  name_index, name, buffer, (long)buffer_size);

	error = -ENODATA;
	if (!EXT4_I(inode)->i_file_acl)
		goto cleanup;
	ea_idebug(inode, ""reading block %llu"",
		  (unsigned long long)EXT4_I(inode)->i_file_acl);
	bh = sb_bread(inode->i_sb, EXT4_I(inode)->i_file_acl);
	if (!bh)
		goto cleanup;
	ea_bdebug(bh, ""b_count=%d, refcount=%d"",
		atomic_read(&(bh->b_count)), le32_to_cpu(BHDR(bh)->h_refcount));
	if (ext4_xattr_check_block(inode, bh)) {
bad_block:
		EXT4_ERROR_INODE(inode, ""bad block %llu"",
				 EXT4_I(inode)->i_file_acl);
		error = -EFSCORRUPTED;
		goto cleanup;
	}
	ext4_xattr_cache_insert(ext4_mb_cache, bh);
	entry = BFIRST(bh);
	error = ext4_xattr_find_entry(&entry, name_index, name, bh->b_size, 1);
	if (error == -EFSCORRUPTED)
		goto bad_block;
	if (error)
		goto cleanup;
	size = le32_to_cpu(entry->e_value_size);
	if (buffer) {
		error = -ERANGE;
		if (size > buffer_size)
			goto cleanup;
		memcpy(buffer, bh->b_data + le16_to_cpu(entry->e_value_offs),
		       size);
	}
	error = size;

cleanup:
	brelse(bh);
	return error;
}
"
5425,183161,,Local,Not required,Partial,CVE-2015-8952,https://www.cvedetails.com/cve/CVE-2015-8952/,CWE-19,Low,,,,2016-10-16,2.1,"The mbcache feature in the ext2 and ext4 filesystem implementations in the Linux kernel before 4.6 mishandles xattr block caching, which allows local users to cause a denial of service (soft lockup) via filesystem operations in environments that use many attributes, as demonstrated by Ceph and Samba.",2018-03-15,DoS ,1,https://github.com/torvalds/linux/commit/82939d7999dfc1f1998c4b1c12e2f19edbdff272,82939d7999dfc1f1998c4b1c12e2f19edbdff272,"ext4: convert to mbcache2

The conversion is generally straightforward. The only tricky part is
that xattr block corresponding to found mbcache entry can get freed
before we get buffer lock for that block. So we have to check whether
the entry is still valid after getting buffer lock.

Signed-off-by: Jan Kara <jack@suse.cz>
Signed-off-by: Theodore Ts'o <tytso@mit.edu>",1,fs/ext4/xattr.c,"{""sha"": ""9ac9e62569ef8fdf981021b58d37ab99d0150882"", ""filename"": ""fs/ext4/ext4.h"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 1, ""changes"": 2, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/ext4.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/ext4.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/ext4.h?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -1468,7 +1468,7 @@ struct ext4_sb_info {\n \tstruct list_head s_es_list;\t/* List of inodes with reclaimable extents */\n \tlong s_es_nr_inode;\n \tstruct ext4_es_stats s_es_stats;\n-\tstruct mb_cache *s_mb_cache;\n+\tstruct mb2_cache *s_mb_cache;\n \tspinlock_t s_es_lock ____cacheline_aligned_in_smp;\n \n \t/* Ratelimit ext4 messages. */""}<_**next**_>{""sha"": ""ecc37e1034358d769ab29971e9d2301fb9e2b3bc"", ""filename"": ""fs/ext4/super.c"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 2, ""changes"": 7, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/super.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/super.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/super.c?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -844,7 +844,6 @@ static void ext4_put_super(struct super_block *sb)\n \text4_release_system_zone(sb);\n \text4_mb_release(sb);\n \text4_ext_release(sb);\n-\text4_xattr_put_super(sb);\n \n \tif (!(sb->s_flags & MS_RDONLY)) {\n \t\text4_clear_feature_journal_needs_recovery(sb);\n@@ -3797,7 +3796,7 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n \n no_journal:\n \tif (ext4_mballoc_ready) {\n-\t\tsbi->s_mb_cache = ext4_xattr_create_cache(sb->s_id);\n+\t\tsbi->s_mb_cache = ext4_xattr_create_cache();\n \t\tif (!sbi->s_mb_cache) {\n \t\t\text4_msg(sb, KERN_ERR, \""Failed to create an mb_cache\"");\n \t\t\tgoto failed_mount_wq;\n@@ -4027,6 +4026,10 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n \tif (EXT4_SB(sb)->rsv_conversion_wq)\n \t\tdestroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);\n failed_mount_wq:\n+\tif (sbi->s_mb_cache) {\n+\t\text4_xattr_destroy_cache(sbi->s_mb_cache);\n+\t\tsbi->s_mb_cache = NULL;\n+\t}\n \tif (sbi->s_journal) {\n \t\tjbd2_journal_destroy(sbi->s_journal);\n \t\tsbi->s_journal = NULL;""}<_**next**_>{""sha"": ""fe9f8d6ab6c91b60689abadefd5435c31893fcae"", ""filename"": ""fs/ext4/xattr.c"", ""status"": ""modified"", ""additions"": 67, ""deletions"": 69, ""changes"": 136, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/xattr.c?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -53,7 +53,7 @@\n #include <linux/init.h>\n #include <linux/fs.h>\n #include <linux/slab.h>\n-#include <linux/mbcache.h>\n+#include <linux/mbcache2.h>\n #include <linux/quotaops.h>\n #include \""ext4_jbd2.h\""\n #include \""ext4.h\""\n@@ -78,10 +78,10 @@\n # define ea_bdebug(bh, fmt, ...)\tno_printk(fmt, ##__VA_ARGS__)\n #endif\n \n-static void ext4_xattr_cache_insert(struct mb_cache *, struct buffer_head *);\n+static void ext4_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);\n static struct buffer_head *ext4_xattr_cache_find(struct inode *,\n \t\t\t\t\t\t struct ext4_xattr_header *,\n-\t\t\t\t\t\t struct mb_cache_entry **);\n+\t\t\t\t\t\t struct mb2_cache_entry **);\n static void ext4_xattr_rehash(struct ext4_xattr_header *,\n \t\t\t      struct ext4_xattr_entry *);\n static int ext4_xattr_list(struct dentry *dentry, char *buffer,\n@@ -276,7 +276,7 @@ ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,\n \tstruct ext4_xattr_entry *entry;\n \tsize_t size;\n \tint error;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tea_idebug(inode, \""name=%d.%s, buffer=%p, buffer_size=%ld\"",\n \t\t  name_index, name, buffer, (long)buffer_size);\n@@ -428,7 +428,7 @@ ext4_xattr_block_list(struct dentry *dentry, char *buffer, size_t buffer_size)\n \tstruct inode *inode = d_inode(dentry);\n \tstruct buffer_head *bh = NULL;\n \tint error;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tea_idebug(inode, \""buffer=%p, buffer_size=%ld\"",\n \t\t  buffer, (long)buffer_size);\n@@ -545,30 +545,31 @@ static void\n ext4_xattr_release_block(handle_t *handle, struct inode *inode,\n \t\t\t struct buffer_head *bh)\n {\n-\tstruct mb_cache_entry *ce = NULL;\n \tint error = 0;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n-\tce = mb_cache_entry_get(ext4_mb_cache, bh->b_bdev, bh->b_blocknr);\n \tBUFFER_TRACE(bh, \""get_write_access\"");\n \terror = ext4_journal_get_write_access(handle, bh);\n \tif (error)\n \t\tgoto out;\n \n \tlock_buffer(bh);\n \tif (BHDR(bh)->h_refcount == cpu_to_le32(1)) {\n+\t\t__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);\n+\n \t\tea_bdebug(bh, \""refcount now=0; freeing\"");\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_free(ce);\n+\t\t/*\n+\t\t * This must happen under buffer lock for\n+\t\t * ext4_xattr_block_set() to reliably detect freed block\n+\t\t */\n+\t\tmb2_cache_entry_delete_block(EXT4_GET_MB_CACHE(inode), hash,\n+\t\t\t\t\t     bh->b_blocknr);\n \t\tget_bh(bh);\n \t\tunlock_buffer(bh);\n \t\text4_free_blocks(handle, inode, bh, 0, 1,\n \t\t\t\t EXT4_FREE_BLOCKS_METADATA |\n \t\t\t\t EXT4_FREE_BLOCKS_FORGET);\n \t} else {\n \t\tle32_add_cpu(&BHDR(bh)->h_refcount, -1);\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_release(ce);\n \t\t/*\n \t\t * Beware of this ugliness: Releasing of xattr block references\n \t\t * from different inodes can race and so we have to protect\n@@ -781,28 +782,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \tstruct super_block *sb = inode->i_sb;\n \tstruct buffer_head *new_bh = NULL;\n \tstruct ext4_xattr_search *s = &bs->s;\n-\tstruct mb_cache_entry *ce = NULL;\n+\tstruct mb2_cache_entry *ce = NULL;\n \tint error = 0;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n #define header(x) ((struct ext4_xattr_header *)(x))\n \n \tif (i->value && i->value_len > sb->s_blocksize)\n \t\treturn -ENOSPC;\n \tif (s->base) {\n-\t\tce = mb_cache_entry_get(ext4_mb_cache, bs->bh->b_bdev,\n-\t\t\t\t\tbs->bh->b_blocknr);\n \t\tBUFFER_TRACE(bs->bh, \""get_write_access\"");\n \t\terror = ext4_journal_get_write_access(handle, bs->bh);\n \t\tif (error)\n \t\t\tgoto cleanup;\n \t\tlock_buffer(bs->bh);\n \n \t\tif (header(s->base)->h_refcount == cpu_to_le32(1)) {\n-\t\t\tif (ce) {\n-\t\t\t\tmb_cache_entry_free(ce);\n-\t\t\t\tce = NULL;\n-\t\t\t}\n+\t\t\t__u32 hash = le32_to_cpu(BHDR(bs->bh)->h_hash);\n+\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext4_xattr_block_set() to reliably detect modified\n+\t\t\t * block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(ext4_mb_cache, hash,\n+\t\t\t\t\t\t     bs->bh->b_blocknr);\n \t\t\tea_bdebug(bs->bh, \""modifying in-place\"");\n \t\t\terror = ext4_xattr_set_entry(i, s);\n \t\t\tif (!error) {\n@@ -826,10 +830,6 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\tint offset = (char *)s->here - bs->bh->b_data;\n \n \t\t\tunlock_buffer(bs->bh);\n-\t\t\tif (ce) {\n-\t\t\t\tmb_cache_entry_release(ce);\n-\t\t\t\tce = NULL;\n-\t\t\t}\n \t\t\tea_bdebug(bs->bh, \""cloning\"");\n \t\t\ts->base = kmalloc(bs->bh->b_size, GFP_NOFS);\n \t\t\terror = -ENOMEM;\n@@ -884,6 +884,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\t\tif (error)\n \t\t\t\t\tgoto cleanup_dquot;\n \t\t\t\tlock_buffer(new_bh);\n+\t\t\t\t/*\n+\t\t\t\t * We have to be careful about races with\n+\t\t\t\t * freeing or rehashing of xattr block. Once we\n+\t\t\t\t * hold buffer lock xattr block's state is\n+\t\t\t\t * stable so we can check whether the block got\n+\t\t\t\t * freed / rehashed or not.  Since we unhash\n+\t\t\t\t * mbcache entry under buffer lock when freeing\n+\t\t\t\t * / rehashing xattr block, checking whether\n+\t\t\t\t * entry is still hashed is reliable.\n+\t\t\t\t */\n+\t\t\t\tif (hlist_bl_unhashed(&ce->e_hash_list)) {\n+\t\t\t\t\t/*\n+\t\t\t\t\t * Undo everything and check mbcache\n+\t\t\t\t\t * again.\n+\t\t\t\t\t */\n+\t\t\t\t\tunlock_buffer(new_bh);\n+\t\t\t\t\tdquot_free_block(inode,\n+\t\t\t\t\t\t\t EXT4_C2B(EXT4_SB(sb),\n+\t\t\t\t\t\t\t\t  1));\n+\t\t\t\t\tbrelse(new_bh);\n+\t\t\t\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n+\t\t\t\t\tce = NULL;\n+\t\t\t\t\tnew_bh = NULL;\n+\t\t\t\t\tgoto inserted;\n+\t\t\t\t}\n \t\t\t\tle32_add_cpu(&BHDR(new_bh)->h_refcount, 1);\n \t\t\t\tea_bdebug(new_bh, \""reusing; refcount now=%d\"",\n \t\t\t\t\tle32_to_cpu(BHDR(new_bh)->h_refcount));\n@@ -894,7 +919,8 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\t\tif (error)\n \t\t\t\t\tgoto cleanup_dquot;\n \t\t\t}\n-\t\t\tmb_cache_entry_release(ce);\n+\t\t\tmb2_cache_entry_touch(ext4_mb_cache, ce);\n+\t\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n \t\t\tce = NULL;\n \t\t} else if (bs->bh && s->base == bs->bh->b_data) {\n \t\t\t/* We were modifying this block in-place. */\n@@ -959,7 +985,7 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \n cleanup:\n \tif (ce)\n-\t\tmb_cache_entry_release(ce);\n+\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n \tbrelse(new_bh);\n \tif (!(bs->bh && s->base == bs->bh->b_data))\n \t\tkfree(s->base);\n@@ -1511,17 +1537,6 @@ ext4_xattr_delete_inode(handle_t *handle, struct inode *inode)\n \tbrelse(bh);\n }\n \n-/*\n- * ext4_xattr_put_super()\n- *\n- * This is called when a file system is unmounted.\n- */\n-void\n-ext4_xattr_put_super(struct super_block *sb)\n-{\n-\tmb_cache_shrink(sb->s_bdev);\n-}\n-\n /*\n  * ext4_xattr_cache_insert()\n  *\n@@ -1531,28 +1546,18 @@ ext4_xattr_put_super(struct super_block *sb)\n  * Returns 0, or a negative error number on failure.\n  */\n static void\n-ext4_xattr_cache_insert(struct mb_cache *ext4_mb_cache, struct buffer_head *bh)\n+ext4_xattr_cache_insert(struct mb2_cache *ext4_mb_cache, struct buffer_head *bh)\n {\n \t__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);\n-\tstruct mb_cache_entry *ce;\n \tint error;\n \n-\tce = mb_cache_entry_alloc(ext4_mb_cache, GFP_NOFS);\n-\tif (!ce) {\n-\t\tea_bdebug(bh, \""out of memory\"");\n-\t\treturn;\n-\t}\n-\terror = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);\n+\terror = mb2_cache_entry_create(ext4_mb_cache, GFP_NOFS, hash,\n+\t\t\t\t       bh->b_blocknr);\n \tif (error) {\n-\t\tmb_cache_entry_free(ce);\n-\t\tif (error == -EBUSY) {\n+\t\tif (error == -EBUSY)\n \t\t\tea_bdebug(bh, \""already in cache\"");\n-\t\t\terror = 0;\n-\t\t}\n-\t} else {\n+\t} else\n \t\tea_bdebug(bh, \""inserting [%x]\"", (int)hash);\n-\t\tmb_cache_entry_release(ce);\n-\t}\n }\n \n /*\n@@ -1605,26 +1610,19 @@ ext4_xattr_cmp(struct ext4_xattr_header *header1,\n  */\n static struct buffer_head *\n ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,\n-\t\t      struct mb_cache_entry **pce)\n+\t\t      struct mb2_cache_entry **pce)\n {\n \t__u32 hash = le32_to_cpu(header->h_hash);\n-\tstruct mb_cache_entry *ce;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache_entry *ce;\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tif (!header->h_hash)\n \t\treturn NULL;  /* never share */\n \tea_idebug(inode, \""looking for cached blocks [%x]\"", (int)hash);\n-again:\n-\tce = mb_cache_entry_find_first(ext4_mb_cache, inode->i_sb->s_bdev,\n-\t\t\t\t       hash);\n+\tce = mb2_cache_entry_find_first(ext4_mb_cache, hash);\n \twhile (ce) {\n \t\tstruct buffer_head *bh;\n \n-\t\tif (IS_ERR(ce)) {\n-\t\t\tif (PTR_ERR(ce) == -EAGAIN)\n-\t\t\t\tgoto again;\n-\t\t\tbreak;\n-\t\t}\n \t\tbh = sb_bread(inode->i_sb, ce->e_block);\n \t\tif (!bh) {\n \t\t\tEXT4_ERROR_INODE(inode, \""block %lu read error\"",\n@@ -1640,7 +1638,7 @@ ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,\n \t\t\treturn bh;\n \t\t}\n \t\tbrelse(bh);\n-\t\tce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);\n+\t\tce = mb2_cache_entry_find_next(ext4_mb_cache, ce);\n \t}\n \treturn NULL;\n }\n@@ -1715,15 +1713,15 @@ static void ext4_xattr_rehash(struct ext4_xattr_header *header,\n \n #define\tHASH_BUCKET_BITS\t10\n \n-struct mb_cache *\n-ext4_xattr_create_cache(char *name)\n+struct mb2_cache *\n+ext4_xattr_create_cache(void)\n {\n-\treturn mb_cache_create(name, HASH_BUCKET_BITS);\n+\treturn mb2_cache_create(HASH_BUCKET_BITS);\n }\n \n-void ext4_xattr_destroy_cache(struct mb_cache *cache)\n+void ext4_xattr_destroy_cache(struct mb2_cache *cache)\n {\n \tif (cache)\n-\t\tmb_cache_destroy(cache);\n+\t\tmb2_cache_destroy(cache);\n }\n ""}<_**next**_>{""sha"": ""10b0f7323ed6fcd628efee26998d0f1be7652c48"", ""filename"": ""fs/ext4/xattr.h"", ""status"": ""modified"", ""additions"": 2, ""deletions"": 3, ""changes"": 5, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/xattr.h?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -108,7 +108,6 @@ extern int ext4_xattr_set(struct inode *, int, const char *, const void *, size_\n extern int ext4_xattr_set_handle(handle_t *, struct inode *, int, const char *, const void *, size_t, int);\n \n extern void ext4_xattr_delete_inode(handle_t *, struct inode *);\n-extern void ext4_xattr_put_super(struct super_block *);\n \n extern int ext4_expand_extra_isize_ea(struct inode *inode, int new_extra_isize,\n \t\t\t    struct ext4_inode *raw_inode, handle_t *handle);\n@@ -124,8 +123,8 @@ extern int ext4_xattr_ibody_inline_set(handle_t *handle, struct inode *inode,\n \t\t\t\t       struct ext4_xattr_info *i,\n \t\t\t\t       struct ext4_xattr_ibody_find *is);\n \n-extern struct mb_cache *ext4_xattr_create_cache(char *name);\n-extern void ext4_xattr_destroy_cache(struct mb_cache *);\n+extern struct mb2_cache *ext4_xattr_create_cache(void);\n+extern void ext4_xattr_destroy_cache(struct mb2_cache *);\n \n #ifdef CONFIG_EXT4_FS_SECURITY\n extern int ext4_init_security(handle_t *handle, struct inode *inode,""}","ext4_xattr_block_list(struct dentry *dentry, char *buffer, size_t buffer_size)
{
 	struct inode *inode = d_inode(dentry);
 	struct buffer_head *bh = NULL;
 	int error;
	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	ea_idebug(inode, ""buffer=%p, buffer_size=%ld"",
 		  buffer, (long)buffer_size);

	error = 0;
	if (!EXT4_I(inode)->i_file_acl)
		goto cleanup;
	ea_idebug(inode, ""reading block %llu"",
		  (unsigned long long)EXT4_I(inode)->i_file_acl);
	bh = sb_bread(inode->i_sb, EXT4_I(inode)->i_file_acl);
	error = -EIO;
	if (!bh)
		goto cleanup;
	ea_bdebug(bh, ""b_count=%d, refcount=%d"",
		atomic_read(&(bh->b_count)), le32_to_cpu(BHDR(bh)->h_refcount));
	if (ext4_xattr_check_block(inode, bh)) {
		EXT4_ERROR_INODE(inode, ""bad block %llu"",
				 EXT4_I(inode)->i_file_acl);
		error = -EFSCORRUPTED;
		goto cleanup;
	}
	ext4_xattr_cache_insert(ext4_mb_cache, bh);
	error = ext4_xattr_list_entries(dentry, BFIRST(bh), buffer, buffer_size);

cleanup:
	brelse(bh);

	return error;
}
","ext4_xattr_block_list(struct dentry *dentry, char *buffer, size_t buffer_size)
{
 	struct inode *inode = d_inode(dentry);
 	struct buffer_head *bh = NULL;
 	int error;
	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	ea_idebug(inode, ""buffer=%p, buffer_size=%ld"",
 		  buffer, (long)buffer_size);

	error = 0;
	if (!EXT4_I(inode)->i_file_acl)
		goto cleanup;
	ea_idebug(inode, ""reading block %llu"",
		  (unsigned long long)EXT4_I(inode)->i_file_acl);
	bh = sb_bread(inode->i_sb, EXT4_I(inode)->i_file_acl);
	error = -EIO;
	if (!bh)
		goto cleanup;
	ea_bdebug(bh, ""b_count=%d, refcount=%d"",
		atomic_read(&(bh->b_count)), le32_to_cpu(BHDR(bh)->h_refcount));
	if (ext4_xattr_check_block(inode, bh)) {
		EXT4_ERROR_INODE(inode, ""bad block %llu"",
				 EXT4_I(inode)->i_file_acl);
		error = -EFSCORRUPTED;
		goto cleanup;
	}
	ext4_xattr_cache_insert(ext4_mb_cache, bh);
	error = ext4_xattr_list_entries(dentry, BFIRST(bh), buffer, buffer_size);

cleanup:
	brelse(bh);

	return error;
}
",C,"	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
","	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
",,"@@ -53,7 +53,7 @@
 #include <linux/init.h>
 #include <linux/fs.h>
 #include <linux/slab.h>
-#include <linux/mbcache.h>
+#include <linux/mbcache2.h>
 #include <linux/quotaops.h>
 #include ""ext4_jbd2.h""
 #include ""ext4.h""
@@ -78,10 +78,10 @@
 # define ea_bdebug(bh, fmt, ...)	no_printk(fmt, ##__VA_ARGS__)
 #endif
 
-static void ext4_xattr_cache_insert(struct mb_cache *, struct buffer_head *);
+static void ext4_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);
 static struct buffer_head *ext4_xattr_cache_find(struct inode *,
 						 struct ext4_xattr_header *,
-						 struct mb_cache_entry **);
+						 struct mb2_cache_entry **);
 static void ext4_xattr_rehash(struct ext4_xattr_header *,
 			      struct ext4_xattr_entry *);
 static int ext4_xattr_list(struct dentry *dentry, char *buffer,
@@ -276,7 +276,7 @@ ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,
 	struct ext4_xattr_entry *entry;
 	size_t size;
 	int error;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	ea_idebug(inode, ""name=%d.%s, buffer=%p, buffer_size=%ld"",
 		  name_index, name, buffer, (long)buffer_size);
@@ -428,7 +428,7 @@ ext4_xattr_block_list(struct dentry *dentry, char *buffer, size_t buffer_size)
 	struct inode *inode = d_inode(dentry);
 	struct buffer_head *bh = NULL;
 	int error;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	ea_idebug(inode, ""buffer=%p, buffer_size=%ld"",
 		  buffer, (long)buffer_size);
@@ -545,30 +545,31 @@ static void
 ext4_xattr_release_block(handle_t *handle, struct inode *inode,
 			 struct buffer_head *bh)
 {
-	struct mb_cache_entry *ce = NULL;
 	int error = 0;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
-	ce = mb_cache_entry_get(ext4_mb_cache, bh->b_bdev, bh->b_blocknr);
 	BUFFER_TRACE(bh, ""get_write_access"");
 	error = ext4_journal_get_write_access(handle, bh);
 	if (error)
 		goto out;
 
 	lock_buffer(bh);
 	if (BHDR(bh)->h_refcount == cpu_to_le32(1)) {
+		__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);
+
 		ea_bdebug(bh, ""refcount now=0; freeing"");
-		if (ce)
-			mb_cache_entry_free(ce);
+		/*
+		 * This must happen under buffer lock for
+		 * ext4_xattr_block_set() to reliably detect freed block
+		 */
+		mb2_cache_entry_delete_block(EXT4_GET_MB_CACHE(inode), hash,
+					     bh->b_blocknr);
 		get_bh(bh);
 		unlock_buffer(bh);
 		ext4_free_blocks(handle, inode, bh, 0, 1,
 				 EXT4_FREE_BLOCKS_METADATA |
 				 EXT4_FREE_BLOCKS_FORGET);
 	} else {
 		le32_add_cpu(&BHDR(bh)->h_refcount, -1);
-		if (ce)
-			mb_cache_entry_release(ce);
 		/*
 		 * Beware of this ugliness: Releasing of xattr block references
 		 * from different inodes can race and so we have to protect
@@ -781,28 +782,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *new_bh = NULL;
 	struct ext4_xattr_search *s = &bs->s;
-	struct mb_cache_entry *ce = NULL;
+	struct mb2_cache_entry *ce = NULL;
 	int error = 0;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 #define header(x) ((struct ext4_xattr_header *)(x))
 
 	if (i->value && i->value_len > sb->s_blocksize)
 		return -ENOSPC;
 	if (s->base) {
-		ce = mb_cache_entry_get(ext4_mb_cache, bs->bh->b_bdev,
-					bs->bh->b_blocknr);
 		BUFFER_TRACE(bs->bh, ""get_write_access"");
 		error = ext4_journal_get_write_access(handle, bs->bh);
 		if (error)
 			goto cleanup;
 		lock_buffer(bs->bh);
 
 		if (header(s->base)->h_refcount == cpu_to_le32(1)) {
-			if (ce) {
-				mb_cache_entry_free(ce);
-				ce = NULL;
-			}
+			__u32 hash = le32_to_cpu(BHDR(bs->bh)->h_hash);
+
+			/*
+			 * This must happen under buffer lock for
+			 * ext4_xattr_block_set() to reliably detect modified
+			 * block
+			 */
+			mb2_cache_entry_delete_block(ext4_mb_cache, hash,
+						     bs->bh->b_blocknr);
 			ea_bdebug(bs->bh, ""modifying in-place"");
 			error = ext4_xattr_set_entry(i, s);
 			if (!error) {
@@ -826,10 +830,6 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 			int offset = (char *)s->here - bs->bh->b_data;
 
 			unlock_buffer(bs->bh);
-			if (ce) {
-				mb_cache_entry_release(ce);
-				ce = NULL;
-			}
 			ea_bdebug(bs->bh, ""cloning"");
 			s->base = kmalloc(bs->bh->b_size, GFP_NOFS);
 			error = -ENOMEM;
@@ -884,6 +884,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 				if (error)
 					goto cleanup_dquot;
 				lock_buffer(new_bh);
+				/*
+				 * We have to be careful about races with
+				 * freeing or rehashing of xattr block. Once we
+				 * hold buffer lock xattr block's state is
+				 * stable so we can check whether the block got
+				 * freed / rehashed or not.  Since we unhash
+				 * mbcache entry under buffer lock when freeing
+				 * / rehashing xattr block, checking whether
+				 * entry is still hashed is reliable.
+				 */
+				if (hlist_bl_unhashed(&ce->e_hash_list)) {
+					/*
+					 * Undo everything and check mbcache
+					 * again.
+					 */
+					unlock_buffer(new_bh);
+					dquot_free_block(inode,
+							 EXT4_C2B(EXT4_SB(sb),
+								  1));
+					brelse(new_bh);
+					mb2_cache_entry_put(ext4_mb_cache, ce);
+					ce = NULL;
+					new_bh = NULL;
+					goto inserted;
+				}
 				le32_add_cpu(&BHDR(new_bh)->h_refcount, 1);
 				ea_bdebug(new_bh, ""reusing; refcount now=%d"",
 					le32_to_cpu(BHDR(new_bh)->h_refcount));
@@ -894,7 +919,8 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 				if (error)
 					goto cleanup_dquot;
 			}
-			mb_cache_entry_release(ce);
+			mb2_cache_entry_touch(ext4_mb_cache, ce);
+			mb2_cache_entry_put(ext4_mb_cache, ce);
 			ce = NULL;
 		} else if (bs->bh && s->base == bs->bh->b_data) {
 			/* We were modifying this block in-place. */
@@ -959,7 +985,7 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 
 cleanup:
 	if (ce)
-		mb_cache_entry_release(ce);
+		mb2_cache_entry_put(ext4_mb_cache, ce);
 	brelse(new_bh);
 	if (!(bs->bh && s->base == bs->bh->b_data))
 		kfree(s->base);
@@ -1511,17 +1537,6 @@ ext4_xattr_delete_inode(handle_t *handle, struct inode *inode)
 	brelse(bh);
 }
 
-/*
- * ext4_xattr_put_super()
- *
- * This is called when a file system is unmounted.
- */
-void
-ext4_xattr_put_super(struct super_block *sb)
-{
-	mb_cache_shrink(sb->s_bdev);
-}
-
 /*
  * ext4_xattr_cache_insert()
  *
@@ -1531,28 +1546,18 @@ ext4_xattr_put_super(struct super_block *sb)
  * Returns 0, or a negative error number on failure.
  */
 static void
-ext4_xattr_cache_insert(struct mb_cache *ext4_mb_cache, struct buffer_head *bh)
+ext4_xattr_cache_insert(struct mb2_cache *ext4_mb_cache, struct buffer_head *bh)
 {
 	__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);
-	struct mb_cache_entry *ce;
 	int error;
 
-	ce = mb_cache_entry_alloc(ext4_mb_cache, GFP_NOFS);
-	if (!ce) {
-		ea_bdebug(bh, ""out of memory"");
-		return;
-	}
-	error = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);
+	error = mb2_cache_entry_create(ext4_mb_cache, GFP_NOFS, hash,
+				       bh->b_blocknr);
 	if (error) {
-		mb_cache_entry_free(ce);
-		if (error == -EBUSY) {
+		if (error == -EBUSY)
 			ea_bdebug(bh, ""already in cache"");
-			error = 0;
-		}
-	} else {
+	} else
 		ea_bdebug(bh, ""inserting [%x]"", (int)hash);
-		mb_cache_entry_release(ce);
-	}
 }
 
 /*
@@ -1605,26 +1610,19 @@ ext4_xattr_cmp(struct ext4_xattr_header *header1,
  */
 static struct buffer_head *
 ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,
-		      struct mb_cache_entry **pce)
+		      struct mb2_cache_entry **pce)
 {
 	__u32 hash = le32_to_cpu(header->h_hash);
-	struct mb_cache_entry *ce;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache_entry *ce;
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	if (!header->h_hash)
 		return NULL;  /* never share */
 	ea_idebug(inode, ""looking for cached blocks [%x]"", (int)hash);
-again:
-	ce = mb_cache_entry_find_first(ext4_mb_cache, inode->i_sb->s_bdev,
-				       hash);
+	ce = mb2_cache_entry_find_first(ext4_mb_cache, hash);
 	while (ce) {
 		struct buffer_head *bh;
 
-		if (IS_ERR(ce)) {
-			if (PTR_ERR(ce) == -EAGAIN)
-				goto again;
-			break;
-		}
 		bh = sb_bread(inode->i_sb, ce->e_block);
 		if (!bh) {
 			EXT4_ERROR_INODE(inode, ""block %lu read error"",
@@ -1640,7 +1638,7 @@ ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,
 			return bh;
 		}
 		brelse(bh);
-		ce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);
+		ce = mb2_cache_entry_find_next(ext4_mb_cache, ce);
 	}
 	return NULL;
 }
@@ -1715,15 +1713,15 @@ static void ext4_xattr_rehash(struct ext4_xattr_header *header,
 
 #define	HASH_BUCKET_BITS	10
 
-struct mb_cache *
-ext4_xattr_create_cache(char *name)
+struct mb2_cache *
+ext4_xattr_create_cache(void)
 {
-	return mb_cache_create(name, HASH_BUCKET_BITS);
+	return mb2_cache_create(HASH_BUCKET_BITS);
 }
 
-void ext4_xattr_destroy_cache(struct mb_cache *cache)
+void ext4_xattr_destroy_cache(struct mb2_cache *cache)
 {
 	if (cache)
-		mb_cache_destroy(cache);
+		mb2_cache_destroy(cache);
 }
 ",linux,82939d7999dfc1f1998c4b1c12e2f19edbdff272,f9a61eb4e2471c56a63cd804c7474128138c38ac,1,"ext4_xattr_block_list(struct dentry *dentry, char *buffer, size_t buffer_size)
{
 	struct inode *inode = d_inode(dentry);
 	struct buffer_head *bh = NULL;
 	int error;
//flaw_line_below:
	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
//fix_flaw_line_below:
//	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	ea_idebug(inode, ""buffer=%p, buffer_size=%ld"",
 		  buffer, (long)buffer_size);

	error = 0;
	if (!EXT4_I(inode)->i_file_acl)
		goto cleanup;
	ea_idebug(inode, ""reading block %llu"",
		  (unsigned long long)EXT4_I(inode)->i_file_acl);
	bh = sb_bread(inode->i_sb, EXT4_I(inode)->i_file_acl);
	error = -EIO;
	if (!bh)
		goto cleanup;
	ea_bdebug(bh, ""b_count=%d, refcount=%d"",
		atomic_read(&(bh->b_count)), le32_to_cpu(BHDR(bh)->h_refcount));
	if (ext4_xattr_check_block(inode, bh)) {
		EXT4_ERROR_INODE(inode, ""bad block %llu"",
				 EXT4_I(inode)->i_file_acl);
		error = -EFSCORRUPTED;
		goto cleanup;
	}
	ext4_xattr_cache_insert(ext4_mb_cache, bh);
	error = ext4_xattr_list_entries(dentry, BFIRST(bh), buffer, buffer_size);

cleanup:
	brelse(bh);

	return error;
}
"
5426,183162,,Local,Not required,Partial,CVE-2015-8952,https://www.cvedetails.com/cve/CVE-2015-8952/,CWE-19,Low,,,,2016-10-16,2.1,"The mbcache feature in the ext2 and ext4 filesystem implementations in the Linux kernel before 4.6 mishandles xattr block caching, which allows local users to cause a denial of service (soft lockup) via filesystem operations in environments that use many attributes, as demonstrated by Ceph and Samba.",2018-03-15,DoS ,39,https://github.com/torvalds/linux/commit/82939d7999dfc1f1998c4b1c12e2f19edbdff272,82939d7999dfc1f1998c4b1c12e2f19edbdff272,"ext4: convert to mbcache2

The conversion is generally straightforward. The only tricky part is
that xattr block corresponding to found mbcache entry can get freed
before we get buffer lock for that block. So we have to check whether
the entry is still valid after getting buffer lock.

Signed-off-by: Jan Kara <jack@suse.cz>
Signed-off-by: Theodore Ts'o <tytso@mit.edu>",14,fs/ext4/xattr.c,"{""sha"": ""9ac9e62569ef8fdf981021b58d37ab99d0150882"", ""filename"": ""fs/ext4/ext4.h"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 1, ""changes"": 2, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/ext4.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/ext4.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/ext4.h?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -1468,7 +1468,7 @@ struct ext4_sb_info {\n \tstruct list_head s_es_list;\t/* List of inodes with reclaimable extents */\n \tlong s_es_nr_inode;\n \tstruct ext4_es_stats s_es_stats;\n-\tstruct mb_cache *s_mb_cache;\n+\tstruct mb2_cache *s_mb_cache;\n \tspinlock_t s_es_lock ____cacheline_aligned_in_smp;\n \n \t/* Ratelimit ext4 messages. */""}<_**next**_>{""sha"": ""ecc37e1034358d769ab29971e9d2301fb9e2b3bc"", ""filename"": ""fs/ext4/super.c"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 2, ""changes"": 7, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/super.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/super.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/super.c?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -844,7 +844,6 @@ static void ext4_put_super(struct super_block *sb)\n \text4_release_system_zone(sb);\n \text4_mb_release(sb);\n \text4_ext_release(sb);\n-\text4_xattr_put_super(sb);\n \n \tif (!(sb->s_flags & MS_RDONLY)) {\n \t\text4_clear_feature_journal_needs_recovery(sb);\n@@ -3797,7 +3796,7 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n \n no_journal:\n \tif (ext4_mballoc_ready) {\n-\t\tsbi->s_mb_cache = ext4_xattr_create_cache(sb->s_id);\n+\t\tsbi->s_mb_cache = ext4_xattr_create_cache();\n \t\tif (!sbi->s_mb_cache) {\n \t\t\text4_msg(sb, KERN_ERR, \""Failed to create an mb_cache\"");\n \t\t\tgoto failed_mount_wq;\n@@ -4027,6 +4026,10 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n \tif (EXT4_SB(sb)->rsv_conversion_wq)\n \t\tdestroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);\n failed_mount_wq:\n+\tif (sbi->s_mb_cache) {\n+\t\text4_xattr_destroy_cache(sbi->s_mb_cache);\n+\t\tsbi->s_mb_cache = NULL;\n+\t}\n \tif (sbi->s_journal) {\n \t\tjbd2_journal_destroy(sbi->s_journal);\n \t\tsbi->s_journal = NULL;""}<_**next**_>{""sha"": ""fe9f8d6ab6c91b60689abadefd5435c31893fcae"", ""filename"": ""fs/ext4/xattr.c"", ""status"": ""modified"", ""additions"": 67, ""deletions"": 69, ""changes"": 136, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/xattr.c?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -53,7 +53,7 @@\n #include <linux/init.h>\n #include <linux/fs.h>\n #include <linux/slab.h>\n-#include <linux/mbcache.h>\n+#include <linux/mbcache2.h>\n #include <linux/quotaops.h>\n #include \""ext4_jbd2.h\""\n #include \""ext4.h\""\n@@ -78,10 +78,10 @@\n # define ea_bdebug(bh, fmt, ...)\tno_printk(fmt, ##__VA_ARGS__)\n #endif\n \n-static void ext4_xattr_cache_insert(struct mb_cache *, struct buffer_head *);\n+static void ext4_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);\n static struct buffer_head *ext4_xattr_cache_find(struct inode *,\n \t\t\t\t\t\t struct ext4_xattr_header *,\n-\t\t\t\t\t\t struct mb_cache_entry **);\n+\t\t\t\t\t\t struct mb2_cache_entry **);\n static void ext4_xattr_rehash(struct ext4_xattr_header *,\n \t\t\t      struct ext4_xattr_entry *);\n static int ext4_xattr_list(struct dentry *dentry, char *buffer,\n@@ -276,7 +276,7 @@ ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,\n \tstruct ext4_xattr_entry *entry;\n \tsize_t size;\n \tint error;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tea_idebug(inode, \""name=%d.%s, buffer=%p, buffer_size=%ld\"",\n \t\t  name_index, name, buffer, (long)buffer_size);\n@@ -428,7 +428,7 @@ ext4_xattr_block_list(struct dentry *dentry, char *buffer, size_t buffer_size)\n \tstruct inode *inode = d_inode(dentry);\n \tstruct buffer_head *bh = NULL;\n \tint error;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tea_idebug(inode, \""buffer=%p, buffer_size=%ld\"",\n \t\t  buffer, (long)buffer_size);\n@@ -545,30 +545,31 @@ static void\n ext4_xattr_release_block(handle_t *handle, struct inode *inode,\n \t\t\t struct buffer_head *bh)\n {\n-\tstruct mb_cache_entry *ce = NULL;\n \tint error = 0;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n-\tce = mb_cache_entry_get(ext4_mb_cache, bh->b_bdev, bh->b_blocknr);\n \tBUFFER_TRACE(bh, \""get_write_access\"");\n \terror = ext4_journal_get_write_access(handle, bh);\n \tif (error)\n \t\tgoto out;\n \n \tlock_buffer(bh);\n \tif (BHDR(bh)->h_refcount == cpu_to_le32(1)) {\n+\t\t__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);\n+\n \t\tea_bdebug(bh, \""refcount now=0; freeing\"");\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_free(ce);\n+\t\t/*\n+\t\t * This must happen under buffer lock for\n+\t\t * ext4_xattr_block_set() to reliably detect freed block\n+\t\t */\n+\t\tmb2_cache_entry_delete_block(EXT4_GET_MB_CACHE(inode), hash,\n+\t\t\t\t\t     bh->b_blocknr);\n \t\tget_bh(bh);\n \t\tunlock_buffer(bh);\n \t\text4_free_blocks(handle, inode, bh, 0, 1,\n \t\t\t\t EXT4_FREE_BLOCKS_METADATA |\n \t\t\t\t EXT4_FREE_BLOCKS_FORGET);\n \t} else {\n \t\tle32_add_cpu(&BHDR(bh)->h_refcount, -1);\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_release(ce);\n \t\t/*\n \t\t * Beware of this ugliness: Releasing of xattr block references\n \t\t * from different inodes can race and so we have to protect\n@@ -781,28 +782,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \tstruct super_block *sb = inode->i_sb;\n \tstruct buffer_head *new_bh = NULL;\n \tstruct ext4_xattr_search *s = &bs->s;\n-\tstruct mb_cache_entry *ce = NULL;\n+\tstruct mb2_cache_entry *ce = NULL;\n \tint error = 0;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n #define header(x) ((struct ext4_xattr_header *)(x))\n \n \tif (i->value && i->value_len > sb->s_blocksize)\n \t\treturn -ENOSPC;\n \tif (s->base) {\n-\t\tce = mb_cache_entry_get(ext4_mb_cache, bs->bh->b_bdev,\n-\t\t\t\t\tbs->bh->b_blocknr);\n \t\tBUFFER_TRACE(bs->bh, \""get_write_access\"");\n \t\terror = ext4_journal_get_write_access(handle, bs->bh);\n \t\tif (error)\n \t\t\tgoto cleanup;\n \t\tlock_buffer(bs->bh);\n \n \t\tif (header(s->base)->h_refcount == cpu_to_le32(1)) {\n-\t\t\tif (ce) {\n-\t\t\t\tmb_cache_entry_free(ce);\n-\t\t\t\tce = NULL;\n-\t\t\t}\n+\t\t\t__u32 hash = le32_to_cpu(BHDR(bs->bh)->h_hash);\n+\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext4_xattr_block_set() to reliably detect modified\n+\t\t\t * block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(ext4_mb_cache, hash,\n+\t\t\t\t\t\t     bs->bh->b_blocknr);\n \t\t\tea_bdebug(bs->bh, \""modifying in-place\"");\n \t\t\terror = ext4_xattr_set_entry(i, s);\n \t\t\tif (!error) {\n@@ -826,10 +830,6 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\tint offset = (char *)s->here - bs->bh->b_data;\n \n \t\t\tunlock_buffer(bs->bh);\n-\t\t\tif (ce) {\n-\t\t\t\tmb_cache_entry_release(ce);\n-\t\t\t\tce = NULL;\n-\t\t\t}\n \t\t\tea_bdebug(bs->bh, \""cloning\"");\n \t\t\ts->base = kmalloc(bs->bh->b_size, GFP_NOFS);\n \t\t\terror = -ENOMEM;\n@@ -884,6 +884,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\t\tif (error)\n \t\t\t\t\tgoto cleanup_dquot;\n \t\t\t\tlock_buffer(new_bh);\n+\t\t\t\t/*\n+\t\t\t\t * We have to be careful about races with\n+\t\t\t\t * freeing or rehashing of xattr block. Once we\n+\t\t\t\t * hold buffer lock xattr block's state is\n+\t\t\t\t * stable so we can check whether the block got\n+\t\t\t\t * freed / rehashed or not.  Since we unhash\n+\t\t\t\t * mbcache entry under buffer lock when freeing\n+\t\t\t\t * / rehashing xattr block, checking whether\n+\t\t\t\t * entry is still hashed is reliable.\n+\t\t\t\t */\n+\t\t\t\tif (hlist_bl_unhashed(&ce->e_hash_list)) {\n+\t\t\t\t\t/*\n+\t\t\t\t\t * Undo everything and check mbcache\n+\t\t\t\t\t * again.\n+\t\t\t\t\t */\n+\t\t\t\t\tunlock_buffer(new_bh);\n+\t\t\t\t\tdquot_free_block(inode,\n+\t\t\t\t\t\t\t EXT4_C2B(EXT4_SB(sb),\n+\t\t\t\t\t\t\t\t  1));\n+\t\t\t\t\tbrelse(new_bh);\n+\t\t\t\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n+\t\t\t\t\tce = NULL;\n+\t\t\t\t\tnew_bh = NULL;\n+\t\t\t\t\tgoto inserted;\n+\t\t\t\t}\n \t\t\t\tle32_add_cpu(&BHDR(new_bh)->h_refcount, 1);\n \t\t\t\tea_bdebug(new_bh, \""reusing; refcount now=%d\"",\n \t\t\t\t\tle32_to_cpu(BHDR(new_bh)->h_refcount));\n@@ -894,7 +919,8 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\t\tif (error)\n \t\t\t\t\tgoto cleanup_dquot;\n \t\t\t}\n-\t\t\tmb_cache_entry_release(ce);\n+\t\t\tmb2_cache_entry_touch(ext4_mb_cache, ce);\n+\t\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n \t\t\tce = NULL;\n \t\t} else if (bs->bh && s->base == bs->bh->b_data) {\n \t\t\t/* We were modifying this block in-place. */\n@@ -959,7 +985,7 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \n cleanup:\n \tif (ce)\n-\t\tmb_cache_entry_release(ce);\n+\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n \tbrelse(new_bh);\n \tif (!(bs->bh && s->base == bs->bh->b_data))\n \t\tkfree(s->base);\n@@ -1511,17 +1537,6 @@ ext4_xattr_delete_inode(handle_t *handle, struct inode *inode)\n \tbrelse(bh);\n }\n \n-/*\n- * ext4_xattr_put_super()\n- *\n- * This is called when a file system is unmounted.\n- */\n-void\n-ext4_xattr_put_super(struct super_block *sb)\n-{\n-\tmb_cache_shrink(sb->s_bdev);\n-}\n-\n /*\n  * ext4_xattr_cache_insert()\n  *\n@@ -1531,28 +1546,18 @@ ext4_xattr_put_super(struct super_block *sb)\n  * Returns 0, or a negative error number on failure.\n  */\n static void\n-ext4_xattr_cache_insert(struct mb_cache *ext4_mb_cache, struct buffer_head *bh)\n+ext4_xattr_cache_insert(struct mb2_cache *ext4_mb_cache, struct buffer_head *bh)\n {\n \t__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);\n-\tstruct mb_cache_entry *ce;\n \tint error;\n \n-\tce = mb_cache_entry_alloc(ext4_mb_cache, GFP_NOFS);\n-\tif (!ce) {\n-\t\tea_bdebug(bh, \""out of memory\"");\n-\t\treturn;\n-\t}\n-\terror = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);\n+\terror = mb2_cache_entry_create(ext4_mb_cache, GFP_NOFS, hash,\n+\t\t\t\t       bh->b_blocknr);\n \tif (error) {\n-\t\tmb_cache_entry_free(ce);\n-\t\tif (error == -EBUSY) {\n+\t\tif (error == -EBUSY)\n \t\t\tea_bdebug(bh, \""already in cache\"");\n-\t\t\terror = 0;\n-\t\t}\n-\t} else {\n+\t} else\n \t\tea_bdebug(bh, \""inserting [%x]\"", (int)hash);\n-\t\tmb_cache_entry_release(ce);\n-\t}\n }\n \n /*\n@@ -1605,26 +1610,19 @@ ext4_xattr_cmp(struct ext4_xattr_header *header1,\n  */\n static struct buffer_head *\n ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,\n-\t\t      struct mb_cache_entry **pce)\n+\t\t      struct mb2_cache_entry **pce)\n {\n \t__u32 hash = le32_to_cpu(header->h_hash);\n-\tstruct mb_cache_entry *ce;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache_entry *ce;\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tif (!header->h_hash)\n \t\treturn NULL;  /* never share */\n \tea_idebug(inode, \""looking for cached blocks [%x]\"", (int)hash);\n-again:\n-\tce = mb_cache_entry_find_first(ext4_mb_cache, inode->i_sb->s_bdev,\n-\t\t\t\t       hash);\n+\tce = mb2_cache_entry_find_first(ext4_mb_cache, hash);\n \twhile (ce) {\n \t\tstruct buffer_head *bh;\n \n-\t\tif (IS_ERR(ce)) {\n-\t\t\tif (PTR_ERR(ce) == -EAGAIN)\n-\t\t\t\tgoto again;\n-\t\t\tbreak;\n-\t\t}\n \t\tbh = sb_bread(inode->i_sb, ce->e_block);\n \t\tif (!bh) {\n \t\t\tEXT4_ERROR_INODE(inode, \""block %lu read error\"",\n@@ -1640,7 +1638,7 @@ ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,\n \t\t\treturn bh;\n \t\t}\n \t\tbrelse(bh);\n-\t\tce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);\n+\t\tce = mb2_cache_entry_find_next(ext4_mb_cache, ce);\n \t}\n \treturn NULL;\n }\n@@ -1715,15 +1713,15 @@ static void ext4_xattr_rehash(struct ext4_xattr_header *header,\n \n #define\tHASH_BUCKET_BITS\t10\n \n-struct mb_cache *\n-ext4_xattr_create_cache(char *name)\n+struct mb2_cache *\n+ext4_xattr_create_cache(void)\n {\n-\treturn mb_cache_create(name, HASH_BUCKET_BITS);\n+\treturn mb2_cache_create(HASH_BUCKET_BITS);\n }\n \n-void ext4_xattr_destroy_cache(struct mb_cache *cache)\n+void ext4_xattr_destroy_cache(struct mb2_cache *cache)\n {\n \tif (cache)\n-\t\tmb_cache_destroy(cache);\n+\t\tmb2_cache_destroy(cache);\n }\n ""}<_**next**_>{""sha"": ""10b0f7323ed6fcd628efee26998d0f1be7652c48"", ""filename"": ""fs/ext4/xattr.h"", ""status"": ""modified"", ""additions"": 2, ""deletions"": 3, ""changes"": 5, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/xattr.h?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -108,7 +108,6 @@ extern int ext4_xattr_set(struct inode *, int, const char *, const void *, size_\n extern int ext4_xattr_set_handle(handle_t *, struct inode *, int, const char *, const void *, size_t, int);\n \n extern void ext4_xattr_delete_inode(handle_t *, struct inode *);\n-extern void ext4_xattr_put_super(struct super_block *);\n \n extern int ext4_expand_extra_isize_ea(struct inode *inode, int new_extra_isize,\n \t\t\t    struct ext4_inode *raw_inode, handle_t *handle);\n@@ -124,8 +123,8 @@ extern int ext4_xattr_ibody_inline_set(handle_t *handle, struct inode *inode,\n \t\t\t\t       struct ext4_xattr_info *i,\n \t\t\t\t       struct ext4_xattr_ibody_find *is);\n \n-extern struct mb_cache *ext4_xattr_create_cache(char *name);\n-extern void ext4_xattr_destroy_cache(struct mb_cache *);\n+extern struct mb2_cache *ext4_xattr_create_cache(void);\n+extern void ext4_xattr_destroy_cache(struct mb2_cache *);\n \n #ifdef CONFIG_EXT4_FS_SECURITY\n extern int ext4_init_security(handle_t *handle, struct inode *inode,""}","ext4_xattr_block_set(handle_t *handle, struct inode *inode,
		     struct ext4_xattr_info *i,
		     struct ext4_xattr_block_find *bs)
{
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *new_bh = NULL;
 	struct ext4_xattr_search *s = &bs->s;
	struct mb2_cache_entry *ce = NULL;
 	int error = 0;
	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 #define header(x) ((struct ext4_xattr_header *)(x))
 
 	if (i->value && i->value_len > sb->s_blocksize)
 		return -ENOSPC;
 	if (s->base) {
 		BUFFER_TRACE(bs->bh, ""get_write_access"");
 		error = ext4_journal_get_write_access(handle, bs->bh);
 		if (error)
 			goto cleanup;
 		lock_buffer(bs->bh);
 
 		if (header(s->base)->h_refcount == cpu_to_le32(1)) {
			__u32 hash = le32_to_cpu(BHDR(bs->bh)->h_hash);

			/*
			 * This must happen under buffer lock for
			 * ext4_xattr_block_set() to reliably detect modified
			 * block
			 */
			mb2_cache_entry_delete_block(ext4_mb_cache, hash,
						     bs->bh->b_blocknr);
 			ea_bdebug(bs->bh, ""modifying in-place"");
 			error = ext4_xattr_set_entry(i, s);
 			if (!error) {
				if (!IS_LAST_ENTRY(s->first))
					ext4_xattr_rehash(header(s->base),
							  s->here);
				ext4_xattr_cache_insert(ext4_mb_cache,
					bs->bh);
			}
			unlock_buffer(bs->bh);
			if (error == -EFSCORRUPTED)
				goto bad_block;
			if (!error)
				error = ext4_handle_dirty_xattr_block(handle,
								      inode,
								      bs->bh);
			if (error)
				goto cleanup;
			goto inserted;
		} else {
 			int offset = (char *)s->here - bs->bh->b_data;
 
 			unlock_buffer(bs->bh);
 			ea_bdebug(bs->bh, ""cloning"");
 			s->base = kmalloc(bs->bh->b_size, GFP_NOFS);
 			error = -ENOMEM;
			if (s->base == NULL)
				goto cleanup;
			memcpy(s->base, BHDR(bs->bh), bs->bh->b_size);
			s->first = ENTRY(header(s->base)+1);
			header(s->base)->h_refcount = cpu_to_le32(1);
			s->here = ENTRY(s->base + offset);
			s->end = s->base + bs->bh->b_size;
		}
	} else {
		/* Allocate a buffer where we construct the new block. */
		s->base = kzalloc(sb->s_blocksize, GFP_NOFS);
		/* assert(header == s->base) */
		error = -ENOMEM;
		if (s->base == NULL)
			goto cleanup;
		header(s->base)->h_magic = cpu_to_le32(EXT4_XATTR_MAGIC);
		header(s->base)->h_blocks = cpu_to_le32(1);
		header(s->base)->h_refcount = cpu_to_le32(1);
		s->first = ENTRY(header(s->base)+1);
		s->here = ENTRY(header(s->base)+1);
		s->end = s->base + sb->s_blocksize;
	}

	error = ext4_xattr_set_entry(i, s);
	if (error == -EFSCORRUPTED)
		goto bad_block;
	if (error)
		goto cleanup;
	if (!IS_LAST_ENTRY(s->first))
		ext4_xattr_rehash(header(s->base), s->here);

inserted:
	if (!IS_LAST_ENTRY(s->first)) {
		new_bh = ext4_xattr_cache_find(inode, header(s->base), &ce);
		if (new_bh) {
			/* We found an identical block in the cache. */
			if (new_bh == bs->bh)
				ea_bdebug(new_bh, ""keeping"");
			else {
				/* The old block is released after updating
				   the inode. */
				error = dquot_alloc_block(inode,
						EXT4_C2B(EXT4_SB(sb), 1));
				if (error)
					goto cleanup;
				BUFFER_TRACE(new_bh, ""get_write_access"");
				error = ext4_journal_get_write_access(handle,
								      new_bh);
 				if (error)
 					goto cleanup_dquot;
 				lock_buffer(new_bh);
				/*
				 * We have to be careful about races with
				 * freeing or rehashing of xattr block. Once we
				 * hold buffer lock xattr block's state is
				 * stable so we can check whether the block got
				 * freed / rehashed or not.  Since we unhash
				 * mbcache entry under buffer lock when freeing
				 * / rehashing xattr block, checking whether
				 * entry is still hashed is reliable.
				 */
				if (hlist_bl_unhashed(&ce->e_hash_list)) {
					/*
					 * Undo everything and check mbcache
					 * again.
					 */
					unlock_buffer(new_bh);
					dquot_free_block(inode,
							 EXT4_C2B(EXT4_SB(sb),
								  1));
					brelse(new_bh);
					mb2_cache_entry_put(ext4_mb_cache, ce);
					ce = NULL;
					new_bh = NULL;
					goto inserted;
				}
 				le32_add_cpu(&BHDR(new_bh)->h_refcount, 1);
 				ea_bdebug(new_bh, ""reusing; refcount now=%d"",
 					le32_to_cpu(BHDR(new_bh)->h_refcount));
				unlock_buffer(new_bh);
				error = ext4_handle_dirty_xattr_block(handle,
								      inode,
								      new_bh);
 				if (error)
 					goto cleanup_dquot;
 			}
			mb2_cache_entry_touch(ext4_mb_cache, ce);
			mb2_cache_entry_put(ext4_mb_cache, ce);
 			ce = NULL;
 		} else if (bs->bh && s->base == bs->bh->b_data) {
 			/* We were modifying this block in-place. */
			ea_bdebug(bs->bh, ""keeping this block"");
			new_bh = bs->bh;
			get_bh(new_bh);
		} else {
			/* We need to allocate a new block */
			ext4_fsblk_t goal, block;

			goal = ext4_group_first_block_no(sb,
						EXT4_I(inode)->i_block_group);

			/* non-extent files can't have physical blocks past 2^32 */
			if (!(ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS)))
				goal = goal & EXT4_MAX_BLOCK_FILE_PHYS;

			block = ext4_new_meta_blocks(handle, inode, goal, 0,
						     NULL, &error);
			if (error)
				goto cleanup;

			if (!(ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS)))
				BUG_ON(block > EXT4_MAX_BLOCK_FILE_PHYS);

			ea_idebug(inode, ""creating block %llu"",
				  (unsigned long long)block);

			new_bh = sb_getblk(sb, block);
			if (unlikely(!new_bh)) {
				error = -ENOMEM;
getblk_failed:
				ext4_free_blocks(handle, inode, NULL, block, 1,
						 EXT4_FREE_BLOCKS_METADATA);
				goto cleanup;
			}
			lock_buffer(new_bh);
			error = ext4_journal_get_create_access(handle, new_bh);
			if (error) {
				unlock_buffer(new_bh);
				error = -EIO;
				goto getblk_failed;
			}
			memcpy(new_bh->b_data, s->base, new_bh->b_size);
			set_buffer_uptodate(new_bh);
			unlock_buffer(new_bh);
			ext4_xattr_cache_insert(ext4_mb_cache, new_bh);
			error = ext4_handle_dirty_xattr_block(handle,
							      inode, new_bh);
			if (error)
				goto cleanup;
		}
	}

	/* Update the inode. */
	EXT4_I(inode)->i_file_acl = new_bh ? new_bh->b_blocknr : 0;

	/* Drop the previous xattr block. */
	if (bs->bh && bs->bh != new_bh)
		ext4_xattr_release_block(handle, inode, bs->bh);
	error = 0;
 
 cleanup:
 	if (ce)
		mb2_cache_entry_put(ext4_mb_cache, ce);
 	brelse(new_bh);
 	if (!(bs->bh && s->base == bs->bh->b_data))
 		kfree(s->base);

	return error;

cleanup_dquot:
	dquot_free_block(inode, EXT4_C2B(EXT4_SB(sb), 1));
	goto cleanup;

bad_block:
	EXT4_ERROR_INODE(inode, ""bad block %llu"",
			 EXT4_I(inode)->i_file_acl);
	goto cleanup;

#undef header
}
","ext4_xattr_block_set(handle_t *handle, struct inode *inode,
		     struct ext4_xattr_info *i,
		     struct ext4_xattr_block_find *bs)
{
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *new_bh = NULL;
 	struct ext4_xattr_search *s = &bs->s;
	struct mb_cache_entry *ce = NULL;
 	int error = 0;
	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 #define header(x) ((struct ext4_xattr_header *)(x))
 
 	if (i->value && i->value_len > sb->s_blocksize)
 		return -ENOSPC;
 	if (s->base) {
		ce = mb_cache_entry_get(ext4_mb_cache, bs->bh->b_bdev,
					bs->bh->b_blocknr);
 		BUFFER_TRACE(bs->bh, ""get_write_access"");
 		error = ext4_journal_get_write_access(handle, bs->bh);
 		if (error)
 			goto cleanup;
 		lock_buffer(bs->bh);
 
 		if (header(s->base)->h_refcount == cpu_to_le32(1)) {
			if (ce) {
				mb_cache_entry_free(ce);
				ce = NULL;
			}
 			ea_bdebug(bs->bh, ""modifying in-place"");
 			error = ext4_xattr_set_entry(i, s);
 			if (!error) {
				if (!IS_LAST_ENTRY(s->first))
					ext4_xattr_rehash(header(s->base),
							  s->here);
				ext4_xattr_cache_insert(ext4_mb_cache,
					bs->bh);
			}
			unlock_buffer(bs->bh);
			if (error == -EFSCORRUPTED)
				goto bad_block;
			if (!error)
				error = ext4_handle_dirty_xattr_block(handle,
								      inode,
								      bs->bh);
			if (error)
				goto cleanup;
			goto inserted;
		} else {
 			int offset = (char *)s->here - bs->bh->b_data;
 
 			unlock_buffer(bs->bh);
			if (ce) {
				mb_cache_entry_release(ce);
				ce = NULL;
			}
 			ea_bdebug(bs->bh, ""cloning"");
 			s->base = kmalloc(bs->bh->b_size, GFP_NOFS);
 			error = -ENOMEM;
			if (s->base == NULL)
				goto cleanup;
			memcpy(s->base, BHDR(bs->bh), bs->bh->b_size);
			s->first = ENTRY(header(s->base)+1);
			header(s->base)->h_refcount = cpu_to_le32(1);
			s->here = ENTRY(s->base + offset);
			s->end = s->base + bs->bh->b_size;
		}
	} else {
		/* Allocate a buffer where we construct the new block. */
		s->base = kzalloc(sb->s_blocksize, GFP_NOFS);
		/* assert(header == s->base) */
		error = -ENOMEM;
		if (s->base == NULL)
			goto cleanup;
		header(s->base)->h_magic = cpu_to_le32(EXT4_XATTR_MAGIC);
		header(s->base)->h_blocks = cpu_to_le32(1);
		header(s->base)->h_refcount = cpu_to_le32(1);
		s->first = ENTRY(header(s->base)+1);
		s->here = ENTRY(header(s->base)+1);
		s->end = s->base + sb->s_blocksize;
	}

	error = ext4_xattr_set_entry(i, s);
	if (error == -EFSCORRUPTED)
		goto bad_block;
	if (error)
		goto cleanup;
	if (!IS_LAST_ENTRY(s->first))
		ext4_xattr_rehash(header(s->base), s->here);

inserted:
	if (!IS_LAST_ENTRY(s->first)) {
		new_bh = ext4_xattr_cache_find(inode, header(s->base), &ce);
		if (new_bh) {
			/* We found an identical block in the cache. */
			if (new_bh == bs->bh)
				ea_bdebug(new_bh, ""keeping"");
			else {
				/* The old block is released after updating
				   the inode. */
				error = dquot_alloc_block(inode,
						EXT4_C2B(EXT4_SB(sb), 1));
				if (error)
					goto cleanup;
				BUFFER_TRACE(new_bh, ""get_write_access"");
				error = ext4_journal_get_write_access(handle,
								      new_bh);
 				if (error)
 					goto cleanup_dquot;
 				lock_buffer(new_bh);
 				le32_add_cpu(&BHDR(new_bh)->h_refcount, 1);
 				ea_bdebug(new_bh, ""reusing; refcount now=%d"",
 					le32_to_cpu(BHDR(new_bh)->h_refcount));
				unlock_buffer(new_bh);
				error = ext4_handle_dirty_xattr_block(handle,
								      inode,
								      new_bh);
 				if (error)
 					goto cleanup_dquot;
 			}
			mb_cache_entry_release(ce);
 			ce = NULL;
 		} else if (bs->bh && s->base == bs->bh->b_data) {
 			/* We were modifying this block in-place. */
			ea_bdebug(bs->bh, ""keeping this block"");
			new_bh = bs->bh;
			get_bh(new_bh);
		} else {
			/* We need to allocate a new block */
			ext4_fsblk_t goal, block;

			goal = ext4_group_first_block_no(sb,
						EXT4_I(inode)->i_block_group);

			/* non-extent files can't have physical blocks past 2^32 */
			if (!(ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS)))
				goal = goal & EXT4_MAX_BLOCK_FILE_PHYS;

			block = ext4_new_meta_blocks(handle, inode, goal, 0,
						     NULL, &error);
			if (error)
				goto cleanup;

			if (!(ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS)))
				BUG_ON(block > EXT4_MAX_BLOCK_FILE_PHYS);

			ea_idebug(inode, ""creating block %llu"",
				  (unsigned long long)block);

			new_bh = sb_getblk(sb, block);
			if (unlikely(!new_bh)) {
				error = -ENOMEM;
getblk_failed:
				ext4_free_blocks(handle, inode, NULL, block, 1,
						 EXT4_FREE_BLOCKS_METADATA);
				goto cleanup;
			}
			lock_buffer(new_bh);
			error = ext4_journal_get_create_access(handle, new_bh);
			if (error) {
				unlock_buffer(new_bh);
				error = -EIO;
				goto getblk_failed;
			}
			memcpy(new_bh->b_data, s->base, new_bh->b_size);
			set_buffer_uptodate(new_bh);
			unlock_buffer(new_bh);
			ext4_xattr_cache_insert(ext4_mb_cache, new_bh);
			error = ext4_handle_dirty_xattr_block(handle,
							      inode, new_bh);
			if (error)
				goto cleanup;
		}
	}

	/* Update the inode. */
	EXT4_I(inode)->i_file_acl = new_bh ? new_bh->b_blocknr : 0;

	/* Drop the previous xattr block. */
	if (bs->bh && bs->bh != new_bh)
		ext4_xattr_release_block(handle, inode, bs->bh);
	error = 0;
 
 cleanup:
 	if (ce)
		mb_cache_entry_release(ce);
 	brelse(new_bh);
 	if (!(bs->bh && s->base == bs->bh->b_data))
 		kfree(s->base);

	return error;

cleanup_dquot:
	dquot_free_block(inode, EXT4_C2B(EXT4_SB(sb), 1));
	goto cleanup;

bad_block:
	EXT4_ERROR_INODE(inode, ""bad block %llu"",
			 EXT4_I(inode)->i_file_acl);
	goto cleanup;

#undef header
}
",C,"	struct mb2_cache_entry *ce = NULL;
	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
			__u32 hash = le32_to_cpu(BHDR(bs->bh)->h_hash);

			/*
			 * This must happen under buffer lock for
			 * ext4_xattr_block_set() to reliably detect modified
			 * block
			 */
			mb2_cache_entry_delete_block(ext4_mb_cache, hash,
						     bs->bh->b_blocknr);
				/*
				 * We have to be careful about races with
				 * freeing or rehashing of xattr block. Once we
				 * hold buffer lock xattr block's state is
				 * stable so we can check whether the block got
				 * freed / rehashed or not.  Since we unhash
				 * mbcache entry under buffer lock when freeing
				 * / rehashing xattr block, checking whether
				 * entry is still hashed is reliable.
				 */
				if (hlist_bl_unhashed(&ce->e_hash_list)) {
					/*
					 * Undo everything and check mbcache
					 * again.
					 */
					unlock_buffer(new_bh);
					dquot_free_block(inode,
							 EXT4_C2B(EXT4_SB(sb),
								  1));
					brelse(new_bh);
					mb2_cache_entry_put(ext4_mb_cache, ce);
					ce = NULL;
					new_bh = NULL;
					goto inserted;
				}
			mb2_cache_entry_touch(ext4_mb_cache, ce);
			mb2_cache_entry_put(ext4_mb_cache, ce);
		mb2_cache_entry_put(ext4_mb_cache, ce);
","	struct mb_cache_entry *ce = NULL;
	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
		ce = mb_cache_entry_get(ext4_mb_cache, bs->bh->b_bdev,
					bs->bh->b_blocknr);
			if (ce) {
				mb_cache_entry_free(ce);
				ce = NULL;
			}
			if (ce) {
				mb_cache_entry_release(ce);
				ce = NULL;
			}
			mb_cache_entry_release(ce);
		mb_cache_entry_release(ce);
",,"@@ -53,7 +53,7 @@
 #include <linux/init.h>
 #include <linux/fs.h>
 #include <linux/slab.h>
-#include <linux/mbcache.h>
+#include <linux/mbcache2.h>
 #include <linux/quotaops.h>
 #include ""ext4_jbd2.h""
 #include ""ext4.h""
@@ -78,10 +78,10 @@
 # define ea_bdebug(bh, fmt, ...)	no_printk(fmt, ##__VA_ARGS__)
 #endif
 
-static void ext4_xattr_cache_insert(struct mb_cache *, struct buffer_head *);
+static void ext4_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);
 static struct buffer_head *ext4_xattr_cache_find(struct inode *,
 						 struct ext4_xattr_header *,
-						 struct mb_cache_entry **);
+						 struct mb2_cache_entry **);
 static void ext4_xattr_rehash(struct ext4_xattr_header *,
 			      struct ext4_xattr_entry *);
 static int ext4_xattr_list(struct dentry *dentry, char *buffer,
@@ -276,7 +276,7 @@ ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,
 	struct ext4_xattr_entry *entry;
 	size_t size;
 	int error;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	ea_idebug(inode, ""name=%d.%s, buffer=%p, buffer_size=%ld"",
 		  name_index, name, buffer, (long)buffer_size);
@@ -428,7 +428,7 @@ ext4_xattr_block_list(struct dentry *dentry, char *buffer, size_t buffer_size)
 	struct inode *inode = d_inode(dentry);
 	struct buffer_head *bh = NULL;
 	int error;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	ea_idebug(inode, ""buffer=%p, buffer_size=%ld"",
 		  buffer, (long)buffer_size);
@@ -545,30 +545,31 @@ static void
 ext4_xattr_release_block(handle_t *handle, struct inode *inode,
 			 struct buffer_head *bh)
 {
-	struct mb_cache_entry *ce = NULL;
 	int error = 0;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
-	ce = mb_cache_entry_get(ext4_mb_cache, bh->b_bdev, bh->b_blocknr);
 	BUFFER_TRACE(bh, ""get_write_access"");
 	error = ext4_journal_get_write_access(handle, bh);
 	if (error)
 		goto out;
 
 	lock_buffer(bh);
 	if (BHDR(bh)->h_refcount == cpu_to_le32(1)) {
+		__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);
+
 		ea_bdebug(bh, ""refcount now=0; freeing"");
-		if (ce)
-			mb_cache_entry_free(ce);
+		/*
+		 * This must happen under buffer lock for
+		 * ext4_xattr_block_set() to reliably detect freed block
+		 */
+		mb2_cache_entry_delete_block(EXT4_GET_MB_CACHE(inode), hash,
+					     bh->b_blocknr);
 		get_bh(bh);
 		unlock_buffer(bh);
 		ext4_free_blocks(handle, inode, bh, 0, 1,
 				 EXT4_FREE_BLOCKS_METADATA |
 				 EXT4_FREE_BLOCKS_FORGET);
 	} else {
 		le32_add_cpu(&BHDR(bh)->h_refcount, -1);
-		if (ce)
-			mb_cache_entry_release(ce);
 		/*
 		 * Beware of this ugliness: Releasing of xattr block references
 		 * from different inodes can race and so we have to protect
@@ -781,28 +782,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *new_bh = NULL;
 	struct ext4_xattr_search *s = &bs->s;
-	struct mb_cache_entry *ce = NULL;
+	struct mb2_cache_entry *ce = NULL;
 	int error = 0;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 #define header(x) ((struct ext4_xattr_header *)(x))
 
 	if (i->value && i->value_len > sb->s_blocksize)
 		return -ENOSPC;
 	if (s->base) {
-		ce = mb_cache_entry_get(ext4_mb_cache, bs->bh->b_bdev,
-					bs->bh->b_blocknr);
 		BUFFER_TRACE(bs->bh, ""get_write_access"");
 		error = ext4_journal_get_write_access(handle, bs->bh);
 		if (error)
 			goto cleanup;
 		lock_buffer(bs->bh);
 
 		if (header(s->base)->h_refcount == cpu_to_le32(1)) {
-			if (ce) {
-				mb_cache_entry_free(ce);
-				ce = NULL;
-			}
+			__u32 hash = le32_to_cpu(BHDR(bs->bh)->h_hash);
+
+			/*
+			 * This must happen under buffer lock for
+			 * ext4_xattr_block_set() to reliably detect modified
+			 * block
+			 */
+			mb2_cache_entry_delete_block(ext4_mb_cache, hash,
+						     bs->bh->b_blocknr);
 			ea_bdebug(bs->bh, ""modifying in-place"");
 			error = ext4_xattr_set_entry(i, s);
 			if (!error) {
@@ -826,10 +830,6 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 			int offset = (char *)s->here - bs->bh->b_data;
 
 			unlock_buffer(bs->bh);
-			if (ce) {
-				mb_cache_entry_release(ce);
-				ce = NULL;
-			}
 			ea_bdebug(bs->bh, ""cloning"");
 			s->base = kmalloc(bs->bh->b_size, GFP_NOFS);
 			error = -ENOMEM;
@@ -884,6 +884,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 				if (error)
 					goto cleanup_dquot;
 				lock_buffer(new_bh);
+				/*
+				 * We have to be careful about races with
+				 * freeing or rehashing of xattr block. Once we
+				 * hold buffer lock xattr block's state is
+				 * stable so we can check whether the block got
+				 * freed / rehashed or not.  Since we unhash
+				 * mbcache entry under buffer lock when freeing
+				 * / rehashing xattr block, checking whether
+				 * entry is still hashed is reliable.
+				 */
+				if (hlist_bl_unhashed(&ce->e_hash_list)) {
+					/*
+					 * Undo everything and check mbcache
+					 * again.
+					 */
+					unlock_buffer(new_bh);
+					dquot_free_block(inode,
+							 EXT4_C2B(EXT4_SB(sb),
+								  1));
+					brelse(new_bh);
+					mb2_cache_entry_put(ext4_mb_cache, ce);
+					ce = NULL;
+					new_bh = NULL;
+					goto inserted;
+				}
 				le32_add_cpu(&BHDR(new_bh)->h_refcount, 1);
 				ea_bdebug(new_bh, ""reusing; refcount now=%d"",
 					le32_to_cpu(BHDR(new_bh)->h_refcount));
@@ -894,7 +919,8 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 				if (error)
 					goto cleanup_dquot;
 			}
-			mb_cache_entry_release(ce);
+			mb2_cache_entry_touch(ext4_mb_cache, ce);
+			mb2_cache_entry_put(ext4_mb_cache, ce);
 			ce = NULL;
 		} else if (bs->bh && s->base == bs->bh->b_data) {
 			/* We were modifying this block in-place. */
@@ -959,7 +985,7 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 
 cleanup:
 	if (ce)
-		mb_cache_entry_release(ce);
+		mb2_cache_entry_put(ext4_mb_cache, ce);
 	brelse(new_bh);
 	if (!(bs->bh && s->base == bs->bh->b_data))
 		kfree(s->base);
@@ -1511,17 +1537,6 @@ ext4_xattr_delete_inode(handle_t *handle, struct inode *inode)
 	brelse(bh);
 }
 
-/*
- * ext4_xattr_put_super()
- *
- * This is called when a file system is unmounted.
- */
-void
-ext4_xattr_put_super(struct super_block *sb)
-{
-	mb_cache_shrink(sb->s_bdev);
-}
-
 /*
  * ext4_xattr_cache_insert()
  *
@@ -1531,28 +1546,18 @@ ext4_xattr_put_super(struct super_block *sb)
  * Returns 0, or a negative error number on failure.
  */
 static void
-ext4_xattr_cache_insert(struct mb_cache *ext4_mb_cache, struct buffer_head *bh)
+ext4_xattr_cache_insert(struct mb2_cache *ext4_mb_cache, struct buffer_head *bh)
 {
 	__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);
-	struct mb_cache_entry *ce;
 	int error;
 
-	ce = mb_cache_entry_alloc(ext4_mb_cache, GFP_NOFS);
-	if (!ce) {
-		ea_bdebug(bh, ""out of memory"");
-		return;
-	}
-	error = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);
+	error = mb2_cache_entry_create(ext4_mb_cache, GFP_NOFS, hash,
+				       bh->b_blocknr);
 	if (error) {
-		mb_cache_entry_free(ce);
-		if (error == -EBUSY) {
+		if (error == -EBUSY)
 			ea_bdebug(bh, ""already in cache"");
-			error = 0;
-		}
-	} else {
+	} else
 		ea_bdebug(bh, ""inserting [%x]"", (int)hash);
-		mb_cache_entry_release(ce);
-	}
 }
 
 /*
@@ -1605,26 +1610,19 @@ ext4_xattr_cmp(struct ext4_xattr_header *header1,
  */
 static struct buffer_head *
 ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,
-		      struct mb_cache_entry **pce)
+		      struct mb2_cache_entry **pce)
 {
 	__u32 hash = le32_to_cpu(header->h_hash);
-	struct mb_cache_entry *ce;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache_entry *ce;
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	if (!header->h_hash)
 		return NULL;  /* never share */
 	ea_idebug(inode, ""looking for cached blocks [%x]"", (int)hash);
-again:
-	ce = mb_cache_entry_find_first(ext4_mb_cache, inode->i_sb->s_bdev,
-				       hash);
+	ce = mb2_cache_entry_find_first(ext4_mb_cache, hash);
 	while (ce) {
 		struct buffer_head *bh;
 
-		if (IS_ERR(ce)) {
-			if (PTR_ERR(ce) == -EAGAIN)
-				goto again;
-			break;
-		}
 		bh = sb_bread(inode->i_sb, ce->e_block);
 		if (!bh) {
 			EXT4_ERROR_INODE(inode, ""block %lu read error"",
@@ -1640,7 +1638,7 @@ ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,
 			return bh;
 		}
 		brelse(bh);
-		ce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);
+		ce = mb2_cache_entry_find_next(ext4_mb_cache, ce);
 	}
 	return NULL;
 }
@@ -1715,15 +1713,15 @@ static void ext4_xattr_rehash(struct ext4_xattr_header *header,
 
 #define	HASH_BUCKET_BITS	10
 
-struct mb_cache *
-ext4_xattr_create_cache(char *name)
+struct mb2_cache *
+ext4_xattr_create_cache(void)
 {
-	return mb_cache_create(name, HASH_BUCKET_BITS);
+	return mb2_cache_create(HASH_BUCKET_BITS);
 }
 
-void ext4_xattr_destroy_cache(struct mb_cache *cache)
+void ext4_xattr_destroy_cache(struct mb2_cache *cache)
 {
 	if (cache)
-		mb_cache_destroy(cache);
+		mb2_cache_destroy(cache);
 }
 ",linux,82939d7999dfc1f1998c4b1c12e2f19edbdff272,f9a61eb4e2471c56a63cd804c7474128138c38ac,1,"ext4_xattr_block_set(handle_t *handle, struct inode *inode,
		     struct ext4_xattr_info *i,
		     struct ext4_xattr_block_find *bs)
{
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *new_bh = NULL;
 	struct ext4_xattr_search *s = &bs->s;
//flaw_line_below:
	struct mb_cache_entry *ce = NULL;
//fix_flaw_line_below:
//	struct mb2_cache_entry *ce = NULL;
 	int error = 0;
//flaw_line_below:
	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
//fix_flaw_line_below:
//	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 #define header(x) ((struct ext4_xattr_header *)(x))
 
 	if (i->value && i->value_len > sb->s_blocksize)
 		return -ENOSPC;
 	if (s->base) {
//flaw_line_below:
		ce = mb_cache_entry_get(ext4_mb_cache, bs->bh->b_bdev,
//flaw_line_below:
					bs->bh->b_blocknr);
 		BUFFER_TRACE(bs->bh, ""get_write_access"");
 		error = ext4_journal_get_write_access(handle, bs->bh);
 		if (error)
 			goto cleanup;
 		lock_buffer(bs->bh);
 
 		if (header(s->base)->h_refcount == cpu_to_le32(1)) {
//flaw_line_below:
			if (ce) {
//flaw_line_below:
				mb_cache_entry_free(ce);
//flaw_line_below:
				ce = NULL;
//flaw_line_below:
			}
//fix_flaw_line_below:
//			__u32 hash = le32_to_cpu(BHDR(bs->bh)->h_hash);
//fix_flaw_line_below:
//
//fix_flaw_line_below:
//			/*
//fix_flaw_line_below:
//			 * This must happen under buffer lock for
//fix_flaw_line_below:
//			 * ext4_xattr_block_set() to reliably detect modified
//fix_flaw_line_below:
//			 * block
//fix_flaw_line_below:
//			 */
//fix_flaw_line_below:
//			mb2_cache_entry_delete_block(ext4_mb_cache, hash,
//fix_flaw_line_below:
//						     bs->bh->b_blocknr);
 			ea_bdebug(bs->bh, ""modifying in-place"");
 			error = ext4_xattr_set_entry(i, s);
 			if (!error) {
				if (!IS_LAST_ENTRY(s->first))
					ext4_xattr_rehash(header(s->base),
							  s->here);
				ext4_xattr_cache_insert(ext4_mb_cache,
					bs->bh);
			}
			unlock_buffer(bs->bh);
			if (error == -EFSCORRUPTED)
				goto bad_block;
			if (!error)
				error = ext4_handle_dirty_xattr_block(handle,
								      inode,
								      bs->bh);
			if (error)
				goto cleanup;
			goto inserted;
		} else {
 			int offset = (char *)s->here - bs->bh->b_data;
 
 			unlock_buffer(bs->bh);
//flaw_line_below:
			if (ce) {
//flaw_line_below:
				mb_cache_entry_release(ce);
//flaw_line_below:
				ce = NULL;
//flaw_line_below:
			}
 			ea_bdebug(bs->bh, ""cloning"");
 			s->base = kmalloc(bs->bh->b_size, GFP_NOFS);
 			error = -ENOMEM;
			if (s->base == NULL)
				goto cleanup;
			memcpy(s->base, BHDR(bs->bh), bs->bh->b_size);
			s->first = ENTRY(header(s->base)+1);
			header(s->base)->h_refcount = cpu_to_le32(1);
			s->here = ENTRY(s->base + offset);
			s->end = s->base + bs->bh->b_size;
		}
	} else {
		/* Allocate a buffer where we construct the new block. */
		s->base = kzalloc(sb->s_blocksize, GFP_NOFS);
		/* assert(header == s->base) */
		error = -ENOMEM;
		if (s->base == NULL)
			goto cleanup;
		header(s->base)->h_magic = cpu_to_le32(EXT4_XATTR_MAGIC);
		header(s->base)->h_blocks = cpu_to_le32(1);
		header(s->base)->h_refcount = cpu_to_le32(1);
		s->first = ENTRY(header(s->base)+1);
		s->here = ENTRY(header(s->base)+1);
		s->end = s->base + sb->s_blocksize;
	}

	error = ext4_xattr_set_entry(i, s);
	if (error == -EFSCORRUPTED)
		goto bad_block;
	if (error)
		goto cleanup;
	if (!IS_LAST_ENTRY(s->first))
		ext4_xattr_rehash(header(s->base), s->here);

inserted:
	if (!IS_LAST_ENTRY(s->first)) {
		new_bh = ext4_xattr_cache_find(inode, header(s->base), &ce);
		if (new_bh) {
			/* We found an identical block in the cache. */
			if (new_bh == bs->bh)
				ea_bdebug(new_bh, ""keeping"");
			else {
				/* The old block is released after updating
				   the inode. */
				error = dquot_alloc_block(inode,
						EXT4_C2B(EXT4_SB(sb), 1));
				if (error)
					goto cleanup;
				BUFFER_TRACE(new_bh, ""get_write_access"");
				error = ext4_journal_get_write_access(handle,
								      new_bh);
 				if (error)
 					goto cleanup_dquot;
 				lock_buffer(new_bh);
//fix_flaw_line_below:
//				/*
//fix_flaw_line_below:
//				 * We have to be careful about races with
//fix_flaw_line_below:
//				 * freeing or rehashing of xattr block. Once we
//fix_flaw_line_below:
//				 * hold buffer lock xattr block's state is
//fix_flaw_line_below:
//				 * stable so we can check whether the block got
//fix_flaw_line_below:
//				 * freed / rehashed or not.  Since we unhash
//fix_flaw_line_below:
//				 * mbcache entry under buffer lock when freeing
//fix_flaw_line_below:
//				 * / rehashing xattr block, checking whether
//fix_flaw_line_below:
//				 * entry is still hashed is reliable.
//fix_flaw_line_below:
//				 */
//fix_flaw_line_below:
//				if (hlist_bl_unhashed(&ce->e_hash_list)) {
//fix_flaw_line_below:
//					/*
//fix_flaw_line_below:
//					 * Undo everything and check mbcache
//fix_flaw_line_below:
//					 * again.
//fix_flaw_line_below:
//					 */
//fix_flaw_line_below:
//					unlock_buffer(new_bh);
//fix_flaw_line_below:
//					dquot_free_block(inode,
//fix_flaw_line_below:
//							 EXT4_C2B(EXT4_SB(sb),
//fix_flaw_line_below:
//								  1));
//fix_flaw_line_below:
//					brelse(new_bh);
//fix_flaw_line_below:
//					mb2_cache_entry_put(ext4_mb_cache, ce);
//fix_flaw_line_below:
//					ce = NULL;
//fix_flaw_line_below:
//					new_bh = NULL;
//fix_flaw_line_below:
//					goto inserted;
//fix_flaw_line_below:
//				}
 				le32_add_cpu(&BHDR(new_bh)->h_refcount, 1);
 				ea_bdebug(new_bh, ""reusing; refcount now=%d"",
 					le32_to_cpu(BHDR(new_bh)->h_refcount));
				unlock_buffer(new_bh);
				error = ext4_handle_dirty_xattr_block(handle,
								      inode,
								      new_bh);
 				if (error)
 					goto cleanup_dquot;
 			}
//flaw_line_below:
			mb_cache_entry_release(ce);
//fix_flaw_line_below:
//			mb2_cache_entry_touch(ext4_mb_cache, ce);
//fix_flaw_line_below:
//			mb2_cache_entry_put(ext4_mb_cache, ce);
 			ce = NULL;
 		} else if (bs->bh && s->base == bs->bh->b_data) {
 			/* We were modifying this block in-place. */
			ea_bdebug(bs->bh, ""keeping this block"");
			new_bh = bs->bh;
			get_bh(new_bh);
		} else {
			/* We need to allocate a new block */
			ext4_fsblk_t goal, block;

			goal = ext4_group_first_block_no(sb,
						EXT4_I(inode)->i_block_group);

			/* non-extent files can't have physical blocks past 2^32 */
			if (!(ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS)))
				goal = goal & EXT4_MAX_BLOCK_FILE_PHYS;

			block = ext4_new_meta_blocks(handle, inode, goal, 0,
						     NULL, &error);
			if (error)
				goto cleanup;

			if (!(ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS)))
				BUG_ON(block > EXT4_MAX_BLOCK_FILE_PHYS);

			ea_idebug(inode, ""creating block %llu"",
				  (unsigned long long)block);

			new_bh = sb_getblk(sb, block);
			if (unlikely(!new_bh)) {
				error = -ENOMEM;
getblk_failed:
				ext4_free_blocks(handle, inode, NULL, block, 1,
						 EXT4_FREE_BLOCKS_METADATA);
				goto cleanup;
			}
			lock_buffer(new_bh);
			error = ext4_journal_get_create_access(handle, new_bh);
			if (error) {
				unlock_buffer(new_bh);
				error = -EIO;
				goto getblk_failed;
			}
			memcpy(new_bh->b_data, s->base, new_bh->b_size);
			set_buffer_uptodate(new_bh);
			unlock_buffer(new_bh);
			ext4_xattr_cache_insert(ext4_mb_cache, new_bh);
			error = ext4_handle_dirty_xattr_block(handle,
							      inode, new_bh);
			if (error)
				goto cleanup;
		}
	}

	/* Update the inode. */
	EXT4_I(inode)->i_file_acl = new_bh ? new_bh->b_blocknr : 0;

	/* Drop the previous xattr block. */
	if (bs->bh && bs->bh != new_bh)
		ext4_xattr_release_block(handle, inode, bs->bh);
	error = 0;
 
 cleanup:
 	if (ce)
//flaw_line_below:
		mb_cache_entry_release(ce);
//fix_flaw_line_below:
//		mb2_cache_entry_put(ext4_mb_cache, ce);
 	brelse(new_bh);
 	if (!(bs->bh && s->base == bs->bh->b_data))
 		kfree(s->base);

	return error;

cleanup_dquot:
	dquot_free_block(inode, EXT4_C2B(EXT4_SB(sb), 1));
	goto cleanup;

bad_block:
	EXT4_ERROR_INODE(inode, ""bad block %llu"",
			 EXT4_I(inode)->i_file_acl);
	goto cleanup;

#undef header
}
"
5427,183163,,Local,Not required,Partial,CVE-2015-8952,https://www.cvedetails.com/cve/CVE-2015-8952/,CWE-19,Low,,,,2016-10-16,2.1,"The mbcache feature in the ext2 and ext4 filesystem implementations in the Linux kernel before 4.6 mishandles xattr block caching, which allows local users to cause a denial of service (soft lockup) via filesystem operations in environments that use many attributes, as demonstrated by Ceph and Samba.",2018-03-15,DoS ,5,https://github.com/torvalds/linux/commit/82939d7999dfc1f1998c4b1c12e2f19edbdff272,82939d7999dfc1f1998c4b1c12e2f19edbdff272,"ext4: convert to mbcache2

The conversion is generally straightforward. The only tricky part is
that xattr block corresponding to found mbcache entry can get freed
before we get buffer lock for that block. So we have to check whether
the entry is still valid after getting buffer lock.

Signed-off-by: Jan Kara <jack@suse.cz>
Signed-off-by: Theodore Ts'o <tytso@mit.edu>",12,fs/ext4/xattr.c,"{""sha"": ""9ac9e62569ef8fdf981021b58d37ab99d0150882"", ""filename"": ""fs/ext4/ext4.h"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 1, ""changes"": 2, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/ext4.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/ext4.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/ext4.h?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -1468,7 +1468,7 @@ struct ext4_sb_info {\n \tstruct list_head s_es_list;\t/* List of inodes with reclaimable extents */\n \tlong s_es_nr_inode;\n \tstruct ext4_es_stats s_es_stats;\n-\tstruct mb_cache *s_mb_cache;\n+\tstruct mb2_cache *s_mb_cache;\n \tspinlock_t s_es_lock ____cacheline_aligned_in_smp;\n \n \t/* Ratelimit ext4 messages. */""}<_**next**_>{""sha"": ""ecc37e1034358d769ab29971e9d2301fb9e2b3bc"", ""filename"": ""fs/ext4/super.c"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 2, ""changes"": 7, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/super.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/super.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/super.c?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -844,7 +844,6 @@ static void ext4_put_super(struct super_block *sb)\n \text4_release_system_zone(sb);\n \text4_mb_release(sb);\n \text4_ext_release(sb);\n-\text4_xattr_put_super(sb);\n \n \tif (!(sb->s_flags & MS_RDONLY)) {\n \t\text4_clear_feature_journal_needs_recovery(sb);\n@@ -3797,7 +3796,7 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n \n no_journal:\n \tif (ext4_mballoc_ready) {\n-\t\tsbi->s_mb_cache = ext4_xattr_create_cache(sb->s_id);\n+\t\tsbi->s_mb_cache = ext4_xattr_create_cache();\n \t\tif (!sbi->s_mb_cache) {\n \t\t\text4_msg(sb, KERN_ERR, \""Failed to create an mb_cache\"");\n \t\t\tgoto failed_mount_wq;\n@@ -4027,6 +4026,10 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n \tif (EXT4_SB(sb)->rsv_conversion_wq)\n \t\tdestroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);\n failed_mount_wq:\n+\tif (sbi->s_mb_cache) {\n+\t\text4_xattr_destroy_cache(sbi->s_mb_cache);\n+\t\tsbi->s_mb_cache = NULL;\n+\t}\n \tif (sbi->s_journal) {\n \t\tjbd2_journal_destroy(sbi->s_journal);\n \t\tsbi->s_journal = NULL;""}<_**next**_>{""sha"": ""fe9f8d6ab6c91b60689abadefd5435c31893fcae"", ""filename"": ""fs/ext4/xattr.c"", ""status"": ""modified"", ""additions"": 67, ""deletions"": 69, ""changes"": 136, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/xattr.c?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -53,7 +53,7 @@\n #include <linux/init.h>\n #include <linux/fs.h>\n #include <linux/slab.h>\n-#include <linux/mbcache.h>\n+#include <linux/mbcache2.h>\n #include <linux/quotaops.h>\n #include \""ext4_jbd2.h\""\n #include \""ext4.h\""\n@@ -78,10 +78,10 @@\n # define ea_bdebug(bh, fmt, ...)\tno_printk(fmt, ##__VA_ARGS__)\n #endif\n \n-static void ext4_xattr_cache_insert(struct mb_cache *, struct buffer_head *);\n+static void ext4_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);\n static struct buffer_head *ext4_xattr_cache_find(struct inode *,\n \t\t\t\t\t\t struct ext4_xattr_header *,\n-\t\t\t\t\t\t struct mb_cache_entry **);\n+\t\t\t\t\t\t struct mb2_cache_entry **);\n static void ext4_xattr_rehash(struct ext4_xattr_header *,\n \t\t\t      struct ext4_xattr_entry *);\n static int ext4_xattr_list(struct dentry *dentry, char *buffer,\n@@ -276,7 +276,7 @@ ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,\n \tstruct ext4_xattr_entry *entry;\n \tsize_t size;\n \tint error;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tea_idebug(inode, \""name=%d.%s, buffer=%p, buffer_size=%ld\"",\n \t\t  name_index, name, buffer, (long)buffer_size);\n@@ -428,7 +428,7 @@ ext4_xattr_block_list(struct dentry *dentry, char *buffer, size_t buffer_size)\n \tstruct inode *inode = d_inode(dentry);\n \tstruct buffer_head *bh = NULL;\n \tint error;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tea_idebug(inode, \""buffer=%p, buffer_size=%ld\"",\n \t\t  buffer, (long)buffer_size);\n@@ -545,30 +545,31 @@ static void\n ext4_xattr_release_block(handle_t *handle, struct inode *inode,\n \t\t\t struct buffer_head *bh)\n {\n-\tstruct mb_cache_entry *ce = NULL;\n \tint error = 0;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n-\tce = mb_cache_entry_get(ext4_mb_cache, bh->b_bdev, bh->b_blocknr);\n \tBUFFER_TRACE(bh, \""get_write_access\"");\n \terror = ext4_journal_get_write_access(handle, bh);\n \tif (error)\n \t\tgoto out;\n \n \tlock_buffer(bh);\n \tif (BHDR(bh)->h_refcount == cpu_to_le32(1)) {\n+\t\t__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);\n+\n \t\tea_bdebug(bh, \""refcount now=0; freeing\"");\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_free(ce);\n+\t\t/*\n+\t\t * This must happen under buffer lock for\n+\t\t * ext4_xattr_block_set() to reliably detect freed block\n+\t\t */\n+\t\tmb2_cache_entry_delete_block(EXT4_GET_MB_CACHE(inode), hash,\n+\t\t\t\t\t     bh->b_blocknr);\n \t\tget_bh(bh);\n \t\tunlock_buffer(bh);\n \t\text4_free_blocks(handle, inode, bh, 0, 1,\n \t\t\t\t EXT4_FREE_BLOCKS_METADATA |\n \t\t\t\t EXT4_FREE_BLOCKS_FORGET);\n \t} else {\n \t\tle32_add_cpu(&BHDR(bh)->h_refcount, -1);\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_release(ce);\n \t\t/*\n \t\t * Beware of this ugliness: Releasing of xattr block references\n \t\t * from different inodes can race and so we have to protect\n@@ -781,28 +782,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \tstruct super_block *sb = inode->i_sb;\n \tstruct buffer_head *new_bh = NULL;\n \tstruct ext4_xattr_search *s = &bs->s;\n-\tstruct mb_cache_entry *ce = NULL;\n+\tstruct mb2_cache_entry *ce = NULL;\n \tint error = 0;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n #define header(x) ((struct ext4_xattr_header *)(x))\n \n \tif (i->value && i->value_len > sb->s_blocksize)\n \t\treturn -ENOSPC;\n \tif (s->base) {\n-\t\tce = mb_cache_entry_get(ext4_mb_cache, bs->bh->b_bdev,\n-\t\t\t\t\tbs->bh->b_blocknr);\n \t\tBUFFER_TRACE(bs->bh, \""get_write_access\"");\n \t\terror = ext4_journal_get_write_access(handle, bs->bh);\n \t\tif (error)\n \t\t\tgoto cleanup;\n \t\tlock_buffer(bs->bh);\n \n \t\tif (header(s->base)->h_refcount == cpu_to_le32(1)) {\n-\t\t\tif (ce) {\n-\t\t\t\tmb_cache_entry_free(ce);\n-\t\t\t\tce = NULL;\n-\t\t\t}\n+\t\t\t__u32 hash = le32_to_cpu(BHDR(bs->bh)->h_hash);\n+\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext4_xattr_block_set() to reliably detect modified\n+\t\t\t * block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(ext4_mb_cache, hash,\n+\t\t\t\t\t\t     bs->bh->b_blocknr);\n \t\t\tea_bdebug(bs->bh, \""modifying in-place\"");\n \t\t\terror = ext4_xattr_set_entry(i, s);\n \t\t\tif (!error) {\n@@ -826,10 +830,6 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\tint offset = (char *)s->here - bs->bh->b_data;\n \n \t\t\tunlock_buffer(bs->bh);\n-\t\t\tif (ce) {\n-\t\t\t\tmb_cache_entry_release(ce);\n-\t\t\t\tce = NULL;\n-\t\t\t}\n \t\t\tea_bdebug(bs->bh, \""cloning\"");\n \t\t\ts->base = kmalloc(bs->bh->b_size, GFP_NOFS);\n \t\t\terror = -ENOMEM;\n@@ -884,6 +884,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\t\tif (error)\n \t\t\t\t\tgoto cleanup_dquot;\n \t\t\t\tlock_buffer(new_bh);\n+\t\t\t\t/*\n+\t\t\t\t * We have to be careful about races with\n+\t\t\t\t * freeing or rehashing of xattr block. Once we\n+\t\t\t\t * hold buffer lock xattr block's state is\n+\t\t\t\t * stable so we can check whether the block got\n+\t\t\t\t * freed / rehashed or not.  Since we unhash\n+\t\t\t\t * mbcache entry under buffer lock when freeing\n+\t\t\t\t * / rehashing xattr block, checking whether\n+\t\t\t\t * entry is still hashed is reliable.\n+\t\t\t\t */\n+\t\t\t\tif (hlist_bl_unhashed(&ce->e_hash_list)) {\n+\t\t\t\t\t/*\n+\t\t\t\t\t * Undo everything and check mbcache\n+\t\t\t\t\t * again.\n+\t\t\t\t\t */\n+\t\t\t\t\tunlock_buffer(new_bh);\n+\t\t\t\t\tdquot_free_block(inode,\n+\t\t\t\t\t\t\t EXT4_C2B(EXT4_SB(sb),\n+\t\t\t\t\t\t\t\t  1));\n+\t\t\t\t\tbrelse(new_bh);\n+\t\t\t\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n+\t\t\t\t\tce = NULL;\n+\t\t\t\t\tnew_bh = NULL;\n+\t\t\t\t\tgoto inserted;\n+\t\t\t\t}\n \t\t\t\tle32_add_cpu(&BHDR(new_bh)->h_refcount, 1);\n \t\t\t\tea_bdebug(new_bh, \""reusing; refcount now=%d\"",\n \t\t\t\t\tle32_to_cpu(BHDR(new_bh)->h_refcount));\n@@ -894,7 +919,8 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\t\tif (error)\n \t\t\t\t\tgoto cleanup_dquot;\n \t\t\t}\n-\t\t\tmb_cache_entry_release(ce);\n+\t\t\tmb2_cache_entry_touch(ext4_mb_cache, ce);\n+\t\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n \t\t\tce = NULL;\n \t\t} else if (bs->bh && s->base == bs->bh->b_data) {\n \t\t\t/* We were modifying this block in-place. */\n@@ -959,7 +985,7 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \n cleanup:\n \tif (ce)\n-\t\tmb_cache_entry_release(ce);\n+\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n \tbrelse(new_bh);\n \tif (!(bs->bh && s->base == bs->bh->b_data))\n \t\tkfree(s->base);\n@@ -1511,17 +1537,6 @@ ext4_xattr_delete_inode(handle_t *handle, struct inode *inode)\n \tbrelse(bh);\n }\n \n-/*\n- * ext4_xattr_put_super()\n- *\n- * This is called when a file system is unmounted.\n- */\n-void\n-ext4_xattr_put_super(struct super_block *sb)\n-{\n-\tmb_cache_shrink(sb->s_bdev);\n-}\n-\n /*\n  * ext4_xattr_cache_insert()\n  *\n@@ -1531,28 +1546,18 @@ ext4_xattr_put_super(struct super_block *sb)\n  * Returns 0, or a negative error number on failure.\n  */\n static void\n-ext4_xattr_cache_insert(struct mb_cache *ext4_mb_cache, struct buffer_head *bh)\n+ext4_xattr_cache_insert(struct mb2_cache *ext4_mb_cache, struct buffer_head *bh)\n {\n \t__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);\n-\tstruct mb_cache_entry *ce;\n \tint error;\n \n-\tce = mb_cache_entry_alloc(ext4_mb_cache, GFP_NOFS);\n-\tif (!ce) {\n-\t\tea_bdebug(bh, \""out of memory\"");\n-\t\treturn;\n-\t}\n-\terror = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);\n+\terror = mb2_cache_entry_create(ext4_mb_cache, GFP_NOFS, hash,\n+\t\t\t\t       bh->b_blocknr);\n \tif (error) {\n-\t\tmb_cache_entry_free(ce);\n-\t\tif (error == -EBUSY) {\n+\t\tif (error == -EBUSY)\n \t\t\tea_bdebug(bh, \""already in cache\"");\n-\t\t\terror = 0;\n-\t\t}\n-\t} else {\n+\t} else\n \t\tea_bdebug(bh, \""inserting [%x]\"", (int)hash);\n-\t\tmb_cache_entry_release(ce);\n-\t}\n }\n \n /*\n@@ -1605,26 +1610,19 @@ ext4_xattr_cmp(struct ext4_xattr_header *header1,\n  */\n static struct buffer_head *\n ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,\n-\t\t      struct mb_cache_entry **pce)\n+\t\t      struct mb2_cache_entry **pce)\n {\n \t__u32 hash = le32_to_cpu(header->h_hash);\n-\tstruct mb_cache_entry *ce;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache_entry *ce;\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tif (!header->h_hash)\n \t\treturn NULL;  /* never share */\n \tea_idebug(inode, \""looking for cached blocks [%x]\"", (int)hash);\n-again:\n-\tce = mb_cache_entry_find_first(ext4_mb_cache, inode->i_sb->s_bdev,\n-\t\t\t\t       hash);\n+\tce = mb2_cache_entry_find_first(ext4_mb_cache, hash);\n \twhile (ce) {\n \t\tstruct buffer_head *bh;\n \n-\t\tif (IS_ERR(ce)) {\n-\t\t\tif (PTR_ERR(ce) == -EAGAIN)\n-\t\t\t\tgoto again;\n-\t\t\tbreak;\n-\t\t}\n \t\tbh = sb_bread(inode->i_sb, ce->e_block);\n \t\tif (!bh) {\n \t\t\tEXT4_ERROR_INODE(inode, \""block %lu read error\"",\n@@ -1640,7 +1638,7 @@ ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,\n \t\t\treturn bh;\n \t\t}\n \t\tbrelse(bh);\n-\t\tce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);\n+\t\tce = mb2_cache_entry_find_next(ext4_mb_cache, ce);\n \t}\n \treturn NULL;\n }\n@@ -1715,15 +1713,15 @@ static void ext4_xattr_rehash(struct ext4_xattr_header *header,\n \n #define\tHASH_BUCKET_BITS\t10\n \n-struct mb_cache *\n-ext4_xattr_create_cache(char *name)\n+struct mb2_cache *\n+ext4_xattr_create_cache(void)\n {\n-\treturn mb_cache_create(name, HASH_BUCKET_BITS);\n+\treturn mb2_cache_create(HASH_BUCKET_BITS);\n }\n \n-void ext4_xattr_destroy_cache(struct mb_cache *cache)\n+void ext4_xattr_destroy_cache(struct mb2_cache *cache)\n {\n \tif (cache)\n-\t\tmb_cache_destroy(cache);\n+\t\tmb2_cache_destroy(cache);\n }\n ""}<_**next**_>{""sha"": ""10b0f7323ed6fcd628efee26998d0f1be7652c48"", ""filename"": ""fs/ext4/xattr.h"", ""status"": ""modified"", ""additions"": 2, ""deletions"": 3, ""changes"": 5, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/xattr.h?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -108,7 +108,6 @@ extern int ext4_xattr_set(struct inode *, int, const char *, const void *, size_\n extern int ext4_xattr_set_handle(handle_t *, struct inode *, int, const char *, const void *, size_t, int);\n \n extern void ext4_xattr_delete_inode(handle_t *, struct inode *);\n-extern void ext4_xattr_put_super(struct super_block *);\n \n extern int ext4_expand_extra_isize_ea(struct inode *inode, int new_extra_isize,\n \t\t\t    struct ext4_inode *raw_inode, handle_t *handle);\n@@ -124,8 +123,8 @@ extern int ext4_xattr_ibody_inline_set(handle_t *handle, struct inode *inode,\n \t\t\t\t       struct ext4_xattr_info *i,\n \t\t\t\t       struct ext4_xattr_ibody_find *is);\n \n-extern struct mb_cache *ext4_xattr_create_cache(char *name);\n-extern void ext4_xattr_destroy_cache(struct mb_cache *);\n+extern struct mb2_cache *ext4_xattr_create_cache(void);\n+extern void ext4_xattr_destroy_cache(struct mb2_cache *);\n \n #ifdef CONFIG_EXT4_FS_SECURITY\n extern int ext4_init_security(handle_t *handle, struct inode *inode,""}"," ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,
		      struct mb2_cache_entry **pce)
 {
 	__u32 hash = le32_to_cpu(header->h_hash);
	struct mb2_cache_entry *ce;
	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	if (!header->h_hash)
 		return NULL;  /* never share */
 	ea_idebug(inode, ""looking for cached blocks [%x]"", (int)hash);
	ce = mb2_cache_entry_find_first(ext4_mb_cache, hash);
 	while (ce) {
 		struct buffer_head *bh;
 
 		bh = sb_bread(inode->i_sb, ce->e_block);
 		if (!bh) {
 			EXT4_ERROR_INODE(inode, ""block %lu read error"",
					 (unsigned long) ce->e_block);
		} else if (le32_to_cpu(BHDR(bh)->h_refcount) >=
				EXT4_XATTR_REFCOUNT_MAX) {
			ea_idebug(inode, ""block %lu refcount %d>=%d"",
				  (unsigned long) ce->e_block,
				  le32_to_cpu(BHDR(bh)->h_refcount),
					  EXT4_XATTR_REFCOUNT_MAX);
		} else if (ext4_xattr_cmp(header, BHDR(bh)) == 0) {
			*pce = ce;
 			return bh;
 		}
 		brelse(bh);
		ce = mb2_cache_entry_find_next(ext4_mb_cache, ce);
 	}
 	return NULL;
 }
"," ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,
		      struct mb_cache_entry **pce)
 {
 	__u32 hash = le32_to_cpu(header->h_hash);
	struct mb_cache_entry *ce;
	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	if (!header->h_hash)
 		return NULL;  /* never share */
 	ea_idebug(inode, ""looking for cached blocks [%x]"", (int)hash);
again:
	ce = mb_cache_entry_find_first(ext4_mb_cache, inode->i_sb->s_bdev,
				       hash);
 	while (ce) {
 		struct buffer_head *bh;
 
		if (IS_ERR(ce)) {
			if (PTR_ERR(ce) == -EAGAIN)
				goto again;
			break;
		}
 		bh = sb_bread(inode->i_sb, ce->e_block);
 		if (!bh) {
 			EXT4_ERROR_INODE(inode, ""block %lu read error"",
					 (unsigned long) ce->e_block);
		} else if (le32_to_cpu(BHDR(bh)->h_refcount) >=
				EXT4_XATTR_REFCOUNT_MAX) {
			ea_idebug(inode, ""block %lu refcount %d>=%d"",
				  (unsigned long) ce->e_block,
				  le32_to_cpu(BHDR(bh)->h_refcount),
					  EXT4_XATTR_REFCOUNT_MAX);
		} else if (ext4_xattr_cmp(header, BHDR(bh)) == 0) {
			*pce = ce;
 			return bh;
 		}
 		brelse(bh);
		ce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);
 	}
 	return NULL;
 }
",C,"		      struct mb2_cache_entry **pce)
	struct mb2_cache_entry *ce;
	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
	ce = mb2_cache_entry_find_first(ext4_mb_cache, hash);
		ce = mb2_cache_entry_find_next(ext4_mb_cache, ce);
","		      struct mb_cache_entry **pce)
	struct mb_cache_entry *ce;
	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
again:
	ce = mb_cache_entry_find_first(ext4_mb_cache, inode->i_sb->s_bdev,
				       hash);
		if (IS_ERR(ce)) {
			if (PTR_ERR(ce) == -EAGAIN)
				goto again;
			break;
		}
		ce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);
",,"@@ -53,7 +53,7 @@
 #include <linux/init.h>
 #include <linux/fs.h>
 #include <linux/slab.h>
-#include <linux/mbcache.h>
+#include <linux/mbcache2.h>
 #include <linux/quotaops.h>
 #include ""ext4_jbd2.h""
 #include ""ext4.h""
@@ -78,10 +78,10 @@
 # define ea_bdebug(bh, fmt, ...)	no_printk(fmt, ##__VA_ARGS__)
 #endif
 
-static void ext4_xattr_cache_insert(struct mb_cache *, struct buffer_head *);
+static void ext4_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);
 static struct buffer_head *ext4_xattr_cache_find(struct inode *,
 						 struct ext4_xattr_header *,
-						 struct mb_cache_entry **);
+						 struct mb2_cache_entry **);
 static void ext4_xattr_rehash(struct ext4_xattr_header *,
 			      struct ext4_xattr_entry *);
 static int ext4_xattr_list(struct dentry *dentry, char *buffer,
@@ -276,7 +276,7 @@ ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,
 	struct ext4_xattr_entry *entry;
 	size_t size;
 	int error;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	ea_idebug(inode, ""name=%d.%s, buffer=%p, buffer_size=%ld"",
 		  name_index, name, buffer, (long)buffer_size);
@@ -428,7 +428,7 @@ ext4_xattr_block_list(struct dentry *dentry, char *buffer, size_t buffer_size)
 	struct inode *inode = d_inode(dentry);
 	struct buffer_head *bh = NULL;
 	int error;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	ea_idebug(inode, ""buffer=%p, buffer_size=%ld"",
 		  buffer, (long)buffer_size);
@@ -545,30 +545,31 @@ static void
 ext4_xattr_release_block(handle_t *handle, struct inode *inode,
 			 struct buffer_head *bh)
 {
-	struct mb_cache_entry *ce = NULL;
 	int error = 0;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
-	ce = mb_cache_entry_get(ext4_mb_cache, bh->b_bdev, bh->b_blocknr);
 	BUFFER_TRACE(bh, ""get_write_access"");
 	error = ext4_journal_get_write_access(handle, bh);
 	if (error)
 		goto out;
 
 	lock_buffer(bh);
 	if (BHDR(bh)->h_refcount == cpu_to_le32(1)) {
+		__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);
+
 		ea_bdebug(bh, ""refcount now=0; freeing"");
-		if (ce)
-			mb_cache_entry_free(ce);
+		/*
+		 * This must happen under buffer lock for
+		 * ext4_xattr_block_set() to reliably detect freed block
+		 */
+		mb2_cache_entry_delete_block(EXT4_GET_MB_CACHE(inode), hash,
+					     bh->b_blocknr);
 		get_bh(bh);
 		unlock_buffer(bh);
 		ext4_free_blocks(handle, inode, bh, 0, 1,
 				 EXT4_FREE_BLOCKS_METADATA |
 				 EXT4_FREE_BLOCKS_FORGET);
 	} else {
 		le32_add_cpu(&BHDR(bh)->h_refcount, -1);
-		if (ce)
-			mb_cache_entry_release(ce);
 		/*
 		 * Beware of this ugliness: Releasing of xattr block references
 		 * from different inodes can race and so we have to protect
@@ -781,28 +782,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *new_bh = NULL;
 	struct ext4_xattr_search *s = &bs->s;
-	struct mb_cache_entry *ce = NULL;
+	struct mb2_cache_entry *ce = NULL;
 	int error = 0;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 #define header(x) ((struct ext4_xattr_header *)(x))
 
 	if (i->value && i->value_len > sb->s_blocksize)
 		return -ENOSPC;
 	if (s->base) {
-		ce = mb_cache_entry_get(ext4_mb_cache, bs->bh->b_bdev,
-					bs->bh->b_blocknr);
 		BUFFER_TRACE(bs->bh, ""get_write_access"");
 		error = ext4_journal_get_write_access(handle, bs->bh);
 		if (error)
 			goto cleanup;
 		lock_buffer(bs->bh);
 
 		if (header(s->base)->h_refcount == cpu_to_le32(1)) {
-			if (ce) {
-				mb_cache_entry_free(ce);
-				ce = NULL;
-			}
+			__u32 hash = le32_to_cpu(BHDR(bs->bh)->h_hash);
+
+			/*
+			 * This must happen under buffer lock for
+			 * ext4_xattr_block_set() to reliably detect modified
+			 * block
+			 */
+			mb2_cache_entry_delete_block(ext4_mb_cache, hash,
+						     bs->bh->b_blocknr);
 			ea_bdebug(bs->bh, ""modifying in-place"");
 			error = ext4_xattr_set_entry(i, s);
 			if (!error) {
@@ -826,10 +830,6 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 			int offset = (char *)s->here - bs->bh->b_data;
 
 			unlock_buffer(bs->bh);
-			if (ce) {
-				mb_cache_entry_release(ce);
-				ce = NULL;
-			}
 			ea_bdebug(bs->bh, ""cloning"");
 			s->base = kmalloc(bs->bh->b_size, GFP_NOFS);
 			error = -ENOMEM;
@@ -884,6 +884,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 				if (error)
 					goto cleanup_dquot;
 				lock_buffer(new_bh);
+				/*
+				 * We have to be careful about races with
+				 * freeing or rehashing of xattr block. Once we
+				 * hold buffer lock xattr block's state is
+				 * stable so we can check whether the block got
+				 * freed / rehashed or not.  Since we unhash
+				 * mbcache entry under buffer lock when freeing
+				 * / rehashing xattr block, checking whether
+				 * entry is still hashed is reliable.
+				 */
+				if (hlist_bl_unhashed(&ce->e_hash_list)) {
+					/*
+					 * Undo everything and check mbcache
+					 * again.
+					 */
+					unlock_buffer(new_bh);
+					dquot_free_block(inode,
+							 EXT4_C2B(EXT4_SB(sb),
+								  1));
+					brelse(new_bh);
+					mb2_cache_entry_put(ext4_mb_cache, ce);
+					ce = NULL;
+					new_bh = NULL;
+					goto inserted;
+				}
 				le32_add_cpu(&BHDR(new_bh)->h_refcount, 1);
 				ea_bdebug(new_bh, ""reusing; refcount now=%d"",
 					le32_to_cpu(BHDR(new_bh)->h_refcount));
@@ -894,7 +919,8 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 				if (error)
 					goto cleanup_dquot;
 			}
-			mb_cache_entry_release(ce);
+			mb2_cache_entry_touch(ext4_mb_cache, ce);
+			mb2_cache_entry_put(ext4_mb_cache, ce);
 			ce = NULL;
 		} else if (bs->bh && s->base == bs->bh->b_data) {
 			/* We were modifying this block in-place. */
@@ -959,7 +985,7 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 
 cleanup:
 	if (ce)
-		mb_cache_entry_release(ce);
+		mb2_cache_entry_put(ext4_mb_cache, ce);
 	brelse(new_bh);
 	if (!(bs->bh && s->base == bs->bh->b_data))
 		kfree(s->base);
@@ -1511,17 +1537,6 @@ ext4_xattr_delete_inode(handle_t *handle, struct inode *inode)
 	brelse(bh);
 }
 
-/*
- * ext4_xattr_put_super()
- *
- * This is called when a file system is unmounted.
- */
-void
-ext4_xattr_put_super(struct super_block *sb)
-{
-	mb_cache_shrink(sb->s_bdev);
-}
-
 /*
  * ext4_xattr_cache_insert()
  *
@@ -1531,28 +1546,18 @@ ext4_xattr_put_super(struct super_block *sb)
  * Returns 0, or a negative error number on failure.
  */
 static void
-ext4_xattr_cache_insert(struct mb_cache *ext4_mb_cache, struct buffer_head *bh)
+ext4_xattr_cache_insert(struct mb2_cache *ext4_mb_cache, struct buffer_head *bh)
 {
 	__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);
-	struct mb_cache_entry *ce;
 	int error;
 
-	ce = mb_cache_entry_alloc(ext4_mb_cache, GFP_NOFS);
-	if (!ce) {
-		ea_bdebug(bh, ""out of memory"");
-		return;
-	}
-	error = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);
+	error = mb2_cache_entry_create(ext4_mb_cache, GFP_NOFS, hash,
+				       bh->b_blocknr);
 	if (error) {
-		mb_cache_entry_free(ce);
-		if (error == -EBUSY) {
+		if (error == -EBUSY)
 			ea_bdebug(bh, ""already in cache"");
-			error = 0;
-		}
-	} else {
+	} else
 		ea_bdebug(bh, ""inserting [%x]"", (int)hash);
-		mb_cache_entry_release(ce);
-	}
 }
 
 /*
@@ -1605,26 +1610,19 @@ ext4_xattr_cmp(struct ext4_xattr_header *header1,
  */
 static struct buffer_head *
 ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,
-		      struct mb_cache_entry **pce)
+		      struct mb2_cache_entry **pce)
 {
 	__u32 hash = le32_to_cpu(header->h_hash);
-	struct mb_cache_entry *ce;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache_entry *ce;
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	if (!header->h_hash)
 		return NULL;  /* never share */
 	ea_idebug(inode, ""looking for cached blocks [%x]"", (int)hash);
-again:
-	ce = mb_cache_entry_find_first(ext4_mb_cache, inode->i_sb->s_bdev,
-				       hash);
+	ce = mb2_cache_entry_find_first(ext4_mb_cache, hash);
 	while (ce) {
 		struct buffer_head *bh;
 
-		if (IS_ERR(ce)) {
-			if (PTR_ERR(ce) == -EAGAIN)
-				goto again;
-			break;
-		}
 		bh = sb_bread(inode->i_sb, ce->e_block);
 		if (!bh) {
 			EXT4_ERROR_INODE(inode, ""block %lu read error"",
@@ -1640,7 +1638,7 @@ ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,
 			return bh;
 		}
 		brelse(bh);
-		ce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);
+		ce = mb2_cache_entry_find_next(ext4_mb_cache, ce);
 	}
 	return NULL;
 }
@@ -1715,15 +1713,15 @@ static void ext4_xattr_rehash(struct ext4_xattr_header *header,
 
 #define	HASH_BUCKET_BITS	10
 
-struct mb_cache *
-ext4_xattr_create_cache(char *name)
+struct mb2_cache *
+ext4_xattr_create_cache(void)
 {
-	return mb_cache_create(name, HASH_BUCKET_BITS);
+	return mb2_cache_create(HASH_BUCKET_BITS);
 }
 
-void ext4_xattr_destroy_cache(struct mb_cache *cache)
+void ext4_xattr_destroy_cache(struct mb2_cache *cache)
 {
 	if (cache)
-		mb_cache_destroy(cache);
+		mb2_cache_destroy(cache);
 }
 ",linux,82939d7999dfc1f1998c4b1c12e2f19edbdff272,f9a61eb4e2471c56a63cd804c7474128138c38ac,1," ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,
//flaw_line_below:
		      struct mb_cache_entry **pce)
//fix_flaw_line_below:
//		      struct mb2_cache_entry **pce)
 {
 	__u32 hash = le32_to_cpu(header->h_hash);
//flaw_line_below:
	struct mb_cache_entry *ce;
//flaw_line_below:
	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
//fix_flaw_line_below:
//	struct mb2_cache_entry *ce;
//fix_flaw_line_below:
//	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	if (!header->h_hash)
 		return NULL;  /* never share */
 	ea_idebug(inode, ""looking for cached blocks [%x]"", (int)hash);
//flaw_line_below:
again:
//flaw_line_below:
	ce = mb_cache_entry_find_first(ext4_mb_cache, inode->i_sb->s_bdev,
//flaw_line_below:
				       hash);
//fix_flaw_line_below:
//	ce = mb2_cache_entry_find_first(ext4_mb_cache, hash);
 	while (ce) {
 		struct buffer_head *bh;
 
//flaw_line_below:
		if (IS_ERR(ce)) {
//flaw_line_below:
			if (PTR_ERR(ce) == -EAGAIN)
//flaw_line_below:
				goto again;
//flaw_line_below:
			break;
//flaw_line_below:
		}
 		bh = sb_bread(inode->i_sb, ce->e_block);
 		if (!bh) {
 			EXT4_ERROR_INODE(inode, ""block %lu read error"",
					 (unsigned long) ce->e_block);
		} else if (le32_to_cpu(BHDR(bh)->h_refcount) >=
				EXT4_XATTR_REFCOUNT_MAX) {
			ea_idebug(inode, ""block %lu refcount %d>=%d"",
				  (unsigned long) ce->e_block,
				  le32_to_cpu(BHDR(bh)->h_refcount),
					  EXT4_XATTR_REFCOUNT_MAX);
		} else if (ext4_xattr_cmp(header, BHDR(bh)) == 0) {
			*pce = ce;
 			return bh;
 		}
 		brelse(bh);
//flaw_line_below:
		ce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);
//fix_flaw_line_below:
//		ce = mb2_cache_entry_find_next(ext4_mb_cache, ce);
 	}
 	return NULL;
 }
"
5428,183164,,Local,Not required,Partial,CVE-2015-8952,https://www.cvedetails.com/cve/CVE-2015-8952/,CWE-19,Low,,,,2016-10-16,2.1,"The mbcache feature in the ext2 and ext4 filesystem implementations in the Linux kernel before 4.6 mishandles xattr block caching, which allows local users to cause a denial of service (soft lockup) via filesystem operations in environments that use many attributes, as demonstrated by Ceph and Samba.",2018-03-15,DoS ,5,https://github.com/torvalds/linux/commit/82939d7999dfc1f1998c4b1c12e2f19edbdff272,82939d7999dfc1f1998c4b1c12e2f19edbdff272,"ext4: convert to mbcache2

The conversion is generally straightforward. The only tricky part is
that xattr block corresponding to found mbcache entry can get freed
before we get buffer lock for that block. So we have to check whether
the entry is still valid after getting buffer lock.

Signed-off-by: Jan Kara <jack@suse.cz>
Signed-off-by: Theodore Ts'o <tytso@mit.edu>",14,fs/ext4/xattr.c,"{""sha"": ""9ac9e62569ef8fdf981021b58d37ab99d0150882"", ""filename"": ""fs/ext4/ext4.h"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 1, ""changes"": 2, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/ext4.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/ext4.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/ext4.h?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -1468,7 +1468,7 @@ struct ext4_sb_info {\n \tstruct list_head s_es_list;\t/* List of inodes with reclaimable extents */\n \tlong s_es_nr_inode;\n \tstruct ext4_es_stats s_es_stats;\n-\tstruct mb_cache *s_mb_cache;\n+\tstruct mb2_cache *s_mb_cache;\n \tspinlock_t s_es_lock ____cacheline_aligned_in_smp;\n \n \t/* Ratelimit ext4 messages. */""}<_**next**_>{""sha"": ""ecc37e1034358d769ab29971e9d2301fb9e2b3bc"", ""filename"": ""fs/ext4/super.c"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 2, ""changes"": 7, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/super.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/super.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/super.c?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -844,7 +844,6 @@ static void ext4_put_super(struct super_block *sb)\n \text4_release_system_zone(sb);\n \text4_mb_release(sb);\n \text4_ext_release(sb);\n-\text4_xattr_put_super(sb);\n \n \tif (!(sb->s_flags & MS_RDONLY)) {\n \t\text4_clear_feature_journal_needs_recovery(sb);\n@@ -3797,7 +3796,7 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n \n no_journal:\n \tif (ext4_mballoc_ready) {\n-\t\tsbi->s_mb_cache = ext4_xattr_create_cache(sb->s_id);\n+\t\tsbi->s_mb_cache = ext4_xattr_create_cache();\n \t\tif (!sbi->s_mb_cache) {\n \t\t\text4_msg(sb, KERN_ERR, \""Failed to create an mb_cache\"");\n \t\t\tgoto failed_mount_wq;\n@@ -4027,6 +4026,10 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n \tif (EXT4_SB(sb)->rsv_conversion_wq)\n \t\tdestroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);\n failed_mount_wq:\n+\tif (sbi->s_mb_cache) {\n+\t\text4_xattr_destroy_cache(sbi->s_mb_cache);\n+\t\tsbi->s_mb_cache = NULL;\n+\t}\n \tif (sbi->s_journal) {\n \t\tjbd2_journal_destroy(sbi->s_journal);\n \t\tsbi->s_journal = NULL;""}<_**next**_>{""sha"": ""fe9f8d6ab6c91b60689abadefd5435c31893fcae"", ""filename"": ""fs/ext4/xattr.c"", ""status"": ""modified"", ""additions"": 67, ""deletions"": 69, ""changes"": 136, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/xattr.c?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -53,7 +53,7 @@\n #include <linux/init.h>\n #include <linux/fs.h>\n #include <linux/slab.h>\n-#include <linux/mbcache.h>\n+#include <linux/mbcache2.h>\n #include <linux/quotaops.h>\n #include \""ext4_jbd2.h\""\n #include \""ext4.h\""\n@@ -78,10 +78,10 @@\n # define ea_bdebug(bh, fmt, ...)\tno_printk(fmt, ##__VA_ARGS__)\n #endif\n \n-static void ext4_xattr_cache_insert(struct mb_cache *, struct buffer_head *);\n+static void ext4_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);\n static struct buffer_head *ext4_xattr_cache_find(struct inode *,\n \t\t\t\t\t\t struct ext4_xattr_header *,\n-\t\t\t\t\t\t struct mb_cache_entry **);\n+\t\t\t\t\t\t struct mb2_cache_entry **);\n static void ext4_xattr_rehash(struct ext4_xattr_header *,\n \t\t\t      struct ext4_xattr_entry *);\n static int ext4_xattr_list(struct dentry *dentry, char *buffer,\n@@ -276,7 +276,7 @@ ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,\n \tstruct ext4_xattr_entry *entry;\n \tsize_t size;\n \tint error;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tea_idebug(inode, \""name=%d.%s, buffer=%p, buffer_size=%ld\"",\n \t\t  name_index, name, buffer, (long)buffer_size);\n@@ -428,7 +428,7 @@ ext4_xattr_block_list(struct dentry *dentry, char *buffer, size_t buffer_size)\n \tstruct inode *inode = d_inode(dentry);\n \tstruct buffer_head *bh = NULL;\n \tint error;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tea_idebug(inode, \""buffer=%p, buffer_size=%ld\"",\n \t\t  buffer, (long)buffer_size);\n@@ -545,30 +545,31 @@ static void\n ext4_xattr_release_block(handle_t *handle, struct inode *inode,\n \t\t\t struct buffer_head *bh)\n {\n-\tstruct mb_cache_entry *ce = NULL;\n \tint error = 0;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n-\tce = mb_cache_entry_get(ext4_mb_cache, bh->b_bdev, bh->b_blocknr);\n \tBUFFER_TRACE(bh, \""get_write_access\"");\n \terror = ext4_journal_get_write_access(handle, bh);\n \tif (error)\n \t\tgoto out;\n \n \tlock_buffer(bh);\n \tif (BHDR(bh)->h_refcount == cpu_to_le32(1)) {\n+\t\t__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);\n+\n \t\tea_bdebug(bh, \""refcount now=0; freeing\"");\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_free(ce);\n+\t\t/*\n+\t\t * This must happen under buffer lock for\n+\t\t * ext4_xattr_block_set() to reliably detect freed block\n+\t\t */\n+\t\tmb2_cache_entry_delete_block(EXT4_GET_MB_CACHE(inode), hash,\n+\t\t\t\t\t     bh->b_blocknr);\n \t\tget_bh(bh);\n \t\tunlock_buffer(bh);\n \t\text4_free_blocks(handle, inode, bh, 0, 1,\n \t\t\t\t EXT4_FREE_BLOCKS_METADATA |\n \t\t\t\t EXT4_FREE_BLOCKS_FORGET);\n \t} else {\n \t\tle32_add_cpu(&BHDR(bh)->h_refcount, -1);\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_release(ce);\n \t\t/*\n \t\t * Beware of this ugliness: Releasing of xattr block references\n \t\t * from different inodes can race and so we have to protect\n@@ -781,28 +782,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \tstruct super_block *sb = inode->i_sb;\n \tstruct buffer_head *new_bh = NULL;\n \tstruct ext4_xattr_search *s = &bs->s;\n-\tstruct mb_cache_entry *ce = NULL;\n+\tstruct mb2_cache_entry *ce = NULL;\n \tint error = 0;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n #define header(x) ((struct ext4_xattr_header *)(x))\n \n \tif (i->value && i->value_len > sb->s_blocksize)\n \t\treturn -ENOSPC;\n \tif (s->base) {\n-\t\tce = mb_cache_entry_get(ext4_mb_cache, bs->bh->b_bdev,\n-\t\t\t\t\tbs->bh->b_blocknr);\n \t\tBUFFER_TRACE(bs->bh, \""get_write_access\"");\n \t\terror = ext4_journal_get_write_access(handle, bs->bh);\n \t\tif (error)\n \t\t\tgoto cleanup;\n \t\tlock_buffer(bs->bh);\n \n \t\tif (header(s->base)->h_refcount == cpu_to_le32(1)) {\n-\t\t\tif (ce) {\n-\t\t\t\tmb_cache_entry_free(ce);\n-\t\t\t\tce = NULL;\n-\t\t\t}\n+\t\t\t__u32 hash = le32_to_cpu(BHDR(bs->bh)->h_hash);\n+\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext4_xattr_block_set() to reliably detect modified\n+\t\t\t * block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(ext4_mb_cache, hash,\n+\t\t\t\t\t\t     bs->bh->b_blocknr);\n \t\t\tea_bdebug(bs->bh, \""modifying in-place\"");\n \t\t\terror = ext4_xattr_set_entry(i, s);\n \t\t\tif (!error) {\n@@ -826,10 +830,6 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\tint offset = (char *)s->here - bs->bh->b_data;\n \n \t\t\tunlock_buffer(bs->bh);\n-\t\t\tif (ce) {\n-\t\t\t\tmb_cache_entry_release(ce);\n-\t\t\t\tce = NULL;\n-\t\t\t}\n \t\t\tea_bdebug(bs->bh, \""cloning\"");\n \t\t\ts->base = kmalloc(bs->bh->b_size, GFP_NOFS);\n \t\t\terror = -ENOMEM;\n@@ -884,6 +884,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\t\tif (error)\n \t\t\t\t\tgoto cleanup_dquot;\n \t\t\t\tlock_buffer(new_bh);\n+\t\t\t\t/*\n+\t\t\t\t * We have to be careful about races with\n+\t\t\t\t * freeing or rehashing of xattr block. Once we\n+\t\t\t\t * hold buffer lock xattr block's state is\n+\t\t\t\t * stable so we can check whether the block got\n+\t\t\t\t * freed / rehashed or not.  Since we unhash\n+\t\t\t\t * mbcache entry under buffer lock when freeing\n+\t\t\t\t * / rehashing xattr block, checking whether\n+\t\t\t\t * entry is still hashed is reliable.\n+\t\t\t\t */\n+\t\t\t\tif (hlist_bl_unhashed(&ce->e_hash_list)) {\n+\t\t\t\t\t/*\n+\t\t\t\t\t * Undo everything and check mbcache\n+\t\t\t\t\t * again.\n+\t\t\t\t\t */\n+\t\t\t\t\tunlock_buffer(new_bh);\n+\t\t\t\t\tdquot_free_block(inode,\n+\t\t\t\t\t\t\t EXT4_C2B(EXT4_SB(sb),\n+\t\t\t\t\t\t\t\t  1));\n+\t\t\t\t\tbrelse(new_bh);\n+\t\t\t\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n+\t\t\t\t\tce = NULL;\n+\t\t\t\t\tnew_bh = NULL;\n+\t\t\t\t\tgoto inserted;\n+\t\t\t\t}\n \t\t\t\tle32_add_cpu(&BHDR(new_bh)->h_refcount, 1);\n \t\t\t\tea_bdebug(new_bh, \""reusing; refcount now=%d\"",\n \t\t\t\t\tle32_to_cpu(BHDR(new_bh)->h_refcount));\n@@ -894,7 +919,8 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\t\tif (error)\n \t\t\t\t\tgoto cleanup_dquot;\n \t\t\t}\n-\t\t\tmb_cache_entry_release(ce);\n+\t\t\tmb2_cache_entry_touch(ext4_mb_cache, ce);\n+\t\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n \t\t\tce = NULL;\n \t\t} else if (bs->bh && s->base == bs->bh->b_data) {\n \t\t\t/* We were modifying this block in-place. */\n@@ -959,7 +985,7 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \n cleanup:\n \tif (ce)\n-\t\tmb_cache_entry_release(ce);\n+\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n \tbrelse(new_bh);\n \tif (!(bs->bh && s->base == bs->bh->b_data))\n \t\tkfree(s->base);\n@@ -1511,17 +1537,6 @@ ext4_xattr_delete_inode(handle_t *handle, struct inode *inode)\n \tbrelse(bh);\n }\n \n-/*\n- * ext4_xattr_put_super()\n- *\n- * This is called when a file system is unmounted.\n- */\n-void\n-ext4_xattr_put_super(struct super_block *sb)\n-{\n-\tmb_cache_shrink(sb->s_bdev);\n-}\n-\n /*\n  * ext4_xattr_cache_insert()\n  *\n@@ -1531,28 +1546,18 @@ ext4_xattr_put_super(struct super_block *sb)\n  * Returns 0, or a negative error number on failure.\n  */\n static void\n-ext4_xattr_cache_insert(struct mb_cache *ext4_mb_cache, struct buffer_head *bh)\n+ext4_xattr_cache_insert(struct mb2_cache *ext4_mb_cache, struct buffer_head *bh)\n {\n \t__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);\n-\tstruct mb_cache_entry *ce;\n \tint error;\n \n-\tce = mb_cache_entry_alloc(ext4_mb_cache, GFP_NOFS);\n-\tif (!ce) {\n-\t\tea_bdebug(bh, \""out of memory\"");\n-\t\treturn;\n-\t}\n-\terror = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);\n+\terror = mb2_cache_entry_create(ext4_mb_cache, GFP_NOFS, hash,\n+\t\t\t\t       bh->b_blocknr);\n \tif (error) {\n-\t\tmb_cache_entry_free(ce);\n-\t\tif (error == -EBUSY) {\n+\t\tif (error == -EBUSY)\n \t\t\tea_bdebug(bh, \""already in cache\"");\n-\t\t\terror = 0;\n-\t\t}\n-\t} else {\n+\t} else\n \t\tea_bdebug(bh, \""inserting [%x]\"", (int)hash);\n-\t\tmb_cache_entry_release(ce);\n-\t}\n }\n \n /*\n@@ -1605,26 +1610,19 @@ ext4_xattr_cmp(struct ext4_xattr_header *header1,\n  */\n static struct buffer_head *\n ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,\n-\t\t      struct mb_cache_entry **pce)\n+\t\t      struct mb2_cache_entry **pce)\n {\n \t__u32 hash = le32_to_cpu(header->h_hash);\n-\tstruct mb_cache_entry *ce;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache_entry *ce;\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tif (!header->h_hash)\n \t\treturn NULL;  /* never share */\n \tea_idebug(inode, \""looking for cached blocks [%x]\"", (int)hash);\n-again:\n-\tce = mb_cache_entry_find_first(ext4_mb_cache, inode->i_sb->s_bdev,\n-\t\t\t\t       hash);\n+\tce = mb2_cache_entry_find_first(ext4_mb_cache, hash);\n \twhile (ce) {\n \t\tstruct buffer_head *bh;\n \n-\t\tif (IS_ERR(ce)) {\n-\t\t\tif (PTR_ERR(ce) == -EAGAIN)\n-\t\t\t\tgoto again;\n-\t\t\tbreak;\n-\t\t}\n \t\tbh = sb_bread(inode->i_sb, ce->e_block);\n \t\tif (!bh) {\n \t\t\tEXT4_ERROR_INODE(inode, \""block %lu read error\"",\n@@ -1640,7 +1638,7 @@ ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,\n \t\t\treturn bh;\n \t\t}\n \t\tbrelse(bh);\n-\t\tce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);\n+\t\tce = mb2_cache_entry_find_next(ext4_mb_cache, ce);\n \t}\n \treturn NULL;\n }\n@@ -1715,15 +1713,15 @@ static void ext4_xattr_rehash(struct ext4_xattr_header *header,\n \n #define\tHASH_BUCKET_BITS\t10\n \n-struct mb_cache *\n-ext4_xattr_create_cache(char *name)\n+struct mb2_cache *\n+ext4_xattr_create_cache(void)\n {\n-\treturn mb_cache_create(name, HASH_BUCKET_BITS);\n+\treturn mb2_cache_create(HASH_BUCKET_BITS);\n }\n \n-void ext4_xattr_destroy_cache(struct mb_cache *cache)\n+void ext4_xattr_destroy_cache(struct mb2_cache *cache)\n {\n \tif (cache)\n-\t\tmb_cache_destroy(cache);\n+\t\tmb2_cache_destroy(cache);\n }\n ""}<_**next**_>{""sha"": ""10b0f7323ed6fcd628efee26998d0f1be7652c48"", ""filename"": ""fs/ext4/xattr.h"", ""status"": ""modified"", ""additions"": 2, ""deletions"": 3, ""changes"": 5, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/xattr.h?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -108,7 +108,6 @@ extern int ext4_xattr_set(struct inode *, int, const char *, const void *, size_\n extern int ext4_xattr_set_handle(handle_t *, struct inode *, int, const char *, const void *, size_t, int);\n \n extern void ext4_xattr_delete_inode(handle_t *, struct inode *);\n-extern void ext4_xattr_put_super(struct super_block *);\n \n extern int ext4_expand_extra_isize_ea(struct inode *inode, int new_extra_isize,\n \t\t\t    struct ext4_inode *raw_inode, handle_t *handle);\n@@ -124,8 +123,8 @@ extern int ext4_xattr_ibody_inline_set(handle_t *handle, struct inode *inode,\n \t\t\t\t       struct ext4_xattr_info *i,\n \t\t\t\t       struct ext4_xattr_ibody_find *is);\n \n-extern struct mb_cache *ext4_xattr_create_cache(char *name);\n-extern void ext4_xattr_destroy_cache(struct mb_cache *);\n+extern struct mb2_cache *ext4_xattr_create_cache(void);\n+extern void ext4_xattr_destroy_cache(struct mb2_cache *);\n \n #ifdef CONFIG_EXT4_FS_SECURITY\n extern int ext4_init_security(handle_t *handle, struct inode *inode,""}","ext4_xattr_cache_insert(struct mb_cache *ext4_mb_cache, struct buffer_head *bh)
ext4_xattr_cache_insert(struct mb2_cache *ext4_mb_cache, struct buffer_head *bh)
 {
 	__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);
 	int error;
 
	error = mb2_cache_entry_create(ext4_mb_cache, GFP_NOFS, hash,
				       bh->b_blocknr);
 	if (error) {
		if (error == -EBUSY)
 			ea_bdebug(bh, ""already in cache"");
	} else
 		ea_bdebug(bh, ""inserting [%x]"", (int)hash);
 }
","ext4_xattr_cache_insert(struct mb_cache *ext4_mb_cache, struct buffer_head *bh)
 {
 	__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);
	struct mb_cache_entry *ce;
 	int error;
 
	ce = mb_cache_entry_alloc(ext4_mb_cache, GFP_NOFS);
	if (!ce) {
		ea_bdebug(bh, ""out of memory"");
		return;
	}
	error = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);
 	if (error) {
		mb_cache_entry_free(ce);
		if (error == -EBUSY) {
 			ea_bdebug(bh, ""already in cache"");
			error = 0;
		}
	} else {
 		ea_bdebug(bh, ""inserting [%x]"", (int)hash);
		mb_cache_entry_release(ce);
	}
 }
",C,"ext4_xattr_cache_insert(struct mb2_cache *ext4_mb_cache, struct buffer_head *bh)
	error = mb2_cache_entry_create(ext4_mb_cache, GFP_NOFS, hash,
				       bh->b_blocknr);
		if (error == -EBUSY)
	} else
","	struct mb_cache_entry *ce;
	ce = mb_cache_entry_alloc(ext4_mb_cache, GFP_NOFS);
	if (!ce) {
		ea_bdebug(bh, ""out of memory"");
		return;
	}
	error = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);
		mb_cache_entry_free(ce);
		if (error == -EBUSY) {
			error = 0;
		}
	} else {
		mb_cache_entry_release(ce);
	}
",,"@@ -53,7 +53,7 @@
 #include <linux/init.h>
 #include <linux/fs.h>
 #include <linux/slab.h>
-#include <linux/mbcache.h>
+#include <linux/mbcache2.h>
 #include <linux/quotaops.h>
 #include ""ext4_jbd2.h""
 #include ""ext4.h""
@@ -78,10 +78,10 @@
 # define ea_bdebug(bh, fmt, ...)	no_printk(fmt, ##__VA_ARGS__)
 #endif
 
-static void ext4_xattr_cache_insert(struct mb_cache *, struct buffer_head *);
+static void ext4_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);
 static struct buffer_head *ext4_xattr_cache_find(struct inode *,
 						 struct ext4_xattr_header *,
-						 struct mb_cache_entry **);
+						 struct mb2_cache_entry **);
 static void ext4_xattr_rehash(struct ext4_xattr_header *,
 			      struct ext4_xattr_entry *);
 static int ext4_xattr_list(struct dentry *dentry, char *buffer,
@@ -276,7 +276,7 @@ ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,
 	struct ext4_xattr_entry *entry;
 	size_t size;
 	int error;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	ea_idebug(inode, ""name=%d.%s, buffer=%p, buffer_size=%ld"",
 		  name_index, name, buffer, (long)buffer_size);
@@ -428,7 +428,7 @@ ext4_xattr_block_list(struct dentry *dentry, char *buffer, size_t buffer_size)
 	struct inode *inode = d_inode(dentry);
 	struct buffer_head *bh = NULL;
 	int error;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	ea_idebug(inode, ""buffer=%p, buffer_size=%ld"",
 		  buffer, (long)buffer_size);
@@ -545,30 +545,31 @@ static void
 ext4_xattr_release_block(handle_t *handle, struct inode *inode,
 			 struct buffer_head *bh)
 {
-	struct mb_cache_entry *ce = NULL;
 	int error = 0;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
-	ce = mb_cache_entry_get(ext4_mb_cache, bh->b_bdev, bh->b_blocknr);
 	BUFFER_TRACE(bh, ""get_write_access"");
 	error = ext4_journal_get_write_access(handle, bh);
 	if (error)
 		goto out;
 
 	lock_buffer(bh);
 	if (BHDR(bh)->h_refcount == cpu_to_le32(1)) {
+		__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);
+
 		ea_bdebug(bh, ""refcount now=0; freeing"");
-		if (ce)
-			mb_cache_entry_free(ce);
+		/*
+		 * This must happen under buffer lock for
+		 * ext4_xattr_block_set() to reliably detect freed block
+		 */
+		mb2_cache_entry_delete_block(EXT4_GET_MB_CACHE(inode), hash,
+					     bh->b_blocknr);
 		get_bh(bh);
 		unlock_buffer(bh);
 		ext4_free_blocks(handle, inode, bh, 0, 1,
 				 EXT4_FREE_BLOCKS_METADATA |
 				 EXT4_FREE_BLOCKS_FORGET);
 	} else {
 		le32_add_cpu(&BHDR(bh)->h_refcount, -1);
-		if (ce)
-			mb_cache_entry_release(ce);
 		/*
 		 * Beware of this ugliness: Releasing of xattr block references
 		 * from different inodes can race and so we have to protect
@@ -781,28 +782,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *new_bh = NULL;
 	struct ext4_xattr_search *s = &bs->s;
-	struct mb_cache_entry *ce = NULL;
+	struct mb2_cache_entry *ce = NULL;
 	int error = 0;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 #define header(x) ((struct ext4_xattr_header *)(x))
 
 	if (i->value && i->value_len > sb->s_blocksize)
 		return -ENOSPC;
 	if (s->base) {
-		ce = mb_cache_entry_get(ext4_mb_cache, bs->bh->b_bdev,
-					bs->bh->b_blocknr);
 		BUFFER_TRACE(bs->bh, ""get_write_access"");
 		error = ext4_journal_get_write_access(handle, bs->bh);
 		if (error)
 			goto cleanup;
 		lock_buffer(bs->bh);
 
 		if (header(s->base)->h_refcount == cpu_to_le32(1)) {
-			if (ce) {
-				mb_cache_entry_free(ce);
-				ce = NULL;
-			}
+			__u32 hash = le32_to_cpu(BHDR(bs->bh)->h_hash);
+
+			/*
+			 * This must happen under buffer lock for
+			 * ext4_xattr_block_set() to reliably detect modified
+			 * block
+			 */
+			mb2_cache_entry_delete_block(ext4_mb_cache, hash,
+						     bs->bh->b_blocknr);
 			ea_bdebug(bs->bh, ""modifying in-place"");
 			error = ext4_xattr_set_entry(i, s);
 			if (!error) {
@@ -826,10 +830,6 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 			int offset = (char *)s->here - bs->bh->b_data;
 
 			unlock_buffer(bs->bh);
-			if (ce) {
-				mb_cache_entry_release(ce);
-				ce = NULL;
-			}
 			ea_bdebug(bs->bh, ""cloning"");
 			s->base = kmalloc(bs->bh->b_size, GFP_NOFS);
 			error = -ENOMEM;
@@ -884,6 +884,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 				if (error)
 					goto cleanup_dquot;
 				lock_buffer(new_bh);
+				/*
+				 * We have to be careful about races with
+				 * freeing or rehashing of xattr block. Once we
+				 * hold buffer lock xattr block's state is
+				 * stable so we can check whether the block got
+				 * freed / rehashed or not.  Since we unhash
+				 * mbcache entry under buffer lock when freeing
+				 * / rehashing xattr block, checking whether
+				 * entry is still hashed is reliable.
+				 */
+				if (hlist_bl_unhashed(&ce->e_hash_list)) {
+					/*
+					 * Undo everything and check mbcache
+					 * again.
+					 */
+					unlock_buffer(new_bh);
+					dquot_free_block(inode,
+							 EXT4_C2B(EXT4_SB(sb),
+								  1));
+					brelse(new_bh);
+					mb2_cache_entry_put(ext4_mb_cache, ce);
+					ce = NULL;
+					new_bh = NULL;
+					goto inserted;
+				}
 				le32_add_cpu(&BHDR(new_bh)->h_refcount, 1);
 				ea_bdebug(new_bh, ""reusing; refcount now=%d"",
 					le32_to_cpu(BHDR(new_bh)->h_refcount));
@@ -894,7 +919,8 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 				if (error)
 					goto cleanup_dquot;
 			}
-			mb_cache_entry_release(ce);
+			mb2_cache_entry_touch(ext4_mb_cache, ce);
+			mb2_cache_entry_put(ext4_mb_cache, ce);
 			ce = NULL;
 		} else if (bs->bh && s->base == bs->bh->b_data) {
 			/* We were modifying this block in-place. */
@@ -959,7 +985,7 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 
 cleanup:
 	if (ce)
-		mb_cache_entry_release(ce);
+		mb2_cache_entry_put(ext4_mb_cache, ce);
 	brelse(new_bh);
 	if (!(bs->bh && s->base == bs->bh->b_data))
 		kfree(s->base);
@@ -1511,17 +1537,6 @@ ext4_xattr_delete_inode(handle_t *handle, struct inode *inode)
 	brelse(bh);
 }
 
-/*
- * ext4_xattr_put_super()
- *
- * This is called when a file system is unmounted.
- */
-void
-ext4_xattr_put_super(struct super_block *sb)
-{
-	mb_cache_shrink(sb->s_bdev);
-}
-
 /*
  * ext4_xattr_cache_insert()
  *
@@ -1531,28 +1546,18 @@ ext4_xattr_put_super(struct super_block *sb)
  * Returns 0, or a negative error number on failure.
  */
 static void
-ext4_xattr_cache_insert(struct mb_cache *ext4_mb_cache, struct buffer_head *bh)
+ext4_xattr_cache_insert(struct mb2_cache *ext4_mb_cache, struct buffer_head *bh)
 {
 	__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);
-	struct mb_cache_entry *ce;
 	int error;
 
-	ce = mb_cache_entry_alloc(ext4_mb_cache, GFP_NOFS);
-	if (!ce) {
-		ea_bdebug(bh, ""out of memory"");
-		return;
-	}
-	error = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);
+	error = mb2_cache_entry_create(ext4_mb_cache, GFP_NOFS, hash,
+				       bh->b_blocknr);
 	if (error) {
-		mb_cache_entry_free(ce);
-		if (error == -EBUSY) {
+		if (error == -EBUSY)
 			ea_bdebug(bh, ""already in cache"");
-			error = 0;
-		}
-	} else {
+	} else
 		ea_bdebug(bh, ""inserting [%x]"", (int)hash);
-		mb_cache_entry_release(ce);
-	}
 }
 
 /*
@@ -1605,26 +1610,19 @@ ext4_xattr_cmp(struct ext4_xattr_header *header1,
  */
 static struct buffer_head *
 ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,
-		      struct mb_cache_entry **pce)
+		      struct mb2_cache_entry **pce)
 {
 	__u32 hash = le32_to_cpu(header->h_hash);
-	struct mb_cache_entry *ce;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache_entry *ce;
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	if (!header->h_hash)
 		return NULL;  /* never share */
 	ea_idebug(inode, ""looking for cached blocks [%x]"", (int)hash);
-again:
-	ce = mb_cache_entry_find_first(ext4_mb_cache, inode->i_sb->s_bdev,
-				       hash);
+	ce = mb2_cache_entry_find_first(ext4_mb_cache, hash);
 	while (ce) {
 		struct buffer_head *bh;
 
-		if (IS_ERR(ce)) {
-			if (PTR_ERR(ce) == -EAGAIN)
-				goto again;
-			break;
-		}
 		bh = sb_bread(inode->i_sb, ce->e_block);
 		if (!bh) {
 			EXT4_ERROR_INODE(inode, ""block %lu read error"",
@@ -1640,7 +1638,7 @@ ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,
 			return bh;
 		}
 		brelse(bh);
-		ce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);
+		ce = mb2_cache_entry_find_next(ext4_mb_cache, ce);
 	}
 	return NULL;
 }
@@ -1715,15 +1713,15 @@ static void ext4_xattr_rehash(struct ext4_xattr_header *header,
 
 #define	HASH_BUCKET_BITS	10
 
-struct mb_cache *
-ext4_xattr_create_cache(char *name)
+struct mb2_cache *
+ext4_xattr_create_cache(void)
 {
-	return mb_cache_create(name, HASH_BUCKET_BITS);
+	return mb2_cache_create(HASH_BUCKET_BITS);
 }
 
-void ext4_xattr_destroy_cache(struct mb_cache *cache)
+void ext4_xattr_destroy_cache(struct mb2_cache *cache)
 {
 	if (cache)
-		mb_cache_destroy(cache);
+		mb2_cache_destroy(cache);
 }
 ",linux,82939d7999dfc1f1998c4b1c12e2f19edbdff272,f9a61eb4e2471c56a63cd804c7474128138c38ac,1,"ext4_xattr_cache_insert(struct mb_cache *ext4_mb_cache, struct buffer_head *bh)
//fix_flaw_line_below:
//ext4_xattr_cache_insert(struct mb2_cache *ext4_mb_cache, struct buffer_head *bh)
 {
 	__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);
//flaw_line_below:
	struct mb_cache_entry *ce;
 	int error;
 
//flaw_line_below:
	ce = mb_cache_entry_alloc(ext4_mb_cache, GFP_NOFS);
//flaw_line_below:
	if (!ce) {
//flaw_line_below:
		ea_bdebug(bh, ""out of memory"");
//flaw_line_below:
		return;
//flaw_line_below:
	}
//flaw_line_below:
	error = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);
//fix_flaw_line_below:
//	error = mb2_cache_entry_create(ext4_mb_cache, GFP_NOFS, hash,
//fix_flaw_line_below:
//				       bh->b_blocknr);
 	if (error) {
//flaw_line_below:
		mb_cache_entry_free(ce);
//flaw_line_below:
		if (error == -EBUSY) {
//fix_flaw_line_below:
//		if (error == -EBUSY)
 			ea_bdebug(bh, ""already in cache"");
//flaw_line_below:
			error = 0;
//flaw_line_below:
		}
//flaw_line_below:
	} else {
//fix_flaw_line_below:
//	} else
 		ea_bdebug(bh, ""inserting [%x]"", (int)hash);
//flaw_line_below:
		mb_cache_entry_release(ce);
//flaw_line_below:
	}
 }
"
5429,183165,,Local,Not required,Partial,CVE-2015-8952,https://www.cvedetails.com/cve/CVE-2015-8952/,CWE-19,Low,,,,2016-10-16,2.1,"The mbcache feature in the ext2 and ext4 filesystem implementations in the Linux kernel before 4.6 mishandles xattr block caching, which allows local users to cause a denial of service (soft lockup) via filesystem operations in environments that use many attributes, as demonstrated by Ceph and Samba.",2018-03-15,DoS ,3,https://github.com/torvalds/linux/commit/82939d7999dfc1f1998c4b1c12e2f19edbdff272,82939d7999dfc1f1998c4b1c12e2f19edbdff272,"ext4: convert to mbcache2

The conversion is generally straightforward. The only tricky part is
that xattr block corresponding to found mbcache entry can get freed
before we get buffer lock for that block. So we have to check whether
the entry is still valid after getting buffer lock.

Signed-off-by: Jan Kara <jack@suse.cz>
Signed-off-by: Theodore Ts'o <tytso@mit.edu>",1,fs/ext4/xattr.c,"{""sha"": ""9ac9e62569ef8fdf981021b58d37ab99d0150882"", ""filename"": ""fs/ext4/ext4.h"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 1, ""changes"": 2, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/ext4.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/ext4.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/ext4.h?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -1468,7 +1468,7 @@ struct ext4_sb_info {\n \tstruct list_head s_es_list;\t/* List of inodes with reclaimable extents */\n \tlong s_es_nr_inode;\n \tstruct ext4_es_stats s_es_stats;\n-\tstruct mb_cache *s_mb_cache;\n+\tstruct mb2_cache *s_mb_cache;\n \tspinlock_t s_es_lock ____cacheline_aligned_in_smp;\n \n \t/* Ratelimit ext4 messages. */""}<_**next**_>{""sha"": ""ecc37e1034358d769ab29971e9d2301fb9e2b3bc"", ""filename"": ""fs/ext4/super.c"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 2, ""changes"": 7, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/super.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/super.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/super.c?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -844,7 +844,6 @@ static void ext4_put_super(struct super_block *sb)\n \text4_release_system_zone(sb);\n \text4_mb_release(sb);\n \text4_ext_release(sb);\n-\text4_xattr_put_super(sb);\n \n \tif (!(sb->s_flags & MS_RDONLY)) {\n \t\text4_clear_feature_journal_needs_recovery(sb);\n@@ -3797,7 +3796,7 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n \n no_journal:\n \tif (ext4_mballoc_ready) {\n-\t\tsbi->s_mb_cache = ext4_xattr_create_cache(sb->s_id);\n+\t\tsbi->s_mb_cache = ext4_xattr_create_cache();\n \t\tif (!sbi->s_mb_cache) {\n \t\t\text4_msg(sb, KERN_ERR, \""Failed to create an mb_cache\"");\n \t\t\tgoto failed_mount_wq;\n@@ -4027,6 +4026,10 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n \tif (EXT4_SB(sb)->rsv_conversion_wq)\n \t\tdestroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);\n failed_mount_wq:\n+\tif (sbi->s_mb_cache) {\n+\t\text4_xattr_destroy_cache(sbi->s_mb_cache);\n+\t\tsbi->s_mb_cache = NULL;\n+\t}\n \tif (sbi->s_journal) {\n \t\tjbd2_journal_destroy(sbi->s_journal);\n \t\tsbi->s_journal = NULL;""}<_**next**_>{""sha"": ""fe9f8d6ab6c91b60689abadefd5435c31893fcae"", ""filename"": ""fs/ext4/xattr.c"", ""status"": ""modified"", ""additions"": 67, ""deletions"": 69, ""changes"": 136, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/xattr.c?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -53,7 +53,7 @@\n #include <linux/init.h>\n #include <linux/fs.h>\n #include <linux/slab.h>\n-#include <linux/mbcache.h>\n+#include <linux/mbcache2.h>\n #include <linux/quotaops.h>\n #include \""ext4_jbd2.h\""\n #include \""ext4.h\""\n@@ -78,10 +78,10 @@\n # define ea_bdebug(bh, fmt, ...)\tno_printk(fmt, ##__VA_ARGS__)\n #endif\n \n-static void ext4_xattr_cache_insert(struct mb_cache *, struct buffer_head *);\n+static void ext4_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);\n static struct buffer_head *ext4_xattr_cache_find(struct inode *,\n \t\t\t\t\t\t struct ext4_xattr_header *,\n-\t\t\t\t\t\t struct mb_cache_entry **);\n+\t\t\t\t\t\t struct mb2_cache_entry **);\n static void ext4_xattr_rehash(struct ext4_xattr_header *,\n \t\t\t      struct ext4_xattr_entry *);\n static int ext4_xattr_list(struct dentry *dentry, char *buffer,\n@@ -276,7 +276,7 @@ ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,\n \tstruct ext4_xattr_entry *entry;\n \tsize_t size;\n \tint error;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tea_idebug(inode, \""name=%d.%s, buffer=%p, buffer_size=%ld\"",\n \t\t  name_index, name, buffer, (long)buffer_size);\n@@ -428,7 +428,7 @@ ext4_xattr_block_list(struct dentry *dentry, char *buffer, size_t buffer_size)\n \tstruct inode *inode = d_inode(dentry);\n \tstruct buffer_head *bh = NULL;\n \tint error;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tea_idebug(inode, \""buffer=%p, buffer_size=%ld\"",\n \t\t  buffer, (long)buffer_size);\n@@ -545,30 +545,31 @@ static void\n ext4_xattr_release_block(handle_t *handle, struct inode *inode,\n \t\t\t struct buffer_head *bh)\n {\n-\tstruct mb_cache_entry *ce = NULL;\n \tint error = 0;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n-\tce = mb_cache_entry_get(ext4_mb_cache, bh->b_bdev, bh->b_blocknr);\n \tBUFFER_TRACE(bh, \""get_write_access\"");\n \terror = ext4_journal_get_write_access(handle, bh);\n \tif (error)\n \t\tgoto out;\n \n \tlock_buffer(bh);\n \tif (BHDR(bh)->h_refcount == cpu_to_le32(1)) {\n+\t\t__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);\n+\n \t\tea_bdebug(bh, \""refcount now=0; freeing\"");\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_free(ce);\n+\t\t/*\n+\t\t * This must happen under buffer lock for\n+\t\t * ext4_xattr_block_set() to reliably detect freed block\n+\t\t */\n+\t\tmb2_cache_entry_delete_block(EXT4_GET_MB_CACHE(inode), hash,\n+\t\t\t\t\t     bh->b_blocknr);\n \t\tget_bh(bh);\n \t\tunlock_buffer(bh);\n \t\text4_free_blocks(handle, inode, bh, 0, 1,\n \t\t\t\t EXT4_FREE_BLOCKS_METADATA |\n \t\t\t\t EXT4_FREE_BLOCKS_FORGET);\n \t} else {\n \t\tle32_add_cpu(&BHDR(bh)->h_refcount, -1);\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_release(ce);\n \t\t/*\n \t\t * Beware of this ugliness: Releasing of xattr block references\n \t\t * from different inodes can race and so we have to protect\n@@ -781,28 +782,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \tstruct super_block *sb = inode->i_sb;\n \tstruct buffer_head *new_bh = NULL;\n \tstruct ext4_xattr_search *s = &bs->s;\n-\tstruct mb_cache_entry *ce = NULL;\n+\tstruct mb2_cache_entry *ce = NULL;\n \tint error = 0;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n #define header(x) ((struct ext4_xattr_header *)(x))\n \n \tif (i->value && i->value_len > sb->s_blocksize)\n \t\treturn -ENOSPC;\n \tif (s->base) {\n-\t\tce = mb_cache_entry_get(ext4_mb_cache, bs->bh->b_bdev,\n-\t\t\t\t\tbs->bh->b_blocknr);\n \t\tBUFFER_TRACE(bs->bh, \""get_write_access\"");\n \t\terror = ext4_journal_get_write_access(handle, bs->bh);\n \t\tif (error)\n \t\t\tgoto cleanup;\n \t\tlock_buffer(bs->bh);\n \n \t\tif (header(s->base)->h_refcount == cpu_to_le32(1)) {\n-\t\t\tif (ce) {\n-\t\t\t\tmb_cache_entry_free(ce);\n-\t\t\t\tce = NULL;\n-\t\t\t}\n+\t\t\t__u32 hash = le32_to_cpu(BHDR(bs->bh)->h_hash);\n+\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext4_xattr_block_set() to reliably detect modified\n+\t\t\t * block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(ext4_mb_cache, hash,\n+\t\t\t\t\t\t     bs->bh->b_blocknr);\n \t\t\tea_bdebug(bs->bh, \""modifying in-place\"");\n \t\t\terror = ext4_xattr_set_entry(i, s);\n \t\t\tif (!error) {\n@@ -826,10 +830,6 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\tint offset = (char *)s->here - bs->bh->b_data;\n \n \t\t\tunlock_buffer(bs->bh);\n-\t\t\tif (ce) {\n-\t\t\t\tmb_cache_entry_release(ce);\n-\t\t\t\tce = NULL;\n-\t\t\t}\n \t\t\tea_bdebug(bs->bh, \""cloning\"");\n \t\t\ts->base = kmalloc(bs->bh->b_size, GFP_NOFS);\n \t\t\terror = -ENOMEM;\n@@ -884,6 +884,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\t\tif (error)\n \t\t\t\t\tgoto cleanup_dquot;\n \t\t\t\tlock_buffer(new_bh);\n+\t\t\t\t/*\n+\t\t\t\t * We have to be careful about races with\n+\t\t\t\t * freeing or rehashing of xattr block. Once we\n+\t\t\t\t * hold buffer lock xattr block's state is\n+\t\t\t\t * stable so we can check whether the block got\n+\t\t\t\t * freed / rehashed or not.  Since we unhash\n+\t\t\t\t * mbcache entry under buffer lock when freeing\n+\t\t\t\t * / rehashing xattr block, checking whether\n+\t\t\t\t * entry is still hashed is reliable.\n+\t\t\t\t */\n+\t\t\t\tif (hlist_bl_unhashed(&ce->e_hash_list)) {\n+\t\t\t\t\t/*\n+\t\t\t\t\t * Undo everything and check mbcache\n+\t\t\t\t\t * again.\n+\t\t\t\t\t */\n+\t\t\t\t\tunlock_buffer(new_bh);\n+\t\t\t\t\tdquot_free_block(inode,\n+\t\t\t\t\t\t\t EXT4_C2B(EXT4_SB(sb),\n+\t\t\t\t\t\t\t\t  1));\n+\t\t\t\t\tbrelse(new_bh);\n+\t\t\t\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n+\t\t\t\t\tce = NULL;\n+\t\t\t\t\tnew_bh = NULL;\n+\t\t\t\t\tgoto inserted;\n+\t\t\t\t}\n \t\t\t\tle32_add_cpu(&BHDR(new_bh)->h_refcount, 1);\n \t\t\t\tea_bdebug(new_bh, \""reusing; refcount now=%d\"",\n \t\t\t\t\tle32_to_cpu(BHDR(new_bh)->h_refcount));\n@@ -894,7 +919,8 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\t\tif (error)\n \t\t\t\t\tgoto cleanup_dquot;\n \t\t\t}\n-\t\t\tmb_cache_entry_release(ce);\n+\t\t\tmb2_cache_entry_touch(ext4_mb_cache, ce);\n+\t\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n \t\t\tce = NULL;\n \t\t} else if (bs->bh && s->base == bs->bh->b_data) {\n \t\t\t/* We were modifying this block in-place. */\n@@ -959,7 +985,7 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \n cleanup:\n \tif (ce)\n-\t\tmb_cache_entry_release(ce);\n+\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n \tbrelse(new_bh);\n \tif (!(bs->bh && s->base == bs->bh->b_data))\n \t\tkfree(s->base);\n@@ -1511,17 +1537,6 @@ ext4_xattr_delete_inode(handle_t *handle, struct inode *inode)\n \tbrelse(bh);\n }\n \n-/*\n- * ext4_xattr_put_super()\n- *\n- * This is called when a file system is unmounted.\n- */\n-void\n-ext4_xattr_put_super(struct super_block *sb)\n-{\n-\tmb_cache_shrink(sb->s_bdev);\n-}\n-\n /*\n  * ext4_xattr_cache_insert()\n  *\n@@ -1531,28 +1546,18 @@ ext4_xattr_put_super(struct super_block *sb)\n  * Returns 0, or a negative error number on failure.\n  */\n static void\n-ext4_xattr_cache_insert(struct mb_cache *ext4_mb_cache, struct buffer_head *bh)\n+ext4_xattr_cache_insert(struct mb2_cache *ext4_mb_cache, struct buffer_head *bh)\n {\n \t__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);\n-\tstruct mb_cache_entry *ce;\n \tint error;\n \n-\tce = mb_cache_entry_alloc(ext4_mb_cache, GFP_NOFS);\n-\tif (!ce) {\n-\t\tea_bdebug(bh, \""out of memory\"");\n-\t\treturn;\n-\t}\n-\terror = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);\n+\terror = mb2_cache_entry_create(ext4_mb_cache, GFP_NOFS, hash,\n+\t\t\t\t       bh->b_blocknr);\n \tif (error) {\n-\t\tmb_cache_entry_free(ce);\n-\t\tif (error == -EBUSY) {\n+\t\tif (error == -EBUSY)\n \t\t\tea_bdebug(bh, \""already in cache\"");\n-\t\t\terror = 0;\n-\t\t}\n-\t} else {\n+\t} else\n \t\tea_bdebug(bh, \""inserting [%x]\"", (int)hash);\n-\t\tmb_cache_entry_release(ce);\n-\t}\n }\n \n /*\n@@ -1605,26 +1610,19 @@ ext4_xattr_cmp(struct ext4_xattr_header *header1,\n  */\n static struct buffer_head *\n ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,\n-\t\t      struct mb_cache_entry **pce)\n+\t\t      struct mb2_cache_entry **pce)\n {\n \t__u32 hash = le32_to_cpu(header->h_hash);\n-\tstruct mb_cache_entry *ce;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache_entry *ce;\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tif (!header->h_hash)\n \t\treturn NULL;  /* never share */\n \tea_idebug(inode, \""looking for cached blocks [%x]\"", (int)hash);\n-again:\n-\tce = mb_cache_entry_find_first(ext4_mb_cache, inode->i_sb->s_bdev,\n-\t\t\t\t       hash);\n+\tce = mb2_cache_entry_find_first(ext4_mb_cache, hash);\n \twhile (ce) {\n \t\tstruct buffer_head *bh;\n \n-\t\tif (IS_ERR(ce)) {\n-\t\t\tif (PTR_ERR(ce) == -EAGAIN)\n-\t\t\t\tgoto again;\n-\t\t\tbreak;\n-\t\t}\n \t\tbh = sb_bread(inode->i_sb, ce->e_block);\n \t\tif (!bh) {\n \t\t\tEXT4_ERROR_INODE(inode, \""block %lu read error\"",\n@@ -1640,7 +1638,7 @@ ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,\n \t\t\treturn bh;\n \t\t}\n \t\tbrelse(bh);\n-\t\tce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);\n+\t\tce = mb2_cache_entry_find_next(ext4_mb_cache, ce);\n \t}\n \treturn NULL;\n }\n@@ -1715,15 +1713,15 @@ static void ext4_xattr_rehash(struct ext4_xattr_header *header,\n \n #define\tHASH_BUCKET_BITS\t10\n \n-struct mb_cache *\n-ext4_xattr_create_cache(char *name)\n+struct mb2_cache *\n+ext4_xattr_create_cache(void)\n {\n-\treturn mb_cache_create(name, HASH_BUCKET_BITS);\n+\treturn mb2_cache_create(HASH_BUCKET_BITS);\n }\n \n-void ext4_xattr_destroy_cache(struct mb_cache *cache)\n+void ext4_xattr_destroy_cache(struct mb2_cache *cache)\n {\n \tif (cache)\n-\t\tmb_cache_destroy(cache);\n+\t\tmb2_cache_destroy(cache);\n }\n ""}<_**next**_>{""sha"": ""10b0f7323ed6fcd628efee26998d0f1be7652c48"", ""filename"": ""fs/ext4/xattr.h"", ""status"": ""modified"", ""additions"": 2, ""deletions"": 3, ""changes"": 5, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/xattr.h?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -108,7 +108,6 @@ extern int ext4_xattr_set(struct inode *, int, const char *, const void *, size_\n extern int ext4_xattr_set_handle(handle_t *, struct inode *, int, const char *, const void *, size_t, int);\n \n extern void ext4_xattr_delete_inode(handle_t *, struct inode *);\n-extern void ext4_xattr_put_super(struct super_block *);\n \n extern int ext4_expand_extra_isize_ea(struct inode *inode, int new_extra_isize,\n \t\t\t    struct ext4_inode *raw_inode, handle_t *handle);\n@@ -124,8 +123,8 @@ extern int ext4_xattr_ibody_inline_set(handle_t *handle, struct inode *inode,\n \t\t\t\t       struct ext4_xattr_info *i,\n \t\t\t\t       struct ext4_xattr_ibody_find *is);\n \n-extern struct mb_cache *ext4_xattr_create_cache(char *name);\n-extern void ext4_xattr_destroy_cache(struct mb_cache *);\n+extern struct mb2_cache *ext4_xattr_create_cache(void);\n+extern void ext4_xattr_destroy_cache(struct mb2_cache *);\n \n #ifdef CONFIG_EXT4_FS_SECURITY\n extern int ext4_init_security(handle_t *handle, struct inode *inode,""}","ext4_xattr_create_cache(char *name)
struct mb2_cache *
ext4_xattr_create_cache(void)
 {
	return mb2_cache_create(HASH_BUCKET_BITS);
 }
","ext4_xattr_create_cache(char *name)
 {
	return mb_cache_create(name, HASH_BUCKET_BITS);
 }
",C,"struct mb2_cache *
ext4_xattr_create_cache(void)
	return mb2_cache_create(HASH_BUCKET_BITS);
","	return mb_cache_create(name, HASH_BUCKET_BITS);
",,"@@ -53,7 +53,7 @@
 #include <linux/init.h>
 #include <linux/fs.h>
 #include <linux/slab.h>
-#include <linux/mbcache.h>
+#include <linux/mbcache2.h>
 #include <linux/quotaops.h>
 #include ""ext4_jbd2.h""
 #include ""ext4.h""
@@ -78,10 +78,10 @@
 # define ea_bdebug(bh, fmt, ...)	no_printk(fmt, ##__VA_ARGS__)
 #endif
 
-static void ext4_xattr_cache_insert(struct mb_cache *, struct buffer_head *);
+static void ext4_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);
 static struct buffer_head *ext4_xattr_cache_find(struct inode *,
 						 struct ext4_xattr_header *,
-						 struct mb_cache_entry **);
+						 struct mb2_cache_entry **);
 static void ext4_xattr_rehash(struct ext4_xattr_header *,
 			      struct ext4_xattr_entry *);
 static int ext4_xattr_list(struct dentry *dentry, char *buffer,
@@ -276,7 +276,7 @@ ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,
 	struct ext4_xattr_entry *entry;
 	size_t size;
 	int error;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	ea_idebug(inode, ""name=%d.%s, buffer=%p, buffer_size=%ld"",
 		  name_index, name, buffer, (long)buffer_size);
@@ -428,7 +428,7 @@ ext4_xattr_block_list(struct dentry *dentry, char *buffer, size_t buffer_size)
 	struct inode *inode = d_inode(dentry);
 	struct buffer_head *bh = NULL;
 	int error;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	ea_idebug(inode, ""buffer=%p, buffer_size=%ld"",
 		  buffer, (long)buffer_size);
@@ -545,30 +545,31 @@ static void
 ext4_xattr_release_block(handle_t *handle, struct inode *inode,
 			 struct buffer_head *bh)
 {
-	struct mb_cache_entry *ce = NULL;
 	int error = 0;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
-	ce = mb_cache_entry_get(ext4_mb_cache, bh->b_bdev, bh->b_blocknr);
 	BUFFER_TRACE(bh, ""get_write_access"");
 	error = ext4_journal_get_write_access(handle, bh);
 	if (error)
 		goto out;
 
 	lock_buffer(bh);
 	if (BHDR(bh)->h_refcount == cpu_to_le32(1)) {
+		__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);
+
 		ea_bdebug(bh, ""refcount now=0; freeing"");
-		if (ce)
-			mb_cache_entry_free(ce);
+		/*
+		 * This must happen under buffer lock for
+		 * ext4_xattr_block_set() to reliably detect freed block
+		 */
+		mb2_cache_entry_delete_block(EXT4_GET_MB_CACHE(inode), hash,
+					     bh->b_blocknr);
 		get_bh(bh);
 		unlock_buffer(bh);
 		ext4_free_blocks(handle, inode, bh, 0, 1,
 				 EXT4_FREE_BLOCKS_METADATA |
 				 EXT4_FREE_BLOCKS_FORGET);
 	} else {
 		le32_add_cpu(&BHDR(bh)->h_refcount, -1);
-		if (ce)
-			mb_cache_entry_release(ce);
 		/*
 		 * Beware of this ugliness: Releasing of xattr block references
 		 * from different inodes can race and so we have to protect
@@ -781,28 +782,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *new_bh = NULL;
 	struct ext4_xattr_search *s = &bs->s;
-	struct mb_cache_entry *ce = NULL;
+	struct mb2_cache_entry *ce = NULL;
 	int error = 0;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 #define header(x) ((struct ext4_xattr_header *)(x))
 
 	if (i->value && i->value_len > sb->s_blocksize)
 		return -ENOSPC;
 	if (s->base) {
-		ce = mb_cache_entry_get(ext4_mb_cache, bs->bh->b_bdev,
-					bs->bh->b_blocknr);
 		BUFFER_TRACE(bs->bh, ""get_write_access"");
 		error = ext4_journal_get_write_access(handle, bs->bh);
 		if (error)
 			goto cleanup;
 		lock_buffer(bs->bh);
 
 		if (header(s->base)->h_refcount == cpu_to_le32(1)) {
-			if (ce) {
-				mb_cache_entry_free(ce);
-				ce = NULL;
-			}
+			__u32 hash = le32_to_cpu(BHDR(bs->bh)->h_hash);
+
+			/*
+			 * This must happen under buffer lock for
+			 * ext4_xattr_block_set() to reliably detect modified
+			 * block
+			 */
+			mb2_cache_entry_delete_block(ext4_mb_cache, hash,
+						     bs->bh->b_blocknr);
 			ea_bdebug(bs->bh, ""modifying in-place"");
 			error = ext4_xattr_set_entry(i, s);
 			if (!error) {
@@ -826,10 +830,6 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 			int offset = (char *)s->here - bs->bh->b_data;
 
 			unlock_buffer(bs->bh);
-			if (ce) {
-				mb_cache_entry_release(ce);
-				ce = NULL;
-			}
 			ea_bdebug(bs->bh, ""cloning"");
 			s->base = kmalloc(bs->bh->b_size, GFP_NOFS);
 			error = -ENOMEM;
@@ -884,6 +884,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 				if (error)
 					goto cleanup_dquot;
 				lock_buffer(new_bh);
+				/*
+				 * We have to be careful about races with
+				 * freeing or rehashing of xattr block. Once we
+				 * hold buffer lock xattr block's state is
+				 * stable so we can check whether the block got
+				 * freed / rehashed or not.  Since we unhash
+				 * mbcache entry under buffer lock when freeing
+				 * / rehashing xattr block, checking whether
+				 * entry is still hashed is reliable.
+				 */
+				if (hlist_bl_unhashed(&ce->e_hash_list)) {
+					/*
+					 * Undo everything and check mbcache
+					 * again.
+					 */
+					unlock_buffer(new_bh);
+					dquot_free_block(inode,
+							 EXT4_C2B(EXT4_SB(sb),
+								  1));
+					brelse(new_bh);
+					mb2_cache_entry_put(ext4_mb_cache, ce);
+					ce = NULL;
+					new_bh = NULL;
+					goto inserted;
+				}
 				le32_add_cpu(&BHDR(new_bh)->h_refcount, 1);
 				ea_bdebug(new_bh, ""reusing; refcount now=%d"",
 					le32_to_cpu(BHDR(new_bh)->h_refcount));
@@ -894,7 +919,8 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 				if (error)
 					goto cleanup_dquot;
 			}
-			mb_cache_entry_release(ce);
+			mb2_cache_entry_touch(ext4_mb_cache, ce);
+			mb2_cache_entry_put(ext4_mb_cache, ce);
 			ce = NULL;
 		} else if (bs->bh && s->base == bs->bh->b_data) {
 			/* We were modifying this block in-place. */
@@ -959,7 +985,7 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 
 cleanup:
 	if (ce)
-		mb_cache_entry_release(ce);
+		mb2_cache_entry_put(ext4_mb_cache, ce);
 	brelse(new_bh);
 	if (!(bs->bh && s->base == bs->bh->b_data))
 		kfree(s->base);
@@ -1511,17 +1537,6 @@ ext4_xattr_delete_inode(handle_t *handle, struct inode *inode)
 	brelse(bh);
 }
 
-/*
- * ext4_xattr_put_super()
- *
- * This is called when a file system is unmounted.
- */
-void
-ext4_xattr_put_super(struct super_block *sb)
-{
-	mb_cache_shrink(sb->s_bdev);
-}
-
 /*
  * ext4_xattr_cache_insert()
  *
@@ -1531,28 +1546,18 @@ ext4_xattr_put_super(struct super_block *sb)
  * Returns 0, or a negative error number on failure.
  */
 static void
-ext4_xattr_cache_insert(struct mb_cache *ext4_mb_cache, struct buffer_head *bh)
+ext4_xattr_cache_insert(struct mb2_cache *ext4_mb_cache, struct buffer_head *bh)
 {
 	__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);
-	struct mb_cache_entry *ce;
 	int error;
 
-	ce = mb_cache_entry_alloc(ext4_mb_cache, GFP_NOFS);
-	if (!ce) {
-		ea_bdebug(bh, ""out of memory"");
-		return;
-	}
-	error = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);
+	error = mb2_cache_entry_create(ext4_mb_cache, GFP_NOFS, hash,
+				       bh->b_blocknr);
 	if (error) {
-		mb_cache_entry_free(ce);
-		if (error == -EBUSY) {
+		if (error == -EBUSY)
 			ea_bdebug(bh, ""already in cache"");
-			error = 0;
-		}
-	} else {
+	} else
 		ea_bdebug(bh, ""inserting [%x]"", (int)hash);
-		mb_cache_entry_release(ce);
-	}
 }
 
 /*
@@ -1605,26 +1610,19 @@ ext4_xattr_cmp(struct ext4_xattr_header *header1,
  */
 static struct buffer_head *
 ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,
-		      struct mb_cache_entry **pce)
+		      struct mb2_cache_entry **pce)
 {
 	__u32 hash = le32_to_cpu(header->h_hash);
-	struct mb_cache_entry *ce;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache_entry *ce;
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	if (!header->h_hash)
 		return NULL;  /* never share */
 	ea_idebug(inode, ""looking for cached blocks [%x]"", (int)hash);
-again:
-	ce = mb_cache_entry_find_first(ext4_mb_cache, inode->i_sb->s_bdev,
-				       hash);
+	ce = mb2_cache_entry_find_first(ext4_mb_cache, hash);
 	while (ce) {
 		struct buffer_head *bh;
 
-		if (IS_ERR(ce)) {
-			if (PTR_ERR(ce) == -EAGAIN)
-				goto again;
-			break;
-		}
 		bh = sb_bread(inode->i_sb, ce->e_block);
 		if (!bh) {
 			EXT4_ERROR_INODE(inode, ""block %lu read error"",
@@ -1640,7 +1638,7 @@ ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,
 			return bh;
 		}
 		brelse(bh);
-		ce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);
+		ce = mb2_cache_entry_find_next(ext4_mb_cache, ce);
 	}
 	return NULL;
 }
@@ -1715,15 +1713,15 @@ static void ext4_xattr_rehash(struct ext4_xattr_header *header,
 
 #define	HASH_BUCKET_BITS	10
 
-struct mb_cache *
-ext4_xattr_create_cache(char *name)
+struct mb2_cache *
+ext4_xattr_create_cache(void)
 {
-	return mb_cache_create(name, HASH_BUCKET_BITS);
+	return mb2_cache_create(HASH_BUCKET_BITS);
 }
 
-void ext4_xattr_destroy_cache(struct mb_cache *cache)
+void ext4_xattr_destroy_cache(struct mb2_cache *cache)
 {
 	if (cache)
-		mb_cache_destroy(cache);
+		mb2_cache_destroy(cache);
 }
 ",linux,82939d7999dfc1f1998c4b1c12e2f19edbdff272,f9a61eb4e2471c56a63cd804c7474128138c38ac,1,"ext4_xattr_create_cache(char *name)
//fix_flaw_line_below:
//struct mb2_cache *
//fix_flaw_line_below:
//ext4_xattr_create_cache(void)
 {
//flaw_line_below:
	return mb_cache_create(name, HASH_BUCKET_BITS);
//fix_flaw_line_below:
//	return mb2_cache_create(HASH_BUCKET_BITS);
 }
"
5430,183166,,Local,Not required,Partial,CVE-2015-8952,https://www.cvedetails.com/cve/CVE-2015-8952/,CWE-19,Low,,,,2016-10-16,2.1,"The mbcache feature in the ext2 and ext4 filesystem implementations in the Linux kernel before 4.6 mishandles xattr block caching, which allows local users to cause a denial of service (soft lockup) via filesystem operations in environments that use many attributes, as demonstrated by Ceph and Samba.",2018-03-15,DoS ,2,https://github.com/torvalds/linux/commit/82939d7999dfc1f1998c4b1c12e2f19edbdff272,82939d7999dfc1f1998c4b1c12e2f19edbdff272,"ext4: convert to mbcache2

The conversion is generally straightforward. The only tricky part is
that xattr block corresponding to found mbcache entry can get freed
before we get buffer lock for that block. So we have to check whether
the entry is still valid after getting buffer lock.

Signed-off-by: Jan Kara <jack@suse.cz>
Signed-off-by: Theodore Ts'o <tytso@mit.edu>",1,fs/ext4/xattr.c,"{""sha"": ""9ac9e62569ef8fdf981021b58d37ab99d0150882"", ""filename"": ""fs/ext4/ext4.h"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 1, ""changes"": 2, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/ext4.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/ext4.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/ext4.h?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -1468,7 +1468,7 @@ struct ext4_sb_info {\n \tstruct list_head s_es_list;\t/* List of inodes with reclaimable extents */\n \tlong s_es_nr_inode;\n \tstruct ext4_es_stats s_es_stats;\n-\tstruct mb_cache *s_mb_cache;\n+\tstruct mb2_cache *s_mb_cache;\n \tspinlock_t s_es_lock ____cacheline_aligned_in_smp;\n \n \t/* Ratelimit ext4 messages. */""}<_**next**_>{""sha"": ""ecc37e1034358d769ab29971e9d2301fb9e2b3bc"", ""filename"": ""fs/ext4/super.c"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 2, ""changes"": 7, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/super.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/super.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/super.c?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -844,7 +844,6 @@ static void ext4_put_super(struct super_block *sb)\n \text4_release_system_zone(sb);\n \text4_mb_release(sb);\n \text4_ext_release(sb);\n-\text4_xattr_put_super(sb);\n \n \tif (!(sb->s_flags & MS_RDONLY)) {\n \t\text4_clear_feature_journal_needs_recovery(sb);\n@@ -3797,7 +3796,7 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n \n no_journal:\n \tif (ext4_mballoc_ready) {\n-\t\tsbi->s_mb_cache = ext4_xattr_create_cache(sb->s_id);\n+\t\tsbi->s_mb_cache = ext4_xattr_create_cache();\n \t\tif (!sbi->s_mb_cache) {\n \t\t\text4_msg(sb, KERN_ERR, \""Failed to create an mb_cache\"");\n \t\t\tgoto failed_mount_wq;\n@@ -4027,6 +4026,10 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n \tif (EXT4_SB(sb)->rsv_conversion_wq)\n \t\tdestroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);\n failed_mount_wq:\n+\tif (sbi->s_mb_cache) {\n+\t\text4_xattr_destroy_cache(sbi->s_mb_cache);\n+\t\tsbi->s_mb_cache = NULL;\n+\t}\n \tif (sbi->s_journal) {\n \t\tjbd2_journal_destroy(sbi->s_journal);\n \t\tsbi->s_journal = NULL;""}<_**next**_>{""sha"": ""fe9f8d6ab6c91b60689abadefd5435c31893fcae"", ""filename"": ""fs/ext4/xattr.c"", ""status"": ""modified"", ""additions"": 67, ""deletions"": 69, ""changes"": 136, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/xattr.c?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -53,7 +53,7 @@\n #include <linux/init.h>\n #include <linux/fs.h>\n #include <linux/slab.h>\n-#include <linux/mbcache.h>\n+#include <linux/mbcache2.h>\n #include <linux/quotaops.h>\n #include \""ext4_jbd2.h\""\n #include \""ext4.h\""\n@@ -78,10 +78,10 @@\n # define ea_bdebug(bh, fmt, ...)\tno_printk(fmt, ##__VA_ARGS__)\n #endif\n \n-static void ext4_xattr_cache_insert(struct mb_cache *, struct buffer_head *);\n+static void ext4_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);\n static struct buffer_head *ext4_xattr_cache_find(struct inode *,\n \t\t\t\t\t\t struct ext4_xattr_header *,\n-\t\t\t\t\t\t struct mb_cache_entry **);\n+\t\t\t\t\t\t struct mb2_cache_entry **);\n static void ext4_xattr_rehash(struct ext4_xattr_header *,\n \t\t\t      struct ext4_xattr_entry *);\n static int ext4_xattr_list(struct dentry *dentry, char *buffer,\n@@ -276,7 +276,7 @@ ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,\n \tstruct ext4_xattr_entry *entry;\n \tsize_t size;\n \tint error;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tea_idebug(inode, \""name=%d.%s, buffer=%p, buffer_size=%ld\"",\n \t\t  name_index, name, buffer, (long)buffer_size);\n@@ -428,7 +428,7 @@ ext4_xattr_block_list(struct dentry *dentry, char *buffer, size_t buffer_size)\n \tstruct inode *inode = d_inode(dentry);\n \tstruct buffer_head *bh = NULL;\n \tint error;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tea_idebug(inode, \""buffer=%p, buffer_size=%ld\"",\n \t\t  buffer, (long)buffer_size);\n@@ -545,30 +545,31 @@ static void\n ext4_xattr_release_block(handle_t *handle, struct inode *inode,\n \t\t\t struct buffer_head *bh)\n {\n-\tstruct mb_cache_entry *ce = NULL;\n \tint error = 0;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n-\tce = mb_cache_entry_get(ext4_mb_cache, bh->b_bdev, bh->b_blocknr);\n \tBUFFER_TRACE(bh, \""get_write_access\"");\n \terror = ext4_journal_get_write_access(handle, bh);\n \tif (error)\n \t\tgoto out;\n \n \tlock_buffer(bh);\n \tif (BHDR(bh)->h_refcount == cpu_to_le32(1)) {\n+\t\t__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);\n+\n \t\tea_bdebug(bh, \""refcount now=0; freeing\"");\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_free(ce);\n+\t\t/*\n+\t\t * This must happen under buffer lock for\n+\t\t * ext4_xattr_block_set() to reliably detect freed block\n+\t\t */\n+\t\tmb2_cache_entry_delete_block(EXT4_GET_MB_CACHE(inode), hash,\n+\t\t\t\t\t     bh->b_blocknr);\n \t\tget_bh(bh);\n \t\tunlock_buffer(bh);\n \t\text4_free_blocks(handle, inode, bh, 0, 1,\n \t\t\t\t EXT4_FREE_BLOCKS_METADATA |\n \t\t\t\t EXT4_FREE_BLOCKS_FORGET);\n \t} else {\n \t\tle32_add_cpu(&BHDR(bh)->h_refcount, -1);\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_release(ce);\n \t\t/*\n \t\t * Beware of this ugliness: Releasing of xattr block references\n \t\t * from different inodes can race and so we have to protect\n@@ -781,28 +782,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \tstruct super_block *sb = inode->i_sb;\n \tstruct buffer_head *new_bh = NULL;\n \tstruct ext4_xattr_search *s = &bs->s;\n-\tstruct mb_cache_entry *ce = NULL;\n+\tstruct mb2_cache_entry *ce = NULL;\n \tint error = 0;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n #define header(x) ((struct ext4_xattr_header *)(x))\n \n \tif (i->value && i->value_len > sb->s_blocksize)\n \t\treturn -ENOSPC;\n \tif (s->base) {\n-\t\tce = mb_cache_entry_get(ext4_mb_cache, bs->bh->b_bdev,\n-\t\t\t\t\tbs->bh->b_blocknr);\n \t\tBUFFER_TRACE(bs->bh, \""get_write_access\"");\n \t\terror = ext4_journal_get_write_access(handle, bs->bh);\n \t\tif (error)\n \t\t\tgoto cleanup;\n \t\tlock_buffer(bs->bh);\n \n \t\tif (header(s->base)->h_refcount == cpu_to_le32(1)) {\n-\t\t\tif (ce) {\n-\t\t\t\tmb_cache_entry_free(ce);\n-\t\t\t\tce = NULL;\n-\t\t\t}\n+\t\t\t__u32 hash = le32_to_cpu(BHDR(bs->bh)->h_hash);\n+\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext4_xattr_block_set() to reliably detect modified\n+\t\t\t * block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(ext4_mb_cache, hash,\n+\t\t\t\t\t\t     bs->bh->b_blocknr);\n \t\t\tea_bdebug(bs->bh, \""modifying in-place\"");\n \t\t\terror = ext4_xattr_set_entry(i, s);\n \t\t\tif (!error) {\n@@ -826,10 +830,6 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\tint offset = (char *)s->here - bs->bh->b_data;\n \n \t\t\tunlock_buffer(bs->bh);\n-\t\t\tif (ce) {\n-\t\t\t\tmb_cache_entry_release(ce);\n-\t\t\t\tce = NULL;\n-\t\t\t}\n \t\t\tea_bdebug(bs->bh, \""cloning\"");\n \t\t\ts->base = kmalloc(bs->bh->b_size, GFP_NOFS);\n \t\t\terror = -ENOMEM;\n@@ -884,6 +884,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\t\tif (error)\n \t\t\t\t\tgoto cleanup_dquot;\n \t\t\t\tlock_buffer(new_bh);\n+\t\t\t\t/*\n+\t\t\t\t * We have to be careful about races with\n+\t\t\t\t * freeing or rehashing of xattr block. Once we\n+\t\t\t\t * hold buffer lock xattr block's state is\n+\t\t\t\t * stable so we can check whether the block got\n+\t\t\t\t * freed / rehashed or not.  Since we unhash\n+\t\t\t\t * mbcache entry under buffer lock when freeing\n+\t\t\t\t * / rehashing xattr block, checking whether\n+\t\t\t\t * entry is still hashed is reliable.\n+\t\t\t\t */\n+\t\t\t\tif (hlist_bl_unhashed(&ce->e_hash_list)) {\n+\t\t\t\t\t/*\n+\t\t\t\t\t * Undo everything and check mbcache\n+\t\t\t\t\t * again.\n+\t\t\t\t\t */\n+\t\t\t\t\tunlock_buffer(new_bh);\n+\t\t\t\t\tdquot_free_block(inode,\n+\t\t\t\t\t\t\t EXT4_C2B(EXT4_SB(sb),\n+\t\t\t\t\t\t\t\t  1));\n+\t\t\t\t\tbrelse(new_bh);\n+\t\t\t\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n+\t\t\t\t\tce = NULL;\n+\t\t\t\t\tnew_bh = NULL;\n+\t\t\t\t\tgoto inserted;\n+\t\t\t\t}\n \t\t\t\tle32_add_cpu(&BHDR(new_bh)->h_refcount, 1);\n \t\t\t\tea_bdebug(new_bh, \""reusing; refcount now=%d\"",\n \t\t\t\t\tle32_to_cpu(BHDR(new_bh)->h_refcount));\n@@ -894,7 +919,8 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\t\tif (error)\n \t\t\t\t\tgoto cleanup_dquot;\n \t\t\t}\n-\t\t\tmb_cache_entry_release(ce);\n+\t\t\tmb2_cache_entry_touch(ext4_mb_cache, ce);\n+\t\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n \t\t\tce = NULL;\n \t\t} else if (bs->bh && s->base == bs->bh->b_data) {\n \t\t\t/* We were modifying this block in-place. */\n@@ -959,7 +985,7 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \n cleanup:\n \tif (ce)\n-\t\tmb_cache_entry_release(ce);\n+\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n \tbrelse(new_bh);\n \tif (!(bs->bh && s->base == bs->bh->b_data))\n \t\tkfree(s->base);\n@@ -1511,17 +1537,6 @@ ext4_xattr_delete_inode(handle_t *handle, struct inode *inode)\n \tbrelse(bh);\n }\n \n-/*\n- * ext4_xattr_put_super()\n- *\n- * This is called when a file system is unmounted.\n- */\n-void\n-ext4_xattr_put_super(struct super_block *sb)\n-{\n-\tmb_cache_shrink(sb->s_bdev);\n-}\n-\n /*\n  * ext4_xattr_cache_insert()\n  *\n@@ -1531,28 +1546,18 @@ ext4_xattr_put_super(struct super_block *sb)\n  * Returns 0, or a negative error number on failure.\n  */\n static void\n-ext4_xattr_cache_insert(struct mb_cache *ext4_mb_cache, struct buffer_head *bh)\n+ext4_xattr_cache_insert(struct mb2_cache *ext4_mb_cache, struct buffer_head *bh)\n {\n \t__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);\n-\tstruct mb_cache_entry *ce;\n \tint error;\n \n-\tce = mb_cache_entry_alloc(ext4_mb_cache, GFP_NOFS);\n-\tif (!ce) {\n-\t\tea_bdebug(bh, \""out of memory\"");\n-\t\treturn;\n-\t}\n-\terror = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);\n+\terror = mb2_cache_entry_create(ext4_mb_cache, GFP_NOFS, hash,\n+\t\t\t\t       bh->b_blocknr);\n \tif (error) {\n-\t\tmb_cache_entry_free(ce);\n-\t\tif (error == -EBUSY) {\n+\t\tif (error == -EBUSY)\n \t\t\tea_bdebug(bh, \""already in cache\"");\n-\t\t\terror = 0;\n-\t\t}\n-\t} else {\n+\t} else\n \t\tea_bdebug(bh, \""inserting [%x]\"", (int)hash);\n-\t\tmb_cache_entry_release(ce);\n-\t}\n }\n \n /*\n@@ -1605,26 +1610,19 @@ ext4_xattr_cmp(struct ext4_xattr_header *header1,\n  */\n static struct buffer_head *\n ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,\n-\t\t      struct mb_cache_entry **pce)\n+\t\t      struct mb2_cache_entry **pce)\n {\n \t__u32 hash = le32_to_cpu(header->h_hash);\n-\tstruct mb_cache_entry *ce;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache_entry *ce;\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tif (!header->h_hash)\n \t\treturn NULL;  /* never share */\n \tea_idebug(inode, \""looking for cached blocks [%x]\"", (int)hash);\n-again:\n-\tce = mb_cache_entry_find_first(ext4_mb_cache, inode->i_sb->s_bdev,\n-\t\t\t\t       hash);\n+\tce = mb2_cache_entry_find_first(ext4_mb_cache, hash);\n \twhile (ce) {\n \t\tstruct buffer_head *bh;\n \n-\t\tif (IS_ERR(ce)) {\n-\t\t\tif (PTR_ERR(ce) == -EAGAIN)\n-\t\t\t\tgoto again;\n-\t\t\tbreak;\n-\t\t}\n \t\tbh = sb_bread(inode->i_sb, ce->e_block);\n \t\tif (!bh) {\n \t\t\tEXT4_ERROR_INODE(inode, \""block %lu read error\"",\n@@ -1640,7 +1638,7 @@ ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,\n \t\t\treturn bh;\n \t\t}\n \t\tbrelse(bh);\n-\t\tce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);\n+\t\tce = mb2_cache_entry_find_next(ext4_mb_cache, ce);\n \t}\n \treturn NULL;\n }\n@@ -1715,15 +1713,15 @@ static void ext4_xattr_rehash(struct ext4_xattr_header *header,\n \n #define\tHASH_BUCKET_BITS\t10\n \n-struct mb_cache *\n-ext4_xattr_create_cache(char *name)\n+struct mb2_cache *\n+ext4_xattr_create_cache(void)\n {\n-\treturn mb_cache_create(name, HASH_BUCKET_BITS);\n+\treturn mb2_cache_create(HASH_BUCKET_BITS);\n }\n \n-void ext4_xattr_destroy_cache(struct mb_cache *cache)\n+void ext4_xattr_destroy_cache(struct mb2_cache *cache)\n {\n \tif (cache)\n-\t\tmb_cache_destroy(cache);\n+\t\tmb2_cache_destroy(cache);\n }\n ""}<_**next**_>{""sha"": ""10b0f7323ed6fcd628efee26998d0f1be7652c48"", ""filename"": ""fs/ext4/xattr.h"", ""status"": ""modified"", ""additions"": 2, ""deletions"": 3, ""changes"": 5, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/xattr.h?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -108,7 +108,6 @@ extern int ext4_xattr_set(struct inode *, int, const char *, const void *, size_\n extern int ext4_xattr_set_handle(handle_t *, struct inode *, int, const char *, const void *, size_t, int);\n \n extern void ext4_xattr_delete_inode(handle_t *, struct inode *);\n-extern void ext4_xattr_put_super(struct super_block *);\n \n extern int ext4_expand_extra_isize_ea(struct inode *inode, int new_extra_isize,\n \t\t\t    struct ext4_inode *raw_inode, handle_t *handle);\n@@ -124,8 +123,8 @@ extern int ext4_xattr_ibody_inline_set(handle_t *handle, struct inode *inode,\n \t\t\t\t       struct ext4_xattr_info *i,\n \t\t\t\t       struct ext4_xattr_ibody_find *is);\n \n-extern struct mb_cache *ext4_xattr_create_cache(char *name);\n-extern void ext4_xattr_destroy_cache(struct mb_cache *);\n+extern struct mb2_cache *ext4_xattr_create_cache(void);\n+extern void ext4_xattr_destroy_cache(struct mb2_cache *);\n \n #ifdef CONFIG_EXT4_FS_SECURITY\n extern int ext4_init_security(handle_t *handle, struct inode *inode,""}","void ext4_xattr_destroy_cache(struct mb_cache *cache)
void ext4_xattr_destroy_cache(struct mb2_cache *cache)
 {
 	if (cache)
		mb2_cache_destroy(cache);
 }
","void ext4_xattr_destroy_cache(struct mb_cache *cache)
 {
 	if (cache)
		mb_cache_destroy(cache);
 }
",C,"void ext4_xattr_destroy_cache(struct mb2_cache *cache)
		mb2_cache_destroy(cache);
","		mb_cache_destroy(cache);
",,"@@ -53,7 +53,7 @@
 #include <linux/init.h>
 #include <linux/fs.h>
 #include <linux/slab.h>
-#include <linux/mbcache.h>
+#include <linux/mbcache2.h>
 #include <linux/quotaops.h>
 #include ""ext4_jbd2.h""
 #include ""ext4.h""
@@ -78,10 +78,10 @@
 # define ea_bdebug(bh, fmt, ...)	no_printk(fmt, ##__VA_ARGS__)
 #endif
 
-static void ext4_xattr_cache_insert(struct mb_cache *, struct buffer_head *);
+static void ext4_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);
 static struct buffer_head *ext4_xattr_cache_find(struct inode *,
 						 struct ext4_xattr_header *,
-						 struct mb_cache_entry **);
+						 struct mb2_cache_entry **);
 static void ext4_xattr_rehash(struct ext4_xattr_header *,
 			      struct ext4_xattr_entry *);
 static int ext4_xattr_list(struct dentry *dentry, char *buffer,
@@ -276,7 +276,7 @@ ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,
 	struct ext4_xattr_entry *entry;
 	size_t size;
 	int error;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	ea_idebug(inode, ""name=%d.%s, buffer=%p, buffer_size=%ld"",
 		  name_index, name, buffer, (long)buffer_size);
@@ -428,7 +428,7 @@ ext4_xattr_block_list(struct dentry *dentry, char *buffer, size_t buffer_size)
 	struct inode *inode = d_inode(dentry);
 	struct buffer_head *bh = NULL;
 	int error;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	ea_idebug(inode, ""buffer=%p, buffer_size=%ld"",
 		  buffer, (long)buffer_size);
@@ -545,30 +545,31 @@ static void
 ext4_xattr_release_block(handle_t *handle, struct inode *inode,
 			 struct buffer_head *bh)
 {
-	struct mb_cache_entry *ce = NULL;
 	int error = 0;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
-	ce = mb_cache_entry_get(ext4_mb_cache, bh->b_bdev, bh->b_blocknr);
 	BUFFER_TRACE(bh, ""get_write_access"");
 	error = ext4_journal_get_write_access(handle, bh);
 	if (error)
 		goto out;
 
 	lock_buffer(bh);
 	if (BHDR(bh)->h_refcount == cpu_to_le32(1)) {
+		__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);
+
 		ea_bdebug(bh, ""refcount now=0; freeing"");
-		if (ce)
-			mb_cache_entry_free(ce);
+		/*
+		 * This must happen under buffer lock for
+		 * ext4_xattr_block_set() to reliably detect freed block
+		 */
+		mb2_cache_entry_delete_block(EXT4_GET_MB_CACHE(inode), hash,
+					     bh->b_blocknr);
 		get_bh(bh);
 		unlock_buffer(bh);
 		ext4_free_blocks(handle, inode, bh, 0, 1,
 				 EXT4_FREE_BLOCKS_METADATA |
 				 EXT4_FREE_BLOCKS_FORGET);
 	} else {
 		le32_add_cpu(&BHDR(bh)->h_refcount, -1);
-		if (ce)
-			mb_cache_entry_release(ce);
 		/*
 		 * Beware of this ugliness: Releasing of xattr block references
 		 * from different inodes can race and so we have to protect
@@ -781,28 +782,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *new_bh = NULL;
 	struct ext4_xattr_search *s = &bs->s;
-	struct mb_cache_entry *ce = NULL;
+	struct mb2_cache_entry *ce = NULL;
 	int error = 0;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 #define header(x) ((struct ext4_xattr_header *)(x))
 
 	if (i->value && i->value_len > sb->s_blocksize)
 		return -ENOSPC;
 	if (s->base) {
-		ce = mb_cache_entry_get(ext4_mb_cache, bs->bh->b_bdev,
-					bs->bh->b_blocknr);
 		BUFFER_TRACE(bs->bh, ""get_write_access"");
 		error = ext4_journal_get_write_access(handle, bs->bh);
 		if (error)
 			goto cleanup;
 		lock_buffer(bs->bh);
 
 		if (header(s->base)->h_refcount == cpu_to_le32(1)) {
-			if (ce) {
-				mb_cache_entry_free(ce);
-				ce = NULL;
-			}
+			__u32 hash = le32_to_cpu(BHDR(bs->bh)->h_hash);
+
+			/*
+			 * This must happen under buffer lock for
+			 * ext4_xattr_block_set() to reliably detect modified
+			 * block
+			 */
+			mb2_cache_entry_delete_block(ext4_mb_cache, hash,
+						     bs->bh->b_blocknr);
 			ea_bdebug(bs->bh, ""modifying in-place"");
 			error = ext4_xattr_set_entry(i, s);
 			if (!error) {
@@ -826,10 +830,6 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 			int offset = (char *)s->here - bs->bh->b_data;
 
 			unlock_buffer(bs->bh);
-			if (ce) {
-				mb_cache_entry_release(ce);
-				ce = NULL;
-			}
 			ea_bdebug(bs->bh, ""cloning"");
 			s->base = kmalloc(bs->bh->b_size, GFP_NOFS);
 			error = -ENOMEM;
@@ -884,6 +884,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 				if (error)
 					goto cleanup_dquot;
 				lock_buffer(new_bh);
+				/*
+				 * We have to be careful about races with
+				 * freeing or rehashing of xattr block. Once we
+				 * hold buffer lock xattr block's state is
+				 * stable so we can check whether the block got
+				 * freed / rehashed or not.  Since we unhash
+				 * mbcache entry under buffer lock when freeing
+				 * / rehashing xattr block, checking whether
+				 * entry is still hashed is reliable.
+				 */
+				if (hlist_bl_unhashed(&ce->e_hash_list)) {
+					/*
+					 * Undo everything and check mbcache
+					 * again.
+					 */
+					unlock_buffer(new_bh);
+					dquot_free_block(inode,
+							 EXT4_C2B(EXT4_SB(sb),
+								  1));
+					brelse(new_bh);
+					mb2_cache_entry_put(ext4_mb_cache, ce);
+					ce = NULL;
+					new_bh = NULL;
+					goto inserted;
+				}
 				le32_add_cpu(&BHDR(new_bh)->h_refcount, 1);
 				ea_bdebug(new_bh, ""reusing; refcount now=%d"",
 					le32_to_cpu(BHDR(new_bh)->h_refcount));
@@ -894,7 +919,8 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 				if (error)
 					goto cleanup_dquot;
 			}
-			mb_cache_entry_release(ce);
+			mb2_cache_entry_touch(ext4_mb_cache, ce);
+			mb2_cache_entry_put(ext4_mb_cache, ce);
 			ce = NULL;
 		} else if (bs->bh && s->base == bs->bh->b_data) {
 			/* We were modifying this block in-place. */
@@ -959,7 +985,7 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 
 cleanup:
 	if (ce)
-		mb_cache_entry_release(ce);
+		mb2_cache_entry_put(ext4_mb_cache, ce);
 	brelse(new_bh);
 	if (!(bs->bh && s->base == bs->bh->b_data))
 		kfree(s->base);
@@ -1511,17 +1537,6 @@ ext4_xattr_delete_inode(handle_t *handle, struct inode *inode)
 	brelse(bh);
 }
 
-/*
- * ext4_xattr_put_super()
- *
- * This is called when a file system is unmounted.
- */
-void
-ext4_xattr_put_super(struct super_block *sb)
-{
-	mb_cache_shrink(sb->s_bdev);
-}
-
 /*
  * ext4_xattr_cache_insert()
  *
@@ -1531,28 +1546,18 @@ ext4_xattr_put_super(struct super_block *sb)
  * Returns 0, or a negative error number on failure.
  */
 static void
-ext4_xattr_cache_insert(struct mb_cache *ext4_mb_cache, struct buffer_head *bh)
+ext4_xattr_cache_insert(struct mb2_cache *ext4_mb_cache, struct buffer_head *bh)
 {
 	__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);
-	struct mb_cache_entry *ce;
 	int error;
 
-	ce = mb_cache_entry_alloc(ext4_mb_cache, GFP_NOFS);
-	if (!ce) {
-		ea_bdebug(bh, ""out of memory"");
-		return;
-	}
-	error = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);
+	error = mb2_cache_entry_create(ext4_mb_cache, GFP_NOFS, hash,
+				       bh->b_blocknr);
 	if (error) {
-		mb_cache_entry_free(ce);
-		if (error == -EBUSY) {
+		if (error == -EBUSY)
 			ea_bdebug(bh, ""already in cache"");
-			error = 0;
-		}
-	} else {
+	} else
 		ea_bdebug(bh, ""inserting [%x]"", (int)hash);
-		mb_cache_entry_release(ce);
-	}
 }
 
 /*
@@ -1605,26 +1610,19 @@ ext4_xattr_cmp(struct ext4_xattr_header *header1,
  */
 static struct buffer_head *
 ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,
-		      struct mb_cache_entry **pce)
+		      struct mb2_cache_entry **pce)
 {
 	__u32 hash = le32_to_cpu(header->h_hash);
-	struct mb_cache_entry *ce;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache_entry *ce;
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	if (!header->h_hash)
 		return NULL;  /* never share */
 	ea_idebug(inode, ""looking for cached blocks [%x]"", (int)hash);
-again:
-	ce = mb_cache_entry_find_first(ext4_mb_cache, inode->i_sb->s_bdev,
-				       hash);
+	ce = mb2_cache_entry_find_first(ext4_mb_cache, hash);
 	while (ce) {
 		struct buffer_head *bh;
 
-		if (IS_ERR(ce)) {
-			if (PTR_ERR(ce) == -EAGAIN)
-				goto again;
-			break;
-		}
 		bh = sb_bread(inode->i_sb, ce->e_block);
 		if (!bh) {
 			EXT4_ERROR_INODE(inode, ""block %lu read error"",
@@ -1640,7 +1638,7 @@ ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,
 			return bh;
 		}
 		brelse(bh);
-		ce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);
+		ce = mb2_cache_entry_find_next(ext4_mb_cache, ce);
 	}
 	return NULL;
 }
@@ -1715,15 +1713,15 @@ static void ext4_xattr_rehash(struct ext4_xattr_header *header,
 
 #define	HASH_BUCKET_BITS	10
 
-struct mb_cache *
-ext4_xattr_create_cache(char *name)
+struct mb2_cache *
+ext4_xattr_create_cache(void)
 {
-	return mb_cache_create(name, HASH_BUCKET_BITS);
+	return mb2_cache_create(HASH_BUCKET_BITS);
 }
 
-void ext4_xattr_destroy_cache(struct mb_cache *cache)
+void ext4_xattr_destroy_cache(struct mb2_cache *cache)
 {
 	if (cache)
-		mb_cache_destroy(cache);
+		mb2_cache_destroy(cache);
 }
 ",linux,82939d7999dfc1f1998c4b1c12e2f19edbdff272,f9a61eb4e2471c56a63cd804c7474128138c38ac,1,"void ext4_xattr_destroy_cache(struct mb_cache *cache)
//fix_flaw_line_below:
//void ext4_xattr_destroy_cache(struct mb2_cache *cache)
 {
 	if (cache)
//flaw_line_below:
		mb_cache_destroy(cache);
//fix_flaw_line_below:
//		mb2_cache_destroy(cache);
 }
"
5431,183167,,Local,Not required,Partial,CVE-2015-8952,https://www.cvedetails.com/cve/CVE-2015-8952/,CWE-19,Low,,,,2016-10-16,2.1,"The mbcache feature in the ext2 and ext4 filesystem implementations in the Linux kernel before 4.6 mishandles xattr block caching, which allows local users to cause a denial of service (soft lockup) via filesystem operations in environments that use many attributes, as demonstrated by Ceph and Samba.",2018-03-15,DoS ,0,https://github.com/torvalds/linux/commit/82939d7999dfc1f1998c4b1c12e2f19edbdff272,82939d7999dfc1f1998c4b1c12e2f19edbdff272,"ext4: convert to mbcache2

The conversion is generally straightforward. The only tricky part is
that xattr block corresponding to found mbcache entry can get freed
before we get buffer lock for that block. So we have to check whether
the entry is still valid after getting buffer lock.

Signed-off-by: Jan Kara <jack@suse.cz>
Signed-off-by: Theodore Ts'o <tytso@mit.edu>",3,fs/ext4/xattr.c,"{""sha"": ""9ac9e62569ef8fdf981021b58d37ab99d0150882"", ""filename"": ""fs/ext4/ext4.h"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 1, ""changes"": 2, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/ext4.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/ext4.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/ext4.h?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -1468,7 +1468,7 @@ struct ext4_sb_info {\n \tstruct list_head s_es_list;\t/* List of inodes with reclaimable extents */\n \tlong s_es_nr_inode;\n \tstruct ext4_es_stats s_es_stats;\n-\tstruct mb_cache *s_mb_cache;\n+\tstruct mb2_cache *s_mb_cache;\n \tspinlock_t s_es_lock ____cacheline_aligned_in_smp;\n \n \t/* Ratelimit ext4 messages. */""}<_**next**_>{""sha"": ""ecc37e1034358d769ab29971e9d2301fb9e2b3bc"", ""filename"": ""fs/ext4/super.c"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 2, ""changes"": 7, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/super.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/super.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/super.c?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -844,7 +844,6 @@ static void ext4_put_super(struct super_block *sb)\n \text4_release_system_zone(sb);\n \text4_mb_release(sb);\n \text4_ext_release(sb);\n-\text4_xattr_put_super(sb);\n \n \tif (!(sb->s_flags & MS_RDONLY)) {\n \t\text4_clear_feature_journal_needs_recovery(sb);\n@@ -3797,7 +3796,7 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n \n no_journal:\n \tif (ext4_mballoc_ready) {\n-\t\tsbi->s_mb_cache = ext4_xattr_create_cache(sb->s_id);\n+\t\tsbi->s_mb_cache = ext4_xattr_create_cache();\n \t\tif (!sbi->s_mb_cache) {\n \t\t\text4_msg(sb, KERN_ERR, \""Failed to create an mb_cache\"");\n \t\t\tgoto failed_mount_wq;\n@@ -4027,6 +4026,10 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n \tif (EXT4_SB(sb)->rsv_conversion_wq)\n \t\tdestroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);\n failed_mount_wq:\n+\tif (sbi->s_mb_cache) {\n+\t\text4_xattr_destroy_cache(sbi->s_mb_cache);\n+\t\tsbi->s_mb_cache = NULL;\n+\t}\n \tif (sbi->s_journal) {\n \t\tjbd2_journal_destroy(sbi->s_journal);\n \t\tsbi->s_journal = NULL;""}<_**next**_>{""sha"": ""fe9f8d6ab6c91b60689abadefd5435c31893fcae"", ""filename"": ""fs/ext4/xattr.c"", ""status"": ""modified"", ""additions"": 67, ""deletions"": 69, ""changes"": 136, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/xattr.c?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -53,7 +53,7 @@\n #include <linux/init.h>\n #include <linux/fs.h>\n #include <linux/slab.h>\n-#include <linux/mbcache.h>\n+#include <linux/mbcache2.h>\n #include <linux/quotaops.h>\n #include \""ext4_jbd2.h\""\n #include \""ext4.h\""\n@@ -78,10 +78,10 @@\n # define ea_bdebug(bh, fmt, ...)\tno_printk(fmt, ##__VA_ARGS__)\n #endif\n \n-static void ext4_xattr_cache_insert(struct mb_cache *, struct buffer_head *);\n+static void ext4_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);\n static struct buffer_head *ext4_xattr_cache_find(struct inode *,\n \t\t\t\t\t\t struct ext4_xattr_header *,\n-\t\t\t\t\t\t struct mb_cache_entry **);\n+\t\t\t\t\t\t struct mb2_cache_entry **);\n static void ext4_xattr_rehash(struct ext4_xattr_header *,\n \t\t\t      struct ext4_xattr_entry *);\n static int ext4_xattr_list(struct dentry *dentry, char *buffer,\n@@ -276,7 +276,7 @@ ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,\n \tstruct ext4_xattr_entry *entry;\n \tsize_t size;\n \tint error;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tea_idebug(inode, \""name=%d.%s, buffer=%p, buffer_size=%ld\"",\n \t\t  name_index, name, buffer, (long)buffer_size);\n@@ -428,7 +428,7 @@ ext4_xattr_block_list(struct dentry *dentry, char *buffer, size_t buffer_size)\n \tstruct inode *inode = d_inode(dentry);\n \tstruct buffer_head *bh = NULL;\n \tint error;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tea_idebug(inode, \""buffer=%p, buffer_size=%ld\"",\n \t\t  buffer, (long)buffer_size);\n@@ -545,30 +545,31 @@ static void\n ext4_xattr_release_block(handle_t *handle, struct inode *inode,\n \t\t\t struct buffer_head *bh)\n {\n-\tstruct mb_cache_entry *ce = NULL;\n \tint error = 0;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n-\tce = mb_cache_entry_get(ext4_mb_cache, bh->b_bdev, bh->b_blocknr);\n \tBUFFER_TRACE(bh, \""get_write_access\"");\n \terror = ext4_journal_get_write_access(handle, bh);\n \tif (error)\n \t\tgoto out;\n \n \tlock_buffer(bh);\n \tif (BHDR(bh)->h_refcount == cpu_to_le32(1)) {\n+\t\t__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);\n+\n \t\tea_bdebug(bh, \""refcount now=0; freeing\"");\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_free(ce);\n+\t\t/*\n+\t\t * This must happen under buffer lock for\n+\t\t * ext4_xattr_block_set() to reliably detect freed block\n+\t\t */\n+\t\tmb2_cache_entry_delete_block(EXT4_GET_MB_CACHE(inode), hash,\n+\t\t\t\t\t     bh->b_blocknr);\n \t\tget_bh(bh);\n \t\tunlock_buffer(bh);\n \t\text4_free_blocks(handle, inode, bh, 0, 1,\n \t\t\t\t EXT4_FREE_BLOCKS_METADATA |\n \t\t\t\t EXT4_FREE_BLOCKS_FORGET);\n \t} else {\n \t\tle32_add_cpu(&BHDR(bh)->h_refcount, -1);\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_release(ce);\n \t\t/*\n \t\t * Beware of this ugliness: Releasing of xattr block references\n \t\t * from different inodes can race and so we have to protect\n@@ -781,28 +782,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \tstruct super_block *sb = inode->i_sb;\n \tstruct buffer_head *new_bh = NULL;\n \tstruct ext4_xattr_search *s = &bs->s;\n-\tstruct mb_cache_entry *ce = NULL;\n+\tstruct mb2_cache_entry *ce = NULL;\n \tint error = 0;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n #define header(x) ((struct ext4_xattr_header *)(x))\n \n \tif (i->value && i->value_len > sb->s_blocksize)\n \t\treturn -ENOSPC;\n \tif (s->base) {\n-\t\tce = mb_cache_entry_get(ext4_mb_cache, bs->bh->b_bdev,\n-\t\t\t\t\tbs->bh->b_blocknr);\n \t\tBUFFER_TRACE(bs->bh, \""get_write_access\"");\n \t\terror = ext4_journal_get_write_access(handle, bs->bh);\n \t\tif (error)\n \t\t\tgoto cleanup;\n \t\tlock_buffer(bs->bh);\n \n \t\tif (header(s->base)->h_refcount == cpu_to_le32(1)) {\n-\t\t\tif (ce) {\n-\t\t\t\tmb_cache_entry_free(ce);\n-\t\t\t\tce = NULL;\n-\t\t\t}\n+\t\t\t__u32 hash = le32_to_cpu(BHDR(bs->bh)->h_hash);\n+\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext4_xattr_block_set() to reliably detect modified\n+\t\t\t * block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(ext4_mb_cache, hash,\n+\t\t\t\t\t\t     bs->bh->b_blocknr);\n \t\t\tea_bdebug(bs->bh, \""modifying in-place\"");\n \t\t\terror = ext4_xattr_set_entry(i, s);\n \t\t\tif (!error) {\n@@ -826,10 +830,6 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\tint offset = (char *)s->here - bs->bh->b_data;\n \n \t\t\tunlock_buffer(bs->bh);\n-\t\t\tif (ce) {\n-\t\t\t\tmb_cache_entry_release(ce);\n-\t\t\t\tce = NULL;\n-\t\t\t}\n \t\t\tea_bdebug(bs->bh, \""cloning\"");\n \t\t\ts->base = kmalloc(bs->bh->b_size, GFP_NOFS);\n \t\t\terror = -ENOMEM;\n@@ -884,6 +884,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\t\tif (error)\n \t\t\t\t\tgoto cleanup_dquot;\n \t\t\t\tlock_buffer(new_bh);\n+\t\t\t\t/*\n+\t\t\t\t * We have to be careful about races with\n+\t\t\t\t * freeing or rehashing of xattr block. Once we\n+\t\t\t\t * hold buffer lock xattr block's state is\n+\t\t\t\t * stable so we can check whether the block got\n+\t\t\t\t * freed / rehashed or not.  Since we unhash\n+\t\t\t\t * mbcache entry under buffer lock when freeing\n+\t\t\t\t * / rehashing xattr block, checking whether\n+\t\t\t\t * entry is still hashed is reliable.\n+\t\t\t\t */\n+\t\t\t\tif (hlist_bl_unhashed(&ce->e_hash_list)) {\n+\t\t\t\t\t/*\n+\t\t\t\t\t * Undo everything and check mbcache\n+\t\t\t\t\t * again.\n+\t\t\t\t\t */\n+\t\t\t\t\tunlock_buffer(new_bh);\n+\t\t\t\t\tdquot_free_block(inode,\n+\t\t\t\t\t\t\t EXT4_C2B(EXT4_SB(sb),\n+\t\t\t\t\t\t\t\t  1));\n+\t\t\t\t\tbrelse(new_bh);\n+\t\t\t\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n+\t\t\t\t\tce = NULL;\n+\t\t\t\t\tnew_bh = NULL;\n+\t\t\t\t\tgoto inserted;\n+\t\t\t\t}\n \t\t\t\tle32_add_cpu(&BHDR(new_bh)->h_refcount, 1);\n \t\t\t\tea_bdebug(new_bh, \""reusing; refcount now=%d\"",\n \t\t\t\t\tle32_to_cpu(BHDR(new_bh)->h_refcount));\n@@ -894,7 +919,8 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\t\tif (error)\n \t\t\t\t\tgoto cleanup_dquot;\n \t\t\t}\n-\t\t\tmb_cache_entry_release(ce);\n+\t\t\tmb2_cache_entry_touch(ext4_mb_cache, ce);\n+\t\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n \t\t\tce = NULL;\n \t\t} else if (bs->bh && s->base == bs->bh->b_data) {\n \t\t\t/* We were modifying this block in-place. */\n@@ -959,7 +985,7 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \n cleanup:\n \tif (ce)\n-\t\tmb_cache_entry_release(ce);\n+\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n \tbrelse(new_bh);\n \tif (!(bs->bh && s->base == bs->bh->b_data))\n \t\tkfree(s->base);\n@@ -1511,17 +1537,6 @@ ext4_xattr_delete_inode(handle_t *handle, struct inode *inode)\n \tbrelse(bh);\n }\n \n-/*\n- * ext4_xattr_put_super()\n- *\n- * This is called when a file system is unmounted.\n- */\n-void\n-ext4_xattr_put_super(struct super_block *sb)\n-{\n-\tmb_cache_shrink(sb->s_bdev);\n-}\n-\n /*\n  * ext4_xattr_cache_insert()\n  *\n@@ -1531,28 +1546,18 @@ ext4_xattr_put_super(struct super_block *sb)\n  * Returns 0, or a negative error number on failure.\n  */\n static void\n-ext4_xattr_cache_insert(struct mb_cache *ext4_mb_cache, struct buffer_head *bh)\n+ext4_xattr_cache_insert(struct mb2_cache *ext4_mb_cache, struct buffer_head *bh)\n {\n \t__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);\n-\tstruct mb_cache_entry *ce;\n \tint error;\n \n-\tce = mb_cache_entry_alloc(ext4_mb_cache, GFP_NOFS);\n-\tif (!ce) {\n-\t\tea_bdebug(bh, \""out of memory\"");\n-\t\treturn;\n-\t}\n-\terror = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);\n+\terror = mb2_cache_entry_create(ext4_mb_cache, GFP_NOFS, hash,\n+\t\t\t\t       bh->b_blocknr);\n \tif (error) {\n-\t\tmb_cache_entry_free(ce);\n-\t\tif (error == -EBUSY) {\n+\t\tif (error == -EBUSY)\n \t\t\tea_bdebug(bh, \""already in cache\"");\n-\t\t\terror = 0;\n-\t\t}\n-\t} else {\n+\t} else\n \t\tea_bdebug(bh, \""inserting [%x]\"", (int)hash);\n-\t\tmb_cache_entry_release(ce);\n-\t}\n }\n \n /*\n@@ -1605,26 +1610,19 @@ ext4_xattr_cmp(struct ext4_xattr_header *header1,\n  */\n static struct buffer_head *\n ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,\n-\t\t      struct mb_cache_entry **pce)\n+\t\t      struct mb2_cache_entry **pce)\n {\n \t__u32 hash = le32_to_cpu(header->h_hash);\n-\tstruct mb_cache_entry *ce;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache_entry *ce;\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tif (!header->h_hash)\n \t\treturn NULL;  /* never share */\n \tea_idebug(inode, \""looking for cached blocks [%x]\"", (int)hash);\n-again:\n-\tce = mb_cache_entry_find_first(ext4_mb_cache, inode->i_sb->s_bdev,\n-\t\t\t\t       hash);\n+\tce = mb2_cache_entry_find_first(ext4_mb_cache, hash);\n \twhile (ce) {\n \t\tstruct buffer_head *bh;\n \n-\t\tif (IS_ERR(ce)) {\n-\t\t\tif (PTR_ERR(ce) == -EAGAIN)\n-\t\t\t\tgoto again;\n-\t\t\tbreak;\n-\t\t}\n \t\tbh = sb_bread(inode->i_sb, ce->e_block);\n \t\tif (!bh) {\n \t\t\tEXT4_ERROR_INODE(inode, \""block %lu read error\"",\n@@ -1640,7 +1638,7 @@ ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,\n \t\t\treturn bh;\n \t\t}\n \t\tbrelse(bh);\n-\t\tce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);\n+\t\tce = mb2_cache_entry_find_next(ext4_mb_cache, ce);\n \t}\n \treturn NULL;\n }\n@@ -1715,15 +1713,15 @@ static void ext4_xattr_rehash(struct ext4_xattr_header *header,\n \n #define\tHASH_BUCKET_BITS\t10\n \n-struct mb_cache *\n-ext4_xattr_create_cache(char *name)\n+struct mb2_cache *\n+ext4_xattr_create_cache(void)\n {\n-\treturn mb_cache_create(name, HASH_BUCKET_BITS);\n+\treturn mb2_cache_create(HASH_BUCKET_BITS);\n }\n \n-void ext4_xattr_destroy_cache(struct mb_cache *cache)\n+void ext4_xattr_destroy_cache(struct mb2_cache *cache)\n {\n \tif (cache)\n-\t\tmb_cache_destroy(cache);\n+\t\tmb2_cache_destroy(cache);\n }\n ""}<_**next**_>{""sha"": ""10b0f7323ed6fcd628efee26998d0f1be7652c48"", ""filename"": ""fs/ext4/xattr.h"", ""status"": ""modified"", ""additions"": 2, ""deletions"": 3, ""changes"": 5, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/xattr.h?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -108,7 +108,6 @@ extern int ext4_xattr_set(struct inode *, int, const char *, const void *, size_\n extern int ext4_xattr_set_handle(handle_t *, struct inode *, int, const char *, const void *, size_t, int);\n \n extern void ext4_xattr_delete_inode(handle_t *, struct inode *);\n-extern void ext4_xattr_put_super(struct super_block *);\n \n extern int ext4_expand_extra_isize_ea(struct inode *inode, int new_extra_isize,\n \t\t\t    struct ext4_inode *raw_inode, handle_t *handle);\n@@ -124,8 +123,8 @@ extern int ext4_xattr_ibody_inline_set(handle_t *handle, struct inode *inode,\n \t\t\t\t       struct ext4_xattr_info *i,\n \t\t\t\t       struct ext4_xattr_ibody_find *is);\n \n-extern struct mb_cache *ext4_xattr_create_cache(char *name);\n-extern void ext4_xattr_destroy_cache(struct mb_cache *);\n+extern struct mb2_cache *ext4_xattr_create_cache(void);\n+extern void ext4_xattr_destroy_cache(struct mb2_cache *);\n \n #ifdef CONFIG_EXT4_FS_SECURITY\n extern int ext4_init_security(handle_t *handle, struct inode *inode,""}","ext4_xattr_put_super(struct super_block *sb)
","ext4_xattr_put_super(struct super_block *sb)
{
	mb_cache_shrink(sb->s_bdev);
}
",C,,"{
	mb_cache_shrink(sb->s_bdev);
}
",,"@@ -53,7 +53,7 @@
 #include <linux/init.h>
 #include <linux/fs.h>
 #include <linux/slab.h>
-#include <linux/mbcache.h>
+#include <linux/mbcache2.h>
 #include <linux/quotaops.h>
 #include ""ext4_jbd2.h""
 #include ""ext4.h""
@@ -78,10 +78,10 @@
 # define ea_bdebug(bh, fmt, ...)	no_printk(fmt, ##__VA_ARGS__)
 #endif
 
-static void ext4_xattr_cache_insert(struct mb_cache *, struct buffer_head *);
+static void ext4_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);
 static struct buffer_head *ext4_xattr_cache_find(struct inode *,
 						 struct ext4_xattr_header *,
-						 struct mb_cache_entry **);
+						 struct mb2_cache_entry **);
 static void ext4_xattr_rehash(struct ext4_xattr_header *,
 			      struct ext4_xattr_entry *);
 static int ext4_xattr_list(struct dentry *dentry, char *buffer,
@@ -276,7 +276,7 @@ ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,
 	struct ext4_xattr_entry *entry;
 	size_t size;
 	int error;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	ea_idebug(inode, ""name=%d.%s, buffer=%p, buffer_size=%ld"",
 		  name_index, name, buffer, (long)buffer_size);
@@ -428,7 +428,7 @@ ext4_xattr_block_list(struct dentry *dentry, char *buffer, size_t buffer_size)
 	struct inode *inode = d_inode(dentry);
 	struct buffer_head *bh = NULL;
 	int error;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	ea_idebug(inode, ""buffer=%p, buffer_size=%ld"",
 		  buffer, (long)buffer_size);
@@ -545,30 +545,31 @@ static void
 ext4_xattr_release_block(handle_t *handle, struct inode *inode,
 			 struct buffer_head *bh)
 {
-	struct mb_cache_entry *ce = NULL;
 	int error = 0;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
-	ce = mb_cache_entry_get(ext4_mb_cache, bh->b_bdev, bh->b_blocknr);
 	BUFFER_TRACE(bh, ""get_write_access"");
 	error = ext4_journal_get_write_access(handle, bh);
 	if (error)
 		goto out;
 
 	lock_buffer(bh);
 	if (BHDR(bh)->h_refcount == cpu_to_le32(1)) {
+		__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);
+
 		ea_bdebug(bh, ""refcount now=0; freeing"");
-		if (ce)
-			mb_cache_entry_free(ce);
+		/*
+		 * This must happen under buffer lock for
+		 * ext4_xattr_block_set() to reliably detect freed block
+		 */
+		mb2_cache_entry_delete_block(EXT4_GET_MB_CACHE(inode), hash,
+					     bh->b_blocknr);
 		get_bh(bh);
 		unlock_buffer(bh);
 		ext4_free_blocks(handle, inode, bh, 0, 1,
 				 EXT4_FREE_BLOCKS_METADATA |
 				 EXT4_FREE_BLOCKS_FORGET);
 	} else {
 		le32_add_cpu(&BHDR(bh)->h_refcount, -1);
-		if (ce)
-			mb_cache_entry_release(ce);
 		/*
 		 * Beware of this ugliness: Releasing of xattr block references
 		 * from different inodes can race and so we have to protect
@@ -781,28 +782,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *new_bh = NULL;
 	struct ext4_xattr_search *s = &bs->s;
-	struct mb_cache_entry *ce = NULL;
+	struct mb2_cache_entry *ce = NULL;
 	int error = 0;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 #define header(x) ((struct ext4_xattr_header *)(x))
 
 	if (i->value && i->value_len > sb->s_blocksize)
 		return -ENOSPC;
 	if (s->base) {
-		ce = mb_cache_entry_get(ext4_mb_cache, bs->bh->b_bdev,
-					bs->bh->b_blocknr);
 		BUFFER_TRACE(bs->bh, ""get_write_access"");
 		error = ext4_journal_get_write_access(handle, bs->bh);
 		if (error)
 			goto cleanup;
 		lock_buffer(bs->bh);
 
 		if (header(s->base)->h_refcount == cpu_to_le32(1)) {
-			if (ce) {
-				mb_cache_entry_free(ce);
-				ce = NULL;
-			}
+			__u32 hash = le32_to_cpu(BHDR(bs->bh)->h_hash);
+
+			/*
+			 * This must happen under buffer lock for
+			 * ext4_xattr_block_set() to reliably detect modified
+			 * block
+			 */
+			mb2_cache_entry_delete_block(ext4_mb_cache, hash,
+						     bs->bh->b_blocknr);
 			ea_bdebug(bs->bh, ""modifying in-place"");
 			error = ext4_xattr_set_entry(i, s);
 			if (!error) {
@@ -826,10 +830,6 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 			int offset = (char *)s->here - bs->bh->b_data;
 
 			unlock_buffer(bs->bh);
-			if (ce) {
-				mb_cache_entry_release(ce);
-				ce = NULL;
-			}
 			ea_bdebug(bs->bh, ""cloning"");
 			s->base = kmalloc(bs->bh->b_size, GFP_NOFS);
 			error = -ENOMEM;
@@ -884,6 +884,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 				if (error)
 					goto cleanup_dquot;
 				lock_buffer(new_bh);
+				/*
+				 * We have to be careful about races with
+				 * freeing or rehashing of xattr block. Once we
+				 * hold buffer lock xattr block's state is
+				 * stable so we can check whether the block got
+				 * freed / rehashed or not.  Since we unhash
+				 * mbcache entry under buffer lock when freeing
+				 * / rehashing xattr block, checking whether
+				 * entry is still hashed is reliable.
+				 */
+				if (hlist_bl_unhashed(&ce->e_hash_list)) {
+					/*
+					 * Undo everything and check mbcache
+					 * again.
+					 */
+					unlock_buffer(new_bh);
+					dquot_free_block(inode,
+							 EXT4_C2B(EXT4_SB(sb),
+								  1));
+					brelse(new_bh);
+					mb2_cache_entry_put(ext4_mb_cache, ce);
+					ce = NULL;
+					new_bh = NULL;
+					goto inserted;
+				}
 				le32_add_cpu(&BHDR(new_bh)->h_refcount, 1);
 				ea_bdebug(new_bh, ""reusing; refcount now=%d"",
 					le32_to_cpu(BHDR(new_bh)->h_refcount));
@@ -894,7 +919,8 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 				if (error)
 					goto cleanup_dquot;
 			}
-			mb_cache_entry_release(ce);
+			mb2_cache_entry_touch(ext4_mb_cache, ce);
+			mb2_cache_entry_put(ext4_mb_cache, ce);
 			ce = NULL;
 		} else if (bs->bh && s->base == bs->bh->b_data) {
 			/* We were modifying this block in-place. */
@@ -959,7 +985,7 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 
 cleanup:
 	if (ce)
-		mb_cache_entry_release(ce);
+		mb2_cache_entry_put(ext4_mb_cache, ce);
 	brelse(new_bh);
 	if (!(bs->bh && s->base == bs->bh->b_data))
 		kfree(s->base);
@@ -1511,17 +1537,6 @@ ext4_xattr_delete_inode(handle_t *handle, struct inode *inode)
 	brelse(bh);
 }
 
-/*
- * ext4_xattr_put_super()
- *
- * This is called when a file system is unmounted.
- */
-void
-ext4_xattr_put_super(struct super_block *sb)
-{
-	mb_cache_shrink(sb->s_bdev);
-}
-
 /*
  * ext4_xattr_cache_insert()
  *
@@ -1531,28 +1546,18 @@ ext4_xattr_put_super(struct super_block *sb)
  * Returns 0, or a negative error number on failure.
  */
 static void
-ext4_xattr_cache_insert(struct mb_cache *ext4_mb_cache, struct buffer_head *bh)
+ext4_xattr_cache_insert(struct mb2_cache *ext4_mb_cache, struct buffer_head *bh)
 {
 	__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);
-	struct mb_cache_entry *ce;
 	int error;
 
-	ce = mb_cache_entry_alloc(ext4_mb_cache, GFP_NOFS);
-	if (!ce) {
-		ea_bdebug(bh, ""out of memory"");
-		return;
-	}
-	error = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);
+	error = mb2_cache_entry_create(ext4_mb_cache, GFP_NOFS, hash,
+				       bh->b_blocknr);
 	if (error) {
-		mb_cache_entry_free(ce);
-		if (error == -EBUSY) {
+		if (error == -EBUSY)
 			ea_bdebug(bh, ""already in cache"");
-			error = 0;
-		}
-	} else {
+	} else
 		ea_bdebug(bh, ""inserting [%x]"", (int)hash);
-		mb_cache_entry_release(ce);
-	}
 }
 
 /*
@@ -1605,26 +1610,19 @@ ext4_xattr_cmp(struct ext4_xattr_header *header1,
  */
 static struct buffer_head *
 ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,
-		      struct mb_cache_entry **pce)
+		      struct mb2_cache_entry **pce)
 {
 	__u32 hash = le32_to_cpu(header->h_hash);
-	struct mb_cache_entry *ce;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache_entry *ce;
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	if (!header->h_hash)
 		return NULL;  /* never share */
 	ea_idebug(inode, ""looking for cached blocks [%x]"", (int)hash);
-again:
-	ce = mb_cache_entry_find_first(ext4_mb_cache, inode->i_sb->s_bdev,
-				       hash);
+	ce = mb2_cache_entry_find_first(ext4_mb_cache, hash);
 	while (ce) {
 		struct buffer_head *bh;
 
-		if (IS_ERR(ce)) {
-			if (PTR_ERR(ce) == -EAGAIN)
-				goto again;
-			break;
-		}
 		bh = sb_bread(inode->i_sb, ce->e_block);
 		if (!bh) {
 			EXT4_ERROR_INODE(inode, ""block %lu read error"",
@@ -1640,7 +1638,7 @@ ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,
 			return bh;
 		}
 		brelse(bh);
-		ce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);
+		ce = mb2_cache_entry_find_next(ext4_mb_cache, ce);
 	}
 	return NULL;
 }
@@ -1715,15 +1713,15 @@ static void ext4_xattr_rehash(struct ext4_xattr_header *header,
 
 #define	HASH_BUCKET_BITS	10
 
-struct mb_cache *
-ext4_xattr_create_cache(char *name)
+struct mb2_cache *
+ext4_xattr_create_cache(void)
 {
-	return mb_cache_create(name, HASH_BUCKET_BITS);
+	return mb2_cache_create(HASH_BUCKET_BITS);
 }
 
-void ext4_xattr_destroy_cache(struct mb_cache *cache)
+void ext4_xattr_destroy_cache(struct mb2_cache *cache)
 {
 	if (cache)
-		mb_cache_destroy(cache);
+		mb2_cache_destroy(cache);
 }
 ",linux,82939d7999dfc1f1998c4b1c12e2f19edbdff272,f9a61eb4e2471c56a63cd804c7474128138c38ac,1,"ext4_xattr_put_super(struct super_block *sb)
//flaw_line_below:
{
//flaw_line_below:
	mb_cache_shrink(sb->s_bdev);
//flaw_line_below:
}
"
5432,183168,,Local,Not required,Partial,CVE-2015-8952,https://www.cvedetails.com/cve/CVE-2015-8952/,CWE-19,Low,,,,2016-10-16,2.1,"The mbcache feature in the ext2 and ext4 filesystem implementations in the Linux kernel before 4.6 mishandles xattr block caching, which allows local users to cause a denial of service (soft lockup) via filesystem operations in environments that use many attributes, as demonstrated by Ceph and Samba.",2018-03-15,DoS ,8,https://github.com/torvalds/linux/commit/82939d7999dfc1f1998c4b1c12e2f19edbdff272,82939d7999dfc1f1998c4b1c12e2f19edbdff272,"ext4: convert to mbcache2

The conversion is generally straightforward. The only tricky part is
that xattr block corresponding to found mbcache entry can get freed
before we get buffer lock for that block. So we have to check whether
the entry is still valid after getting buffer lock.

Signed-off-by: Jan Kara <jack@suse.cz>
Signed-off-by: Theodore Ts'o <tytso@mit.edu>",7,fs/ext4/xattr.c,"{""sha"": ""9ac9e62569ef8fdf981021b58d37ab99d0150882"", ""filename"": ""fs/ext4/ext4.h"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 1, ""changes"": 2, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/ext4.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/ext4.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/ext4.h?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -1468,7 +1468,7 @@ struct ext4_sb_info {\n \tstruct list_head s_es_list;\t/* List of inodes with reclaimable extents */\n \tlong s_es_nr_inode;\n \tstruct ext4_es_stats s_es_stats;\n-\tstruct mb_cache *s_mb_cache;\n+\tstruct mb2_cache *s_mb_cache;\n \tspinlock_t s_es_lock ____cacheline_aligned_in_smp;\n \n \t/* Ratelimit ext4 messages. */""}<_**next**_>{""sha"": ""ecc37e1034358d769ab29971e9d2301fb9e2b3bc"", ""filename"": ""fs/ext4/super.c"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 2, ""changes"": 7, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/super.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/super.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/super.c?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -844,7 +844,6 @@ static void ext4_put_super(struct super_block *sb)\n \text4_release_system_zone(sb);\n \text4_mb_release(sb);\n \text4_ext_release(sb);\n-\text4_xattr_put_super(sb);\n \n \tif (!(sb->s_flags & MS_RDONLY)) {\n \t\text4_clear_feature_journal_needs_recovery(sb);\n@@ -3797,7 +3796,7 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n \n no_journal:\n \tif (ext4_mballoc_ready) {\n-\t\tsbi->s_mb_cache = ext4_xattr_create_cache(sb->s_id);\n+\t\tsbi->s_mb_cache = ext4_xattr_create_cache();\n \t\tif (!sbi->s_mb_cache) {\n \t\t\text4_msg(sb, KERN_ERR, \""Failed to create an mb_cache\"");\n \t\t\tgoto failed_mount_wq;\n@@ -4027,6 +4026,10 @@ static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n \tif (EXT4_SB(sb)->rsv_conversion_wq)\n \t\tdestroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);\n failed_mount_wq:\n+\tif (sbi->s_mb_cache) {\n+\t\text4_xattr_destroy_cache(sbi->s_mb_cache);\n+\t\tsbi->s_mb_cache = NULL;\n+\t}\n \tif (sbi->s_journal) {\n \t\tjbd2_journal_destroy(sbi->s_journal);\n \t\tsbi->s_journal = NULL;""}<_**next**_>{""sha"": ""fe9f8d6ab6c91b60689abadefd5435c31893fcae"", ""filename"": ""fs/ext4/xattr.c"", ""status"": ""modified"", ""additions"": 67, ""deletions"": 69, ""changes"": 136, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.c"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.c"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/xattr.c?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -53,7 +53,7 @@\n #include <linux/init.h>\n #include <linux/fs.h>\n #include <linux/slab.h>\n-#include <linux/mbcache.h>\n+#include <linux/mbcache2.h>\n #include <linux/quotaops.h>\n #include \""ext4_jbd2.h\""\n #include \""ext4.h\""\n@@ -78,10 +78,10 @@\n # define ea_bdebug(bh, fmt, ...)\tno_printk(fmt, ##__VA_ARGS__)\n #endif\n \n-static void ext4_xattr_cache_insert(struct mb_cache *, struct buffer_head *);\n+static void ext4_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);\n static struct buffer_head *ext4_xattr_cache_find(struct inode *,\n \t\t\t\t\t\t struct ext4_xattr_header *,\n-\t\t\t\t\t\t struct mb_cache_entry **);\n+\t\t\t\t\t\t struct mb2_cache_entry **);\n static void ext4_xattr_rehash(struct ext4_xattr_header *,\n \t\t\t      struct ext4_xattr_entry *);\n static int ext4_xattr_list(struct dentry *dentry, char *buffer,\n@@ -276,7 +276,7 @@ ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,\n \tstruct ext4_xattr_entry *entry;\n \tsize_t size;\n \tint error;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tea_idebug(inode, \""name=%d.%s, buffer=%p, buffer_size=%ld\"",\n \t\t  name_index, name, buffer, (long)buffer_size);\n@@ -428,7 +428,7 @@ ext4_xattr_block_list(struct dentry *dentry, char *buffer, size_t buffer_size)\n \tstruct inode *inode = d_inode(dentry);\n \tstruct buffer_head *bh = NULL;\n \tint error;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tea_idebug(inode, \""buffer=%p, buffer_size=%ld\"",\n \t\t  buffer, (long)buffer_size);\n@@ -545,30 +545,31 @@ static void\n ext4_xattr_release_block(handle_t *handle, struct inode *inode,\n \t\t\t struct buffer_head *bh)\n {\n-\tstruct mb_cache_entry *ce = NULL;\n \tint error = 0;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n-\tce = mb_cache_entry_get(ext4_mb_cache, bh->b_bdev, bh->b_blocknr);\n \tBUFFER_TRACE(bh, \""get_write_access\"");\n \terror = ext4_journal_get_write_access(handle, bh);\n \tif (error)\n \t\tgoto out;\n \n \tlock_buffer(bh);\n \tif (BHDR(bh)->h_refcount == cpu_to_le32(1)) {\n+\t\t__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);\n+\n \t\tea_bdebug(bh, \""refcount now=0; freeing\"");\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_free(ce);\n+\t\t/*\n+\t\t * This must happen under buffer lock for\n+\t\t * ext4_xattr_block_set() to reliably detect freed block\n+\t\t */\n+\t\tmb2_cache_entry_delete_block(EXT4_GET_MB_CACHE(inode), hash,\n+\t\t\t\t\t     bh->b_blocknr);\n \t\tget_bh(bh);\n \t\tunlock_buffer(bh);\n \t\text4_free_blocks(handle, inode, bh, 0, 1,\n \t\t\t\t EXT4_FREE_BLOCKS_METADATA |\n \t\t\t\t EXT4_FREE_BLOCKS_FORGET);\n \t} else {\n \t\tle32_add_cpu(&BHDR(bh)->h_refcount, -1);\n-\t\tif (ce)\n-\t\t\tmb_cache_entry_release(ce);\n \t\t/*\n \t\t * Beware of this ugliness: Releasing of xattr block references\n \t\t * from different inodes can race and so we have to protect\n@@ -781,28 +782,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \tstruct super_block *sb = inode->i_sb;\n \tstruct buffer_head *new_bh = NULL;\n \tstruct ext4_xattr_search *s = &bs->s;\n-\tstruct mb_cache_entry *ce = NULL;\n+\tstruct mb2_cache_entry *ce = NULL;\n \tint error = 0;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n #define header(x) ((struct ext4_xattr_header *)(x))\n \n \tif (i->value && i->value_len > sb->s_blocksize)\n \t\treturn -ENOSPC;\n \tif (s->base) {\n-\t\tce = mb_cache_entry_get(ext4_mb_cache, bs->bh->b_bdev,\n-\t\t\t\t\tbs->bh->b_blocknr);\n \t\tBUFFER_TRACE(bs->bh, \""get_write_access\"");\n \t\terror = ext4_journal_get_write_access(handle, bs->bh);\n \t\tif (error)\n \t\t\tgoto cleanup;\n \t\tlock_buffer(bs->bh);\n \n \t\tif (header(s->base)->h_refcount == cpu_to_le32(1)) {\n-\t\t\tif (ce) {\n-\t\t\t\tmb_cache_entry_free(ce);\n-\t\t\t\tce = NULL;\n-\t\t\t}\n+\t\t\t__u32 hash = le32_to_cpu(BHDR(bs->bh)->h_hash);\n+\n+\t\t\t/*\n+\t\t\t * This must happen under buffer lock for\n+\t\t\t * ext4_xattr_block_set() to reliably detect modified\n+\t\t\t * block\n+\t\t\t */\n+\t\t\tmb2_cache_entry_delete_block(ext4_mb_cache, hash,\n+\t\t\t\t\t\t     bs->bh->b_blocknr);\n \t\t\tea_bdebug(bs->bh, \""modifying in-place\"");\n \t\t\terror = ext4_xattr_set_entry(i, s);\n \t\t\tif (!error) {\n@@ -826,10 +830,6 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\tint offset = (char *)s->here - bs->bh->b_data;\n \n \t\t\tunlock_buffer(bs->bh);\n-\t\t\tif (ce) {\n-\t\t\t\tmb_cache_entry_release(ce);\n-\t\t\t\tce = NULL;\n-\t\t\t}\n \t\t\tea_bdebug(bs->bh, \""cloning\"");\n \t\t\ts->base = kmalloc(bs->bh->b_size, GFP_NOFS);\n \t\t\terror = -ENOMEM;\n@@ -884,6 +884,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\t\tif (error)\n \t\t\t\t\tgoto cleanup_dquot;\n \t\t\t\tlock_buffer(new_bh);\n+\t\t\t\t/*\n+\t\t\t\t * We have to be careful about races with\n+\t\t\t\t * freeing or rehashing of xattr block. Once we\n+\t\t\t\t * hold buffer lock xattr block's state is\n+\t\t\t\t * stable so we can check whether the block got\n+\t\t\t\t * freed / rehashed or not.  Since we unhash\n+\t\t\t\t * mbcache entry under buffer lock when freeing\n+\t\t\t\t * / rehashing xattr block, checking whether\n+\t\t\t\t * entry is still hashed is reliable.\n+\t\t\t\t */\n+\t\t\t\tif (hlist_bl_unhashed(&ce->e_hash_list)) {\n+\t\t\t\t\t/*\n+\t\t\t\t\t * Undo everything and check mbcache\n+\t\t\t\t\t * again.\n+\t\t\t\t\t */\n+\t\t\t\t\tunlock_buffer(new_bh);\n+\t\t\t\t\tdquot_free_block(inode,\n+\t\t\t\t\t\t\t EXT4_C2B(EXT4_SB(sb),\n+\t\t\t\t\t\t\t\t  1));\n+\t\t\t\t\tbrelse(new_bh);\n+\t\t\t\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n+\t\t\t\t\tce = NULL;\n+\t\t\t\t\tnew_bh = NULL;\n+\t\t\t\t\tgoto inserted;\n+\t\t\t\t}\n \t\t\t\tle32_add_cpu(&BHDR(new_bh)->h_refcount, 1);\n \t\t\t\tea_bdebug(new_bh, \""reusing; refcount now=%d\"",\n \t\t\t\t\tle32_to_cpu(BHDR(new_bh)->h_refcount));\n@@ -894,7 +919,8 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \t\t\t\tif (error)\n \t\t\t\t\tgoto cleanup_dquot;\n \t\t\t}\n-\t\t\tmb_cache_entry_release(ce);\n+\t\t\tmb2_cache_entry_touch(ext4_mb_cache, ce);\n+\t\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n \t\t\tce = NULL;\n \t\t} else if (bs->bh && s->base == bs->bh->b_data) {\n \t\t\t/* We were modifying this block in-place. */\n@@ -959,7 +985,7 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,\n \n cleanup:\n \tif (ce)\n-\t\tmb_cache_entry_release(ce);\n+\t\tmb2_cache_entry_put(ext4_mb_cache, ce);\n \tbrelse(new_bh);\n \tif (!(bs->bh && s->base == bs->bh->b_data))\n \t\tkfree(s->base);\n@@ -1511,17 +1537,6 @@ ext4_xattr_delete_inode(handle_t *handle, struct inode *inode)\n \tbrelse(bh);\n }\n \n-/*\n- * ext4_xattr_put_super()\n- *\n- * This is called when a file system is unmounted.\n- */\n-void\n-ext4_xattr_put_super(struct super_block *sb)\n-{\n-\tmb_cache_shrink(sb->s_bdev);\n-}\n-\n /*\n  * ext4_xattr_cache_insert()\n  *\n@@ -1531,28 +1546,18 @@ ext4_xattr_put_super(struct super_block *sb)\n  * Returns 0, or a negative error number on failure.\n  */\n static void\n-ext4_xattr_cache_insert(struct mb_cache *ext4_mb_cache, struct buffer_head *bh)\n+ext4_xattr_cache_insert(struct mb2_cache *ext4_mb_cache, struct buffer_head *bh)\n {\n \t__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);\n-\tstruct mb_cache_entry *ce;\n \tint error;\n \n-\tce = mb_cache_entry_alloc(ext4_mb_cache, GFP_NOFS);\n-\tif (!ce) {\n-\t\tea_bdebug(bh, \""out of memory\"");\n-\t\treturn;\n-\t}\n-\terror = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);\n+\terror = mb2_cache_entry_create(ext4_mb_cache, GFP_NOFS, hash,\n+\t\t\t\t       bh->b_blocknr);\n \tif (error) {\n-\t\tmb_cache_entry_free(ce);\n-\t\tif (error == -EBUSY) {\n+\t\tif (error == -EBUSY)\n \t\t\tea_bdebug(bh, \""already in cache\"");\n-\t\t\terror = 0;\n-\t\t}\n-\t} else {\n+\t} else\n \t\tea_bdebug(bh, \""inserting [%x]\"", (int)hash);\n-\t\tmb_cache_entry_release(ce);\n-\t}\n }\n \n /*\n@@ -1605,26 +1610,19 @@ ext4_xattr_cmp(struct ext4_xattr_header *header1,\n  */\n static struct buffer_head *\n ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,\n-\t\t      struct mb_cache_entry **pce)\n+\t\t      struct mb2_cache_entry **pce)\n {\n \t__u32 hash = le32_to_cpu(header->h_hash);\n-\tstruct mb_cache_entry *ce;\n-\tstruct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n+\tstruct mb2_cache_entry *ce;\n+\tstruct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);\n \n \tif (!header->h_hash)\n \t\treturn NULL;  /* never share */\n \tea_idebug(inode, \""looking for cached blocks [%x]\"", (int)hash);\n-again:\n-\tce = mb_cache_entry_find_first(ext4_mb_cache, inode->i_sb->s_bdev,\n-\t\t\t\t       hash);\n+\tce = mb2_cache_entry_find_first(ext4_mb_cache, hash);\n \twhile (ce) {\n \t\tstruct buffer_head *bh;\n \n-\t\tif (IS_ERR(ce)) {\n-\t\t\tif (PTR_ERR(ce) == -EAGAIN)\n-\t\t\t\tgoto again;\n-\t\t\tbreak;\n-\t\t}\n \t\tbh = sb_bread(inode->i_sb, ce->e_block);\n \t\tif (!bh) {\n \t\t\tEXT4_ERROR_INODE(inode, \""block %lu read error\"",\n@@ -1640,7 +1638,7 @@ ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,\n \t\t\treturn bh;\n \t\t}\n \t\tbrelse(bh);\n-\t\tce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);\n+\t\tce = mb2_cache_entry_find_next(ext4_mb_cache, ce);\n \t}\n \treturn NULL;\n }\n@@ -1715,15 +1713,15 @@ static void ext4_xattr_rehash(struct ext4_xattr_header *header,\n \n #define\tHASH_BUCKET_BITS\t10\n \n-struct mb_cache *\n-ext4_xattr_create_cache(char *name)\n+struct mb2_cache *\n+ext4_xattr_create_cache(void)\n {\n-\treturn mb_cache_create(name, HASH_BUCKET_BITS);\n+\treturn mb2_cache_create(HASH_BUCKET_BITS);\n }\n \n-void ext4_xattr_destroy_cache(struct mb_cache *cache)\n+void ext4_xattr_destroy_cache(struct mb2_cache *cache)\n {\n \tif (cache)\n-\t\tmb_cache_destroy(cache);\n+\t\tmb2_cache_destroy(cache);\n }\n ""}<_**next**_>{""sha"": ""10b0f7323ed6fcd628efee26998d0f1be7652c48"", ""filename"": ""fs/ext4/xattr.h"", ""status"": ""modified"", ""additions"": 2, ""deletions"": 3, ""changes"": 5, ""blob_url"": ""https://github.com/torvalds/linux/blob/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.h"", ""raw_url"": ""https://github.com/torvalds/linux/raw/82939d7999dfc1f1998c4b1c12e2f19edbdff272/fs/ext4/xattr.h"", ""contents_url"": ""https://api.github.com/repos/torvalds/linux/contents/fs/ext4/xattr.h?ref=82939d7999dfc1f1998c4b1c12e2f19edbdff272"", ""patch"": ""@@ -108,7 +108,6 @@ extern int ext4_xattr_set(struct inode *, int, const char *, const void *, size_\n extern int ext4_xattr_set_handle(handle_t *, struct inode *, int, const char *, const void *, size_t, int);\n \n extern void ext4_xattr_delete_inode(handle_t *, struct inode *);\n-extern void ext4_xattr_put_super(struct super_block *);\n \n extern int ext4_expand_extra_isize_ea(struct inode *inode, int new_extra_isize,\n \t\t\t    struct ext4_inode *raw_inode, handle_t *handle);\n@@ -124,8 +123,8 @@ extern int ext4_xattr_ibody_inline_set(handle_t *handle, struct inode *inode,\n \t\t\t\t       struct ext4_xattr_info *i,\n \t\t\t\t       struct ext4_xattr_ibody_find *is);\n \n-extern struct mb_cache *ext4_xattr_create_cache(char *name);\n-extern void ext4_xattr_destroy_cache(struct mb_cache *);\n+extern struct mb2_cache *ext4_xattr_create_cache(void);\n+extern void ext4_xattr_destroy_cache(struct mb2_cache *);\n \n #ifdef CONFIG_EXT4_FS_SECURITY\n extern int ext4_init_security(handle_t *handle, struct inode *inode,""}"," ext4_xattr_release_block(handle_t *handle, struct inode *inode,
 			 struct buffer_head *bh)
 {
 	int error = 0;
 
 	BUFFER_TRACE(bh, ""get_write_access"");
 	error = ext4_journal_get_write_access(handle, bh);
 	if (error)
 		goto out;
 
 	lock_buffer(bh);
 	if (BHDR(bh)->h_refcount == cpu_to_le32(1)) {
		__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);

 		ea_bdebug(bh, ""refcount now=0; freeing"");
		/*
		 * This must happen under buffer lock for
		 * ext4_xattr_block_set() to reliably detect freed block
		 */
		mb2_cache_entry_delete_block(EXT4_GET_MB_CACHE(inode), hash,
					     bh->b_blocknr);
 		get_bh(bh);
 		unlock_buffer(bh);
 		ext4_free_blocks(handle, inode, bh, 0, 1,
 				 EXT4_FREE_BLOCKS_METADATA |
 				 EXT4_FREE_BLOCKS_FORGET);
 	} else {
 		le32_add_cpu(&BHDR(bh)->h_refcount, -1);
 		/*
 		 * Beware of this ugliness: Releasing of xattr block references
 		 * from different inodes can race and so we have to protect
		 * from a race where someone else frees the block (and releases
		 * its journal_head) before we are done dirtying the buffer. In
		 * nojournal mode this race is harmless and we actually cannot
		 * call ext4_handle_dirty_xattr_block() with locked buffer as
		 * that function can call sync_dirty_buffer() so for that case
		 * we handle the dirtying after unlocking the buffer.
		 */
		if (ext4_handle_valid(handle))
			error = ext4_handle_dirty_xattr_block(handle, inode,
							      bh);
		unlock_buffer(bh);
		if (!ext4_handle_valid(handle))
			error = ext4_handle_dirty_xattr_block(handle, inode,
							      bh);
		if (IS_SYNC(inode))
			ext4_handle_sync(handle);
		dquot_free_block(inode, EXT4_C2B(EXT4_SB(inode->i_sb), 1));
		ea_bdebug(bh, ""refcount now=%d; releasing"",
			  le32_to_cpu(BHDR(bh)->h_refcount));
	}
out:
	ext4_std_error(inode->i_sb, error);
	return;
}
"," ext4_xattr_release_block(handle_t *handle, struct inode *inode,
 			 struct buffer_head *bh)
 {
	struct mb_cache_entry *ce = NULL;
 	int error = 0;
	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
	ce = mb_cache_entry_get(ext4_mb_cache, bh->b_bdev, bh->b_blocknr);
 	BUFFER_TRACE(bh, ""get_write_access"");
 	error = ext4_journal_get_write_access(handle, bh);
 	if (error)
 		goto out;
 
 	lock_buffer(bh);
 	if (BHDR(bh)->h_refcount == cpu_to_le32(1)) {
 		ea_bdebug(bh, ""refcount now=0; freeing"");
		if (ce)
			mb_cache_entry_free(ce);
 		get_bh(bh);
 		unlock_buffer(bh);
 		ext4_free_blocks(handle, inode, bh, 0, 1,
 				 EXT4_FREE_BLOCKS_METADATA |
 				 EXT4_FREE_BLOCKS_FORGET);
 	} else {
 		le32_add_cpu(&BHDR(bh)->h_refcount, -1);
		if (ce)
			mb_cache_entry_release(ce);
 		/*
 		 * Beware of this ugliness: Releasing of xattr block references
 		 * from different inodes can race and so we have to protect
		 * from a race where someone else frees the block (and releases
		 * its journal_head) before we are done dirtying the buffer. In
		 * nojournal mode this race is harmless and we actually cannot
		 * call ext4_handle_dirty_xattr_block() with locked buffer as
		 * that function can call sync_dirty_buffer() so for that case
		 * we handle the dirtying after unlocking the buffer.
		 */
		if (ext4_handle_valid(handle))
			error = ext4_handle_dirty_xattr_block(handle, inode,
							      bh);
		unlock_buffer(bh);
		if (!ext4_handle_valid(handle))
			error = ext4_handle_dirty_xattr_block(handle, inode,
							      bh);
		if (IS_SYNC(inode))
			ext4_handle_sync(handle);
		dquot_free_block(inode, EXT4_C2B(EXT4_SB(inode->i_sb), 1));
		ea_bdebug(bh, ""refcount now=%d; releasing"",
			  le32_to_cpu(BHDR(bh)->h_refcount));
	}
out:
	ext4_std_error(inode->i_sb, error);
	return;
}
",C,"		__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);

		/*
		 * This must happen under buffer lock for
		 * ext4_xattr_block_set() to reliably detect freed block
		 */
		mb2_cache_entry_delete_block(EXT4_GET_MB_CACHE(inode), hash,
					     bh->b_blocknr);
","	struct mb_cache_entry *ce = NULL;
	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
	ce = mb_cache_entry_get(ext4_mb_cache, bh->b_bdev, bh->b_blocknr);
		if (ce)
			mb_cache_entry_free(ce);
		if (ce)
			mb_cache_entry_release(ce);
",,"@@ -53,7 +53,7 @@
 #include <linux/init.h>
 #include <linux/fs.h>
 #include <linux/slab.h>
-#include <linux/mbcache.h>
+#include <linux/mbcache2.h>
 #include <linux/quotaops.h>
 #include ""ext4_jbd2.h""
 #include ""ext4.h""
@@ -78,10 +78,10 @@
 # define ea_bdebug(bh, fmt, ...)	no_printk(fmt, ##__VA_ARGS__)
 #endif
 
-static void ext4_xattr_cache_insert(struct mb_cache *, struct buffer_head *);
+static void ext4_xattr_cache_insert(struct mb2_cache *, struct buffer_head *);
 static struct buffer_head *ext4_xattr_cache_find(struct inode *,
 						 struct ext4_xattr_header *,
-						 struct mb_cache_entry **);
+						 struct mb2_cache_entry **);
 static void ext4_xattr_rehash(struct ext4_xattr_header *,
 			      struct ext4_xattr_entry *);
 static int ext4_xattr_list(struct dentry *dentry, char *buffer,
@@ -276,7 +276,7 @@ ext4_xattr_block_get(struct inode *inode, int name_index, const char *name,
 	struct ext4_xattr_entry *entry;
 	size_t size;
 	int error;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	ea_idebug(inode, ""name=%d.%s, buffer=%p, buffer_size=%ld"",
 		  name_index, name, buffer, (long)buffer_size);
@@ -428,7 +428,7 @@ ext4_xattr_block_list(struct dentry *dentry, char *buffer, size_t buffer_size)
 	struct inode *inode = d_inode(dentry);
 	struct buffer_head *bh = NULL;
 	int error;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	ea_idebug(inode, ""buffer=%p, buffer_size=%ld"",
 		  buffer, (long)buffer_size);
@@ -545,30 +545,31 @@ static void
 ext4_xattr_release_block(handle_t *handle, struct inode *inode,
 			 struct buffer_head *bh)
 {
-	struct mb_cache_entry *ce = NULL;
 	int error = 0;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
-	ce = mb_cache_entry_get(ext4_mb_cache, bh->b_bdev, bh->b_blocknr);
 	BUFFER_TRACE(bh, ""get_write_access"");
 	error = ext4_journal_get_write_access(handle, bh);
 	if (error)
 		goto out;
 
 	lock_buffer(bh);
 	if (BHDR(bh)->h_refcount == cpu_to_le32(1)) {
+		__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);
+
 		ea_bdebug(bh, ""refcount now=0; freeing"");
-		if (ce)
-			mb_cache_entry_free(ce);
+		/*
+		 * This must happen under buffer lock for
+		 * ext4_xattr_block_set() to reliably detect freed block
+		 */
+		mb2_cache_entry_delete_block(EXT4_GET_MB_CACHE(inode), hash,
+					     bh->b_blocknr);
 		get_bh(bh);
 		unlock_buffer(bh);
 		ext4_free_blocks(handle, inode, bh, 0, 1,
 				 EXT4_FREE_BLOCKS_METADATA |
 				 EXT4_FREE_BLOCKS_FORGET);
 	} else {
 		le32_add_cpu(&BHDR(bh)->h_refcount, -1);
-		if (ce)
-			mb_cache_entry_release(ce);
 		/*
 		 * Beware of this ugliness: Releasing of xattr block references
 		 * from different inodes can race and so we have to protect
@@ -781,28 +782,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *new_bh = NULL;
 	struct ext4_xattr_search *s = &bs->s;
-	struct mb_cache_entry *ce = NULL;
+	struct mb2_cache_entry *ce = NULL;
 	int error = 0;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 #define header(x) ((struct ext4_xattr_header *)(x))
 
 	if (i->value && i->value_len > sb->s_blocksize)
 		return -ENOSPC;
 	if (s->base) {
-		ce = mb_cache_entry_get(ext4_mb_cache, bs->bh->b_bdev,
-					bs->bh->b_blocknr);
 		BUFFER_TRACE(bs->bh, ""get_write_access"");
 		error = ext4_journal_get_write_access(handle, bs->bh);
 		if (error)
 			goto cleanup;
 		lock_buffer(bs->bh);
 
 		if (header(s->base)->h_refcount == cpu_to_le32(1)) {
-			if (ce) {
-				mb_cache_entry_free(ce);
-				ce = NULL;
-			}
+			__u32 hash = le32_to_cpu(BHDR(bs->bh)->h_hash);
+
+			/*
+			 * This must happen under buffer lock for
+			 * ext4_xattr_block_set() to reliably detect modified
+			 * block
+			 */
+			mb2_cache_entry_delete_block(ext4_mb_cache, hash,
+						     bs->bh->b_blocknr);
 			ea_bdebug(bs->bh, ""modifying in-place"");
 			error = ext4_xattr_set_entry(i, s);
 			if (!error) {
@@ -826,10 +830,6 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 			int offset = (char *)s->here - bs->bh->b_data;
 
 			unlock_buffer(bs->bh);
-			if (ce) {
-				mb_cache_entry_release(ce);
-				ce = NULL;
-			}
 			ea_bdebug(bs->bh, ""cloning"");
 			s->base = kmalloc(bs->bh->b_size, GFP_NOFS);
 			error = -ENOMEM;
@@ -884,6 +884,31 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 				if (error)
 					goto cleanup_dquot;
 				lock_buffer(new_bh);
+				/*
+				 * We have to be careful about races with
+				 * freeing or rehashing of xattr block. Once we
+				 * hold buffer lock xattr block's state is
+				 * stable so we can check whether the block got
+				 * freed / rehashed or not.  Since we unhash
+				 * mbcache entry under buffer lock when freeing
+				 * / rehashing xattr block, checking whether
+				 * entry is still hashed is reliable.
+				 */
+				if (hlist_bl_unhashed(&ce->e_hash_list)) {
+					/*
+					 * Undo everything and check mbcache
+					 * again.
+					 */
+					unlock_buffer(new_bh);
+					dquot_free_block(inode,
+							 EXT4_C2B(EXT4_SB(sb),
+								  1));
+					brelse(new_bh);
+					mb2_cache_entry_put(ext4_mb_cache, ce);
+					ce = NULL;
+					new_bh = NULL;
+					goto inserted;
+				}
 				le32_add_cpu(&BHDR(new_bh)->h_refcount, 1);
 				ea_bdebug(new_bh, ""reusing; refcount now=%d"",
 					le32_to_cpu(BHDR(new_bh)->h_refcount));
@@ -894,7 +919,8 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 				if (error)
 					goto cleanup_dquot;
 			}
-			mb_cache_entry_release(ce);
+			mb2_cache_entry_touch(ext4_mb_cache, ce);
+			mb2_cache_entry_put(ext4_mb_cache, ce);
 			ce = NULL;
 		} else if (bs->bh && s->base == bs->bh->b_data) {
 			/* We were modifying this block in-place. */
@@ -959,7 +985,7 @@ ext4_xattr_block_set(handle_t *handle, struct inode *inode,
 
 cleanup:
 	if (ce)
-		mb_cache_entry_release(ce);
+		mb2_cache_entry_put(ext4_mb_cache, ce);
 	brelse(new_bh);
 	if (!(bs->bh && s->base == bs->bh->b_data))
 		kfree(s->base);
@@ -1511,17 +1537,6 @@ ext4_xattr_delete_inode(handle_t *handle, struct inode *inode)
 	brelse(bh);
 }
 
-/*
- * ext4_xattr_put_super()
- *
- * This is called when a file system is unmounted.
- */
-void
-ext4_xattr_put_super(struct super_block *sb)
-{
-	mb_cache_shrink(sb->s_bdev);
-}
-
 /*
  * ext4_xattr_cache_insert()
  *
@@ -1531,28 +1546,18 @@ ext4_xattr_put_super(struct super_block *sb)
  * Returns 0, or a negative error number on failure.
  */
 static void
-ext4_xattr_cache_insert(struct mb_cache *ext4_mb_cache, struct buffer_head *bh)
+ext4_xattr_cache_insert(struct mb2_cache *ext4_mb_cache, struct buffer_head *bh)
 {
 	__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);
-	struct mb_cache_entry *ce;
 	int error;
 
-	ce = mb_cache_entry_alloc(ext4_mb_cache, GFP_NOFS);
-	if (!ce) {
-		ea_bdebug(bh, ""out of memory"");
-		return;
-	}
-	error = mb_cache_entry_insert(ce, bh->b_bdev, bh->b_blocknr, hash);
+	error = mb2_cache_entry_create(ext4_mb_cache, GFP_NOFS, hash,
+				       bh->b_blocknr);
 	if (error) {
-		mb_cache_entry_free(ce);
-		if (error == -EBUSY) {
+		if (error == -EBUSY)
 			ea_bdebug(bh, ""already in cache"");
-			error = 0;
-		}
-	} else {
+	} else
 		ea_bdebug(bh, ""inserting [%x]"", (int)hash);
-		mb_cache_entry_release(ce);
-	}
 }
 
 /*
@@ -1605,26 +1610,19 @@ ext4_xattr_cmp(struct ext4_xattr_header *header1,
  */
 static struct buffer_head *
 ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,
-		      struct mb_cache_entry **pce)
+		      struct mb2_cache_entry **pce)
 {
 	__u32 hash = le32_to_cpu(header->h_hash);
-	struct mb_cache_entry *ce;
-	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
+	struct mb2_cache_entry *ce;
+	struct mb2_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
 	if (!header->h_hash)
 		return NULL;  /* never share */
 	ea_idebug(inode, ""looking for cached blocks [%x]"", (int)hash);
-again:
-	ce = mb_cache_entry_find_first(ext4_mb_cache, inode->i_sb->s_bdev,
-				       hash);
+	ce = mb2_cache_entry_find_first(ext4_mb_cache, hash);
 	while (ce) {
 		struct buffer_head *bh;
 
-		if (IS_ERR(ce)) {
-			if (PTR_ERR(ce) == -EAGAIN)
-				goto again;
-			break;
-		}
 		bh = sb_bread(inode->i_sb, ce->e_block);
 		if (!bh) {
 			EXT4_ERROR_INODE(inode, ""block %lu read error"",
@@ -1640,7 +1638,7 @@ ext4_xattr_cache_find(struct inode *inode, struct ext4_xattr_header *header,
 			return bh;
 		}
 		brelse(bh);
-		ce = mb_cache_entry_find_next(ce, inode->i_sb->s_bdev, hash);
+		ce = mb2_cache_entry_find_next(ext4_mb_cache, ce);
 	}
 	return NULL;
 }
@@ -1715,15 +1713,15 @@ static void ext4_xattr_rehash(struct ext4_xattr_header *header,
 
 #define	HASH_BUCKET_BITS	10
 
-struct mb_cache *
-ext4_xattr_create_cache(char *name)
+struct mb2_cache *
+ext4_xattr_create_cache(void)
 {
-	return mb_cache_create(name, HASH_BUCKET_BITS);
+	return mb2_cache_create(HASH_BUCKET_BITS);
 }
 
-void ext4_xattr_destroy_cache(struct mb_cache *cache)
+void ext4_xattr_destroy_cache(struct mb2_cache *cache)
 {
 	if (cache)
-		mb_cache_destroy(cache);
+		mb2_cache_destroy(cache);
 }
 ",linux,82939d7999dfc1f1998c4b1c12e2f19edbdff272,f9a61eb4e2471c56a63cd804c7474128138c38ac,1," ext4_xattr_release_block(handle_t *handle, struct inode *inode,
 			 struct buffer_head *bh)
 {
//flaw_line_below:
	struct mb_cache_entry *ce = NULL;
 	int error = 0;
//flaw_line_below:
	struct mb_cache *ext4_mb_cache = EXT4_GET_MB_CACHE(inode);
 
//flaw_line_below:
	ce = mb_cache_entry_get(ext4_mb_cache, bh->b_bdev, bh->b_blocknr);
 	BUFFER_TRACE(bh, ""get_write_access"");
 	error = ext4_journal_get_write_access(handle, bh);
 	if (error)
 		goto out;
 
 	lock_buffer(bh);
 	if (BHDR(bh)->h_refcount == cpu_to_le32(1)) {
//fix_flaw_line_below:
//		__u32 hash = le32_to_cpu(BHDR(bh)->h_hash);
//fix_flaw_line_below:
//
 		ea_bdebug(bh, ""refcount now=0; freeing"");
//flaw_line_below:
		if (ce)
//flaw_line_below:
			mb_cache_entry_free(ce);
//fix_flaw_line_below:
//		/*
//fix_flaw_line_below:
//		 * This must happen under buffer lock for
//fix_flaw_line_below:
//		 * ext4_xattr_block_set() to reliably detect freed block
//fix_flaw_line_below:
//		 */
//fix_flaw_line_below:
//		mb2_cache_entry_delete_block(EXT4_GET_MB_CACHE(inode), hash,
//fix_flaw_line_below:
//					     bh->b_blocknr);
 		get_bh(bh);
 		unlock_buffer(bh);
 		ext4_free_blocks(handle, inode, bh, 0, 1,
 				 EXT4_FREE_BLOCKS_METADATA |
 				 EXT4_FREE_BLOCKS_FORGET);
 	} else {
 		le32_add_cpu(&BHDR(bh)->h_refcount, -1);
//flaw_line_below:
		if (ce)
//flaw_line_below:
			mb_cache_entry_release(ce);
 		/*
 		 * Beware of this ugliness: Releasing of xattr block references
 		 * from different inodes can race and so we have to protect
		 * from a race where someone else frees the block (and releases
		 * its journal_head) before we are done dirtying the buffer. In
		 * nojournal mode this race is harmless and we actually cannot
		 * call ext4_handle_dirty_xattr_block() with locked buffer as
		 * that function can call sync_dirty_buffer() so for that case
		 * we handle the dirtying after unlocking the buffer.
		 */
		if (ext4_handle_valid(handle))
			error = ext4_handle_dirty_xattr_block(handle, inode,
							      bh);
		unlock_buffer(bh);
		if (!ext4_handle_valid(handle))
			error = ext4_handle_dirty_xattr_block(handle, inode,
							      bh);
		if (IS_SYNC(inode))
			ext4_handle_sync(handle);
		dquot_free_block(inode, EXT4_C2B(EXT4_SB(inode->i_sb), 1));
		ea_bdebug(bh, ""refcount now=%d; releasing"",
			  le32_to_cpu(BHDR(bh)->h_refcount));
	}
out:
	ext4_std_error(inode->i_sb, error);
	return;
}
"
6883,184619,,Remote,Not required,Partial,CVE-2011-3927,https://www.cvedetails.com/cve/CVE-2011-3927/,CWE-19,Low,Partial,Partial,,2012-01-23,7.5,"Skia, as used in Google Chrome before 16.0.912.77, does not perform all required initialization of values, which allows remote attackers to cause a denial of service or possibly have unspecified other impact via unknown vectors.",2017-09-18,DoS ,11,https://github.com/chromium/chromium/commit/58ffd25567098d8ce9443b7c977382929d163b3d,58ffd25567098d8ce9443b7c977382929d163b3d,"[skia] not all convex paths are convex, so recompute convexity for the problematic ones
https://bugs.webkit.org/show_bug.cgi?id=75960

Reviewed by Stephen White.

No new tests.
See related chrome issue
http://code.google.com/p/chromium/issues/detail?id=108605

* platform/graphics/skia/GraphicsContextSkia.cpp:
(WebCore::setPathFromConvexPoints):


git-svn-id: svn://svn.chromium.org/blink/trunk@104609 bbb929c8-8fbe-4397-9dbb-9b2b20218538",1,third_party/WebKit/Source/WebCore/platform/graphics/skia/GraphicsContextSkia.cpp,"{""sha"": ""8710fc85b1d579e074c14b06e77c1c52fb6b1bf9"", ""filename"": ""third_party/WebKit/Source/WebCore/ChangeLog"", ""status"": ""modified"", ""additions"": 14, ""deletions"": 0, ""changes"": 14, ""blob_url"": ""https://github.com/chromium/chromium/blob/58ffd25567098d8ce9443b7c977382929d163b3d/third_party/WebKit/Source/WebCore/ChangeLog"", ""raw_url"": ""https://github.com/chromium/chromium/raw/58ffd25567098d8ce9443b7c977382929d163b3d/third_party/WebKit/Source/WebCore/ChangeLog"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/third_party/WebKit/Source/WebCore/ChangeLog?ref=58ffd25567098d8ce9443b7c977382929d163b3d"", ""patch"": ""@@ -1,3 +1,17 @@\n+2012-01-10  Mike Reed  <reed@google.com>\n+\n+        [skia] not all convex paths are convex, so recompute convexity for the problematic ones\n+        https://bugs.webkit.org/show_bug.cgi?id=75960\n+\n+        Reviewed by Stephen White.\n+\n+        No new tests.\n+        See related chrome issue\n+        http://code.google.com/p/chromium/issues/detail?id=108605\n+\n+        * platform/graphics/skia/GraphicsContextSkia.cpp:\n+        (WebCore::setPathFromConvexPoints):\n+\n 2012-01-10  Gavin Barraclough  <barraclough@apple.com>\n \n         Do not allow Array length to be set if it is non-configurable""}<_**next**_>{""sha"": ""db343615fb8840fc386b646fb2d057a4d3ae6936"", ""filename"": ""third_party/WebKit/Source/WebCore/platform/graphics/skia/GraphicsContextSkia.cpp"", ""status"": ""modified"", ""additions"": 11, ""deletions"": 1, ""changes"": 12, ""blob_url"": ""https://github.com/chromium/chromium/blob/58ffd25567098d8ce9443b7c977382929d163b3d/third_party/WebKit/Source/WebCore/platform/graphics/skia/GraphicsContextSkia.cpp"", ""raw_url"": ""https://github.com/chromium/chromium/raw/58ffd25567098d8ce9443b7c977382929d163b3d/third_party/WebKit/Source/WebCore/platform/graphics/skia/GraphicsContextSkia.cpp"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/third_party/WebKit/Source/WebCore/platform/graphics/skia/GraphicsContextSkia.cpp?ref=58ffd25567098d8ce9443b7c977382929d163b3d"", ""patch"": ""@@ -440,7 +440,17 @@ static void setPathFromConvexPoints(SkPath* path, size_t numPoints, const FloatP\n         path->lineTo(WebCoreFloatToSkScalar(points[i].x()),\n                      WebCoreFloatToSkScalar(points[i].y()));\n     }\n-    path->setIsConvex(true);\n+\n+    /*  The code used to just blindly call this\n+            path->setIsConvex(true);\n+        But webkit can sometimes send us non-convex 4-point values, so we mark the path's\n+        convexity as unknown, so it will get computed by skia at draw time.\n+        See crbug.com 108605\n+    */\n+    SkPath::Convexity convexity = SkPath::kConvex_Convexity;\n+    if (numPoints == 4)\n+        convexity = SkPath::kUnknown_Convexity;\n+    path->setConvexity(convexity);\n }\n \n void GraphicsContext::drawConvexPolygon(size_t numPoints,""}","static void setPathFromConvexPoints(SkPath* path, size_t numPoints, const FloatPoint* points)
{
    path->incReserve(numPoints);
    path->moveTo(WebCoreFloatToSkScalar(points[0].x()),
                 WebCoreFloatToSkScalar(points[0].y()));
    for (size_t i = 1; i < numPoints; ++i) {
         path->lineTo(WebCoreFloatToSkScalar(points[i].x()),
                      WebCoreFloatToSkScalar(points[i].y()));
     }

    /*  The code used to just blindly call this
            path->setIsConvex(true);
        But webkit can sometimes send us non-convex 4-point values, so we mark the path's
        convexity as unknown, so it will get computed by skia at draw time.
        See crbug.com 108605
    */
    SkPath::Convexity convexity = SkPath::kConvex_Convexity;
    if (numPoints == 4)
        convexity = SkPath::kUnknown_Convexity;
    path->setConvexity(convexity);
 }
","static void setPathFromConvexPoints(SkPath* path, size_t numPoints, const FloatPoint* points)
{
    path->incReserve(numPoints);
    path->moveTo(WebCoreFloatToSkScalar(points[0].x()),
                 WebCoreFloatToSkScalar(points[0].y()));
    for (size_t i = 1; i < numPoints; ++i) {
         path->lineTo(WebCoreFloatToSkScalar(points[i].x()),
                      WebCoreFloatToSkScalar(points[i].y()));
     }
    path->setIsConvex(true);
 }
",C,"
    /*  The code used to just blindly call this
            path->setIsConvex(true);
        But webkit can sometimes send us non-convex 4-point values, so we mark the path's
        convexity as unknown, so it will get computed by skia at draw time.
        See crbug.com 108605
    */
    SkPath::Convexity convexity = SkPath::kConvex_Convexity;
    if (numPoints == 4)
        convexity = SkPath::kUnknown_Convexity;
    path->setConvexity(convexity);
","    path->setIsConvex(true);
",,"@@ -440,7 +440,17 @@ static void setPathFromConvexPoints(SkPath* path, size_t numPoints, const FloatP
         path->lineTo(WebCoreFloatToSkScalar(points[i].x()),
                      WebCoreFloatToSkScalar(points[i].y()));
     }
-    path->setIsConvex(true);
+
+    /*  The code used to just blindly call this
+            path->setIsConvex(true);
+        But webkit can sometimes send us non-convex 4-point values, so we mark the path's
+        convexity as unknown, so it will get computed by skia at draw time.
+        See crbug.com 108605
+    */
+    SkPath::Convexity convexity = SkPath::kConvex_Convexity;
+    if (numPoints == 4)
+        convexity = SkPath::kUnknown_Convexity;
+    path->setConvexity(convexity);
 }
 
 void GraphicsContext::drawConvexPolygon(size_t numPoints,",Chrome,58ffd25567098d8ce9443b7c977382929d163b3d,d18b03cf294a6f08e872e98b78f196ba20d37163,1,"static void setPathFromConvexPoints(SkPath* path, size_t numPoints, const FloatPoint* points)
{
    path->incReserve(numPoints);
    path->moveTo(WebCoreFloatToSkScalar(points[0].x()),
                 WebCoreFloatToSkScalar(points[0].y()));
    for (size_t i = 1; i < numPoints; ++i) {
         path->lineTo(WebCoreFloatToSkScalar(points[i].x()),
                      WebCoreFloatToSkScalar(points[i].y()));
     }
//flaw_line_below:
    path->setIsConvex(true);
//fix_flaw_line_below:
//
//fix_flaw_line_below:
//    /*  The code used to just blindly call this
//fix_flaw_line_below:
//            path->setIsConvex(true);
//fix_flaw_line_below:
//        But webkit can sometimes send us non-convex 4-point values, so we mark the path's
//fix_flaw_line_below:
//        convexity as unknown, so it will get computed by skia at draw time.
//fix_flaw_line_below:
//        See crbug.com 108605
//fix_flaw_line_below:
//    */
//fix_flaw_line_below:
//    SkPath::Convexity convexity = SkPath::kConvex_Convexity;
//fix_flaw_line_below:
//    if (numPoints == 4)
//fix_flaw_line_below:
//        convexity = SkPath::kUnknown_Convexity;
//fix_flaw_line_below:
//    path->setConvexity(convexity);
 }
"
8212,185948,,Remote,Not required,,CVE-2015-1229,https://www.cvedetails.com/cve/CVE-2015-1229/,CWE-19,Low,,Partial,,2015-03-08,5.0,"net/http/proxy_client_socket.cc in Google Chrome before 41.0.2272.76 does not properly handle a 407 (aka Proxy Authentication Required) HTTP status code accompanied by a Set-Cookie header, which allows remote proxy servers to conduct cookie-injection attacks via a crafted response.",2016-12-21,,13,https://github.com/chromium/chromium/commit/7933c117fd16b192e70609c331641e9112af5e42,7933c117fd16b192e70609c331641e9112af5e42,"Sanitize headers in Proxy Authentication Required responses

BUG=431504

Review URL: https://codereview.chromium.org/769043003

Cr-Commit-Position: refs/heads/master@{#310014}",10,net/http/http_proxy_client_socket.cc,"{""sha"": ""21a8c008e252fa4053b397be884c49cf9051e618"", ""filename"": ""net/http/http_network_transaction_unittest.cc"", ""status"": ""modified"", ""additions"": 75, ""deletions"": 12, ""changes"": 87, ""blob_url"": ""https://github.com/chromium/chromium/blob/7933c117fd16b192e70609c331641e9112af5e42/net/http/http_network_transaction_unittest.cc"", ""raw_url"": ""https://github.com/chromium/chromium/raw/7933c117fd16b192e70609c331641e9112af5e42/net/http/http_network_transaction_unittest.cc"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/net/http/http_network_transaction_unittest.cc?ref=7933c117fd16b192e70609c331641e9112af5e42"", ""patch"": ""@@ -2546,11 +2546,11 @@ TEST_P(HttpNetworkTransactionTest, BasicAuthProxyKeepAlive) {\n       NetLog::PHASE_NONE);\n \n   const HttpResponseInfo* response = trans->GetResponseInfo();\n-  ASSERT_TRUE(response != NULL);\n-  ASSERT_FALSE(response->headers.get() == NULL);\n+  ASSERT_TRUE(response);\n+  ASSERT_TRUE(response->headers);\n   EXPECT_TRUE(response->headers->IsKeepAlive());\n   EXPECT_EQ(407, response->headers->response_code());\n-  EXPECT_EQ(10, response->headers->GetContentLength());\n+  EXPECT_EQ(-1, response->headers->GetContentLength());\n   EXPECT_TRUE(HttpVersion(1, 1) == response->headers->GetHttpVersion());\n   EXPECT_TRUE(CheckBasicProxyAuth(response->auth_challenge.get()));\n \n@@ -2565,11 +2565,11 @@ TEST_P(HttpNetworkTransactionTest, BasicAuthProxyKeepAlive) {\n   EXPECT_EQ(OK, rv);\n \n   response = trans->GetResponseInfo();\n-  ASSERT_TRUE(response != NULL);\n-  ASSERT_FALSE(response->headers.get() == NULL);\n+  ASSERT_TRUE(response);\n+  ASSERT_TRUE(response->headers);\n   EXPECT_TRUE(response->headers->IsKeepAlive());\n   EXPECT_EQ(407, response->headers->response_code());\n-  EXPECT_EQ(10, response->headers->GetContentLength());\n+  EXPECT_EQ(-1, response->headers->GetContentLength());\n   EXPECT_TRUE(HttpVersion(1, 1) == response->headers->GetHttpVersion());\n   EXPECT_TRUE(CheckBasicProxyAuth(response->auth_challenge.get()));\n \n@@ -2603,10 +2603,11 @@ TEST_P(HttpNetworkTransactionTest, BasicAuthProxyCancelTunnel) {\n \n   // The proxy responds to the connect with a 407.\n   MockRead data_reads[] = {\n-    MockRead(\""HTTP/1.1 407 Proxy Authentication Required\\r\\n\""),\n-    MockRead(\""Proxy-Authenticate: Basic realm=\\\""MyRealm1\\\""\\r\\n\""),\n-    MockRead(\""Content-Length: 10\\r\\n\\r\\n\""),\n-    MockRead(SYNCHRONOUS, ERR_UNEXPECTED),  // Should not be reached.\n+      MockRead(\""HTTP/1.1 407 Proxy Authentication Required\\r\\n\""),\n+      MockRead(\""Proxy-Authenticate: Basic realm=\\\""MyRealm1\\\""\\r\\n\""),\n+      MockRead(\""Content-Length: 10\\r\\n\\r\\n\""),\n+      MockRead(\""0123456789\""),  // Should not be reached.\n+      MockRead(SYNCHRONOUS, ERR_UNEXPECTED),\n   };\n \n   StaticSocketDataProvider data(data_reads, arraysize(data_reads),\n@@ -2622,12 +2623,74 @@ TEST_P(HttpNetworkTransactionTest, BasicAuthProxyCancelTunnel) {\n   EXPECT_EQ(OK, rv);\n \n   const HttpResponseInfo* response = trans->GetResponseInfo();\n-  ASSERT_TRUE(response != NULL);\n+  ASSERT_TRUE(response);\n+  ASSERT_TRUE(response->headers);\n+  EXPECT_TRUE(response->headers->IsKeepAlive());\n+  EXPECT_EQ(407, response->headers->response_code());\n+  EXPECT_TRUE(HttpVersion(1, 1) == response->headers->GetHttpVersion());\n+\n+  std::string response_data;\n+  rv = ReadTransaction(trans.get(), &response_data);\n+  EXPECT_EQ(ERR_TUNNEL_CONNECTION_FAILED, rv);\n+\n+  // Flush the idle socket before the HttpNetworkTransaction goes out of scope.\n+  session->CloseAllConnections();\n+}\n+\n+// Test that we don't pass extraneous headers from the proxy's response to the\n+// caller when the proxy responds to CONNECT with 407.\n+TEST_P(HttpNetworkTransactionTest, SanitizeProxyAuthHeaders) {\n+  HttpRequestInfo request;\n+  request.method = \""GET\"";\n+  request.url = GURL(\""https://www.google.com/\"");\n+  request.load_flags = 0;\n+\n+  // Configure against proxy server \""myproxy:70\"".\n+  session_deps_.proxy_service.reset(ProxyService::CreateFixed(\""myproxy:70\""));\n+\n+  scoped_refptr<HttpNetworkSession> session(CreateSession(&session_deps_));\n+\n+  scoped_ptr<HttpTransaction> trans(\n+      new HttpNetworkTransaction(DEFAULT_PRIORITY, session.get()));\n+\n+  // Since we have proxy, should try to establish tunnel.\n+  MockWrite data_writes[] = {\n+      MockWrite(\n+          \""CONNECT www.google.com:443 HTTP/1.1\\r\\n\""\n+          \""Host: www.google.com\\r\\n\""\n+          \""Proxy-Connection: keep-alive\\r\\n\\r\\n\""),\n+  };\n+\n+  // The proxy responds to the connect with a 407.\n+  MockRead data_reads[] = {\n+      MockRead(\""HTTP/1.1 407 Proxy Authentication Required\\r\\n\""),\n+      MockRead(\""X-Foo: bar\\r\\n\""),\n+      MockRead(\""Set-Cookie: foo=bar\\r\\n\""),\n+      MockRead(\""Proxy-Authenticate: Basic realm=\\\""MyRealm1\\\""\\r\\n\""),\n+      MockRead(\""Content-Length: 10\\r\\n\\r\\n\""),\n+      MockRead(SYNCHRONOUS, ERR_UNEXPECTED),  // Should not be reached.\n+  };\n+\n+  StaticSocketDataProvider data(data_reads, arraysize(data_reads), data_writes,\n+                                arraysize(data_writes));\n+  session_deps_.socket_factory->AddSocketDataProvider(&data);\n+\n+  TestCompletionCallback callback;\n \n+  int rv = trans->Start(&request, callback.callback(), BoundNetLog());\n+  EXPECT_EQ(ERR_IO_PENDING, rv);\n+\n+  rv = callback.WaitForResult();\n+  EXPECT_EQ(OK, rv);\n+\n+  const HttpResponseInfo* response = trans->GetResponseInfo();\n+  ASSERT_TRUE(response);\n+  ASSERT_TRUE(response->headers);\n   EXPECT_TRUE(response->headers->IsKeepAlive());\n   EXPECT_EQ(407, response->headers->response_code());\n-  EXPECT_EQ(10, response->headers->GetContentLength());\n   EXPECT_TRUE(HttpVersion(1, 1) == response->headers->GetHttpVersion());\n+  EXPECT_FALSE(response->headers->HasHeader(\""X-Foo\""));\n+  EXPECT_FALSE(response->headers->HasHeader(\""Set-Cookie\""));\n \n   std::string response_data;\n   rv = ReadTransaction(trans.get(), &response_data);""}<_**next**_>{""sha"": ""97945d919341e45be655f4e0ebc9f5a5ff89fce0"", ""filename"": ""net/http/http_proxy_client_socket.cc"", ""status"": ""modified"", ""additions"": 13, ""deletions"": 11, ""changes"": 24, ""blob_url"": ""https://github.com/chromium/chromium/blob/7933c117fd16b192e70609c331641e9112af5e42/net/http/http_proxy_client_socket.cc"", ""raw_url"": ""https://github.com/chromium/chromium/raw/7933c117fd16b192e70609c331641e9112af5e42/net/http/http_proxy_client_socket.cc"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/net/http/http_proxy_client_socket.cc?ref=7933c117fd16b192e70609c331641e9112af5e42"", ""patch"": ""@@ -483,25 +483,27 @@ int HttpProxyClientSocket::DoReadHeadersComplete(int result) {\n       // sanitize the response.  This still allows a rogue HTTPS proxy to\n       // redirect an HTTPS site load to a similar-looking site, but no longer\n       // allows it to impersonate the site the user requested.\n-      if (is_https_proxy_ && SanitizeProxyRedirect(&response_, request_.url)) {\n-        bool is_connection_reused = http_stream_parser_->IsConnectionReused();\n-        redirect_has_load_timing_info_ =\n-            transport_->GetLoadTimingInfo(\n-                is_connection_reused, &redirect_load_timing_info_);\n-        transport_.reset();\n-        http_stream_parser_.reset();\n-        return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;\n+      if (!is_https_proxy_ || !SanitizeProxyRedirect(&response_)) {\n+        LogBlockedTunnelResponse();\n+        return ERR_TUNNEL_CONNECTION_FAILED;\n       }\n \n-      // We're not using an HTTPS proxy, or we couldn't sanitize the redirect.\n-      LogBlockedTunnelResponse();\n-      return ERR_TUNNEL_CONNECTION_FAILED;\n+      redirect_has_load_timing_info_ = transport_->GetLoadTimingInfo(\n+          http_stream_parser_->IsConnectionReused(),\n+          &redirect_load_timing_info_);\n+      transport_.reset();\n+      http_stream_parser_.reset();\n+      return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;\n \n     case 407:  // Proxy Authentication Required\n       // We need this status code to allow proxy authentication.  Our\n       // authentication code is smart enough to avoid being tricked by an\n       // active network attacker.\n       // The next state is intentionally not set as it should be STATE_NONE;\n+      if (!SanitizeProxyAuth(&response_)) {\n+        LogBlockedTunnelResponse();\n+        return ERR_TUNNEL_CONNECTION_FAILED;\n+      }\n       return HandleProxyAuthChallenge(auth_.get(), &response_, net_log_);\n \n     default:""}<_**next**_>{""sha"": ""3c539c6895e295a98f9645070e4258bbf78b5d73"", ""filename"": ""net/http/proxy_client_socket.cc"", ""status"": ""modified"", ""additions"": 41, ""deletions"": 10, ""changes"": 51, ""blob_url"": ""https://github.com/chromium/chromium/blob/7933c117fd16b192e70609c331641e9112af5e42/net/http/proxy_client_socket.cc"", ""raw_url"": ""https://github.com/chromium/chromium/raw/7933c117fd16b192e70609c331641e9112af5e42/net/http/proxy_client_socket.cc"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/net/http/proxy_client_socket.cc?ref=7933c117fd16b192e70609c331641e9112af5e42"", ""patch"": ""@@ -17,6 +17,20 @@\n \n namespace net {\n \n+namespace {\n+\n+void CopyHeaderValues(scoped_refptr<HttpResponseHeaders> source,\n+                      scoped_refptr<HttpResponseHeaders> dest,\n+                      const std::string& header_name) {\n+  void* iter = NULL;\n+  std::string header_value;\n+\n+  while (source->EnumerateHeader(&iter, header_name, &header_value))\n+    dest->AddHeader(header_name + \"": \"" + header_value);\n+}\n+\n+}  // namespace\n+\n // static\n void ProxyClientSocket::BuildTunnelRequest(\n     const HttpRequestInfo& request_info,\n@@ -72,22 +86,39 @@ void ProxyClientSocket::LogBlockedTunnelResponse(int http_status_code,\n }\n \n // static\n-bool ProxyClientSocket::SanitizeProxyRedirect(HttpResponseInfo* response,\n-                                              const GURL& url) {\n+bool ProxyClientSocket::SanitizeProxyAuth(HttpResponseInfo* response) {\n+  DCHECK(response && response->headers.get());\n+\n+  scoped_refptr<HttpResponseHeaders> old_headers = response->headers;\n+\n+  const char kHeaders[] = \""HTTP/1.1 407 Proxy Authentication Required\\n\\n\"";\n+  scoped_refptr<HttpResponseHeaders> new_headers = new HttpResponseHeaders(\n+      HttpUtil::AssembleRawHeaders(kHeaders, arraysize(kHeaders)));\n+\n+  new_headers->ReplaceStatusLine(old_headers->GetStatusLine());\n+  CopyHeaderValues(old_headers, new_headers, \""Connection\"");\n+  CopyHeaderValues(old_headers, new_headers, \""Proxy-Authenticate\"");\n+\n+  response->headers = new_headers;\n+  return true;\n+}\n+\n+// static\n+bool ProxyClientSocket::SanitizeProxyRedirect(HttpResponseInfo* response) {\n   DCHECK(response && response->headers.get());\n \n   std::string location;\n   if (!response->headers->IsRedirect(&location))\n     return false;\n \n-  // Return minimal headers; set \""Content-length: 0\"" to ignore response body.\n-  std::string fake_response_headers =\n-      base::StringPrintf(\""HTTP/1.0 302 Found\\n\""\n-                         \""Location: %s\\n\""\n-                         \""Content-length: 0\\n\""\n-                         \""Connection: close\\n\""\n-                         \""\\n\"",\n-                         location.c_str());\n+  // Return minimal headers; set \""Content-Length: 0\"" to ignore response body.\n+  std::string fake_response_headers = base::StringPrintf(\n+      \""HTTP/1.0 302 Found\\n\""\n+      \""Location: %s\\n\""\n+      \""Content-Length: 0\\n\""\n+      \""Connection: close\\n\""\n+      \""\\n\"",\n+      location.c_str());\n   std::string raw_headers =\n       HttpUtil::AssembleRawHeaders(fake_response_headers.data(),\n                                    fake_response_headers.length());""}<_**next**_>{""sha"": ""f3347c8972e14677a15b1841c5de9dd65389124b"", ""filename"": ""net/http/proxy_client_socket.h"", ""status"": ""modified"", ""additions"": 9, ""deletions"": 3, ""changes"": 12, ""blob_url"": ""https://github.com/chromium/chromium/blob/7933c117fd16b192e70609c331641e9112af5e42/net/http/proxy_client_socket.h"", ""raw_url"": ""https://github.com/chromium/chromium/raw/7933c117fd16b192e70609c331641e9112af5e42/net/http/proxy_client_socket.h"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/net/http/proxy_client_socket.h?ref=7933c117fd16b192e70609c331641e9112af5e42"", ""patch"": ""@@ -74,13 +74,19 @@ class NET_EXPORT_PRIVATE ProxyClientSocket : public StreamSocket {\n                                        const GURL& url,\n                                        bool is_https_proxy);\n \n+  // When a proxy authentication response is received during tunnel\n+  // construction, this method should be called to strip everything\n+  // but the auth header from the redirect response.  If it returns\n+  // false, the response should be discarded and tunnel construction should\n+  // fail.\n+  static bool SanitizeProxyAuth(HttpResponseInfo* response);\n+\n   // When a redirect (e.g. 302 response) is received during tunnel\n   // construction, this method should be called to strip everything\n   // but the Location header from the redirect response.  If it returns\n   // false, the response should be discarded and tunnel construction should\n-  // fail.  |url| is for logging purposes.\n-  static bool SanitizeProxyRedirect(HttpResponseInfo* response,\n-                                    const GURL& url);\n+  // fail.\n+  static bool SanitizeProxyRedirect(HttpResponseInfo* response);\n \n  private:\n   DISALLOW_COPY_AND_ASSIGN(ProxyClientSocket);""}<_**next**_>{""sha"": ""661cfd99a7be6a60fe18edb209d21d33a21160ee"", ""filename"": ""net/spdy/spdy_proxy_client_socket.cc"", ""status"": ""modified"", ""additions"": 12, ""deletions"": 8, ""changes"": 20, ""blob_url"": ""https://github.com/chromium/chromium/blob/7933c117fd16b192e70609c331641e9112af5e42/net/spdy/spdy_proxy_client_socket.cc"", ""raw_url"": ""https://github.com/chromium/chromium/raw/7933c117fd16b192e70609c331641e9112af5e42/net/spdy/spdy_proxy_client_socket.cc"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/net/spdy/spdy_proxy_client_socket.cc?ref=7933c117fd16b192e70609c331641e9112af5e42"", ""patch"": ""@@ -414,20 +414,24 @@ int SpdyProxyClientSocket::DoReadReplyComplete(int result) {\n     case 302:  // Found / Moved Temporarily\n       // Try to return a sanitized response so we can follow auth redirects.\n       // If we can't, fail the tunnel connection.\n-      if (SanitizeProxyRedirect(&response_, request_.url)) {\n-        redirect_has_load_timing_info_ =\n-            spdy_stream_->GetLoadTimingInfo(&redirect_load_timing_info_);\n-        // Note that this triggers a RST_STREAM_CANCEL.\n-        spdy_stream_->DetachDelegate();\n-        next_state_ = STATE_DISCONNECTED;\n-        return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;\n-      } else {\n+      if (!SanitizeProxyRedirect(&response_)) {\n         LogBlockedTunnelResponse();\n         return ERR_TUNNEL_CONNECTION_FAILED;\n       }\n \n+      redirect_has_load_timing_info_ =\n+          spdy_stream_->GetLoadTimingInfo(&redirect_load_timing_info_);\n+      // Note that this triggers a RST_STREAM_CANCEL.\n+      spdy_stream_->DetachDelegate();\n+      next_state_ = STATE_DISCONNECTED;\n+      return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;\n+\n     case 407:  // Proxy Authentication Required\n       next_state_ = STATE_OPEN;\n+      if (!SanitizeProxyAuth(&response_)) {\n+        LogBlockedTunnelResponse();\n+        return ERR_TUNNEL_CONNECTION_FAILED;\n+      }\n       return HandleProxyAuthChallenge(auth_.get(), &response_, net_log_);\n \n     default:""}","int HttpProxyClientSocket::DoReadHeadersComplete(int result) {
  if (result < 0)
    return result;

  if (response_.headers->GetParsedHttpVersion() < HttpVersion(1, 0))
    return ERR_TUNNEL_CONNECTION_FAILED;

  net_log_.AddEvent(
      NetLog::TYPE_HTTP_TRANSACTION_READ_TUNNEL_RESPONSE_HEADERS,
      base::Bind(&HttpResponseHeaders::NetLogCallback, response_.headers));

  if (proxy_delegate_) {
    proxy_delegate_->OnTunnelHeadersReceived(
        HostPortPair::FromURL(request_.url),
        proxy_server_,
        *response_.headers);
  }

  switch (response_.headers->response_code()) {
    case 200:  // OK
      if (http_stream_parser_->IsMoreDataBuffered())
        return ERR_TUNNEL_CONNECTION_FAILED;

      next_state_ = STATE_DONE;
      return OK;


    case 302:  // Found / Moved Temporarily
      if (!is_https_proxy_ || !SanitizeProxyRedirect(&response_)) {
        LogBlockedTunnelResponse();
        return ERR_TUNNEL_CONNECTION_FAILED;
       }
 
      redirect_has_load_timing_info_ = transport_->GetLoadTimingInfo(
          http_stream_parser_->IsConnectionReused(),
          &redirect_load_timing_info_);
      transport_.reset();
      http_stream_parser_.reset();
      return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;
 
     case 407:  // Proxy Authentication Required
      if (!SanitizeProxyAuth(&response_)) {
        LogBlockedTunnelResponse();
        return ERR_TUNNEL_CONNECTION_FAILED;
      }
       return HandleProxyAuthChallenge(auth_.get(), &response_, net_log_);
 
     default:
      LogBlockedTunnelResponse();
      return ERR_TUNNEL_CONNECTION_FAILED;
  }
}
","int HttpProxyClientSocket::DoReadHeadersComplete(int result) {
  if (result < 0)
    return result;

  if (response_.headers->GetParsedHttpVersion() < HttpVersion(1, 0))
    return ERR_TUNNEL_CONNECTION_FAILED;

  net_log_.AddEvent(
      NetLog::TYPE_HTTP_TRANSACTION_READ_TUNNEL_RESPONSE_HEADERS,
      base::Bind(&HttpResponseHeaders::NetLogCallback, response_.headers));

  if (proxy_delegate_) {
    proxy_delegate_->OnTunnelHeadersReceived(
        HostPortPair::FromURL(request_.url),
        proxy_server_,
        *response_.headers);
  }

  switch (response_.headers->response_code()) {
    case 200:  // OK
      if (http_stream_parser_->IsMoreDataBuffered())
        return ERR_TUNNEL_CONNECTION_FAILED;

      next_state_ = STATE_DONE;
      return OK;


    case 302:  // Found / Moved Temporarily
      if (is_https_proxy_ && SanitizeProxyRedirect(&response_, request_.url)) {
        bool is_connection_reused = http_stream_parser_->IsConnectionReused();
        redirect_has_load_timing_info_ =
            transport_->GetLoadTimingInfo(
                is_connection_reused, &redirect_load_timing_info_);
        transport_.reset();
        http_stream_parser_.reset();
        return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;
       }
 
      LogBlockedTunnelResponse();
      return ERR_TUNNEL_CONNECTION_FAILED;
 
     case 407:  // Proxy Authentication Required
       return HandleProxyAuthChallenge(auth_.get(), &response_, net_log_);
 
     default:
      LogBlockedTunnelResponse();
      return ERR_TUNNEL_CONNECTION_FAILED;
  }
}
",C,"      if (!is_https_proxy_ || !SanitizeProxyRedirect(&response_)) {
        LogBlockedTunnelResponse();
        return ERR_TUNNEL_CONNECTION_FAILED;
      redirect_has_load_timing_info_ = transport_->GetLoadTimingInfo(
          http_stream_parser_->IsConnectionReused(),
          &redirect_load_timing_info_);
      transport_.reset();
      http_stream_parser_.reset();
      return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;
      if (!SanitizeProxyAuth(&response_)) {
        LogBlockedTunnelResponse();
        return ERR_TUNNEL_CONNECTION_FAILED;
      }
","      if (is_https_proxy_ && SanitizeProxyRedirect(&response_, request_.url)) {
        bool is_connection_reused = http_stream_parser_->IsConnectionReused();
        redirect_has_load_timing_info_ =
            transport_->GetLoadTimingInfo(
                is_connection_reused, &redirect_load_timing_info_);
        transport_.reset();
        http_stream_parser_.reset();
        return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;
      LogBlockedTunnelResponse();
      return ERR_TUNNEL_CONNECTION_FAILED;
",,"@@ -483,25 +483,27 @@ int HttpProxyClientSocket::DoReadHeadersComplete(int result) {
       // sanitize the response.  This still allows a rogue HTTPS proxy to
       // redirect an HTTPS site load to a similar-looking site, but no longer
       // allows it to impersonate the site the user requested.
-      if (is_https_proxy_ && SanitizeProxyRedirect(&response_, request_.url)) {
-        bool is_connection_reused = http_stream_parser_->IsConnectionReused();
-        redirect_has_load_timing_info_ =
-            transport_->GetLoadTimingInfo(
-                is_connection_reused, &redirect_load_timing_info_);
-        transport_.reset();
-        http_stream_parser_.reset();
-        return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;
+      if (!is_https_proxy_ || !SanitizeProxyRedirect(&response_)) {
+        LogBlockedTunnelResponse();
+        return ERR_TUNNEL_CONNECTION_FAILED;
       }
 
-      // We're not using an HTTPS proxy, or we couldn't sanitize the redirect.
-      LogBlockedTunnelResponse();
-      return ERR_TUNNEL_CONNECTION_FAILED;
+      redirect_has_load_timing_info_ = transport_->GetLoadTimingInfo(
+          http_stream_parser_->IsConnectionReused(),
+          &redirect_load_timing_info_);
+      transport_.reset();
+      http_stream_parser_.reset();
+      return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;
 
     case 407:  // Proxy Authentication Required
       // We need this status code to allow proxy authentication.  Our
       // authentication code is smart enough to avoid being tricked by an
       // active network attacker.
       // The next state is intentionally not set as it should be STATE_NONE;
+      if (!SanitizeProxyAuth(&response_)) {
+        LogBlockedTunnelResponse();
+        return ERR_TUNNEL_CONNECTION_FAILED;
+      }
       return HandleProxyAuthChallenge(auth_.get(), &response_, net_log_);
 
     default:",Chrome,7933c117fd16b192e70609c331641e9112af5e42,8249145b13b4893f0de507cbe26de72dd7ffbd79,1,"int HttpProxyClientSocket::DoReadHeadersComplete(int result) {
  if (result < 0)
    return result;

  // Require the ""HTTP/1.x"" status line for SSL CONNECT.
  if (response_.headers->GetParsedHttpVersion() < HttpVersion(1, 0))
    return ERR_TUNNEL_CONNECTION_FAILED;

  net_log_.AddEvent(
      NetLog::TYPE_HTTP_TRANSACTION_READ_TUNNEL_RESPONSE_HEADERS,
      base::Bind(&HttpResponseHeaders::NetLogCallback, response_.headers));

  if (proxy_delegate_) {
    proxy_delegate_->OnTunnelHeadersReceived(
        HostPortPair::FromURL(request_.url),
        proxy_server_,
        *response_.headers);
  }

  switch (response_.headers->response_code()) {
    case 200:  // OK
      if (http_stream_parser_->IsMoreDataBuffered())
        // The proxy sent extraneous data after the headers.
        return ERR_TUNNEL_CONNECTION_FAILED;

      next_state_ = STATE_DONE;
      return OK;

      // We aren't able to CONNECT to the remote host through the proxy.  We
      // need to be very suspicious about the response because an active network
      // attacker can force us into this state by masquerading as the proxy.
      // The only safe thing to do here is to fail the connection because our
      // client is expecting an SSL protected response.
      // See http://crbug.com/7338.

    case 302:  // Found / Moved Temporarily
      // Attempt to follow redirects from HTTPS proxies, but only if we can
       // sanitize the response.  This still allows a rogue HTTPS proxy to
       // redirect an HTTPS site load to a similar-looking site, but no longer
       // allows it to impersonate the site the user requested.
//flaw_line_below:
      if (is_https_proxy_ && SanitizeProxyRedirect(&response_, request_.url)) {
//flaw_line_below:
        bool is_connection_reused = http_stream_parser_->IsConnectionReused();
//flaw_line_below:
        redirect_has_load_timing_info_ =
//flaw_line_below:
            transport_->GetLoadTimingInfo(
//flaw_line_below:
                is_connection_reused, &redirect_load_timing_info_);
//flaw_line_below:
        transport_.reset();
//flaw_line_below:
        http_stream_parser_.reset();
//flaw_line_below:
        return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;
//fix_flaw_line_below:
//      if (!is_https_proxy_ || !SanitizeProxyRedirect(&response_)) {
//fix_flaw_line_below:
//        LogBlockedTunnelResponse();
//fix_flaw_line_below:
//        return ERR_TUNNEL_CONNECTION_FAILED;
       }
 
//flaw_line_below:
      // We're not using an HTTPS proxy, or we couldn't sanitize the redirect.
//flaw_line_below:
      LogBlockedTunnelResponse();
//flaw_line_below:
      return ERR_TUNNEL_CONNECTION_FAILED;
//fix_flaw_line_below:
//      redirect_has_load_timing_info_ = transport_->GetLoadTimingInfo(
//fix_flaw_line_below:
//          http_stream_parser_->IsConnectionReused(),
//fix_flaw_line_below:
//          &redirect_load_timing_info_);
//fix_flaw_line_below:
//      transport_.reset();
//fix_flaw_line_below:
//      http_stream_parser_.reset();
//fix_flaw_line_below:
//      return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;
 
     case 407:  // Proxy Authentication Required
       // We need this status code to allow proxy authentication.  Our
       // authentication code is smart enough to avoid being tricked by an
       // active network attacker.
       // The next state is intentionally not set as it should be STATE_NONE;
//fix_flaw_line_below:
//      if (!SanitizeProxyAuth(&response_)) {
//fix_flaw_line_below:
//        LogBlockedTunnelResponse();
//fix_flaw_line_below:
//        return ERR_TUNNEL_CONNECTION_FAILED;
//fix_flaw_line_below:
//      }
       return HandleProxyAuthChallenge(auth_.get(), &response_, net_log_);
 
     default:
      // Ignore response to avoid letting the proxy impersonate the target
      // server.  (See http://crbug.com/137891.)
      // We lose something by doing this.  We have seen proxy 403, 404, and
      // 501 response bodies that contain a useful error message.  For
      // example, Squid uses a 404 response to report the DNS error: ""The
      // domain name does not exist.""
      LogBlockedTunnelResponse();
      return ERR_TUNNEL_CONNECTION_FAILED;
  }
}
"
8213,185949,,Remote,Not required,,CVE-2015-1229,https://www.cvedetails.com/cve/CVE-2015-1229/,CWE-19,Low,,Partial,,2015-03-08,5.0,"net/http/proxy_client_socket.cc in Google Chrome before 41.0.2272.76 does not properly handle a 407 (aka Proxy Authentication Required) HTTP status code accompanied by a Set-Cookie header, which allows remote proxy servers to conduct cookie-injection attacks via a crafted response.",2016-12-21,,26,https://github.com/chromium/chromium/commit/7933c117fd16b192e70609c331641e9112af5e42,7933c117fd16b192e70609c331641e9112af5e42,"Sanitize headers in Proxy Authentication Required responses

BUG=431504

Review URL: https://codereview.chromium.org/769043003

Cr-Commit-Position: refs/heads/master@{#310014}",8,net/http/proxy_client_socket.cc,"{""sha"": ""21a8c008e252fa4053b397be884c49cf9051e618"", ""filename"": ""net/http/http_network_transaction_unittest.cc"", ""status"": ""modified"", ""additions"": 75, ""deletions"": 12, ""changes"": 87, ""blob_url"": ""https://github.com/chromium/chromium/blob/7933c117fd16b192e70609c331641e9112af5e42/net/http/http_network_transaction_unittest.cc"", ""raw_url"": ""https://github.com/chromium/chromium/raw/7933c117fd16b192e70609c331641e9112af5e42/net/http/http_network_transaction_unittest.cc"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/net/http/http_network_transaction_unittest.cc?ref=7933c117fd16b192e70609c331641e9112af5e42"", ""patch"": ""@@ -2546,11 +2546,11 @@ TEST_P(HttpNetworkTransactionTest, BasicAuthProxyKeepAlive) {\n       NetLog::PHASE_NONE);\n \n   const HttpResponseInfo* response = trans->GetResponseInfo();\n-  ASSERT_TRUE(response != NULL);\n-  ASSERT_FALSE(response->headers.get() == NULL);\n+  ASSERT_TRUE(response);\n+  ASSERT_TRUE(response->headers);\n   EXPECT_TRUE(response->headers->IsKeepAlive());\n   EXPECT_EQ(407, response->headers->response_code());\n-  EXPECT_EQ(10, response->headers->GetContentLength());\n+  EXPECT_EQ(-1, response->headers->GetContentLength());\n   EXPECT_TRUE(HttpVersion(1, 1) == response->headers->GetHttpVersion());\n   EXPECT_TRUE(CheckBasicProxyAuth(response->auth_challenge.get()));\n \n@@ -2565,11 +2565,11 @@ TEST_P(HttpNetworkTransactionTest, BasicAuthProxyKeepAlive) {\n   EXPECT_EQ(OK, rv);\n \n   response = trans->GetResponseInfo();\n-  ASSERT_TRUE(response != NULL);\n-  ASSERT_FALSE(response->headers.get() == NULL);\n+  ASSERT_TRUE(response);\n+  ASSERT_TRUE(response->headers);\n   EXPECT_TRUE(response->headers->IsKeepAlive());\n   EXPECT_EQ(407, response->headers->response_code());\n-  EXPECT_EQ(10, response->headers->GetContentLength());\n+  EXPECT_EQ(-1, response->headers->GetContentLength());\n   EXPECT_TRUE(HttpVersion(1, 1) == response->headers->GetHttpVersion());\n   EXPECT_TRUE(CheckBasicProxyAuth(response->auth_challenge.get()));\n \n@@ -2603,10 +2603,11 @@ TEST_P(HttpNetworkTransactionTest, BasicAuthProxyCancelTunnel) {\n \n   // The proxy responds to the connect with a 407.\n   MockRead data_reads[] = {\n-    MockRead(\""HTTP/1.1 407 Proxy Authentication Required\\r\\n\""),\n-    MockRead(\""Proxy-Authenticate: Basic realm=\\\""MyRealm1\\\""\\r\\n\""),\n-    MockRead(\""Content-Length: 10\\r\\n\\r\\n\""),\n-    MockRead(SYNCHRONOUS, ERR_UNEXPECTED),  // Should not be reached.\n+      MockRead(\""HTTP/1.1 407 Proxy Authentication Required\\r\\n\""),\n+      MockRead(\""Proxy-Authenticate: Basic realm=\\\""MyRealm1\\\""\\r\\n\""),\n+      MockRead(\""Content-Length: 10\\r\\n\\r\\n\""),\n+      MockRead(\""0123456789\""),  // Should not be reached.\n+      MockRead(SYNCHRONOUS, ERR_UNEXPECTED),\n   };\n \n   StaticSocketDataProvider data(data_reads, arraysize(data_reads),\n@@ -2622,12 +2623,74 @@ TEST_P(HttpNetworkTransactionTest, BasicAuthProxyCancelTunnel) {\n   EXPECT_EQ(OK, rv);\n \n   const HttpResponseInfo* response = trans->GetResponseInfo();\n-  ASSERT_TRUE(response != NULL);\n+  ASSERT_TRUE(response);\n+  ASSERT_TRUE(response->headers);\n+  EXPECT_TRUE(response->headers->IsKeepAlive());\n+  EXPECT_EQ(407, response->headers->response_code());\n+  EXPECT_TRUE(HttpVersion(1, 1) == response->headers->GetHttpVersion());\n+\n+  std::string response_data;\n+  rv = ReadTransaction(trans.get(), &response_data);\n+  EXPECT_EQ(ERR_TUNNEL_CONNECTION_FAILED, rv);\n+\n+  // Flush the idle socket before the HttpNetworkTransaction goes out of scope.\n+  session->CloseAllConnections();\n+}\n+\n+// Test that we don't pass extraneous headers from the proxy's response to the\n+// caller when the proxy responds to CONNECT with 407.\n+TEST_P(HttpNetworkTransactionTest, SanitizeProxyAuthHeaders) {\n+  HttpRequestInfo request;\n+  request.method = \""GET\"";\n+  request.url = GURL(\""https://www.google.com/\"");\n+  request.load_flags = 0;\n+\n+  // Configure against proxy server \""myproxy:70\"".\n+  session_deps_.proxy_service.reset(ProxyService::CreateFixed(\""myproxy:70\""));\n+\n+  scoped_refptr<HttpNetworkSession> session(CreateSession(&session_deps_));\n+\n+  scoped_ptr<HttpTransaction> trans(\n+      new HttpNetworkTransaction(DEFAULT_PRIORITY, session.get()));\n+\n+  // Since we have proxy, should try to establish tunnel.\n+  MockWrite data_writes[] = {\n+      MockWrite(\n+          \""CONNECT www.google.com:443 HTTP/1.1\\r\\n\""\n+          \""Host: www.google.com\\r\\n\""\n+          \""Proxy-Connection: keep-alive\\r\\n\\r\\n\""),\n+  };\n+\n+  // The proxy responds to the connect with a 407.\n+  MockRead data_reads[] = {\n+      MockRead(\""HTTP/1.1 407 Proxy Authentication Required\\r\\n\""),\n+      MockRead(\""X-Foo: bar\\r\\n\""),\n+      MockRead(\""Set-Cookie: foo=bar\\r\\n\""),\n+      MockRead(\""Proxy-Authenticate: Basic realm=\\\""MyRealm1\\\""\\r\\n\""),\n+      MockRead(\""Content-Length: 10\\r\\n\\r\\n\""),\n+      MockRead(SYNCHRONOUS, ERR_UNEXPECTED),  // Should not be reached.\n+  };\n+\n+  StaticSocketDataProvider data(data_reads, arraysize(data_reads), data_writes,\n+                                arraysize(data_writes));\n+  session_deps_.socket_factory->AddSocketDataProvider(&data);\n+\n+  TestCompletionCallback callback;\n \n+  int rv = trans->Start(&request, callback.callback(), BoundNetLog());\n+  EXPECT_EQ(ERR_IO_PENDING, rv);\n+\n+  rv = callback.WaitForResult();\n+  EXPECT_EQ(OK, rv);\n+\n+  const HttpResponseInfo* response = trans->GetResponseInfo();\n+  ASSERT_TRUE(response);\n+  ASSERT_TRUE(response->headers);\n   EXPECT_TRUE(response->headers->IsKeepAlive());\n   EXPECT_EQ(407, response->headers->response_code());\n-  EXPECT_EQ(10, response->headers->GetContentLength());\n   EXPECT_TRUE(HttpVersion(1, 1) == response->headers->GetHttpVersion());\n+  EXPECT_FALSE(response->headers->HasHeader(\""X-Foo\""));\n+  EXPECT_FALSE(response->headers->HasHeader(\""Set-Cookie\""));\n \n   std::string response_data;\n   rv = ReadTransaction(trans.get(), &response_data);""}<_**next**_>{""sha"": ""97945d919341e45be655f4e0ebc9f5a5ff89fce0"", ""filename"": ""net/http/http_proxy_client_socket.cc"", ""status"": ""modified"", ""additions"": 13, ""deletions"": 11, ""changes"": 24, ""blob_url"": ""https://github.com/chromium/chromium/blob/7933c117fd16b192e70609c331641e9112af5e42/net/http/http_proxy_client_socket.cc"", ""raw_url"": ""https://github.com/chromium/chromium/raw/7933c117fd16b192e70609c331641e9112af5e42/net/http/http_proxy_client_socket.cc"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/net/http/http_proxy_client_socket.cc?ref=7933c117fd16b192e70609c331641e9112af5e42"", ""patch"": ""@@ -483,25 +483,27 @@ int HttpProxyClientSocket::DoReadHeadersComplete(int result) {\n       // sanitize the response.  This still allows a rogue HTTPS proxy to\n       // redirect an HTTPS site load to a similar-looking site, but no longer\n       // allows it to impersonate the site the user requested.\n-      if (is_https_proxy_ && SanitizeProxyRedirect(&response_, request_.url)) {\n-        bool is_connection_reused = http_stream_parser_->IsConnectionReused();\n-        redirect_has_load_timing_info_ =\n-            transport_->GetLoadTimingInfo(\n-                is_connection_reused, &redirect_load_timing_info_);\n-        transport_.reset();\n-        http_stream_parser_.reset();\n-        return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;\n+      if (!is_https_proxy_ || !SanitizeProxyRedirect(&response_)) {\n+        LogBlockedTunnelResponse();\n+        return ERR_TUNNEL_CONNECTION_FAILED;\n       }\n \n-      // We're not using an HTTPS proxy, or we couldn't sanitize the redirect.\n-      LogBlockedTunnelResponse();\n-      return ERR_TUNNEL_CONNECTION_FAILED;\n+      redirect_has_load_timing_info_ = transport_->GetLoadTimingInfo(\n+          http_stream_parser_->IsConnectionReused(),\n+          &redirect_load_timing_info_);\n+      transport_.reset();\n+      http_stream_parser_.reset();\n+      return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;\n \n     case 407:  // Proxy Authentication Required\n       // We need this status code to allow proxy authentication.  Our\n       // authentication code is smart enough to avoid being tricked by an\n       // active network attacker.\n       // The next state is intentionally not set as it should be STATE_NONE;\n+      if (!SanitizeProxyAuth(&response_)) {\n+        LogBlockedTunnelResponse();\n+        return ERR_TUNNEL_CONNECTION_FAILED;\n+      }\n       return HandleProxyAuthChallenge(auth_.get(), &response_, net_log_);\n \n     default:""}<_**next**_>{""sha"": ""3c539c6895e295a98f9645070e4258bbf78b5d73"", ""filename"": ""net/http/proxy_client_socket.cc"", ""status"": ""modified"", ""additions"": 41, ""deletions"": 10, ""changes"": 51, ""blob_url"": ""https://github.com/chromium/chromium/blob/7933c117fd16b192e70609c331641e9112af5e42/net/http/proxy_client_socket.cc"", ""raw_url"": ""https://github.com/chromium/chromium/raw/7933c117fd16b192e70609c331641e9112af5e42/net/http/proxy_client_socket.cc"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/net/http/proxy_client_socket.cc?ref=7933c117fd16b192e70609c331641e9112af5e42"", ""patch"": ""@@ -17,6 +17,20 @@\n \n namespace net {\n \n+namespace {\n+\n+void CopyHeaderValues(scoped_refptr<HttpResponseHeaders> source,\n+                      scoped_refptr<HttpResponseHeaders> dest,\n+                      const std::string& header_name) {\n+  void* iter = NULL;\n+  std::string header_value;\n+\n+  while (source->EnumerateHeader(&iter, header_name, &header_value))\n+    dest->AddHeader(header_name + \"": \"" + header_value);\n+}\n+\n+}  // namespace\n+\n // static\n void ProxyClientSocket::BuildTunnelRequest(\n     const HttpRequestInfo& request_info,\n@@ -72,22 +86,39 @@ void ProxyClientSocket::LogBlockedTunnelResponse(int http_status_code,\n }\n \n // static\n-bool ProxyClientSocket::SanitizeProxyRedirect(HttpResponseInfo* response,\n-                                              const GURL& url) {\n+bool ProxyClientSocket::SanitizeProxyAuth(HttpResponseInfo* response) {\n+  DCHECK(response && response->headers.get());\n+\n+  scoped_refptr<HttpResponseHeaders> old_headers = response->headers;\n+\n+  const char kHeaders[] = \""HTTP/1.1 407 Proxy Authentication Required\\n\\n\"";\n+  scoped_refptr<HttpResponseHeaders> new_headers = new HttpResponseHeaders(\n+      HttpUtil::AssembleRawHeaders(kHeaders, arraysize(kHeaders)));\n+\n+  new_headers->ReplaceStatusLine(old_headers->GetStatusLine());\n+  CopyHeaderValues(old_headers, new_headers, \""Connection\"");\n+  CopyHeaderValues(old_headers, new_headers, \""Proxy-Authenticate\"");\n+\n+  response->headers = new_headers;\n+  return true;\n+}\n+\n+// static\n+bool ProxyClientSocket::SanitizeProxyRedirect(HttpResponseInfo* response) {\n   DCHECK(response && response->headers.get());\n \n   std::string location;\n   if (!response->headers->IsRedirect(&location))\n     return false;\n \n-  // Return minimal headers; set \""Content-length: 0\"" to ignore response body.\n-  std::string fake_response_headers =\n-      base::StringPrintf(\""HTTP/1.0 302 Found\\n\""\n-                         \""Location: %s\\n\""\n-                         \""Content-length: 0\\n\""\n-                         \""Connection: close\\n\""\n-                         \""\\n\"",\n-                         location.c_str());\n+  // Return minimal headers; set \""Content-Length: 0\"" to ignore response body.\n+  std::string fake_response_headers = base::StringPrintf(\n+      \""HTTP/1.0 302 Found\\n\""\n+      \""Location: %s\\n\""\n+      \""Content-Length: 0\\n\""\n+      \""Connection: close\\n\""\n+      \""\\n\"",\n+      location.c_str());\n   std::string raw_headers =\n       HttpUtil::AssembleRawHeaders(fake_response_headers.data(),\n                                    fake_response_headers.length());""}<_**next**_>{""sha"": ""f3347c8972e14677a15b1841c5de9dd65389124b"", ""filename"": ""net/http/proxy_client_socket.h"", ""status"": ""modified"", ""additions"": 9, ""deletions"": 3, ""changes"": 12, ""blob_url"": ""https://github.com/chromium/chromium/blob/7933c117fd16b192e70609c331641e9112af5e42/net/http/proxy_client_socket.h"", ""raw_url"": ""https://github.com/chromium/chromium/raw/7933c117fd16b192e70609c331641e9112af5e42/net/http/proxy_client_socket.h"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/net/http/proxy_client_socket.h?ref=7933c117fd16b192e70609c331641e9112af5e42"", ""patch"": ""@@ -74,13 +74,19 @@ class NET_EXPORT_PRIVATE ProxyClientSocket : public StreamSocket {\n                                        const GURL& url,\n                                        bool is_https_proxy);\n \n+  // When a proxy authentication response is received during tunnel\n+  // construction, this method should be called to strip everything\n+  // but the auth header from the redirect response.  If it returns\n+  // false, the response should be discarded and tunnel construction should\n+  // fail.\n+  static bool SanitizeProxyAuth(HttpResponseInfo* response);\n+\n   // When a redirect (e.g. 302 response) is received during tunnel\n   // construction, this method should be called to strip everything\n   // but the Location header from the redirect response.  If it returns\n   // false, the response should be discarded and tunnel construction should\n-  // fail.  |url| is for logging purposes.\n-  static bool SanitizeProxyRedirect(HttpResponseInfo* response,\n-                                    const GURL& url);\n+  // fail.\n+  static bool SanitizeProxyRedirect(HttpResponseInfo* response);\n \n  private:\n   DISALLOW_COPY_AND_ASSIGN(ProxyClientSocket);""}<_**next**_>{""sha"": ""661cfd99a7be6a60fe18edb209d21d33a21160ee"", ""filename"": ""net/spdy/spdy_proxy_client_socket.cc"", ""status"": ""modified"", ""additions"": 12, ""deletions"": 8, ""changes"": 20, ""blob_url"": ""https://github.com/chromium/chromium/blob/7933c117fd16b192e70609c331641e9112af5e42/net/spdy/spdy_proxy_client_socket.cc"", ""raw_url"": ""https://github.com/chromium/chromium/raw/7933c117fd16b192e70609c331641e9112af5e42/net/spdy/spdy_proxy_client_socket.cc"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/net/spdy/spdy_proxy_client_socket.cc?ref=7933c117fd16b192e70609c331641e9112af5e42"", ""patch"": ""@@ -414,20 +414,24 @@ int SpdyProxyClientSocket::DoReadReplyComplete(int result) {\n     case 302:  // Found / Moved Temporarily\n       // Try to return a sanitized response so we can follow auth redirects.\n       // If we can't, fail the tunnel connection.\n-      if (SanitizeProxyRedirect(&response_, request_.url)) {\n-        redirect_has_load_timing_info_ =\n-            spdy_stream_->GetLoadTimingInfo(&redirect_load_timing_info_);\n-        // Note that this triggers a RST_STREAM_CANCEL.\n-        spdy_stream_->DetachDelegate();\n-        next_state_ = STATE_DISCONNECTED;\n-        return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;\n-      } else {\n+      if (!SanitizeProxyRedirect(&response_)) {\n         LogBlockedTunnelResponse();\n         return ERR_TUNNEL_CONNECTION_FAILED;\n       }\n \n+      redirect_has_load_timing_info_ =\n+          spdy_stream_->GetLoadTimingInfo(&redirect_load_timing_info_);\n+      // Note that this triggers a RST_STREAM_CANCEL.\n+      spdy_stream_->DetachDelegate();\n+      next_state_ = STATE_DISCONNECTED;\n+      return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;\n+\n     case 407:  // Proxy Authentication Required\n       next_state_ = STATE_OPEN;\n+      if (!SanitizeProxyAuth(&response_)) {\n+        LogBlockedTunnelResponse();\n+        return ERR_TUNNEL_CONNECTION_FAILED;\n+      }\n       return HandleProxyAuthChallenge(auth_.get(), &response_, net_log_);\n \n     default:""}","bool ProxyClientSocket::SanitizeProxyRedirect(HttpResponseInfo* response,
bool ProxyClientSocket::SanitizeProxyAuth(HttpResponseInfo* response) {
  DCHECK(response && response->headers.get());

  scoped_refptr<HttpResponseHeaders> old_headers = response->headers;

  const char kHeaders[] = ""HTTP/1.1 407 Proxy Authentication Required\n\n"";
  scoped_refptr<HttpResponseHeaders> new_headers = new HttpResponseHeaders(
      HttpUtil::AssembleRawHeaders(kHeaders, arraysize(kHeaders)));

  new_headers->ReplaceStatusLine(old_headers->GetStatusLine());
  CopyHeaderValues(old_headers, new_headers, ""Connection"");
  CopyHeaderValues(old_headers, new_headers, ""Proxy-Authenticate"");

  response->headers = new_headers;
  return true;
}

//// static
bool ProxyClientSocket::SanitizeProxyRedirect(HttpResponseInfo* response) {
   DCHECK(response && response->headers.get());
 
   std::string location;
   if (!response->headers->IsRedirect(&location))
     return false;
 
  // Return minimal headers; set ""Content-Length: 0"" to ignore response body.
  std::string fake_response_headers = base::StringPrintf(
      ""HTTP/1.0 302 Found\n""
      ""Location: %s\n""
      ""Content-Length: 0\n""
      ""Connection: close\n""
      ""\n"",
      location.c_str());
   std::string raw_headers =
       HttpUtil::AssembleRawHeaders(fake_response_headers.data(),
                                    fake_response_headers.length());
  response->headers = new HttpResponseHeaders(raw_headers);

  return true;
}
","bool ProxyClientSocket::SanitizeProxyRedirect(HttpResponseInfo* response,
                                              const GURL& url) {
//// static
   DCHECK(response && response->headers.get());
 
   std::string location;
   if (!response->headers->IsRedirect(&location))
     return false;
 
  std::string fake_response_headers =
      base::StringPrintf(""HTTP/1.0 302 Found\n""
                         ""Location: %s\n""
                         ""Content-length: 0\n""
                         ""Connection: close\n""
                         ""\n"",
                         location.c_str());
   std::string raw_headers =
       HttpUtil::AssembleRawHeaders(fake_response_headers.data(),
                                    fake_response_headers.length());
  response->headers = new HttpResponseHeaders(raw_headers);

  return true;
}
",C,"bool ProxyClientSocket::SanitizeProxyAuth(HttpResponseInfo* response) {
  DCHECK(response && response->headers.get());

  scoped_refptr<HttpResponseHeaders> old_headers = response->headers;

  const char kHeaders[] = ""HTTP/1.1 407 Proxy Authentication Required\n\n"";
  scoped_refptr<HttpResponseHeaders> new_headers = new HttpResponseHeaders(
      HttpUtil::AssembleRawHeaders(kHeaders, arraysize(kHeaders)));

  new_headers->ReplaceStatusLine(old_headers->GetStatusLine());
  CopyHeaderValues(old_headers, new_headers, ""Connection"");
  CopyHeaderValues(old_headers, new_headers, ""Proxy-Authenticate"");

  response->headers = new_headers;
  return true;
}

bool ProxyClientSocket::SanitizeProxyRedirect(HttpResponseInfo* response) {
  // Return minimal headers; set ""Content-Length: 0"" to ignore response body.
  std::string fake_response_headers = base::StringPrintf(
      ""HTTP/1.0 302 Found\n""
      ""Location: %s\n""
      ""Content-Length: 0\n""
      ""Connection: close\n""
      ""\n"",
      location.c_str());
","                                              const GURL& url) {
  std::string fake_response_headers =
      base::StringPrintf(""HTTP/1.0 302 Found\n""
                         ""Location: %s\n""
                         ""Content-length: 0\n""
                         ""Connection: close\n""
                         ""\n"",
                         location.c_str());
",,"@@ -17,6 +17,20 @@
 
 namespace net {
 
+namespace {
+
+void CopyHeaderValues(scoped_refptr<HttpResponseHeaders> source,
+                      scoped_refptr<HttpResponseHeaders> dest,
+                      const std::string& header_name) {
+  void* iter = NULL;
+  std::string header_value;
+
+  while (source->EnumerateHeader(&iter, header_name, &header_value))
+    dest->AddHeader(header_name + "": "" + header_value);
+}
+
+}  // namespace
+
 // static
 void ProxyClientSocket::BuildTunnelRequest(
     const HttpRequestInfo& request_info,
@@ -72,22 +86,39 @@ void ProxyClientSocket::LogBlockedTunnelResponse(int http_status_code,
 }
 
 // static
-bool ProxyClientSocket::SanitizeProxyRedirect(HttpResponseInfo* response,
-                                              const GURL& url) {
+bool ProxyClientSocket::SanitizeProxyAuth(HttpResponseInfo* response) {
+  DCHECK(response && response->headers.get());
+
+  scoped_refptr<HttpResponseHeaders> old_headers = response->headers;
+
+  const char kHeaders[] = ""HTTP/1.1 407 Proxy Authentication Required\n\n"";
+  scoped_refptr<HttpResponseHeaders> new_headers = new HttpResponseHeaders(
+      HttpUtil::AssembleRawHeaders(kHeaders, arraysize(kHeaders)));
+
+  new_headers->ReplaceStatusLine(old_headers->GetStatusLine());
+  CopyHeaderValues(old_headers, new_headers, ""Connection"");
+  CopyHeaderValues(old_headers, new_headers, ""Proxy-Authenticate"");
+
+  response->headers = new_headers;
+  return true;
+}
+
+// static
+bool ProxyClientSocket::SanitizeProxyRedirect(HttpResponseInfo* response) {
   DCHECK(response && response->headers.get());
 
   std::string location;
   if (!response->headers->IsRedirect(&location))
     return false;
 
-  // Return minimal headers; set ""Content-length: 0"" to ignore response body.
-  std::string fake_response_headers =
-      base::StringPrintf(""HTTP/1.0 302 Found\n""
-                         ""Location: %s\n""
-                         ""Content-length: 0\n""
-                         ""Connection: close\n""
-                         ""\n"",
-                         location.c_str());
+  // Return minimal headers; set ""Content-Length: 0"" to ignore response body.
+  std::string fake_response_headers = base::StringPrintf(
+      ""HTTP/1.0 302 Found\n""
+      ""Location: %s\n""
+      ""Content-Length: 0\n""
+      ""Connection: close\n""
+      ""\n"",
+      location.c_str());
   std::string raw_headers =
       HttpUtil::AssembleRawHeaders(fake_response_headers.data(),
                                    fake_response_headers.length());",Chrome,7933c117fd16b192e70609c331641e9112af5e42,8249145b13b4893f0de507cbe26de72dd7ffbd79,1,"bool ProxyClientSocket::SanitizeProxyRedirect(HttpResponseInfo* response,
//flaw_line_below:
                                              const GURL& url) {
//fix_flaw_line_below:
//bool ProxyClientSocket::SanitizeProxyAuth(HttpResponseInfo* response) {
//fix_flaw_line_below:
//  DCHECK(response && response->headers.get());
//fix_flaw_line_below:
//
//fix_flaw_line_below:
//  scoped_refptr<HttpResponseHeaders> old_headers = response->headers;
//fix_flaw_line_below:
//
//fix_flaw_line_below:
//  const char kHeaders[] = ""HTTP/1.1 407 Proxy Authentication Required\n\n"";
//fix_flaw_line_below:
//  scoped_refptr<HttpResponseHeaders> new_headers = new HttpResponseHeaders(
//fix_flaw_line_below:
//      HttpUtil::AssembleRawHeaders(kHeaders, arraysize(kHeaders)));
//fix_flaw_line_below:
//
//fix_flaw_line_below:
//  new_headers->ReplaceStatusLine(old_headers->GetStatusLine());
//fix_flaw_line_below:
//  CopyHeaderValues(old_headers, new_headers, ""Connection"");
//fix_flaw_line_below:
//  CopyHeaderValues(old_headers, new_headers, ""Proxy-Authenticate"");
//fix_flaw_line_below:
//
//fix_flaw_line_below:
//  response->headers = new_headers;
//fix_flaw_line_below:
//  return true;
//fix_flaw_line_below:
//}
//fix_flaw_line_below:
//
//fix_flaw_line_below:
//// static
//fix_flaw_line_below:
//bool ProxyClientSocket::SanitizeProxyRedirect(HttpResponseInfo* response) {
   DCHECK(response && response->headers.get());
 
   std::string location;
   if (!response->headers->IsRedirect(&location))
     return false;
 
//flaw_line_below:
  // Return minimal headers; set ""Content-length: 0"" to ignore response body.
//flaw_line_below:
  std::string fake_response_headers =
//flaw_line_below:
      base::StringPrintf(""HTTP/1.0 302 Found\n""
//flaw_line_below:
                         ""Location: %s\n""
//flaw_line_below:
                         ""Content-length: 0\n""
//flaw_line_below:
                         ""Connection: close\n""
//flaw_line_below:
                         ""\n"",
//flaw_line_below:
                         location.c_str());
//fix_flaw_line_below:
//  // Return minimal headers; set ""Content-Length: 0"" to ignore response body.
//fix_flaw_line_below:
//  std::string fake_response_headers = base::StringPrintf(
//fix_flaw_line_below:
//      ""HTTP/1.0 302 Found\n""
//fix_flaw_line_below:
//      ""Location: %s\n""
//fix_flaw_line_below:
//      ""Content-Length: 0\n""
//fix_flaw_line_below:
//      ""Connection: close\n""
//fix_flaw_line_below:
//      ""\n"",
//fix_flaw_line_below:
//      location.c_str());
   std::string raw_headers =
       HttpUtil::AssembleRawHeaders(fake_response_headers.data(),
                                    fake_response_headers.length());
  response->headers = new HttpResponseHeaders(raw_headers);

  return true;
}
"
8214,185950,,Remote,Not required,,CVE-2015-1229,https://www.cvedetails.com/cve/CVE-2015-1229/,CWE-19,Low,,Partial,,2015-03-08,5.0,"net/http/proxy_client_socket.cc in Google Chrome before 41.0.2272.76 does not properly handle a 407 (aka Proxy Authentication Required) HTTP status code accompanied by a Set-Cookie header, which allows remote proxy servers to conduct cookie-injection attacks via a crafted response.",2016-12-21,,12,https://github.com/chromium/chromium/commit/7933c117fd16b192e70609c331641e9112af5e42,7933c117fd16b192e70609c331641e9112af5e42,"Sanitize headers in Proxy Authentication Required responses

BUG=431504

Review URL: https://codereview.chromium.org/769043003

Cr-Commit-Position: refs/heads/master@{#310014}",7,net/spdy/spdy_proxy_client_socket.cc,"{""sha"": ""21a8c008e252fa4053b397be884c49cf9051e618"", ""filename"": ""net/http/http_network_transaction_unittest.cc"", ""status"": ""modified"", ""additions"": 75, ""deletions"": 12, ""changes"": 87, ""blob_url"": ""https://github.com/chromium/chromium/blob/7933c117fd16b192e70609c331641e9112af5e42/net/http/http_network_transaction_unittest.cc"", ""raw_url"": ""https://github.com/chromium/chromium/raw/7933c117fd16b192e70609c331641e9112af5e42/net/http/http_network_transaction_unittest.cc"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/net/http/http_network_transaction_unittest.cc?ref=7933c117fd16b192e70609c331641e9112af5e42"", ""patch"": ""@@ -2546,11 +2546,11 @@ TEST_P(HttpNetworkTransactionTest, BasicAuthProxyKeepAlive) {\n       NetLog::PHASE_NONE);\n \n   const HttpResponseInfo* response = trans->GetResponseInfo();\n-  ASSERT_TRUE(response != NULL);\n-  ASSERT_FALSE(response->headers.get() == NULL);\n+  ASSERT_TRUE(response);\n+  ASSERT_TRUE(response->headers);\n   EXPECT_TRUE(response->headers->IsKeepAlive());\n   EXPECT_EQ(407, response->headers->response_code());\n-  EXPECT_EQ(10, response->headers->GetContentLength());\n+  EXPECT_EQ(-1, response->headers->GetContentLength());\n   EXPECT_TRUE(HttpVersion(1, 1) == response->headers->GetHttpVersion());\n   EXPECT_TRUE(CheckBasicProxyAuth(response->auth_challenge.get()));\n \n@@ -2565,11 +2565,11 @@ TEST_P(HttpNetworkTransactionTest, BasicAuthProxyKeepAlive) {\n   EXPECT_EQ(OK, rv);\n \n   response = trans->GetResponseInfo();\n-  ASSERT_TRUE(response != NULL);\n-  ASSERT_FALSE(response->headers.get() == NULL);\n+  ASSERT_TRUE(response);\n+  ASSERT_TRUE(response->headers);\n   EXPECT_TRUE(response->headers->IsKeepAlive());\n   EXPECT_EQ(407, response->headers->response_code());\n-  EXPECT_EQ(10, response->headers->GetContentLength());\n+  EXPECT_EQ(-1, response->headers->GetContentLength());\n   EXPECT_TRUE(HttpVersion(1, 1) == response->headers->GetHttpVersion());\n   EXPECT_TRUE(CheckBasicProxyAuth(response->auth_challenge.get()));\n \n@@ -2603,10 +2603,11 @@ TEST_P(HttpNetworkTransactionTest, BasicAuthProxyCancelTunnel) {\n \n   // The proxy responds to the connect with a 407.\n   MockRead data_reads[] = {\n-    MockRead(\""HTTP/1.1 407 Proxy Authentication Required\\r\\n\""),\n-    MockRead(\""Proxy-Authenticate: Basic realm=\\\""MyRealm1\\\""\\r\\n\""),\n-    MockRead(\""Content-Length: 10\\r\\n\\r\\n\""),\n-    MockRead(SYNCHRONOUS, ERR_UNEXPECTED),  // Should not be reached.\n+      MockRead(\""HTTP/1.1 407 Proxy Authentication Required\\r\\n\""),\n+      MockRead(\""Proxy-Authenticate: Basic realm=\\\""MyRealm1\\\""\\r\\n\""),\n+      MockRead(\""Content-Length: 10\\r\\n\\r\\n\""),\n+      MockRead(\""0123456789\""),  // Should not be reached.\n+      MockRead(SYNCHRONOUS, ERR_UNEXPECTED),\n   };\n \n   StaticSocketDataProvider data(data_reads, arraysize(data_reads),\n@@ -2622,12 +2623,74 @@ TEST_P(HttpNetworkTransactionTest, BasicAuthProxyCancelTunnel) {\n   EXPECT_EQ(OK, rv);\n \n   const HttpResponseInfo* response = trans->GetResponseInfo();\n-  ASSERT_TRUE(response != NULL);\n+  ASSERT_TRUE(response);\n+  ASSERT_TRUE(response->headers);\n+  EXPECT_TRUE(response->headers->IsKeepAlive());\n+  EXPECT_EQ(407, response->headers->response_code());\n+  EXPECT_TRUE(HttpVersion(1, 1) == response->headers->GetHttpVersion());\n+\n+  std::string response_data;\n+  rv = ReadTransaction(trans.get(), &response_data);\n+  EXPECT_EQ(ERR_TUNNEL_CONNECTION_FAILED, rv);\n+\n+  // Flush the idle socket before the HttpNetworkTransaction goes out of scope.\n+  session->CloseAllConnections();\n+}\n+\n+// Test that we don't pass extraneous headers from the proxy's response to the\n+// caller when the proxy responds to CONNECT with 407.\n+TEST_P(HttpNetworkTransactionTest, SanitizeProxyAuthHeaders) {\n+  HttpRequestInfo request;\n+  request.method = \""GET\"";\n+  request.url = GURL(\""https://www.google.com/\"");\n+  request.load_flags = 0;\n+\n+  // Configure against proxy server \""myproxy:70\"".\n+  session_deps_.proxy_service.reset(ProxyService::CreateFixed(\""myproxy:70\""));\n+\n+  scoped_refptr<HttpNetworkSession> session(CreateSession(&session_deps_));\n+\n+  scoped_ptr<HttpTransaction> trans(\n+      new HttpNetworkTransaction(DEFAULT_PRIORITY, session.get()));\n+\n+  // Since we have proxy, should try to establish tunnel.\n+  MockWrite data_writes[] = {\n+      MockWrite(\n+          \""CONNECT www.google.com:443 HTTP/1.1\\r\\n\""\n+          \""Host: www.google.com\\r\\n\""\n+          \""Proxy-Connection: keep-alive\\r\\n\\r\\n\""),\n+  };\n+\n+  // The proxy responds to the connect with a 407.\n+  MockRead data_reads[] = {\n+      MockRead(\""HTTP/1.1 407 Proxy Authentication Required\\r\\n\""),\n+      MockRead(\""X-Foo: bar\\r\\n\""),\n+      MockRead(\""Set-Cookie: foo=bar\\r\\n\""),\n+      MockRead(\""Proxy-Authenticate: Basic realm=\\\""MyRealm1\\\""\\r\\n\""),\n+      MockRead(\""Content-Length: 10\\r\\n\\r\\n\""),\n+      MockRead(SYNCHRONOUS, ERR_UNEXPECTED),  // Should not be reached.\n+  };\n+\n+  StaticSocketDataProvider data(data_reads, arraysize(data_reads), data_writes,\n+                                arraysize(data_writes));\n+  session_deps_.socket_factory->AddSocketDataProvider(&data);\n+\n+  TestCompletionCallback callback;\n \n+  int rv = trans->Start(&request, callback.callback(), BoundNetLog());\n+  EXPECT_EQ(ERR_IO_PENDING, rv);\n+\n+  rv = callback.WaitForResult();\n+  EXPECT_EQ(OK, rv);\n+\n+  const HttpResponseInfo* response = trans->GetResponseInfo();\n+  ASSERT_TRUE(response);\n+  ASSERT_TRUE(response->headers);\n   EXPECT_TRUE(response->headers->IsKeepAlive());\n   EXPECT_EQ(407, response->headers->response_code());\n-  EXPECT_EQ(10, response->headers->GetContentLength());\n   EXPECT_TRUE(HttpVersion(1, 1) == response->headers->GetHttpVersion());\n+  EXPECT_FALSE(response->headers->HasHeader(\""X-Foo\""));\n+  EXPECT_FALSE(response->headers->HasHeader(\""Set-Cookie\""));\n \n   std::string response_data;\n   rv = ReadTransaction(trans.get(), &response_data);""}<_**next**_>{""sha"": ""97945d919341e45be655f4e0ebc9f5a5ff89fce0"", ""filename"": ""net/http/http_proxy_client_socket.cc"", ""status"": ""modified"", ""additions"": 13, ""deletions"": 11, ""changes"": 24, ""blob_url"": ""https://github.com/chromium/chromium/blob/7933c117fd16b192e70609c331641e9112af5e42/net/http/http_proxy_client_socket.cc"", ""raw_url"": ""https://github.com/chromium/chromium/raw/7933c117fd16b192e70609c331641e9112af5e42/net/http/http_proxy_client_socket.cc"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/net/http/http_proxy_client_socket.cc?ref=7933c117fd16b192e70609c331641e9112af5e42"", ""patch"": ""@@ -483,25 +483,27 @@ int HttpProxyClientSocket::DoReadHeadersComplete(int result) {\n       // sanitize the response.  This still allows a rogue HTTPS proxy to\n       // redirect an HTTPS site load to a similar-looking site, but no longer\n       // allows it to impersonate the site the user requested.\n-      if (is_https_proxy_ && SanitizeProxyRedirect(&response_, request_.url)) {\n-        bool is_connection_reused = http_stream_parser_->IsConnectionReused();\n-        redirect_has_load_timing_info_ =\n-            transport_->GetLoadTimingInfo(\n-                is_connection_reused, &redirect_load_timing_info_);\n-        transport_.reset();\n-        http_stream_parser_.reset();\n-        return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;\n+      if (!is_https_proxy_ || !SanitizeProxyRedirect(&response_)) {\n+        LogBlockedTunnelResponse();\n+        return ERR_TUNNEL_CONNECTION_FAILED;\n       }\n \n-      // We're not using an HTTPS proxy, or we couldn't sanitize the redirect.\n-      LogBlockedTunnelResponse();\n-      return ERR_TUNNEL_CONNECTION_FAILED;\n+      redirect_has_load_timing_info_ = transport_->GetLoadTimingInfo(\n+          http_stream_parser_->IsConnectionReused(),\n+          &redirect_load_timing_info_);\n+      transport_.reset();\n+      http_stream_parser_.reset();\n+      return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;\n \n     case 407:  // Proxy Authentication Required\n       // We need this status code to allow proxy authentication.  Our\n       // authentication code is smart enough to avoid being tricked by an\n       // active network attacker.\n       // The next state is intentionally not set as it should be STATE_NONE;\n+      if (!SanitizeProxyAuth(&response_)) {\n+        LogBlockedTunnelResponse();\n+        return ERR_TUNNEL_CONNECTION_FAILED;\n+      }\n       return HandleProxyAuthChallenge(auth_.get(), &response_, net_log_);\n \n     default:""}<_**next**_>{""sha"": ""3c539c6895e295a98f9645070e4258bbf78b5d73"", ""filename"": ""net/http/proxy_client_socket.cc"", ""status"": ""modified"", ""additions"": 41, ""deletions"": 10, ""changes"": 51, ""blob_url"": ""https://github.com/chromium/chromium/blob/7933c117fd16b192e70609c331641e9112af5e42/net/http/proxy_client_socket.cc"", ""raw_url"": ""https://github.com/chromium/chromium/raw/7933c117fd16b192e70609c331641e9112af5e42/net/http/proxy_client_socket.cc"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/net/http/proxy_client_socket.cc?ref=7933c117fd16b192e70609c331641e9112af5e42"", ""patch"": ""@@ -17,6 +17,20 @@\n \n namespace net {\n \n+namespace {\n+\n+void CopyHeaderValues(scoped_refptr<HttpResponseHeaders> source,\n+                      scoped_refptr<HttpResponseHeaders> dest,\n+                      const std::string& header_name) {\n+  void* iter = NULL;\n+  std::string header_value;\n+\n+  while (source->EnumerateHeader(&iter, header_name, &header_value))\n+    dest->AddHeader(header_name + \"": \"" + header_value);\n+}\n+\n+}  // namespace\n+\n // static\n void ProxyClientSocket::BuildTunnelRequest(\n     const HttpRequestInfo& request_info,\n@@ -72,22 +86,39 @@ void ProxyClientSocket::LogBlockedTunnelResponse(int http_status_code,\n }\n \n // static\n-bool ProxyClientSocket::SanitizeProxyRedirect(HttpResponseInfo* response,\n-                                              const GURL& url) {\n+bool ProxyClientSocket::SanitizeProxyAuth(HttpResponseInfo* response) {\n+  DCHECK(response && response->headers.get());\n+\n+  scoped_refptr<HttpResponseHeaders> old_headers = response->headers;\n+\n+  const char kHeaders[] = \""HTTP/1.1 407 Proxy Authentication Required\\n\\n\"";\n+  scoped_refptr<HttpResponseHeaders> new_headers = new HttpResponseHeaders(\n+      HttpUtil::AssembleRawHeaders(kHeaders, arraysize(kHeaders)));\n+\n+  new_headers->ReplaceStatusLine(old_headers->GetStatusLine());\n+  CopyHeaderValues(old_headers, new_headers, \""Connection\"");\n+  CopyHeaderValues(old_headers, new_headers, \""Proxy-Authenticate\"");\n+\n+  response->headers = new_headers;\n+  return true;\n+}\n+\n+// static\n+bool ProxyClientSocket::SanitizeProxyRedirect(HttpResponseInfo* response) {\n   DCHECK(response && response->headers.get());\n \n   std::string location;\n   if (!response->headers->IsRedirect(&location))\n     return false;\n \n-  // Return minimal headers; set \""Content-length: 0\"" to ignore response body.\n-  std::string fake_response_headers =\n-      base::StringPrintf(\""HTTP/1.0 302 Found\\n\""\n-                         \""Location: %s\\n\""\n-                         \""Content-length: 0\\n\""\n-                         \""Connection: close\\n\""\n-                         \""\\n\"",\n-                         location.c_str());\n+  // Return minimal headers; set \""Content-Length: 0\"" to ignore response body.\n+  std::string fake_response_headers = base::StringPrintf(\n+      \""HTTP/1.0 302 Found\\n\""\n+      \""Location: %s\\n\""\n+      \""Content-Length: 0\\n\""\n+      \""Connection: close\\n\""\n+      \""\\n\"",\n+      location.c_str());\n   std::string raw_headers =\n       HttpUtil::AssembleRawHeaders(fake_response_headers.data(),\n                                    fake_response_headers.length());""}<_**next**_>{""sha"": ""f3347c8972e14677a15b1841c5de9dd65389124b"", ""filename"": ""net/http/proxy_client_socket.h"", ""status"": ""modified"", ""additions"": 9, ""deletions"": 3, ""changes"": 12, ""blob_url"": ""https://github.com/chromium/chromium/blob/7933c117fd16b192e70609c331641e9112af5e42/net/http/proxy_client_socket.h"", ""raw_url"": ""https://github.com/chromium/chromium/raw/7933c117fd16b192e70609c331641e9112af5e42/net/http/proxy_client_socket.h"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/net/http/proxy_client_socket.h?ref=7933c117fd16b192e70609c331641e9112af5e42"", ""patch"": ""@@ -74,13 +74,19 @@ class NET_EXPORT_PRIVATE ProxyClientSocket : public StreamSocket {\n                                        const GURL& url,\n                                        bool is_https_proxy);\n \n+  // When a proxy authentication response is received during tunnel\n+  // construction, this method should be called to strip everything\n+  // but the auth header from the redirect response.  If it returns\n+  // false, the response should be discarded and tunnel construction should\n+  // fail.\n+  static bool SanitizeProxyAuth(HttpResponseInfo* response);\n+\n   // When a redirect (e.g. 302 response) is received during tunnel\n   // construction, this method should be called to strip everything\n   // but the Location header from the redirect response.  If it returns\n   // false, the response should be discarded and tunnel construction should\n-  // fail.  |url| is for logging purposes.\n-  static bool SanitizeProxyRedirect(HttpResponseInfo* response,\n-                                    const GURL& url);\n+  // fail.\n+  static bool SanitizeProxyRedirect(HttpResponseInfo* response);\n \n  private:\n   DISALLOW_COPY_AND_ASSIGN(ProxyClientSocket);""}<_**next**_>{""sha"": ""661cfd99a7be6a60fe18edb209d21d33a21160ee"", ""filename"": ""net/spdy/spdy_proxy_client_socket.cc"", ""status"": ""modified"", ""additions"": 12, ""deletions"": 8, ""changes"": 20, ""blob_url"": ""https://github.com/chromium/chromium/blob/7933c117fd16b192e70609c331641e9112af5e42/net/spdy/spdy_proxy_client_socket.cc"", ""raw_url"": ""https://github.com/chromium/chromium/raw/7933c117fd16b192e70609c331641e9112af5e42/net/spdy/spdy_proxy_client_socket.cc"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/net/spdy/spdy_proxy_client_socket.cc?ref=7933c117fd16b192e70609c331641e9112af5e42"", ""patch"": ""@@ -414,20 +414,24 @@ int SpdyProxyClientSocket::DoReadReplyComplete(int result) {\n     case 302:  // Found / Moved Temporarily\n       // Try to return a sanitized response so we can follow auth redirects.\n       // If we can't, fail the tunnel connection.\n-      if (SanitizeProxyRedirect(&response_, request_.url)) {\n-        redirect_has_load_timing_info_ =\n-            spdy_stream_->GetLoadTimingInfo(&redirect_load_timing_info_);\n-        // Note that this triggers a RST_STREAM_CANCEL.\n-        spdy_stream_->DetachDelegate();\n-        next_state_ = STATE_DISCONNECTED;\n-        return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;\n-      } else {\n+      if (!SanitizeProxyRedirect(&response_)) {\n         LogBlockedTunnelResponse();\n         return ERR_TUNNEL_CONNECTION_FAILED;\n       }\n \n+      redirect_has_load_timing_info_ =\n+          spdy_stream_->GetLoadTimingInfo(&redirect_load_timing_info_);\n+      // Note that this triggers a RST_STREAM_CANCEL.\n+      spdy_stream_->DetachDelegate();\n+      next_state_ = STATE_DISCONNECTED;\n+      return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;\n+\n     case 407:  // Proxy Authentication Required\n       next_state_ = STATE_OPEN;\n+      if (!SanitizeProxyAuth(&response_)) {\n+        LogBlockedTunnelResponse();\n+        return ERR_TUNNEL_CONNECTION_FAILED;\n+      }\n       return HandleProxyAuthChallenge(auth_.get(), &response_, net_log_);\n \n     default:""}","int SpdyProxyClientSocket::DoReadReplyComplete(int result) {

  if (result < 0)
    return result;

  if (response_.headers->GetParsedHttpVersion() < HttpVersion(1, 0))
    return ERR_TUNNEL_CONNECTION_FAILED;

  net_log_.AddEvent(
      NetLog::TYPE_HTTP_TRANSACTION_READ_TUNNEL_RESPONSE_HEADERS,
      base::Bind(&HttpResponseHeaders::NetLogCallback, response_.headers));

  switch (response_.headers->response_code()) {
    case 200:  // OK
      next_state_ = STATE_OPEN;
      return OK;

     case 302:  // Found / Moved Temporarily
      if (!SanitizeProxyRedirect(&response_)) {
         LogBlockedTunnelResponse();
         return ERR_TUNNEL_CONNECTION_FAILED;
       }
 
      redirect_has_load_timing_info_ =
          spdy_stream_->GetLoadTimingInfo(&redirect_load_timing_info_);
      // Note that this triggers a RST_STREAM_CANCEL.
      spdy_stream_->DetachDelegate();
      next_state_ = STATE_DISCONNECTED;
      return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;

     case 407:  // Proxy Authentication Required
       next_state_ = STATE_OPEN;
      if (!SanitizeProxyAuth(&response_)) {
        LogBlockedTunnelResponse();
        return ERR_TUNNEL_CONNECTION_FAILED;
      }
       return HandleProxyAuthChallenge(auth_.get(), &response_, net_log_);
 
     default:
      LogBlockedTunnelResponse();
      return ERR_TUNNEL_CONNECTION_FAILED;
  }
}
","int SpdyProxyClientSocket::DoReadReplyComplete(int result) {

  if (result < 0)
    return result;

  if (response_.headers->GetParsedHttpVersion() < HttpVersion(1, 0))
    return ERR_TUNNEL_CONNECTION_FAILED;

  net_log_.AddEvent(
      NetLog::TYPE_HTTP_TRANSACTION_READ_TUNNEL_RESPONSE_HEADERS,
      base::Bind(&HttpResponseHeaders::NetLogCallback, response_.headers));

  switch (response_.headers->response_code()) {
    case 200:  // OK
      next_state_ = STATE_OPEN;
      return OK;

     case 302:  // Found / Moved Temporarily
      if (SanitizeProxyRedirect(&response_, request_.url)) {
        redirect_has_load_timing_info_ =
            spdy_stream_->GetLoadTimingInfo(&redirect_load_timing_info_);
        spdy_stream_->DetachDelegate();
        next_state_ = STATE_DISCONNECTED;
        return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;
      } else {
         LogBlockedTunnelResponse();
         return ERR_TUNNEL_CONNECTION_FAILED;
       }
 
     case 407:  // Proxy Authentication Required
       next_state_ = STATE_OPEN;
       return HandleProxyAuthChallenge(auth_.get(), &response_, net_log_);
 
     default:
      LogBlockedTunnelResponse();
      return ERR_TUNNEL_CONNECTION_FAILED;
  }
}
",C,"      if (!SanitizeProxyRedirect(&response_)) {
      redirect_has_load_timing_info_ =
          spdy_stream_->GetLoadTimingInfo(&redirect_load_timing_info_);
      // Note that this triggers a RST_STREAM_CANCEL.
      spdy_stream_->DetachDelegate();
      next_state_ = STATE_DISCONNECTED;
      return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;

      if (!SanitizeProxyAuth(&response_)) {
        LogBlockedTunnelResponse();
        return ERR_TUNNEL_CONNECTION_FAILED;
      }
","      if (SanitizeProxyRedirect(&response_, request_.url)) {
        redirect_has_load_timing_info_ =
            spdy_stream_->GetLoadTimingInfo(&redirect_load_timing_info_);
        spdy_stream_->DetachDelegate();
        next_state_ = STATE_DISCONNECTED;
        return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;
      } else {
",,"@@ -414,20 +414,24 @@ int SpdyProxyClientSocket::DoReadReplyComplete(int result) {
     case 302:  // Found / Moved Temporarily
       // Try to return a sanitized response so we can follow auth redirects.
       // If we can't, fail the tunnel connection.
-      if (SanitizeProxyRedirect(&response_, request_.url)) {
-        redirect_has_load_timing_info_ =
-            spdy_stream_->GetLoadTimingInfo(&redirect_load_timing_info_);
-        // Note that this triggers a RST_STREAM_CANCEL.
-        spdy_stream_->DetachDelegate();
-        next_state_ = STATE_DISCONNECTED;
-        return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;
-      } else {
+      if (!SanitizeProxyRedirect(&response_)) {
         LogBlockedTunnelResponse();
         return ERR_TUNNEL_CONNECTION_FAILED;
       }
 
+      redirect_has_load_timing_info_ =
+          spdy_stream_->GetLoadTimingInfo(&redirect_load_timing_info_);
+      // Note that this triggers a RST_STREAM_CANCEL.
+      spdy_stream_->DetachDelegate();
+      next_state_ = STATE_DISCONNECTED;
+      return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;
+
     case 407:  // Proxy Authentication Required
       next_state_ = STATE_OPEN;
+      if (!SanitizeProxyAuth(&response_)) {
+        LogBlockedTunnelResponse();
+        return ERR_TUNNEL_CONNECTION_FAILED;
+      }
       return HandleProxyAuthChallenge(auth_.get(), &response_, net_log_);
 
     default:",Chrome,7933c117fd16b192e70609c331641e9112af5e42,8249145b13b4893f0de507cbe26de72dd7ffbd79,1,"int SpdyProxyClientSocket::DoReadReplyComplete(int result) {
  // We enter this method directly from DoSendRequestComplete, since
  // we are notified by a callback when the SYN_REPLY frame arrives

  if (result < 0)
    return result;

  // Require the ""HTTP/1.x"" status line for SSL CONNECT.
  if (response_.headers->GetParsedHttpVersion() < HttpVersion(1, 0))
    return ERR_TUNNEL_CONNECTION_FAILED;

  net_log_.AddEvent(
      NetLog::TYPE_HTTP_TRANSACTION_READ_TUNNEL_RESPONSE_HEADERS,
      base::Bind(&HttpResponseHeaders::NetLogCallback, response_.headers));

  switch (response_.headers->response_code()) {
    case 200:  // OK
      next_state_ = STATE_OPEN;
      return OK;

     case 302:  // Found / Moved Temporarily
       // Try to return a sanitized response so we can follow auth redirects.
       // If we can't, fail the tunnel connection.
//flaw_line_below:
      if (SanitizeProxyRedirect(&response_, request_.url)) {
//flaw_line_below:
        redirect_has_load_timing_info_ =
//flaw_line_below:
            spdy_stream_->GetLoadTimingInfo(&redirect_load_timing_info_);
//flaw_line_below:
        // Note that this triggers a RST_STREAM_CANCEL.
//flaw_line_below:
        spdy_stream_->DetachDelegate();
//flaw_line_below:
        next_state_ = STATE_DISCONNECTED;
//flaw_line_below:
        return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;
//flaw_line_below:
      } else {
//fix_flaw_line_below:
//      if (!SanitizeProxyRedirect(&response_)) {
         LogBlockedTunnelResponse();
         return ERR_TUNNEL_CONNECTION_FAILED;
       }
 
//fix_flaw_line_below:
//      redirect_has_load_timing_info_ =
//fix_flaw_line_below:
//          spdy_stream_->GetLoadTimingInfo(&redirect_load_timing_info_);
//fix_flaw_line_below:
//      // Note that this triggers a RST_STREAM_CANCEL.
//fix_flaw_line_below:
//      spdy_stream_->DetachDelegate();
//fix_flaw_line_below:
//      next_state_ = STATE_DISCONNECTED;
//fix_flaw_line_below:
//      return ERR_HTTPS_PROXY_TUNNEL_RESPONSE;
//fix_flaw_line_below:
//
     case 407:  // Proxy Authentication Required
       next_state_ = STATE_OPEN;
//fix_flaw_line_below:
//      if (!SanitizeProxyAuth(&response_)) {
//fix_flaw_line_below:
//        LogBlockedTunnelResponse();
//fix_flaw_line_below:
//        return ERR_TUNNEL_CONNECTION_FAILED;
//fix_flaw_line_below:
//      }
       return HandleProxyAuthChallenge(auth_.get(), &response_, net_log_);
 
     default:
      // Ignore response to avoid letting the proxy impersonate the target
      // server.  (See http://crbug.com/137891.)
      LogBlockedTunnelResponse();
      return ERR_TUNNEL_CONNECTION_FAILED;
  }
}
"
8233,185969,,Remote,Not required,Partial,CVE-2016-5153,https://www.cvedetails.com/cve/CVE-2016-5153/,CWE-19,Medium,Partial,Partial,,2016-09-11,6.8,"The Web Animations implementation in Blink, as used in Google Chrome before 53.0.2785.89 on Windows and OS X and before 53.0.2785.92 on Linux, improperly relies on list iteration, which allows remote attackers to cause a denial of service (use-after-destruction) or possibly have unspecified other impact via a crafted web site.",2018-10-30,DoS ,0,https://github.com/chromium/chromium/commit/20a9e39a925dd0fb183acb61bb7b87f29abea83f,20a9e39a925dd0fb183acb61bb7b87f29abea83f,"Tracing: Connect to service on startup

Temporary workaround for flaky tests introduced by
https://chromium-review.googlesource.com/c/chromium/src/+/1439082

TBR=eseckler@chromium.org

Bug: 928410, 928363
Change-Id: I0dcf20cbdf91a7beea167a220ba9ef7e0604c1ab
Reviewed-on: https://chromium-review.googlesource.com/c/1452767
Reviewed-by: oysteine <oysteine@chromium.org>
Reviewed-by: Eric Seckler <eseckler@chromium.org>
Reviewed-by: Aaron Gable <agable@chromium.org>
Commit-Queue: oysteine <oysteine@chromium.org>
Cr-Commit-Position: refs/heads/master@{#631052}",1,content/browser/tracing/tracing_controller_impl.cc,"{""sha"": ""df934deb2f6bfd705eb8686f0ab4e49490b176fe"", ""filename"": ""content/browser/tracing/tracing_controller_impl.cc"", ""status"": ""modified"", ""additions"": 4, ""deletions"": 1, ""changes"": 5, ""blob_url"": ""https://github.com/chromium/chromium/blob/20a9e39a925dd0fb183acb61bb7b87f29abea83f/content/browser/tracing/tracing_controller_impl.cc"", ""raw_url"": ""https://github.com/chromium/chromium/raw/20a9e39a925dd0fb183acb61bb7b87f29abea83f/content/browser/tracing/tracing_controller_impl.cc"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/content/browser/tracing/tracing_controller_impl.cc?ref=20a9e39a925dd0fb183acb61bb7b87f29abea83f"", ""patch"": ""@@ -153,6 +153,10 @@ TracingControllerImpl::TracingControllerImpl()\n   base::trace_event::TraceLog::GetInstance()->AddAsyncEnabledStateObserver(\n       weak_ptr_factory_.GetWeakPtr());\n   g_tracing_controller = this;\n+\n+  // TODO(oysteine): Instead of connecting right away, we should connect\n+  // in StartTracing once this no longer causes test flakiness.\n+  ConnectToServiceIfNeeded();\n }\n \n TracingControllerImpl::~TracingControllerImpl() {\n@@ -365,7 +369,6 @@ bool TracingControllerImpl::StartTracing(\n       std::make_unique<base::trace_event::TraceConfig>(trace_config);\n \n   start_tracing_done_ = std::move(callback);\n-  ConnectToServiceIfNeeded();\n   coordinator_->StartTracing(trace_config.ToString());\n \n   if (start_tracing_done_ &&""}","bool TracingControllerImpl::StartTracing(
    const base::trace_event::TraceConfig& trace_config,
    StartTracingDoneCallback callback) {
  DCHECK_CURRENTLY_ON(BrowserThread::UI);
  if (IsTracing()) {
    if (trace_config.process_filter_config().empty() ||
        trace_config_->process_filter_config().empty()) {
      return false;
    }
    base::trace_event::TraceConfig old_config_copy(*trace_config_);
    base::trace_event::TraceConfig new_config_copy(trace_config);
    old_config_copy.SetProcessFilterConfig(
        base::trace_event::TraceConfig::ProcessFilterConfig());
    new_config_copy.SetProcessFilterConfig(
        base::trace_event::TraceConfig::ProcessFilterConfig());
    if (old_config_copy.ToString() != new_config_copy.ToString())
      return false;
  }
  trace_config_ =
       std::make_unique<base::trace_event::TraceConfig>(trace_config);
 
   start_tracing_done_ = std::move(callback);
   coordinator_->StartTracing(trace_config.ToString());
 
   if (start_tracing_done_ &&
      (base::trace_event::TraceLog::GetInstance()->IsEnabled() ||
       !trace_config.process_filter_config().IsEnabled(
           base::Process::Current().Pid()))) {
    std::move(start_tracing_done_).Run();
  }

  return true;
}
","bool TracingControllerImpl::StartTracing(
    const base::trace_event::TraceConfig& trace_config,
    StartTracingDoneCallback callback) {
  DCHECK_CURRENTLY_ON(BrowserThread::UI);
  if (IsTracing()) {
    if (trace_config.process_filter_config().empty() ||
        trace_config_->process_filter_config().empty()) {
      return false;
    }
    base::trace_event::TraceConfig old_config_copy(*trace_config_);
    base::trace_event::TraceConfig new_config_copy(trace_config);
    old_config_copy.SetProcessFilterConfig(
        base::trace_event::TraceConfig::ProcessFilterConfig());
    new_config_copy.SetProcessFilterConfig(
        base::trace_event::TraceConfig::ProcessFilterConfig());
    if (old_config_copy.ToString() != new_config_copy.ToString())
      return false;
  }
  trace_config_ =
       std::make_unique<base::trace_event::TraceConfig>(trace_config);
 
   start_tracing_done_ = std::move(callback);
  ConnectToServiceIfNeeded();
   coordinator_->StartTracing(trace_config.ToString());
 
   if (start_tracing_done_ &&
      (base::trace_event::TraceLog::GetInstance()->IsEnabled() ||
       !trace_config.process_filter_config().IsEnabled(
           base::Process::Current().Pid()))) {
    std::move(start_tracing_done_).Run();
  }

  return true;
}
",C,,"  ConnectToServiceIfNeeded();
",,"@@ -153,6 +153,10 @@ TracingControllerImpl::TracingControllerImpl()
   base::trace_event::TraceLog::GetInstance()->AddAsyncEnabledStateObserver(
       weak_ptr_factory_.GetWeakPtr());
   g_tracing_controller = this;
+
+  // TODO(oysteine): Instead of connecting right away, we should connect
+  // in StartTracing once this no longer causes test flakiness.
+  ConnectToServiceIfNeeded();
 }
 
 TracingControllerImpl::~TracingControllerImpl() {
@@ -365,7 +369,6 @@ bool TracingControllerImpl::StartTracing(
       std::make_unique<base::trace_event::TraceConfig>(trace_config);
 
   start_tracing_done_ = std::move(callback);
-  ConnectToServiceIfNeeded();
   coordinator_->StartTracing(trace_config.ToString());
 
   if (start_tracing_done_ &&",Chrome,20a9e39a925dd0fb183acb61bb7b87f29abea83f,1bd22c55cf05e17d9d7a89e800eab0bacb4e97cc,1,"bool TracingControllerImpl::StartTracing(
    const base::trace_event::TraceConfig& trace_config,
    StartTracingDoneCallback callback) {
  DCHECK_CURRENTLY_ON(BrowserThread::UI);
  // TODO(chiniforooshan): The actual value should be received by callback and
  // this function should return void.
  if (IsTracing()) {
    // Do not allow updating trace config when process filter is not used.
    if (trace_config.process_filter_config().empty() ||
        trace_config_->process_filter_config().empty()) {
      return false;
    }
    // Make sure other parts of trace_config (besides process filter)
    // did not change.
    base::trace_event::TraceConfig old_config_copy(*trace_config_);
    base::trace_event::TraceConfig new_config_copy(trace_config);
    old_config_copy.SetProcessFilterConfig(
        base::trace_event::TraceConfig::ProcessFilterConfig());
    new_config_copy.SetProcessFilterConfig(
        base::trace_event::TraceConfig::ProcessFilterConfig());
    if (old_config_copy.ToString() != new_config_copy.ToString())
      return false;
  }
  trace_config_ =
       std::make_unique<base::trace_event::TraceConfig>(trace_config);
 
   start_tracing_done_ = std::move(callback);
//flaw_line_below:
  ConnectToServiceIfNeeded();
   coordinator_->StartTracing(trace_config.ToString());
 
   if (start_tracing_done_ &&
      (base::trace_event::TraceLog::GetInstance()->IsEnabled() ||
       !trace_config.process_filter_config().IsEnabled(
           base::Process::Current().Pid()))) {
    // If we're already tracing, or if the current process is excluded from the
    // process filter, we'll never receive a callback from the TraceLog, so then
    // we just run the callback right away.
    std::move(start_tracing_done_).Run();
  }

  // TODO(chiniforooshan): The actual success value should be sent by the
  // callback asynchronously.
  return true;
}
"
8234,185970,,Remote,Not required,Partial,CVE-2016-5153,https://www.cvedetails.com/cve/CVE-2016-5153/,CWE-19,Medium,Partial,Partial,,2016-09-11,6.8,"The Web Animations implementation in Blink, as used in Google Chrome before 53.0.2785.89 on Windows and OS X and before 53.0.2785.92 on Linux, improperly relies on list iteration, which allows remote attackers to cause a denial of service (use-after-destruction) or possibly have unspecified other impact via a crafted web site.",2018-10-30,DoS ,4,https://github.com/chromium/chromium/commit/20a9e39a925dd0fb183acb61bb7b87f29abea83f,20a9e39a925dd0fb183acb61bb7b87f29abea83f,"Tracing: Connect to service on startup

Temporary workaround for flaky tests introduced by
https://chromium-review.googlesource.com/c/chromium/src/+/1439082

TBR=eseckler@chromium.org

Bug: 928410, 928363
Change-Id: I0dcf20cbdf91a7beea167a220ba9ef7e0604c1ab
Reviewed-on: https://chromium-review.googlesource.com/c/1452767
Reviewed-by: oysteine <oysteine@chromium.org>
Reviewed-by: Eric Seckler <eseckler@chromium.org>
Reviewed-by: Aaron Gable <agable@chromium.org>
Commit-Queue: oysteine <oysteine@chromium.org>
Cr-Commit-Position: refs/heads/master@{#631052}",0,content/browser/tracing/tracing_controller_impl.cc,"{""sha"": ""df934deb2f6bfd705eb8686f0ab4e49490b176fe"", ""filename"": ""content/browser/tracing/tracing_controller_impl.cc"", ""status"": ""modified"", ""additions"": 4, ""deletions"": 1, ""changes"": 5, ""blob_url"": ""https://github.com/chromium/chromium/blob/20a9e39a925dd0fb183acb61bb7b87f29abea83f/content/browser/tracing/tracing_controller_impl.cc"", ""raw_url"": ""https://github.com/chromium/chromium/raw/20a9e39a925dd0fb183acb61bb7b87f29abea83f/content/browser/tracing/tracing_controller_impl.cc"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/content/browser/tracing/tracing_controller_impl.cc?ref=20a9e39a925dd0fb183acb61bb7b87f29abea83f"", ""patch"": ""@@ -153,6 +153,10 @@ TracingControllerImpl::TracingControllerImpl()\n   base::trace_event::TraceLog::GetInstance()->AddAsyncEnabledStateObserver(\n       weak_ptr_factory_.GetWeakPtr());\n   g_tracing_controller = this;\n+\n+  // TODO(oysteine): Instead of connecting right away, we should connect\n+  // in StartTracing once this no longer causes test flakiness.\n+  ConnectToServiceIfNeeded();\n }\n \n TracingControllerImpl::~TracingControllerImpl() {\n@@ -365,7 +369,6 @@ bool TracingControllerImpl::StartTracing(\n       std::make_unique<base::trace_event::TraceConfig>(trace_config);\n \n   start_tracing_done_ = std::move(callback);\n-  ConnectToServiceIfNeeded();\n   coordinator_->StartTracing(trace_config.ToString());\n \n   if (start_tracing_done_ &&""}","TracingControllerImpl::TracingControllerImpl()
    : delegate_(GetContentClient()->browser()->GetTracingDelegate()),
      weak_ptr_factory_(this) {
  DCHECK(!g_tracing_controller);
  DCHECK_CURRENTLY_ON(BrowserThread::UI);
  base::FileTracing::SetProvider(new FileTracingProviderImpl);
  AddAgents();
   base::trace_event::TraceLog::GetInstance()->AddAsyncEnabledStateObserver(
       weak_ptr_factory_.GetWeakPtr());
   g_tracing_controller = this;

  // TODO(oysteine): Instead of connecting right away, we should connect
  // in StartTracing once this no longer causes test flakiness.
  ConnectToServiceIfNeeded();
 }
","TracingControllerImpl::TracingControllerImpl()
    : delegate_(GetContentClient()->browser()->GetTracingDelegate()),
      weak_ptr_factory_(this) {
  DCHECK(!g_tracing_controller);
  DCHECK_CURRENTLY_ON(BrowserThread::UI);
  base::FileTracing::SetProvider(new FileTracingProviderImpl);
  AddAgents();
   base::trace_event::TraceLog::GetInstance()->AddAsyncEnabledStateObserver(
       weak_ptr_factory_.GetWeakPtr());
   g_tracing_controller = this;
 }
",C,"
  // TODO(oysteine): Instead of connecting right away, we should connect
  // in StartTracing once this no longer causes test flakiness.
  ConnectToServiceIfNeeded();
",,,"@@ -153,6 +153,10 @@ TracingControllerImpl::TracingControllerImpl()
   base::trace_event::TraceLog::GetInstance()->AddAsyncEnabledStateObserver(
       weak_ptr_factory_.GetWeakPtr());
   g_tracing_controller = this;
+
+  // TODO(oysteine): Instead of connecting right away, we should connect
+  // in StartTracing once this no longer causes test flakiness.
+  ConnectToServiceIfNeeded();
 }
 
 TracingControllerImpl::~TracingControllerImpl() {
@@ -365,7 +369,6 @@ bool TracingControllerImpl::StartTracing(
       std::make_unique<base::trace_event::TraceConfig>(trace_config);
 
   start_tracing_done_ = std::move(callback);
-  ConnectToServiceIfNeeded();
   coordinator_->StartTracing(trace_config.ToString());
 
   if (start_tracing_done_ &&",Chrome,20a9e39a925dd0fb183acb61bb7b87f29abea83f,1bd22c55cf05e17d9d7a89e800eab0bacb4e97cc,1,"TracingControllerImpl::TracingControllerImpl()
    : delegate_(GetContentClient()->browser()->GetTracingDelegate()),
      weak_ptr_factory_(this) {
  DCHECK(!g_tracing_controller);
  DCHECK_CURRENTLY_ON(BrowserThread::UI);
  // Deliberately leaked, like this class.
  base::FileTracing::SetProvider(new FileTracingProviderImpl);
  AddAgents();
   base::trace_event::TraceLog::GetInstance()->AddAsyncEnabledStateObserver(
       weak_ptr_factory_.GetWeakPtr());
   g_tracing_controller = this;
//fix_flaw_line_below:
//
//fix_flaw_line_below:
//  // TODO(oysteine): Instead of connecting right away, we should connect
//fix_flaw_line_below:
//  // in StartTracing once this no longer causes test flakiness.
//fix_flaw_line_below:
//  ConnectToServiceIfNeeded();
 }
"
8745,186481,,Remote,Not required,,CVE-2016-5214,https://www.cvedetails.com/cve/CVE-2016-5214/,CWE-19,Medium,,Partial,,2017-01-19,4.3,"Google Chrome prior to 55.0.2883.75 for Windows mishandled downloaded files, which allowed a remote attacker to prevent the downloaded file from receiving the Mark of the Web via a crafted HTML page.",2018-01-04,,0,https://github.com/chromium/chromium/commit/fff73016a86f9a5990d080dc76058f8528a423f9,fff73016a86f9a5990d080dc76058f8528a423f9,"Revert ""Enable camera blob stream when needed""

This reverts commit 10f4b93635e12f9fa0cba1641a10938ca38ed448.

Reason for revert:

Findit (https://goo.gl/kROfz5) identified CL at revision 601492 as the
culprit for failures in the build cycles as shown on:
https://findit-for-me.appspot.com/waterfall/culprit?key=ag9zfmZpbmRpdC1mb3ItbWVyRAsSDVdmU3VzcGVjdGVkQ0wiMWNocm9taXVtLzEwZjRiOTM2MzVlMTJmOWZhMGNiYTE2NDFhMTA5MzhjYTM4ZWQ0NDgM

Sample Failed Build: https://ci.chromium.org/buildbot/chromium.memory/Linux%20ChromiumOS%20MSan%20Tests/9190

Sample Failed Step: capture_unittests

Original change's description:
> Enable camera blob stream when needed
> 
> Since blob stream needs higher resolution, it causes higher cpu loading
> to require higher resolution and resize to smaller resolution.
> In hangout app, we don't need blob stream. Enabling blob stream when
> needed can save a lot of cpu usage.
> 
> BUG=b:114676133
> TEST=manually test in apprtc and CCA. make sure picture taking still
> works in CCA.
> 
> Change-Id: I9144461bc76627903d0b3b359ce9cf962ff3628c
> Reviewed-on: https://chromium-review.googlesource.com/c/1261242
> Commit-Queue: Heng-ruey Hsu <henryhsu@chromium.org>
> Reviewed-by: Ricky Liang <jcliang@chromium.org>
> Reviewed-by: Xiaohan Wang <xhwang@chromium.org>
> Reviewed-by: Robert Sesek <rsesek@chromium.org>
> Cr-Commit-Position: refs/heads/master@{#601492}

No-Presubmit: true
No-Tree-Checks: true
No-Try: true
BUG=b:114676133

Change-Id: If173ffe9259f7eca849b184806bd56e2a9fbaac4
Reviewed-on: https://chromium-review.googlesource.com/c/1292256
Cr-Commit-Position: refs/heads/master@{#601538}",3,media/capture/mojom/video_capture_types_mojom_traits.cc,"{""sha"": ""849014ef4908ef3ef91fc0ae60499c2704742b58"", ""filename"": ""media/capture/mojom/video_capture_types.mojom"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 2, ""changes"": 3, ""blob_url"": ""https://github.com/chromium/chromium/blob/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/mojom/video_capture_types.mojom"", ""raw_url"": ""https://github.com/chromium/chromium/raw/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/mojom/video_capture_types.mojom"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/media/capture/mojom/video_capture_types.mojom?ref=fff73016a86f9a5990d080dc76058f8528a423f9"", ""patch"": ""@@ -205,8 +205,7 @@ enum VideoCaptureError {\n   kMacDeckLinkCouldNotStartCapturing,\n   kMacDeckLinkUnsupportedPixelFormat,\n   kMacAvFoundationReceivedAVCaptureSessionRuntimeErrorNotification,\n-  kAndroidApi2ErrorConfiguringCamera,\n-  kCrosHalV3DeviceDelegateFailedToFlush\n+  kAndroidApi2ErrorConfiguringCamera\n };\n \n enum VideoCaptureFrameDropReason {""}<_**next**_>{""sha"": ""02e2f9757b9d66ad79679536c875fccad7408572"", ""filename"": ""media/capture/mojom/video_capture_types_mojom_traits.cc"", ""status"": ""modified"", ""additions"": 0, ""deletions"": 6, ""changes"": 6, ""blob_url"": ""https://github.com/chromium/chromium/blob/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/mojom/video_capture_types_mojom_traits.cc"", ""raw_url"": ""https://github.com/chromium/chromium/raw/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/mojom/video_capture_types_mojom_traits.cc"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/media/capture/mojom/video_capture_types_mojom_traits.cc?ref=fff73016a86f9a5990d080dc76058f8528a423f9"", ""patch"": ""@@ -658,9 +658,6 @@ EnumTraits<media::mojom::VideoCaptureError, media::VideoCaptureError>::ToMojom(\n     case media::VideoCaptureError::kAndroidApi2ErrorConfiguringCamera:\n       return media::mojom::VideoCaptureError::\n           kAndroidApi2ErrorConfiguringCamera;\n-    case media::VideoCaptureError::kCrosHalV3DeviceDelegateFailedToFlush:\n-      return media::mojom::VideoCaptureError::\n-          kCrosHalV3DeviceDelegateFailedToFlush;\n   }\n   NOTREACHED();\n   return media::mojom::VideoCaptureError::kNone;\n@@ -1179,9 +1176,6 @@ bool EnumTraits<media::mojom::VideoCaptureError, media::VideoCaptureError>::\n     case media::mojom::VideoCaptureError::kAndroidApi2ErrorConfiguringCamera:\n       *output = media::VideoCaptureError::kAndroidApi2ErrorConfiguringCamera;\n       return true;\n-    case media::mojom::VideoCaptureError::kCrosHalV3DeviceDelegateFailedToFlush:\n-      *output = media::VideoCaptureError::kCrosHalV3DeviceDelegateFailedToFlush;\n-      return true;\n   }\n   NOTREACHED();\n   return false;""}<_**next**_>{""sha"": ""ecc9f87f4a2161a083c714a10046ba4adfe51131"", ""filename"": ""media/capture/video/chromeos/camera_device_delegate.cc"", ""status"": ""modified"", ""additions"": 38, ""deletions"": 76, ""changes"": 114, ""blob_url"": ""https://github.com/chromium/chromium/blob/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video/chromeos/camera_device_delegate.cc"", ""raw_url"": ""https://github.com/chromium/chromium/raw/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video/chromeos/camera_device_delegate.cc"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/media/capture/video/chromeos/camera_device_delegate.cc?ref=fff73016a86f9a5990d080dc76058f8528a423f9"", ""patch"": ""@@ -133,12 +133,6 @@ class CameraDeviceDelegate::StreamCaptureInterfaceImpl final\n     }\n   }\n \n-  void Flush(base::OnceCallback<void(int32_t)> callback) final {\n-    if (camera_device_delegate_) {\n-      camera_device_delegate_->Flush(std::move(callback));\n-    }\n-  }\n-\n  private:\n   const base::WeakPtr<CameraDeviceDelegate> camera_device_delegate_;\n };\n@@ -195,7 +189,7 @@ void CameraDeviceDelegate::StopAndDeAllocate(\n     // The device delegate is in the process of opening the camera device.\n     return;\n   }\n-  stream_buffer_manager_->StopPreview(base::NullCallback());\n+  stream_buffer_manager_->StopPreview();\n   device_ops_->Close(\n       base::BindOnce(&CameraDeviceDelegate::OnClosed, GetWeakPtr()));\n }\n@@ -232,17 +226,18 @@ void CameraDeviceDelegate::GetPhotoState(\n     return;\n   }\n \n-  int32_t max_blob_width = 0, max_blob_height = 0;\n-  GetMaxBlobStreamResolution(static_metadata_, &max_blob_width,\n-                             &max_blob_height);\n-  photo_state->width->current = max_blob_width;\n-  photo_state->width->min = max_blob_width;\n-  photo_state->width->max = max_blob_width;\n-  photo_state->width->step = 0.0;\n-  photo_state->height->current = max_blob_height;\n-  photo_state->height->min = max_blob_height;\n-  photo_state->height->max = max_blob_height;\n-  photo_state->height->step = 0.0;\n+  auto stream_config =\n+      stream_buffer_manager_->GetStreamConfiguration(StreamType::kStillCapture);\n+  if (stream_config) {\n+    photo_state->width->current = stream_config->width;\n+    photo_state->width->min = stream_config->width;\n+    photo_state->width->max = stream_config->width;\n+    photo_state->width->step = 0.0;\n+    photo_state->height->current = stream_config->height;\n+    photo_state->height->min = stream_config->height;\n+    photo_state->height->max = stream_config->height;\n+    photo_state->height->step = 0.0;\n+  }\n   std::move(callback).Run(std::move(photo_state));\n }\n \n@@ -263,14 +258,7 @@ void CameraDeviceDelegate::SetPhotoOptions(\n     return;\n   }\n \n-  if (stream_buffer_manager_->GetStreamNumber() < kMaxConfiguredStreams) {\n-    stream_buffer_manager_->StopPreview(\n-        base::BindOnce(&CameraDeviceDelegate::OnFlushed, GetWeakPtr()));\n-    set_photo_option_callback_ = std::move(callback);\n-  } else {\n-    set_photo_option_callback_.Reset();\n-    std::move(callback).Run(true);\n-  }\n+  std::move(callback).Run(true);\n }\n \n void CameraDeviceDelegate::SetRotation(int rotation) {\n@@ -294,7 +282,7 @@ void CameraDeviceDelegate::OnMojoConnectionError() {\n   } else {\n     // The Mojo channel terminated unexpectedly.\n     if (stream_buffer_manager_) {\n-      stream_buffer_manager_->StopPreview(base::NullCallback());\n+      stream_buffer_manager_->StopPreview();\n     }\n     device_context_->SetState(CameraDeviceContext::State::kStopped);\n     device_context_->SetErrorState(\n@@ -307,19 +295,6 @@ void CameraDeviceDelegate::OnMojoConnectionError() {\n   }\n }\n \n-void CameraDeviceDelegate::OnFlushed(int32_t result) {\n-  DCHECK(ipc_task_runner_->BelongsToCurrentThread());\n-  if (result) {\n-    device_context_->SetErrorState(\n-        media::VideoCaptureError::kCrosHalV3DeviceDelegateFailedToFlush,\n-        FROM_HERE,\n-        std::string(\""Flush failed: \"") + base::safe_strerror(-result));\n-    return;\n-  }\n-  device_context_->SetState(CameraDeviceContext::State::kInitialized);\n-  ConfigureStreams(true);\n-}\n-\n void CameraDeviceDelegate::OnClosed(int32_t result) {\n   DCHECK(ipc_task_runner_->BelongsToCurrentThread());\n   DCHECK_EQ(device_context_->GetState(), CameraDeviceContext::State::kStopping);\n@@ -451,10 +426,10 @@ void CameraDeviceDelegate::OnInitialized(int32_t result) {\n     return;\n   }\n   device_context_->SetState(CameraDeviceContext::State::kInitialized);\n-  ConfigureStreams(false);\n+  ConfigureStreams();\n }\n \n-void CameraDeviceDelegate::ConfigureStreams(bool require_photo) {\n+void CameraDeviceDelegate::ConfigureStreams() {\n   DCHECK(ipc_task_runner_->BelongsToCurrentThread());\n   DCHECK_EQ(device_context_->GetState(),\n             CameraDeviceContext::State::kInitialized);\n@@ -475,34 +450,31 @@ void CameraDeviceDelegate::ConfigureStreams(bool require_photo) {\n   preview_stream->rotation =\n       cros::mojom::Camera3StreamRotation::CAMERA3_STREAM_ROTATION_0;\n \n-  cros::mojom::Camera3StreamConfigurationPtr stream_config =\n-      cros::mojom::Camera3StreamConfiguration::New();\n-  stream_config->streams.push_back(std::move(preview_stream));\n-\n   // Set up context for still capture stream. We set still capture stream to the\n   // JPEG stream configuration with maximum supported resolution.\n   // TODO(jcliang): Once we support SetPhotoOptions() the still capture stream\n   // should be configured dynamically per the photo options.\n-  if (require_photo) {\n-    int32_t max_blob_width = 0, max_blob_height = 0;\n-    GetMaxBlobStreamResolution(static_metadata_, &max_blob_width,\n-                               &max_blob_height);\n-\n-    cros::mojom::Camera3StreamPtr still_capture_stream =\n-        cros::mojom::Camera3Stream::New();\n-    still_capture_stream->id = static_cast<uint64_t>(StreamType::kStillCapture);\n-    still_capture_stream->stream_type =\n-        cros::mojom::Camera3StreamType::CAMERA3_STREAM_OUTPUT;\n-    still_capture_stream->width = max_blob_width;\n-    still_capture_stream->height = max_blob_height;\n-    still_capture_stream->format =\n-        cros::mojom::HalPixelFormat::HAL_PIXEL_FORMAT_BLOB;\n-    still_capture_stream->data_space = 0;\n-    still_capture_stream->rotation =\n-        cros::mojom::Camera3StreamRotation::CAMERA3_STREAM_ROTATION_0;\n-    stream_config->streams.push_back(std::move(still_capture_stream));\n-  }\n+  int32_t max_blob_width = 0, max_blob_height = 0;\n+  GetMaxBlobStreamResolution(static_metadata_, &max_blob_width,\n+                             &max_blob_height);\n \n+  cros::mojom::Camera3StreamPtr still_capture_stream =\n+      cros::mojom::Camera3Stream::New();\n+  still_capture_stream->id = static_cast<uint64_t>(StreamType::kStillCapture);\n+  still_capture_stream->stream_type =\n+      cros::mojom::Camera3StreamType::CAMERA3_STREAM_OUTPUT;\n+  still_capture_stream->width = max_blob_width;\n+  still_capture_stream->height = max_blob_height;\n+  still_capture_stream->format =\n+      cros::mojom::HalPixelFormat::HAL_PIXEL_FORMAT_BLOB;\n+  still_capture_stream->data_space = 0;\n+  still_capture_stream->rotation =\n+      cros::mojom::Camera3StreamRotation::CAMERA3_STREAM_ROTATION_0;\n+\n+  cros::mojom::Camera3StreamConfigurationPtr stream_config =\n+      cros::mojom::Camera3StreamConfiguration::New();\n+  stream_config->streams.push_back(std::move(preview_stream));\n+  stream_config->streams.push_back(std::move(still_capture_stream));\n   stream_config->operation_mode = cros::mojom::Camera3StreamConfigurationMode::\n       CAMERA3_STREAM_CONFIGURATION_NORMAL_MODE;\n   device_ops_->ConfigureStreams(\n@@ -530,8 +502,7 @@ void CameraDeviceDelegate::OnConfiguredStreams(\n     return;\n   }\n   if (!updated_config ||\n-      updated_config->streams.size() > kMaxConfiguredStreams ||\n-      updated_config->streams.size() < 1) {\n+      updated_config->streams.size() != kMaxConfiguredStreams) {\n     device_context_->SetErrorState(\n         media::VideoCaptureError::\n             kCrosHalV3DeviceDelegateWrongNumberOfStreamsConfigured,\n@@ -598,10 +569,6 @@ void CameraDeviceDelegate::OnConstructedDefaultPreviewRequestSettings(\n         base::BindOnce(&CameraDeviceDelegate::ConstructDefaultRequestSettings,\n                        GetWeakPtr(), StreamType::kStillCapture));\n   }\n-\n-  if (set_photo_option_callback_) {\n-    std::move(set_photo_option_callback_).Run(true);\n-  }\n }\n \n void CameraDeviceDelegate::OnConstructedDefaultStillCaptureRequestSettings(\n@@ -666,11 +633,6 @@ void CameraDeviceDelegate::ProcessCaptureRequest(\n   device_ops_->ProcessCaptureRequest(std::move(request), std::move(callback));\n }\n \n-void CameraDeviceDelegate::Flush(base::OnceCallback<void(int32_t)> callback) {\n-  DCHECK(ipc_task_runner_->BelongsToCurrentThread());\n-  device_ops_->Flush(std::move(callback));\n-}\n-\n bool CameraDeviceDelegate::SetPointsOfInterest(\n     const std::vector<mojom::Point2DPtr>& points_of_interest) {\n   if (points_of_interest.empty()) {""}<_**next**_>{""sha"": ""1f4c3966071593f821acdf6701fad6c6dc613e8f"", ""filename"": ""media/capture/video/chromeos/camera_device_delegate.h"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 10, ""changes"": 11, ""blob_url"": ""https://github.com/chromium/chromium/blob/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video/chromeos/camera_device_delegate.h"", ""raw_url"": ""https://github.com/chromium/chromium/raw/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video/chromeos/camera_device_delegate.h"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/media/capture/video/chromeos/camera_device_delegate.h?ref=fff73016a86f9a5990d080dc76058f8528a423f9"", ""patch"": ""@@ -60,9 +60,6 @@ class CAPTURE_EXPORT StreamCaptureInterface {\n   virtual void ProcessCaptureRequest(\n       cros::mojom::Camera3CaptureRequestPtr request,\n       base::OnceCallback<void(int32_t)> callback) = 0;\n-\n-  // Send flush to cancel all pending requests to the camera HAL.\n-  virtual void Flush(base::OnceCallback<void(int32_t)> callback) = 0;\n };\n \n // CameraDeviceDelegate is instantiated on the capture thread where\n@@ -102,9 +99,6 @@ class CAPTURE_EXPORT CameraDeviceDelegate final {\n   // Mojo connection error handler.\n   void OnMojoConnectionError();\n \n-  // Reconfigure streams for picture taking.\n-  void OnFlushed(int32_t result);\n-\n   // Callback method for the Close Mojo IPC call.  This method resets the Mojo\n   // connection and closes the camera device.\n   void OnClosed(int32_t result);\n@@ -130,7 +124,7 @@ class CAPTURE_EXPORT CameraDeviceDelegate final {\n   // indicates.  If there's no error OnConfiguredStreams notifies\n   // |client_| the capture has started by calling OnStarted, and proceeds to\n   // ConstructDefaultRequestSettings.\n-  void ConfigureStreams(bool require_photo);\n+  void ConfigureStreams();\n   void OnConfiguredStreams(\n       int32_t result,\n       cros::mojom::Camera3StreamConfigurationPtr updated_config);\n@@ -161,7 +155,6 @@ class CAPTURE_EXPORT CameraDeviceDelegate final {\n                       base::OnceCallback<void(int32_t)> callback);\n   void ProcessCaptureRequest(cros::mojom::Camera3CaptureRequestPtr request,\n                              base::OnceCallback<void(int32_t)> callback);\n-  void Flush(base::OnceCallback<void(int32_t)> callback);\n \n   bool SetPointsOfInterest(\n       const std::vector<mojom::Point2DPtr>& points_of_interest);\n@@ -194,8 +187,6 @@ class CAPTURE_EXPORT CameraDeviceDelegate final {\n \n   base::OnceClosure device_close_callback_;\n \n-  VideoCaptureDevice::SetPhotoOptionsCallback set_photo_option_callback_;\n-\n   base::WeakPtrFactory<CameraDeviceDelegate> weak_ptr_factory_;\n \n   DISALLOW_IMPLICIT_CONSTRUCTORS(CameraDeviceDelegate);""}<_**next**_>{""sha"": ""d2c0646ab8372f2d8a6996a3774f513a80f52648"", ""filename"": ""media/capture/video/chromeos/camera_device_delegate_unittest.cc"", ""status"": ""modified"", ""additions"": 18, ""deletions"": 27, ""changes"": 45, ""blob_url"": ""https://github.com/chromium/chromium/blob/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video/chromeos/camera_device_delegate_unittest.cc"", ""raw_url"": ""https://github.com/chromium/chromium/raw/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video/chromeos/camera_device_delegate_unittest.cc"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/media/capture/video/chromeos/camera_device_delegate_unittest.cc?ref=fff73016a86f9a5990d080dc76058f8528a423f9"", ""patch"": ""@@ -242,13 +242,11 @@ class CameraDeviceDelegateTest : public ::testing::Test {\n       base::OnceCallback<void(int32_t,\n                               cros::mojom::Camera3StreamConfigurationPtr)>&\n           callback) {\n-    ASSERT_GE(2u, config->streams.size());\n-    ASSERT_LT(0u, config->streams.size());\n+    ASSERT_EQ(2u, config->streams.size());\n     for (size_t i = 0; i < config->streams.size(); ++i) {\n       config->streams[i]->usage = 0;\n       config->streams[i]->max_buffers = 1;\n     }\n-    num_streams_ = config->streams.size();\n     std::move(callback).Run(0, std::move(config));\n   }\n \n@@ -334,16 +332,14 @@ class CameraDeviceDelegateTest : public ::testing::Test {\n         .Times(1)\n         .WillOnce(Invoke(&unittest_internal::MockGpuMemoryBufferManager::\n                              CreateFakeGpuMemoryBuffer));\n-    if (num_streams_ == 2) {\n-      EXPECT_CALL(\n-          mock_gpu_memory_buffer_manager_,\n-          CreateGpuMemoryBuffer(_, gfx::BufferFormat::R_8,\n-                                gfx::BufferUsage::CAMERA_AND_CPU_READ_WRITE,\n-                                gpu::kNullSurfaceHandle))\n-          .Times(1)\n-          .WillOnce(Invoke(&unittest_internal::MockGpuMemoryBufferManager::\n-                               CreateFakeGpuMemoryBuffer));\n-    }\n+    EXPECT_CALL(\n+        mock_gpu_memory_buffer_manager_,\n+        CreateGpuMemoryBuffer(_, gfx::BufferFormat::R_8,\n+                              gfx::BufferUsage::CAMERA_AND_CPU_READ_WRITE,\n+                              gpu::kNullSurfaceHandle))\n+        .Times(1)\n+        .WillOnce(Invoke(&unittest_internal::MockGpuMemoryBufferManager::\n+                             CreateFakeGpuMemoryBuffer));\n     EXPECT_CALL(\n         mock_gpu_memory_buffer_manager_,\n         CreateGpuMemoryBuffer(gfx::Size(kDefaultWidth, kDefaultHeight),\n@@ -353,16 +349,14 @@ class CameraDeviceDelegateTest : public ::testing::Test {\n         .Times(1)\n         .WillOnce(Invoke(&unittest_internal::MockGpuMemoryBufferManager::\n                              CreateFakeGpuMemoryBuffer));\n-    if (num_streams_ == 2) {\n-      EXPECT_CALL(mock_gpu_memory_buffer_manager_,\n-                  CreateGpuMemoryBuffer(\n-                      gfx::Size(kJpegMaxBufferSize, 1), gfx::BufferFormat::R_8,\n-                      gfx::BufferUsage::CAMERA_AND_CPU_READ_WRITE,\n-                      gpu::kNullSurfaceHandle))\n-          .Times(1)\n-          .WillOnce(Invoke(&unittest_internal::MockGpuMemoryBufferManager::\n-                               CreateFakeGpuMemoryBuffer));\n-    }\n+    EXPECT_CALL(mock_gpu_memory_buffer_manager_,\n+                CreateGpuMemoryBuffer(\n+                    gfx::Size(kJpegMaxBufferSize, 1), gfx::BufferFormat::R_8,\n+                    gfx::BufferUsage::CAMERA_AND_CPU_READ_WRITE,\n+                    gpu::kNullSurfaceHandle))\n+        .Times(1)\n+        .WillOnce(Invoke(&unittest_internal::MockGpuMemoryBufferManager::\n+                             CreateFakeGpuMemoryBuffer));\n   }\n \n   void SetUpExpectationUntilCapturing(\n@@ -428,7 +422,6 @@ class CameraDeviceDelegateTest : public ::testing::Test {\n     ASSERT_TRUE(camera_device_delegate_);\n     device_delegate_thread_.Stop();\n     camera_device_delegate_.reset();\n-    num_streams_ = 0;\n   }\n \n   void DoLoop() {\n@@ -468,8 +461,6 @@ class CameraDeviceDelegateTest : public ::testing::Test {\n \n   std::unique_ptr<CameraDeviceContext> device_context_;\n \n-  size_t num_streams_;\n-\n  private:\n   base::test::ScopedTaskEnvironment scoped_task_environment_;\n   base::Thread hal_delegate_thread_;\n@@ -612,7 +603,7 @@ TEST_F(CameraDeviceDelegateTest, FailToOpenDevice) {\n   };\n   EXPECT_CALL(*mock_client, OnError(_, _, _))\n       .Times(AtLeast(1))\n-      .WillRepeatedly(InvokeWithoutArgs(stop_on_error));\n+      .WillOnce(InvokeWithoutArgs(stop_on_error));\n \n   EXPECT_CALL(mock_camera_module_, DoGetCameraInfo(0, _))\n       .Times(1)""}<_**next**_>{""sha"": ""05e0da906502a6b44265bc01f33a5122a3cebb39"", ""filename"": ""media/capture/video/chromeos/stream_buffer_manager.cc"", ""status"": ""modified"", ""additions"": 3, ""deletions"": 11, ""changes"": 14, ""blob_url"": ""https://github.com/chromium/chromium/blob/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video/chromeos/stream_buffer_manager.cc"", ""raw_url"": ""https://github.com/chromium/chromium/raw/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video/chromeos/stream_buffer_manager.cc"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/media/capture/video/chromeos/stream_buffer_manager.cc?ref=fff73016a86f9a5990d080dc76058f8528a423f9"", ""patch"": ""@@ -187,13 +187,9 @@ void StreamBufferManager::StartPreview(\n   RegisterBuffer(StreamType::kPreview);\n }\n \n-void StreamBufferManager::StopPreview(\n-    base::OnceCallback<void(int32_t)> callback) {\n+void StreamBufferManager::StopPreview() {\n   DCHECK(ipc_task_runner_->BelongsToCurrentThread());\n   capturing_ = false;\n-  if (callback) {\n-    capture_interface_->Flush(std::move(callback));\n-  }\n }\n \n cros::mojom::Camera3StreamPtr StreamBufferManager::GetStreamConfiguration(\n@@ -227,10 +223,6 @@ void StreamBufferManager::TakePhoto(\n   RegisterBuffer(StreamType::kStillCapture);\n }\n \n-size_t StreamBufferManager::GetStreamNumber() {\n-  return stream_context_.size();\n-}\n-\n void StreamBufferManager::AddResultMetadataObserver(\n     ResultMetadataObserver* observer) {\n   DCHECK(ipc_task_runner_->BelongsToCurrentThread());\n@@ -424,6 +416,7 @@ void StreamBufferManager::OnRegisteredBuffer(StreamType stream_type,\n void StreamBufferManager::ProcessCaptureRequest() {\n   DCHECK(ipc_task_runner_->BelongsToCurrentThread());\n   DCHECK(stream_context_[StreamType::kPreview]);\n+  DCHECK(stream_context_[StreamType::kStillCapture]);\n \n   cros::mojom::Camera3CaptureRequestPtr request =\n       cros::mojom::Camera3CaptureRequest::New();\n@@ -446,8 +439,7 @@ void StreamBufferManager::ProcessCaptureRequest() {\n     request->output_buffers.push_back(std::move(buffer));\n   }\n \n-  if (stream_context_.count(StreamType::kStillCapture) &&\n-      !stream_context_[StreamType::kStillCapture]->registered_buffers.empty()) {\n+  if (!stream_context_[StreamType::kStillCapture]->registered_buffers.empty()) {\n     DCHECK(!still_capture_callbacks_currently_processing_.empty());\n     cros::mojom::Camera3StreamBufferPtr buffer =\n         cros::mojom::Camera3StreamBuffer::New();""}<_**next**_>{""sha"": ""1fa3f22573e3314a77fad39379daca6d18637dbd"", ""filename"": ""media/capture/video/chromeos/stream_buffer_manager.h"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 3, ""changes"": 4, ""blob_url"": ""https://github.com/chromium/chromium/blob/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video/chromeos/stream_buffer_manager.h"", ""raw_url"": ""https://github.com/chromium/chromium/raw/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video/chromeos/stream_buffer_manager.h"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/media/capture/video/chromeos/stream_buffer_manager.h?ref=fff73016a86f9a5990d080dc76058f8528a423f9"", ""patch"": ""@@ -116,15 +116,13 @@ class CAPTURE_EXPORT StreamBufferManager final\n \n   // Stops the capture loop.  After StopPreview is called |callback_ops_| is\n   // unbound, so no new capture request or result will be processed.\n-  void StopPreview(base::OnceCallback<void(int32_t)> callback);\n+  void StopPreview();\n \n   cros::mojom::Camera3StreamPtr GetStreamConfiguration(StreamType stream_type);\n \n   void TakePhoto(cros::mojom::CameraMetadataPtr settings,\n                  VideoCaptureDevice::TakePhotoCallback callback);\n \n-  size_t GetStreamNumber();\n-\n   // CaptureMetadataDispatcher implementations.\n   void AddResultMetadataObserver(ResultMetadataObserver* observer) override;\n   void RemoveResultMetadataObserver(ResultMetadataObserver* observer) override;""}<_**next**_>{""sha"": ""2fcbdfeb4065cd52fb78234eafcd6c99520bc811"", ""filename"": ""media/capture/video/chromeos/stream_buffer_manager_unittest.cc"", ""status"": ""modified"", ""additions"": 0, ""deletions"": 3, ""changes"": 3, ""blob_url"": ""https://github.com/chromium/chromium/blob/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video/chromeos/stream_buffer_manager_unittest.cc"", ""raw_url"": ""https://github.com/chromium/chromium/raw/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video/chromeos/stream_buffer_manager_unittest.cc"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/media/capture/video/chromeos/stream_buffer_manager_unittest.cc?ref=fff73016a86f9a5990d080dc76058f8528a423f9"", ""patch"": ""@@ -63,9 +63,6 @@ class MockStreamCaptureInterface : public StreamCaptureInterface {\n   MOCK_METHOD2(DoProcessCaptureRequest,\n                void(cros::mojom::Camera3CaptureRequestPtr& request,\n                     base::OnceCallback<void(int32_t)>& callback));\n-\n-  void Flush(base::OnceCallback<void(int32_t)> callback) { DoFlush(callback); }\n-  MOCK_METHOD1(DoFlush, void(base::OnceCallback<void(int32_t)>& callback));\n };\n \n const VideoCaptureFormat kDefaultCaptureFormat(gfx::Size(1280, 720),""}<_**next**_>{""sha"": ""599200ed423d1215a8ab81f0dc732138fb94b02a"", ""filename"": ""media/capture/video_capture_types.h"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 2, ""changes"": 3, ""blob_url"": ""https://github.com/chromium/chromium/blob/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video_capture_types.h"", ""raw_url"": ""https://github.com/chromium/chromium/raw/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video_capture_types.h"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/media/capture/video_capture_types.h?ref=fff73016a86f9a5990d080dc76058f8528a423f9"", ""patch"": ""@@ -178,8 +178,7 @@ enum class VideoCaptureError {\n   kMacDeckLinkUnsupportedPixelFormat = 112,\n   kMacAvFoundationReceivedAVCaptureSessionRuntimeErrorNotification = 113,\n   kAndroidApi2ErrorConfiguringCamera = 114,\n-  kCrosHalV3DeviceDelegateFailedToFlush = 115,\n-  kMaxValue = 115\n+  kMaxValue = 114\n };\n \n // WARNING: Do not change the values assigned to the entries. They are used for""}","    FromMojom(media::mojom::VideoCaptureError input,
              media::VideoCaptureError* output) {
  switch (input) {
    case media::mojom::VideoCaptureError::kNone:
      *output = media::VideoCaptureError::kNone;
      return true;
    case media::mojom::VideoCaptureError::
        kVideoCaptureControllerInvalidOrUnsupportedVideoCaptureParametersRequested:
      *output = media::VideoCaptureError::
          kVideoCaptureControllerInvalidOrUnsupportedVideoCaptureParametersRequested;
      return true;
    case media::mojom::VideoCaptureError::
        kVideoCaptureControllerIsAlreadyInErrorState:
      *output = media::VideoCaptureError::
          kVideoCaptureControllerIsAlreadyInErrorState;
      return true;
    case media::mojom::VideoCaptureError::
        kVideoCaptureManagerDeviceConnectionLost:
      *output =
          media::VideoCaptureError::kVideoCaptureManagerDeviceConnectionLost;
      return true;
    case media::mojom::VideoCaptureError::
        kFrameSinkVideoCaptureDeviceAleradyEndedOnFatalError:
      *output = media::VideoCaptureError::
          kFrameSinkVideoCaptureDeviceAleradyEndedOnFatalError;
      return true;
    case media::mojom::VideoCaptureError::
        kFrameSinkVideoCaptureDeviceEncounteredFatalError:
      *output = media::VideoCaptureError::
          kFrameSinkVideoCaptureDeviceEncounteredFatalError;
      return true;
    case media::mojom::VideoCaptureError::kV4L2FailedToOpenV4L2DeviceDriverFile:
      *output = media::VideoCaptureError::kV4L2FailedToOpenV4L2DeviceDriverFile;
      return true;
    case media::mojom::VideoCaptureError::kV4L2ThisIsNotAV4L2VideoCaptureDevice:
      *output = media::VideoCaptureError::kV4L2ThisIsNotAV4L2VideoCaptureDevice;
      return true;
    case media::mojom::VideoCaptureError::
        kV4L2FailedToFindASupportedCameraFormat:
      *output =
          media::VideoCaptureError::kV4L2FailedToFindASupportedCameraFormat;
      return true;
    case media::mojom::VideoCaptureError::kV4L2FailedToSetVideoCaptureFormat:
      *output = media::VideoCaptureError::kV4L2FailedToSetVideoCaptureFormat;
      return true;
    case media::mojom::VideoCaptureError::kV4L2UnsupportedPixelFormat:
      *output = media::VideoCaptureError::kV4L2UnsupportedPixelFormat;
      return true;
    case media::mojom::VideoCaptureError::kV4L2FailedToSetCameraFramerate:
      *output = media::VideoCaptureError::kV4L2FailedToSetCameraFramerate;
      return true;
    case media::mojom::VideoCaptureError::kV4L2ErrorRequestingMmapBuffers:
      *output = media::VideoCaptureError::kV4L2ErrorRequestingMmapBuffers;
      return true;
    case media::mojom::VideoCaptureError::kV4L2AllocateBufferFailed:
      *output = media::VideoCaptureError::kV4L2AllocateBufferFailed;
      return true;
    case media::mojom::VideoCaptureError::kV4L2VidiocStreamonFailed:
      *output = media::VideoCaptureError::kV4L2VidiocStreamonFailed;
      return true;
    case media::mojom::VideoCaptureError::kV4L2VidiocStreamoffFailed:
      *output = media::VideoCaptureError::kV4L2VidiocStreamoffFailed;
      return true;
    case media::mojom::VideoCaptureError::kV4L2FailedToVidiocReqbufsWithCount0:
      *output = media::VideoCaptureError::kV4L2FailedToVidiocReqbufsWithCount0;
      return true;
    case media::mojom::VideoCaptureError::kV4L2PollFailed:
      *output = media::VideoCaptureError::kV4L2PollFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kV4L2MultipleContinuousTimeoutsWhileReadPolling:
      *output = media::VideoCaptureError::
          kV4L2MultipleContinuousTimeoutsWhileReadPolling;
      return true;
    case media::mojom::VideoCaptureError::kV4L2FailedToDequeueCaptureBuffer:
      *output = media::VideoCaptureError::kV4L2FailedToDequeueCaptureBuffer;
      return true;
    case media::mojom::VideoCaptureError::kV4L2FailedToEnqueueCaptureBuffer:
      *output = media::VideoCaptureError::kV4L2FailedToEnqueueCaptureBuffer;
      return true;
    case media::mojom::VideoCaptureError::
        kSingleClientVideoCaptureHostLostConnectionToDevice:
      *output = media::VideoCaptureError::
          kSingleClientVideoCaptureHostLostConnectionToDevice;
      return true;
    case media::mojom::VideoCaptureError::
        kSingleClientVideoCaptureDeviceLaunchAborted:
      *output = media::VideoCaptureError::
          kSingleClientVideoCaptureDeviceLaunchAborted;
      return true;
    case media::mojom::VideoCaptureError::
        kDesktopCaptureDeviceWebrtcDesktopCapturerHasFailed:
      *output = media::VideoCaptureError::
          kDesktopCaptureDeviceWebrtcDesktopCapturerHasFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kFileVideoCaptureDeviceCouldNotOpenVideoFile:
      *output = media::VideoCaptureError::
          kFileVideoCaptureDeviceCouldNotOpenVideoFile;
      return true;
    case media::mojom::VideoCaptureError::
        kDeviceCaptureLinuxFailedToCreateVideoCaptureDelegate:
      *output = media::VideoCaptureError::
          kDeviceCaptureLinuxFailedToCreateVideoCaptureDelegate;
      return true;
    case media::mojom::VideoCaptureError::
        kErrorFakeDeviceIntentionallyEmittingErrorEvent:
      *output = media::VideoCaptureError::
          kErrorFakeDeviceIntentionallyEmittingErrorEvent;
      return true;
    case media::mojom::VideoCaptureError::kDeviceClientTooManyFramesDroppedY16:
      *output = media::VideoCaptureError::kDeviceClientTooManyFramesDroppedY16;
      return true;
    case media::mojom::VideoCaptureError::
        kDeviceMediaToMojoAdapterEncounteredUnsupportedBufferType:
      *output = media::VideoCaptureError::
          kDeviceMediaToMojoAdapterEncounteredUnsupportedBufferType;
      return true;
    case media::mojom::VideoCaptureError::
        kVideoCaptureManagerProcessDeviceStartQueueDeviceInfoNotFound:
      *output = media::VideoCaptureError::
          kVideoCaptureManagerProcessDeviceStartQueueDeviceInfoNotFound;
      return true;
    case media::mojom::VideoCaptureError::
        kInProcessDeviceLauncherFailedToCreateDeviceInstance:
      *output = media::VideoCaptureError::
          kInProcessDeviceLauncherFailedToCreateDeviceInstance;
      return true;
    case media::mojom::VideoCaptureError::
        kServiceDeviceLauncherLostConnectionToDeviceFactoryDuringDeviceStart:
      *output = media::VideoCaptureError::
          kServiceDeviceLauncherLostConnectionToDeviceFactoryDuringDeviceStart;
      return true;
    case media::mojom::VideoCaptureError::
        kServiceDeviceLauncherServiceRespondedWithDeviceNotFound:
      *output = media::VideoCaptureError::
          kServiceDeviceLauncherServiceRespondedWithDeviceNotFound;
      return true;
    case media::mojom::VideoCaptureError::
        kServiceDeviceLauncherConnectionLostWhileWaitingForCallback:
      *output = media::VideoCaptureError::
          kServiceDeviceLauncherConnectionLostWhileWaitingForCallback;
      return true;
    case media::mojom::VideoCaptureError::kIntentionalErrorRaisedByUnitTest:
      *output = media::VideoCaptureError::kIntentionalErrorRaisedByUnitTest;
      return true;
    case media::mojom::VideoCaptureError::kCrosHalV3FailedToStartDeviceThread:
      *output = media::VideoCaptureError::kCrosHalV3FailedToStartDeviceThread;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3DeviceDelegateMojoConnectionError:
      *output =
          media::VideoCaptureError::kCrosHalV3DeviceDelegateMojoConnectionError;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToGetCameraInfo:
      *output = media::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToGetCameraInfo;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3DeviceDelegateMissingSensorOrientationInfo:
      *output = media::VideoCaptureError::
          kCrosHalV3DeviceDelegateMissingSensorOrientationInfo;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToOpenCameraDevice:
      *output = media::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToOpenCameraDevice;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToInitializeCameraDevice:
      *output = media::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToInitializeCameraDevice;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToConfigureStreams:
      *output = media::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToConfigureStreams;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3DeviceDelegateWrongNumberOfStreamsConfigured:
      *output = media::VideoCaptureError::
          kCrosHalV3DeviceDelegateWrongNumberOfStreamsConfigured;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToGetDefaultRequestSettings:
      *output = media::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToGetDefaultRequestSettings;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerHalRequestedTooManyBuffers:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerHalRequestedTooManyBuffers;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToCreateGpuMemoryBuffer:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToCreateGpuMemoryBuffer;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToMapGpuMemoryBuffer:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToMapGpuMemoryBuffer;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerUnsupportedVideoPixelFormat:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerUnsupportedVideoPixelFormat;
      return true;
    case media::mojom::VideoCaptureError::kCrosHalV3BufferManagerFailedToDupFd:
      *output = media::VideoCaptureError::kCrosHalV3BufferManagerFailedToDupFd;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToWrapGpuMemoryHandle:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToWrapGpuMemoryHandle;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToRegisterBuffer:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToRegisterBuffer;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerProcessCaptureRequestFailed:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerProcessCaptureRequestFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerInvalidPendingResultId:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerInvalidPendingResultId;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerReceivedDuplicatedPartialMetadata:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerReceivedDuplicatedPartialMetadata;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerIncorrectNumberOfOutputBuffersReceived:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerIncorrectNumberOfOutputBuffersReceived;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerInvalidTypeOfOutputBuffersReceived:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerInvalidTypeOfOutputBuffersReceived;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerReceivedMultipleResultBuffersForFrame:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerReceivedMultipleResultBuffersForFrame;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerUnknownStreamInCamera3NotifyMsg:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerUnknownStreamInCamera3NotifyMsg;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerReceivedInvalidShutterTime:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerReceivedInvalidShutterTime;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerFatalDeviceError:
      *output =
          media::VideoCaptureError::kCrosHalV3BufferManagerFatalDeviceError;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerReceivedFrameIsOutOfOrder:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerReceivedFrameIsOutOfOrder;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToUnwrapReleaseFenceFd:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToUnwrapReleaseFenceFd;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerSyncWaitOnReleaseFenceTimedOut:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerSyncWaitOnReleaseFenceTimedOut;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerInvalidJpegBlob:
      *output =
          media::VideoCaptureError::kCrosHalV3BufferManagerInvalidJpegBlob;
      return true;
    case media::mojom::VideoCaptureError::kAndroidFailedToAllocate:
      *output = media::VideoCaptureError::kAndroidFailedToAllocate;
      return true;
    case media::mojom::VideoCaptureError::kAndroidFailedToStartCapture:
      *output = media::VideoCaptureError::kAndroidFailedToStartCapture;
      return true;
    case media::mojom::VideoCaptureError::kAndroidFailedToStopCapture:
      *output = media::VideoCaptureError::kAndroidFailedToStopCapture;
      return true;
    case media::mojom::VideoCaptureError::
        kAndroidApi1CameraErrorCallbackReceived:
      *output =
          media::VideoCaptureError::kAndroidApi1CameraErrorCallbackReceived;
      return true;
    case media::mojom::VideoCaptureError::kAndroidApi2CameraDeviceErrorReceived:
      *output = media::VideoCaptureError::kAndroidApi2CameraDeviceErrorReceived;
      return true;
    case media::mojom::VideoCaptureError::
        kAndroidApi2CaptureSessionConfigureFailed:
      *output =
          media::VideoCaptureError::kAndroidApi2CaptureSessionConfigureFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kAndroidApi2ImageReaderUnexpectedImageFormat:
      *output = media::VideoCaptureError::
          kAndroidApi2ImageReaderUnexpectedImageFormat;
      return true;
    case media::mojom::VideoCaptureError::
        kAndroidApi2ImageReaderSizeDidNotMatchImageSize:
      *output = media::VideoCaptureError::
          kAndroidApi2ImageReaderSizeDidNotMatchImageSize;
      return true;
    case media::mojom::VideoCaptureError::kAndroidApi2ErrorRestartingPreview:
      *output = media::VideoCaptureError::kAndroidApi2ErrorRestartingPreview;
      return true;
    case media::mojom::VideoCaptureError::
        kAndroidScreenCaptureUnsupportedFormat:
      *output =
          media::VideoCaptureError::kAndroidScreenCaptureUnsupportedFormat;
      return true;
    case media::mojom::VideoCaptureError::
        kAndroidScreenCaptureFailedToStartCaptureMachine:
      *output = media::VideoCaptureError::
          kAndroidScreenCaptureFailedToStartCaptureMachine;
      return true;
    case media::mojom::VideoCaptureError::
        kAndroidScreenCaptureTheUserDeniedScreenCapture:
      *output = media::VideoCaptureError::
          kAndroidScreenCaptureTheUserDeniedScreenCapture;
      return true;
    case media::mojom::VideoCaptureError::
        kAndroidScreenCaptureFailedToStartScreenCapture:
      *output = media::VideoCaptureError::
          kAndroidScreenCaptureFailedToStartScreenCapture;
      return true;
    case media::mojom::VideoCaptureError::
        kWinDirectShowCantGetCaptureFormatSettings:
      *output =
          media::VideoCaptureError::kWinDirectShowCantGetCaptureFormatSettings;
      return true;
    case media::mojom::VideoCaptureError::
        kWinDirectShowFailedToGetNumberOfCapabilities:
      *output = media::VideoCaptureError::
          kWinDirectShowFailedToGetNumberOfCapabilities;
      return true;
    case media::mojom::VideoCaptureError::
        kWinDirectShowFailedToGetCaptureDeviceCapabilities:
      *output = media::VideoCaptureError::
          kWinDirectShowFailedToGetCaptureDeviceCapabilities;
      return true;
    case media::mojom::VideoCaptureError::
        kWinDirectShowFailedToSetCaptureDeviceOutputFormat:
      *output = media::VideoCaptureError::
          kWinDirectShowFailedToSetCaptureDeviceOutputFormat;
      return true;
    case media::mojom::VideoCaptureError::
        kWinDirectShowFailedToConnectTheCaptureGraph:
      *output = media::VideoCaptureError::
          kWinDirectShowFailedToConnectTheCaptureGraph;
      return true;
    case media::mojom::VideoCaptureError::
        kWinDirectShowFailedToPauseTheCaptureDevice:
      *output =
          media::VideoCaptureError::kWinDirectShowFailedToPauseTheCaptureDevice;
      return true;
    case media::mojom::VideoCaptureError::
        kWinDirectShowFailedToStartTheCaptureDevice:
      *output =
          media::VideoCaptureError::kWinDirectShowFailedToStartTheCaptureDevice;
      return true;
    case media::mojom::VideoCaptureError::
        kWinDirectShowFailedToStopTheCaptureGraph:
      *output =
          media::VideoCaptureError::kWinDirectShowFailedToStopTheCaptureGraph;
      return true;
    case media::mojom::VideoCaptureError::kWinMediaFoundationEngineIsNull:
      *output = media::VideoCaptureError::kWinMediaFoundationEngineIsNull;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationEngineGetSourceFailed:
      *output =
          media::VideoCaptureError::kWinMediaFoundationEngineGetSourceFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationFillPhotoCapabilitiesFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationFillPhotoCapabilitiesFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationFillVideoCapabilitiesFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationFillVideoCapabilitiesFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationNoVideoCapabilityFound:
      *output =
          media::VideoCaptureError::kWinMediaFoundationNoVideoCapabilityFound;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationGetAvailableDeviceMediaTypeFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationGetAvailableDeviceMediaTypeFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationSetCurrentDeviceMediaTypeFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationSetCurrentDeviceMediaTypeFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationEngineGetSinkFailed:
      *output =
          media::VideoCaptureError::kWinMediaFoundationEngineGetSinkFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationSinkQueryCapturePreviewInterfaceFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationSinkQueryCapturePreviewInterfaceFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationSinkRemoveAllStreamsFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationSinkRemoveAllStreamsFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationCreateSinkVideoMediaTypeFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationCreateSinkVideoMediaTypeFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationConvertToVideoSinkMediaTypeFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationConvertToVideoSinkMediaTypeFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationSinkAddStreamFailed:
      *output =
          media::VideoCaptureError::kWinMediaFoundationSinkAddStreamFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationSinkSetSampleCallbackFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationSinkSetSampleCallbackFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationEngineStartPreviewFailed:
      *output =
          media::VideoCaptureError::kWinMediaFoundationEngineStartPreviewFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationGetMediaEventStatusFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationGetMediaEventStatusFailed;
      return true;
    case media::mojom::VideoCaptureError::kMacSetCaptureDeviceFailed:
      *output = media::VideoCaptureError::kMacSetCaptureDeviceFailed;
      return true;
    case media::mojom::VideoCaptureError::kMacCouldNotStartCaptureDevice:
      *output = media::VideoCaptureError::kMacCouldNotStartCaptureDevice;
      return true;
    case media::mojom::VideoCaptureError::
        kMacReceivedFrameWithUnexpectedResolution:
      *output =
          media::VideoCaptureError::kMacReceivedFrameWithUnexpectedResolution;
      return true;
    case media::mojom::VideoCaptureError::kMacUpdateCaptureResolutionFailed:
      *output = media::VideoCaptureError::kMacUpdateCaptureResolutionFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kMacDeckLinkDeviceIdNotFoundInTheSystem:
      *output =
          media::VideoCaptureError::kMacDeckLinkDeviceIdNotFoundInTheSystem;
      return true;
    case media::mojom::VideoCaptureError::
        kMacDeckLinkErrorQueryingInputInterface:
      *output =
          media::VideoCaptureError::kMacDeckLinkErrorQueryingInputInterface;
      return true;
    case media::mojom::VideoCaptureError::
        kMacDeckLinkErrorCreatingDisplayModeIterator:
      *output = media::VideoCaptureError::
          kMacDeckLinkErrorCreatingDisplayModeIterator;
      return true;
    case media::mojom::VideoCaptureError::kMacDeckLinkCouldNotFindADisplayMode:
      *output = media::VideoCaptureError::kMacDeckLinkCouldNotFindADisplayMode;
      return true;
    case media::mojom::VideoCaptureError::
        kMacDeckLinkCouldNotSelectTheVideoFormatWeLike:
      *output = media::VideoCaptureError::
          kMacDeckLinkCouldNotSelectTheVideoFormatWeLike;
      return true;
    case media::mojom::VideoCaptureError::kMacDeckLinkCouldNotStartCapturing:
      *output = media::VideoCaptureError::kMacDeckLinkCouldNotStartCapturing;
      return true;
    case media::mojom::VideoCaptureError::kMacDeckLinkUnsupportedPixelFormat:
      *output = media::VideoCaptureError::kMacDeckLinkUnsupportedPixelFormat;
      return true;
    case media::mojom::VideoCaptureError::
        kMacAvFoundationReceivedAVCaptureSessionRuntimeErrorNotification:
      *output = media::VideoCaptureError::
          kMacAvFoundationReceivedAVCaptureSessionRuntimeErrorNotification;
      return true;
     case media::mojom::VideoCaptureError::kAndroidApi2ErrorConfiguringCamera:
       *output = media::VideoCaptureError::kAndroidApi2ErrorConfiguringCamera;
       return true;
   }
   NOTREACHED();
   return false;
}
","    FromMojom(media::mojom::VideoCaptureError input,
              media::VideoCaptureError* output) {
  switch (input) {
    case media::mojom::VideoCaptureError::kNone:
      *output = media::VideoCaptureError::kNone;
      return true;
    case media::mojom::VideoCaptureError::
        kVideoCaptureControllerInvalidOrUnsupportedVideoCaptureParametersRequested:
      *output = media::VideoCaptureError::
          kVideoCaptureControllerInvalidOrUnsupportedVideoCaptureParametersRequested;
      return true;
    case media::mojom::VideoCaptureError::
        kVideoCaptureControllerIsAlreadyInErrorState:
      *output = media::VideoCaptureError::
          kVideoCaptureControllerIsAlreadyInErrorState;
      return true;
    case media::mojom::VideoCaptureError::
        kVideoCaptureManagerDeviceConnectionLost:
      *output =
          media::VideoCaptureError::kVideoCaptureManagerDeviceConnectionLost;
      return true;
    case media::mojom::VideoCaptureError::
        kFrameSinkVideoCaptureDeviceAleradyEndedOnFatalError:
      *output = media::VideoCaptureError::
          kFrameSinkVideoCaptureDeviceAleradyEndedOnFatalError;
      return true;
    case media::mojom::VideoCaptureError::
        kFrameSinkVideoCaptureDeviceEncounteredFatalError:
      *output = media::VideoCaptureError::
          kFrameSinkVideoCaptureDeviceEncounteredFatalError;
      return true;
    case media::mojom::VideoCaptureError::kV4L2FailedToOpenV4L2DeviceDriverFile:
      *output = media::VideoCaptureError::kV4L2FailedToOpenV4L2DeviceDriverFile;
      return true;
    case media::mojom::VideoCaptureError::kV4L2ThisIsNotAV4L2VideoCaptureDevice:
      *output = media::VideoCaptureError::kV4L2ThisIsNotAV4L2VideoCaptureDevice;
      return true;
    case media::mojom::VideoCaptureError::
        kV4L2FailedToFindASupportedCameraFormat:
      *output =
          media::VideoCaptureError::kV4L2FailedToFindASupportedCameraFormat;
      return true;
    case media::mojom::VideoCaptureError::kV4L2FailedToSetVideoCaptureFormat:
      *output = media::VideoCaptureError::kV4L2FailedToSetVideoCaptureFormat;
      return true;
    case media::mojom::VideoCaptureError::kV4L2UnsupportedPixelFormat:
      *output = media::VideoCaptureError::kV4L2UnsupportedPixelFormat;
      return true;
    case media::mojom::VideoCaptureError::kV4L2FailedToSetCameraFramerate:
      *output = media::VideoCaptureError::kV4L2FailedToSetCameraFramerate;
      return true;
    case media::mojom::VideoCaptureError::kV4L2ErrorRequestingMmapBuffers:
      *output = media::VideoCaptureError::kV4L2ErrorRequestingMmapBuffers;
      return true;
    case media::mojom::VideoCaptureError::kV4L2AllocateBufferFailed:
      *output = media::VideoCaptureError::kV4L2AllocateBufferFailed;
      return true;
    case media::mojom::VideoCaptureError::kV4L2VidiocStreamonFailed:
      *output = media::VideoCaptureError::kV4L2VidiocStreamonFailed;
      return true;
    case media::mojom::VideoCaptureError::kV4L2VidiocStreamoffFailed:
      *output = media::VideoCaptureError::kV4L2VidiocStreamoffFailed;
      return true;
    case media::mojom::VideoCaptureError::kV4L2FailedToVidiocReqbufsWithCount0:
      *output = media::VideoCaptureError::kV4L2FailedToVidiocReqbufsWithCount0;
      return true;
    case media::mojom::VideoCaptureError::kV4L2PollFailed:
      *output = media::VideoCaptureError::kV4L2PollFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kV4L2MultipleContinuousTimeoutsWhileReadPolling:
      *output = media::VideoCaptureError::
          kV4L2MultipleContinuousTimeoutsWhileReadPolling;
      return true;
    case media::mojom::VideoCaptureError::kV4L2FailedToDequeueCaptureBuffer:
      *output = media::VideoCaptureError::kV4L2FailedToDequeueCaptureBuffer;
      return true;
    case media::mojom::VideoCaptureError::kV4L2FailedToEnqueueCaptureBuffer:
      *output = media::VideoCaptureError::kV4L2FailedToEnqueueCaptureBuffer;
      return true;
    case media::mojom::VideoCaptureError::
        kSingleClientVideoCaptureHostLostConnectionToDevice:
      *output = media::VideoCaptureError::
          kSingleClientVideoCaptureHostLostConnectionToDevice;
      return true;
    case media::mojom::VideoCaptureError::
        kSingleClientVideoCaptureDeviceLaunchAborted:
      *output = media::VideoCaptureError::
          kSingleClientVideoCaptureDeviceLaunchAborted;
      return true;
    case media::mojom::VideoCaptureError::
        kDesktopCaptureDeviceWebrtcDesktopCapturerHasFailed:
      *output = media::VideoCaptureError::
          kDesktopCaptureDeviceWebrtcDesktopCapturerHasFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kFileVideoCaptureDeviceCouldNotOpenVideoFile:
      *output = media::VideoCaptureError::
          kFileVideoCaptureDeviceCouldNotOpenVideoFile;
      return true;
    case media::mojom::VideoCaptureError::
        kDeviceCaptureLinuxFailedToCreateVideoCaptureDelegate:
      *output = media::VideoCaptureError::
          kDeviceCaptureLinuxFailedToCreateVideoCaptureDelegate;
      return true;
    case media::mojom::VideoCaptureError::
        kErrorFakeDeviceIntentionallyEmittingErrorEvent:
      *output = media::VideoCaptureError::
          kErrorFakeDeviceIntentionallyEmittingErrorEvent;
      return true;
    case media::mojom::VideoCaptureError::kDeviceClientTooManyFramesDroppedY16:
      *output = media::VideoCaptureError::kDeviceClientTooManyFramesDroppedY16;
      return true;
    case media::mojom::VideoCaptureError::
        kDeviceMediaToMojoAdapterEncounteredUnsupportedBufferType:
      *output = media::VideoCaptureError::
          kDeviceMediaToMojoAdapterEncounteredUnsupportedBufferType;
      return true;
    case media::mojom::VideoCaptureError::
        kVideoCaptureManagerProcessDeviceStartQueueDeviceInfoNotFound:
      *output = media::VideoCaptureError::
          kVideoCaptureManagerProcessDeviceStartQueueDeviceInfoNotFound;
      return true;
    case media::mojom::VideoCaptureError::
        kInProcessDeviceLauncherFailedToCreateDeviceInstance:
      *output = media::VideoCaptureError::
          kInProcessDeviceLauncherFailedToCreateDeviceInstance;
      return true;
    case media::mojom::VideoCaptureError::
        kServiceDeviceLauncherLostConnectionToDeviceFactoryDuringDeviceStart:
      *output = media::VideoCaptureError::
          kServiceDeviceLauncherLostConnectionToDeviceFactoryDuringDeviceStart;
      return true;
    case media::mojom::VideoCaptureError::
        kServiceDeviceLauncherServiceRespondedWithDeviceNotFound:
      *output = media::VideoCaptureError::
          kServiceDeviceLauncherServiceRespondedWithDeviceNotFound;
      return true;
    case media::mojom::VideoCaptureError::
        kServiceDeviceLauncherConnectionLostWhileWaitingForCallback:
      *output = media::VideoCaptureError::
          kServiceDeviceLauncherConnectionLostWhileWaitingForCallback;
      return true;
    case media::mojom::VideoCaptureError::kIntentionalErrorRaisedByUnitTest:
      *output = media::VideoCaptureError::kIntentionalErrorRaisedByUnitTest;
      return true;
    case media::mojom::VideoCaptureError::kCrosHalV3FailedToStartDeviceThread:
      *output = media::VideoCaptureError::kCrosHalV3FailedToStartDeviceThread;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3DeviceDelegateMojoConnectionError:
      *output =
          media::VideoCaptureError::kCrosHalV3DeviceDelegateMojoConnectionError;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToGetCameraInfo:
      *output = media::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToGetCameraInfo;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3DeviceDelegateMissingSensorOrientationInfo:
      *output = media::VideoCaptureError::
          kCrosHalV3DeviceDelegateMissingSensorOrientationInfo;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToOpenCameraDevice:
      *output = media::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToOpenCameraDevice;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToInitializeCameraDevice:
      *output = media::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToInitializeCameraDevice;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToConfigureStreams:
      *output = media::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToConfigureStreams;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3DeviceDelegateWrongNumberOfStreamsConfigured:
      *output = media::VideoCaptureError::
          kCrosHalV3DeviceDelegateWrongNumberOfStreamsConfigured;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToGetDefaultRequestSettings:
      *output = media::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToGetDefaultRequestSettings;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerHalRequestedTooManyBuffers:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerHalRequestedTooManyBuffers;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToCreateGpuMemoryBuffer:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToCreateGpuMemoryBuffer;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToMapGpuMemoryBuffer:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToMapGpuMemoryBuffer;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerUnsupportedVideoPixelFormat:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerUnsupportedVideoPixelFormat;
      return true;
    case media::mojom::VideoCaptureError::kCrosHalV3BufferManagerFailedToDupFd:
      *output = media::VideoCaptureError::kCrosHalV3BufferManagerFailedToDupFd;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToWrapGpuMemoryHandle:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToWrapGpuMemoryHandle;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToRegisterBuffer:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToRegisterBuffer;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerProcessCaptureRequestFailed:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerProcessCaptureRequestFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerInvalidPendingResultId:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerInvalidPendingResultId;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerReceivedDuplicatedPartialMetadata:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerReceivedDuplicatedPartialMetadata;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerIncorrectNumberOfOutputBuffersReceived:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerIncorrectNumberOfOutputBuffersReceived;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerInvalidTypeOfOutputBuffersReceived:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerInvalidTypeOfOutputBuffersReceived;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerReceivedMultipleResultBuffersForFrame:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerReceivedMultipleResultBuffersForFrame;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerUnknownStreamInCamera3NotifyMsg:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerUnknownStreamInCamera3NotifyMsg;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerReceivedInvalidShutterTime:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerReceivedInvalidShutterTime;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerFatalDeviceError:
      *output =
          media::VideoCaptureError::kCrosHalV3BufferManagerFatalDeviceError;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerReceivedFrameIsOutOfOrder:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerReceivedFrameIsOutOfOrder;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToUnwrapReleaseFenceFd:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToUnwrapReleaseFenceFd;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerSyncWaitOnReleaseFenceTimedOut:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerSyncWaitOnReleaseFenceTimedOut;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerInvalidJpegBlob:
      *output =
          media::VideoCaptureError::kCrosHalV3BufferManagerInvalidJpegBlob;
      return true;
    case media::mojom::VideoCaptureError::kAndroidFailedToAllocate:
      *output = media::VideoCaptureError::kAndroidFailedToAllocate;
      return true;
    case media::mojom::VideoCaptureError::kAndroidFailedToStartCapture:
      *output = media::VideoCaptureError::kAndroidFailedToStartCapture;
      return true;
    case media::mojom::VideoCaptureError::kAndroidFailedToStopCapture:
      *output = media::VideoCaptureError::kAndroidFailedToStopCapture;
      return true;
    case media::mojom::VideoCaptureError::
        kAndroidApi1CameraErrorCallbackReceived:
      *output =
          media::VideoCaptureError::kAndroidApi1CameraErrorCallbackReceived;
      return true;
    case media::mojom::VideoCaptureError::kAndroidApi2CameraDeviceErrorReceived:
      *output = media::VideoCaptureError::kAndroidApi2CameraDeviceErrorReceived;
      return true;
    case media::mojom::VideoCaptureError::
        kAndroidApi2CaptureSessionConfigureFailed:
      *output =
          media::VideoCaptureError::kAndroidApi2CaptureSessionConfigureFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kAndroidApi2ImageReaderUnexpectedImageFormat:
      *output = media::VideoCaptureError::
          kAndroidApi2ImageReaderUnexpectedImageFormat;
      return true;
    case media::mojom::VideoCaptureError::
        kAndroidApi2ImageReaderSizeDidNotMatchImageSize:
      *output = media::VideoCaptureError::
          kAndroidApi2ImageReaderSizeDidNotMatchImageSize;
      return true;
    case media::mojom::VideoCaptureError::kAndroidApi2ErrorRestartingPreview:
      *output = media::VideoCaptureError::kAndroidApi2ErrorRestartingPreview;
      return true;
    case media::mojom::VideoCaptureError::
        kAndroidScreenCaptureUnsupportedFormat:
      *output =
          media::VideoCaptureError::kAndroidScreenCaptureUnsupportedFormat;
      return true;
    case media::mojom::VideoCaptureError::
        kAndroidScreenCaptureFailedToStartCaptureMachine:
      *output = media::VideoCaptureError::
          kAndroidScreenCaptureFailedToStartCaptureMachine;
      return true;
    case media::mojom::VideoCaptureError::
        kAndroidScreenCaptureTheUserDeniedScreenCapture:
      *output = media::VideoCaptureError::
          kAndroidScreenCaptureTheUserDeniedScreenCapture;
      return true;
    case media::mojom::VideoCaptureError::
        kAndroidScreenCaptureFailedToStartScreenCapture:
      *output = media::VideoCaptureError::
          kAndroidScreenCaptureFailedToStartScreenCapture;
      return true;
    case media::mojom::VideoCaptureError::
        kWinDirectShowCantGetCaptureFormatSettings:
      *output =
          media::VideoCaptureError::kWinDirectShowCantGetCaptureFormatSettings;
      return true;
    case media::mojom::VideoCaptureError::
        kWinDirectShowFailedToGetNumberOfCapabilities:
      *output = media::VideoCaptureError::
          kWinDirectShowFailedToGetNumberOfCapabilities;
      return true;
    case media::mojom::VideoCaptureError::
        kWinDirectShowFailedToGetCaptureDeviceCapabilities:
      *output = media::VideoCaptureError::
          kWinDirectShowFailedToGetCaptureDeviceCapabilities;
      return true;
    case media::mojom::VideoCaptureError::
        kWinDirectShowFailedToSetCaptureDeviceOutputFormat:
      *output = media::VideoCaptureError::
          kWinDirectShowFailedToSetCaptureDeviceOutputFormat;
      return true;
    case media::mojom::VideoCaptureError::
        kWinDirectShowFailedToConnectTheCaptureGraph:
      *output = media::VideoCaptureError::
          kWinDirectShowFailedToConnectTheCaptureGraph;
      return true;
    case media::mojom::VideoCaptureError::
        kWinDirectShowFailedToPauseTheCaptureDevice:
      *output =
          media::VideoCaptureError::kWinDirectShowFailedToPauseTheCaptureDevice;
      return true;
    case media::mojom::VideoCaptureError::
        kWinDirectShowFailedToStartTheCaptureDevice:
      *output =
          media::VideoCaptureError::kWinDirectShowFailedToStartTheCaptureDevice;
      return true;
    case media::mojom::VideoCaptureError::
        kWinDirectShowFailedToStopTheCaptureGraph:
      *output =
          media::VideoCaptureError::kWinDirectShowFailedToStopTheCaptureGraph;
      return true;
    case media::mojom::VideoCaptureError::kWinMediaFoundationEngineIsNull:
      *output = media::VideoCaptureError::kWinMediaFoundationEngineIsNull;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationEngineGetSourceFailed:
      *output =
          media::VideoCaptureError::kWinMediaFoundationEngineGetSourceFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationFillPhotoCapabilitiesFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationFillPhotoCapabilitiesFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationFillVideoCapabilitiesFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationFillVideoCapabilitiesFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationNoVideoCapabilityFound:
      *output =
          media::VideoCaptureError::kWinMediaFoundationNoVideoCapabilityFound;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationGetAvailableDeviceMediaTypeFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationGetAvailableDeviceMediaTypeFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationSetCurrentDeviceMediaTypeFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationSetCurrentDeviceMediaTypeFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationEngineGetSinkFailed:
      *output =
          media::VideoCaptureError::kWinMediaFoundationEngineGetSinkFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationSinkQueryCapturePreviewInterfaceFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationSinkQueryCapturePreviewInterfaceFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationSinkRemoveAllStreamsFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationSinkRemoveAllStreamsFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationCreateSinkVideoMediaTypeFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationCreateSinkVideoMediaTypeFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationConvertToVideoSinkMediaTypeFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationConvertToVideoSinkMediaTypeFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationSinkAddStreamFailed:
      *output =
          media::VideoCaptureError::kWinMediaFoundationSinkAddStreamFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationSinkSetSampleCallbackFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationSinkSetSampleCallbackFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationEngineStartPreviewFailed:
      *output =
          media::VideoCaptureError::kWinMediaFoundationEngineStartPreviewFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationGetMediaEventStatusFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationGetMediaEventStatusFailed;
      return true;
    case media::mojom::VideoCaptureError::kMacSetCaptureDeviceFailed:
      *output = media::VideoCaptureError::kMacSetCaptureDeviceFailed;
      return true;
    case media::mojom::VideoCaptureError::kMacCouldNotStartCaptureDevice:
      *output = media::VideoCaptureError::kMacCouldNotStartCaptureDevice;
      return true;
    case media::mojom::VideoCaptureError::
        kMacReceivedFrameWithUnexpectedResolution:
      *output =
          media::VideoCaptureError::kMacReceivedFrameWithUnexpectedResolution;
      return true;
    case media::mojom::VideoCaptureError::kMacUpdateCaptureResolutionFailed:
      *output = media::VideoCaptureError::kMacUpdateCaptureResolutionFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kMacDeckLinkDeviceIdNotFoundInTheSystem:
      *output =
          media::VideoCaptureError::kMacDeckLinkDeviceIdNotFoundInTheSystem;
      return true;
    case media::mojom::VideoCaptureError::
        kMacDeckLinkErrorQueryingInputInterface:
      *output =
          media::VideoCaptureError::kMacDeckLinkErrorQueryingInputInterface;
      return true;
    case media::mojom::VideoCaptureError::
        kMacDeckLinkErrorCreatingDisplayModeIterator:
      *output = media::VideoCaptureError::
          kMacDeckLinkErrorCreatingDisplayModeIterator;
      return true;
    case media::mojom::VideoCaptureError::kMacDeckLinkCouldNotFindADisplayMode:
      *output = media::VideoCaptureError::kMacDeckLinkCouldNotFindADisplayMode;
      return true;
    case media::mojom::VideoCaptureError::
        kMacDeckLinkCouldNotSelectTheVideoFormatWeLike:
      *output = media::VideoCaptureError::
          kMacDeckLinkCouldNotSelectTheVideoFormatWeLike;
      return true;
    case media::mojom::VideoCaptureError::kMacDeckLinkCouldNotStartCapturing:
      *output = media::VideoCaptureError::kMacDeckLinkCouldNotStartCapturing;
      return true;
    case media::mojom::VideoCaptureError::kMacDeckLinkUnsupportedPixelFormat:
      *output = media::VideoCaptureError::kMacDeckLinkUnsupportedPixelFormat;
      return true;
    case media::mojom::VideoCaptureError::
        kMacAvFoundationReceivedAVCaptureSessionRuntimeErrorNotification:
      *output = media::VideoCaptureError::
          kMacAvFoundationReceivedAVCaptureSessionRuntimeErrorNotification;
      return true;
     case media::mojom::VideoCaptureError::kAndroidApi2ErrorConfiguringCamera:
       *output = media::VideoCaptureError::kAndroidApi2ErrorConfiguringCamera;
       return true;
    case media::mojom::VideoCaptureError::kCrosHalV3DeviceDelegateFailedToFlush:
      *output = media::VideoCaptureError::kCrosHalV3DeviceDelegateFailedToFlush;
      return true;
   }
   NOTREACHED();
   return false;
}
",C,,"    case media::mojom::VideoCaptureError::kCrosHalV3DeviceDelegateFailedToFlush:
      *output = media::VideoCaptureError::kCrosHalV3DeviceDelegateFailedToFlush;
      return true;
",,"@@ -658,9 +658,6 @@ EnumTraits<media::mojom::VideoCaptureError, media::VideoCaptureError>::ToMojom(
     case media::VideoCaptureError::kAndroidApi2ErrorConfiguringCamera:
       return media::mojom::VideoCaptureError::
           kAndroidApi2ErrorConfiguringCamera;
-    case media::VideoCaptureError::kCrosHalV3DeviceDelegateFailedToFlush:
-      return media::mojom::VideoCaptureError::
-          kCrosHalV3DeviceDelegateFailedToFlush;
   }
   NOTREACHED();
   return media::mojom::VideoCaptureError::kNone;
@@ -1179,9 +1176,6 @@ bool EnumTraits<media::mojom::VideoCaptureError, media::VideoCaptureError>::
     case media::mojom::VideoCaptureError::kAndroidApi2ErrorConfiguringCamera:
       *output = media::VideoCaptureError::kAndroidApi2ErrorConfiguringCamera;
       return true;
-    case media::mojom::VideoCaptureError::kCrosHalV3DeviceDelegateFailedToFlush:
-      *output = media::VideoCaptureError::kCrosHalV3DeviceDelegateFailedToFlush;
-      return true;
   }
   NOTREACHED();
   return false;",Chrome,fff73016a86f9a5990d080dc76058f8528a423f9,3b62417ecd317d4ff62f2396a3f10d8cc310e146,1,"    FromMojom(media::mojom::VideoCaptureError input,
              media::VideoCaptureError* output) {
  switch (input) {
    case media::mojom::VideoCaptureError::kNone:
      *output = media::VideoCaptureError::kNone;
      return true;
    case media::mojom::VideoCaptureError::
        kVideoCaptureControllerInvalidOrUnsupportedVideoCaptureParametersRequested:
      *output = media::VideoCaptureError::
          kVideoCaptureControllerInvalidOrUnsupportedVideoCaptureParametersRequested;
      return true;
    case media::mojom::VideoCaptureError::
        kVideoCaptureControllerIsAlreadyInErrorState:
      *output = media::VideoCaptureError::
          kVideoCaptureControllerIsAlreadyInErrorState;
      return true;
    case media::mojom::VideoCaptureError::
        kVideoCaptureManagerDeviceConnectionLost:
      *output =
          media::VideoCaptureError::kVideoCaptureManagerDeviceConnectionLost;
      return true;
    case media::mojom::VideoCaptureError::
        kFrameSinkVideoCaptureDeviceAleradyEndedOnFatalError:
      *output = media::VideoCaptureError::
          kFrameSinkVideoCaptureDeviceAleradyEndedOnFatalError;
      return true;
    case media::mojom::VideoCaptureError::
        kFrameSinkVideoCaptureDeviceEncounteredFatalError:
      *output = media::VideoCaptureError::
          kFrameSinkVideoCaptureDeviceEncounteredFatalError;
      return true;
    case media::mojom::VideoCaptureError::kV4L2FailedToOpenV4L2DeviceDriverFile:
      *output = media::VideoCaptureError::kV4L2FailedToOpenV4L2DeviceDriverFile;
      return true;
    case media::mojom::VideoCaptureError::kV4L2ThisIsNotAV4L2VideoCaptureDevice:
      *output = media::VideoCaptureError::kV4L2ThisIsNotAV4L2VideoCaptureDevice;
      return true;
    case media::mojom::VideoCaptureError::
        kV4L2FailedToFindASupportedCameraFormat:
      *output =
          media::VideoCaptureError::kV4L2FailedToFindASupportedCameraFormat;
      return true;
    case media::mojom::VideoCaptureError::kV4L2FailedToSetVideoCaptureFormat:
      *output = media::VideoCaptureError::kV4L2FailedToSetVideoCaptureFormat;
      return true;
    case media::mojom::VideoCaptureError::kV4L2UnsupportedPixelFormat:
      *output = media::VideoCaptureError::kV4L2UnsupportedPixelFormat;
      return true;
    case media::mojom::VideoCaptureError::kV4L2FailedToSetCameraFramerate:
      *output = media::VideoCaptureError::kV4L2FailedToSetCameraFramerate;
      return true;
    case media::mojom::VideoCaptureError::kV4L2ErrorRequestingMmapBuffers:
      *output = media::VideoCaptureError::kV4L2ErrorRequestingMmapBuffers;
      return true;
    case media::mojom::VideoCaptureError::kV4L2AllocateBufferFailed:
      *output = media::VideoCaptureError::kV4L2AllocateBufferFailed;
      return true;
    case media::mojom::VideoCaptureError::kV4L2VidiocStreamonFailed:
      *output = media::VideoCaptureError::kV4L2VidiocStreamonFailed;
      return true;
    case media::mojom::VideoCaptureError::kV4L2VidiocStreamoffFailed:
      *output = media::VideoCaptureError::kV4L2VidiocStreamoffFailed;
      return true;
    case media::mojom::VideoCaptureError::kV4L2FailedToVidiocReqbufsWithCount0:
      *output = media::VideoCaptureError::kV4L2FailedToVidiocReqbufsWithCount0;
      return true;
    case media::mojom::VideoCaptureError::kV4L2PollFailed:
      *output = media::VideoCaptureError::kV4L2PollFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kV4L2MultipleContinuousTimeoutsWhileReadPolling:
      *output = media::VideoCaptureError::
          kV4L2MultipleContinuousTimeoutsWhileReadPolling;
      return true;
    case media::mojom::VideoCaptureError::kV4L2FailedToDequeueCaptureBuffer:
      *output = media::VideoCaptureError::kV4L2FailedToDequeueCaptureBuffer;
      return true;
    case media::mojom::VideoCaptureError::kV4L2FailedToEnqueueCaptureBuffer:
      *output = media::VideoCaptureError::kV4L2FailedToEnqueueCaptureBuffer;
      return true;
    case media::mojom::VideoCaptureError::
        kSingleClientVideoCaptureHostLostConnectionToDevice:
      *output = media::VideoCaptureError::
          kSingleClientVideoCaptureHostLostConnectionToDevice;
      return true;
    case media::mojom::VideoCaptureError::
        kSingleClientVideoCaptureDeviceLaunchAborted:
      *output = media::VideoCaptureError::
          kSingleClientVideoCaptureDeviceLaunchAborted;
      return true;
    case media::mojom::VideoCaptureError::
        kDesktopCaptureDeviceWebrtcDesktopCapturerHasFailed:
      *output = media::VideoCaptureError::
          kDesktopCaptureDeviceWebrtcDesktopCapturerHasFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kFileVideoCaptureDeviceCouldNotOpenVideoFile:
      *output = media::VideoCaptureError::
          kFileVideoCaptureDeviceCouldNotOpenVideoFile;
      return true;
    case media::mojom::VideoCaptureError::
        kDeviceCaptureLinuxFailedToCreateVideoCaptureDelegate:
      *output = media::VideoCaptureError::
          kDeviceCaptureLinuxFailedToCreateVideoCaptureDelegate;
      return true;
    case media::mojom::VideoCaptureError::
        kErrorFakeDeviceIntentionallyEmittingErrorEvent:
      *output = media::VideoCaptureError::
          kErrorFakeDeviceIntentionallyEmittingErrorEvent;
      return true;
    case media::mojom::VideoCaptureError::kDeviceClientTooManyFramesDroppedY16:
      *output = media::VideoCaptureError::kDeviceClientTooManyFramesDroppedY16;
      return true;
    case media::mojom::VideoCaptureError::
        kDeviceMediaToMojoAdapterEncounteredUnsupportedBufferType:
      *output = media::VideoCaptureError::
          kDeviceMediaToMojoAdapterEncounteredUnsupportedBufferType;
      return true;
    case media::mojom::VideoCaptureError::
        kVideoCaptureManagerProcessDeviceStartQueueDeviceInfoNotFound:
      *output = media::VideoCaptureError::
          kVideoCaptureManagerProcessDeviceStartQueueDeviceInfoNotFound;
      return true;
    case media::mojom::VideoCaptureError::
        kInProcessDeviceLauncherFailedToCreateDeviceInstance:
      *output = media::VideoCaptureError::
          kInProcessDeviceLauncherFailedToCreateDeviceInstance;
      return true;
    case media::mojom::VideoCaptureError::
        kServiceDeviceLauncherLostConnectionToDeviceFactoryDuringDeviceStart:
      *output = media::VideoCaptureError::
          kServiceDeviceLauncherLostConnectionToDeviceFactoryDuringDeviceStart;
      return true;
    case media::mojom::VideoCaptureError::
        kServiceDeviceLauncherServiceRespondedWithDeviceNotFound:
      *output = media::VideoCaptureError::
          kServiceDeviceLauncherServiceRespondedWithDeviceNotFound;
      return true;
    case media::mojom::VideoCaptureError::
        kServiceDeviceLauncherConnectionLostWhileWaitingForCallback:
      *output = media::VideoCaptureError::
          kServiceDeviceLauncherConnectionLostWhileWaitingForCallback;
      return true;
    case media::mojom::VideoCaptureError::kIntentionalErrorRaisedByUnitTest:
      *output = media::VideoCaptureError::kIntentionalErrorRaisedByUnitTest;
      return true;
    case media::mojom::VideoCaptureError::kCrosHalV3FailedToStartDeviceThread:
      *output = media::VideoCaptureError::kCrosHalV3FailedToStartDeviceThread;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3DeviceDelegateMojoConnectionError:
      *output =
          media::VideoCaptureError::kCrosHalV3DeviceDelegateMojoConnectionError;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToGetCameraInfo:
      *output = media::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToGetCameraInfo;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3DeviceDelegateMissingSensorOrientationInfo:
      *output = media::VideoCaptureError::
          kCrosHalV3DeviceDelegateMissingSensorOrientationInfo;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToOpenCameraDevice:
      *output = media::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToOpenCameraDevice;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToInitializeCameraDevice:
      *output = media::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToInitializeCameraDevice;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToConfigureStreams:
      *output = media::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToConfigureStreams;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3DeviceDelegateWrongNumberOfStreamsConfigured:
      *output = media::VideoCaptureError::
          kCrosHalV3DeviceDelegateWrongNumberOfStreamsConfigured;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToGetDefaultRequestSettings:
      *output = media::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToGetDefaultRequestSettings;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerHalRequestedTooManyBuffers:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerHalRequestedTooManyBuffers;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToCreateGpuMemoryBuffer:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToCreateGpuMemoryBuffer;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToMapGpuMemoryBuffer:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToMapGpuMemoryBuffer;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerUnsupportedVideoPixelFormat:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerUnsupportedVideoPixelFormat;
      return true;
    case media::mojom::VideoCaptureError::kCrosHalV3BufferManagerFailedToDupFd:
      *output = media::VideoCaptureError::kCrosHalV3BufferManagerFailedToDupFd;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToWrapGpuMemoryHandle:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToWrapGpuMemoryHandle;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToRegisterBuffer:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToRegisterBuffer;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerProcessCaptureRequestFailed:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerProcessCaptureRequestFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerInvalidPendingResultId:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerInvalidPendingResultId;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerReceivedDuplicatedPartialMetadata:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerReceivedDuplicatedPartialMetadata;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerIncorrectNumberOfOutputBuffersReceived:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerIncorrectNumberOfOutputBuffersReceived;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerInvalidTypeOfOutputBuffersReceived:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerInvalidTypeOfOutputBuffersReceived;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerReceivedMultipleResultBuffersForFrame:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerReceivedMultipleResultBuffersForFrame;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerUnknownStreamInCamera3NotifyMsg:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerUnknownStreamInCamera3NotifyMsg;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerReceivedInvalidShutterTime:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerReceivedInvalidShutterTime;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerFatalDeviceError:
      *output =
          media::VideoCaptureError::kCrosHalV3BufferManagerFatalDeviceError;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerReceivedFrameIsOutOfOrder:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerReceivedFrameIsOutOfOrder;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToUnwrapReleaseFenceFd:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToUnwrapReleaseFenceFd;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerSyncWaitOnReleaseFenceTimedOut:
      *output = media::VideoCaptureError::
          kCrosHalV3BufferManagerSyncWaitOnReleaseFenceTimedOut;
      return true;
    case media::mojom::VideoCaptureError::
        kCrosHalV3BufferManagerInvalidJpegBlob:
      *output =
          media::VideoCaptureError::kCrosHalV3BufferManagerInvalidJpegBlob;
      return true;
    case media::mojom::VideoCaptureError::kAndroidFailedToAllocate:
      *output = media::VideoCaptureError::kAndroidFailedToAllocate;
      return true;
    case media::mojom::VideoCaptureError::kAndroidFailedToStartCapture:
      *output = media::VideoCaptureError::kAndroidFailedToStartCapture;
      return true;
    case media::mojom::VideoCaptureError::kAndroidFailedToStopCapture:
      *output = media::VideoCaptureError::kAndroidFailedToStopCapture;
      return true;
    case media::mojom::VideoCaptureError::
        kAndroidApi1CameraErrorCallbackReceived:
      *output =
          media::VideoCaptureError::kAndroidApi1CameraErrorCallbackReceived;
      return true;
    case media::mojom::VideoCaptureError::kAndroidApi2CameraDeviceErrorReceived:
      *output = media::VideoCaptureError::kAndroidApi2CameraDeviceErrorReceived;
      return true;
    case media::mojom::VideoCaptureError::
        kAndroidApi2CaptureSessionConfigureFailed:
      *output =
          media::VideoCaptureError::kAndroidApi2CaptureSessionConfigureFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kAndroidApi2ImageReaderUnexpectedImageFormat:
      *output = media::VideoCaptureError::
          kAndroidApi2ImageReaderUnexpectedImageFormat;
      return true;
    case media::mojom::VideoCaptureError::
        kAndroidApi2ImageReaderSizeDidNotMatchImageSize:
      *output = media::VideoCaptureError::
          kAndroidApi2ImageReaderSizeDidNotMatchImageSize;
      return true;
    case media::mojom::VideoCaptureError::kAndroidApi2ErrorRestartingPreview:
      *output = media::VideoCaptureError::kAndroidApi2ErrorRestartingPreview;
      return true;
    case media::mojom::VideoCaptureError::
        kAndroidScreenCaptureUnsupportedFormat:
      *output =
          media::VideoCaptureError::kAndroidScreenCaptureUnsupportedFormat;
      return true;
    case media::mojom::VideoCaptureError::
        kAndroidScreenCaptureFailedToStartCaptureMachine:
      *output = media::VideoCaptureError::
          kAndroidScreenCaptureFailedToStartCaptureMachine;
      return true;
    case media::mojom::VideoCaptureError::
        kAndroidScreenCaptureTheUserDeniedScreenCapture:
      *output = media::VideoCaptureError::
          kAndroidScreenCaptureTheUserDeniedScreenCapture;
      return true;
    case media::mojom::VideoCaptureError::
        kAndroidScreenCaptureFailedToStartScreenCapture:
      *output = media::VideoCaptureError::
          kAndroidScreenCaptureFailedToStartScreenCapture;
      return true;
    case media::mojom::VideoCaptureError::
        kWinDirectShowCantGetCaptureFormatSettings:
      *output =
          media::VideoCaptureError::kWinDirectShowCantGetCaptureFormatSettings;
      return true;
    case media::mojom::VideoCaptureError::
        kWinDirectShowFailedToGetNumberOfCapabilities:
      *output = media::VideoCaptureError::
          kWinDirectShowFailedToGetNumberOfCapabilities;
      return true;
    case media::mojom::VideoCaptureError::
        kWinDirectShowFailedToGetCaptureDeviceCapabilities:
      *output = media::VideoCaptureError::
          kWinDirectShowFailedToGetCaptureDeviceCapabilities;
      return true;
    case media::mojom::VideoCaptureError::
        kWinDirectShowFailedToSetCaptureDeviceOutputFormat:
      *output = media::VideoCaptureError::
          kWinDirectShowFailedToSetCaptureDeviceOutputFormat;
      return true;
    case media::mojom::VideoCaptureError::
        kWinDirectShowFailedToConnectTheCaptureGraph:
      *output = media::VideoCaptureError::
          kWinDirectShowFailedToConnectTheCaptureGraph;
      return true;
    case media::mojom::VideoCaptureError::
        kWinDirectShowFailedToPauseTheCaptureDevice:
      *output =
          media::VideoCaptureError::kWinDirectShowFailedToPauseTheCaptureDevice;
      return true;
    case media::mojom::VideoCaptureError::
        kWinDirectShowFailedToStartTheCaptureDevice:
      *output =
          media::VideoCaptureError::kWinDirectShowFailedToStartTheCaptureDevice;
      return true;
    case media::mojom::VideoCaptureError::
        kWinDirectShowFailedToStopTheCaptureGraph:
      *output =
          media::VideoCaptureError::kWinDirectShowFailedToStopTheCaptureGraph;
      return true;
    case media::mojom::VideoCaptureError::kWinMediaFoundationEngineIsNull:
      *output = media::VideoCaptureError::kWinMediaFoundationEngineIsNull;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationEngineGetSourceFailed:
      *output =
          media::VideoCaptureError::kWinMediaFoundationEngineGetSourceFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationFillPhotoCapabilitiesFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationFillPhotoCapabilitiesFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationFillVideoCapabilitiesFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationFillVideoCapabilitiesFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationNoVideoCapabilityFound:
      *output =
          media::VideoCaptureError::kWinMediaFoundationNoVideoCapabilityFound;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationGetAvailableDeviceMediaTypeFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationGetAvailableDeviceMediaTypeFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationSetCurrentDeviceMediaTypeFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationSetCurrentDeviceMediaTypeFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationEngineGetSinkFailed:
      *output =
          media::VideoCaptureError::kWinMediaFoundationEngineGetSinkFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationSinkQueryCapturePreviewInterfaceFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationSinkQueryCapturePreviewInterfaceFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationSinkRemoveAllStreamsFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationSinkRemoveAllStreamsFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationCreateSinkVideoMediaTypeFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationCreateSinkVideoMediaTypeFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationConvertToVideoSinkMediaTypeFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationConvertToVideoSinkMediaTypeFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationSinkAddStreamFailed:
      *output =
          media::VideoCaptureError::kWinMediaFoundationSinkAddStreamFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationSinkSetSampleCallbackFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationSinkSetSampleCallbackFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationEngineStartPreviewFailed:
      *output =
          media::VideoCaptureError::kWinMediaFoundationEngineStartPreviewFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kWinMediaFoundationGetMediaEventStatusFailed:
      *output = media::VideoCaptureError::
          kWinMediaFoundationGetMediaEventStatusFailed;
      return true;
    case media::mojom::VideoCaptureError::kMacSetCaptureDeviceFailed:
      *output = media::VideoCaptureError::kMacSetCaptureDeviceFailed;
      return true;
    case media::mojom::VideoCaptureError::kMacCouldNotStartCaptureDevice:
      *output = media::VideoCaptureError::kMacCouldNotStartCaptureDevice;
      return true;
    case media::mojom::VideoCaptureError::
        kMacReceivedFrameWithUnexpectedResolution:
      *output =
          media::VideoCaptureError::kMacReceivedFrameWithUnexpectedResolution;
      return true;
    case media::mojom::VideoCaptureError::kMacUpdateCaptureResolutionFailed:
      *output = media::VideoCaptureError::kMacUpdateCaptureResolutionFailed;
      return true;
    case media::mojom::VideoCaptureError::
        kMacDeckLinkDeviceIdNotFoundInTheSystem:
      *output =
          media::VideoCaptureError::kMacDeckLinkDeviceIdNotFoundInTheSystem;
      return true;
    case media::mojom::VideoCaptureError::
        kMacDeckLinkErrorQueryingInputInterface:
      *output =
          media::VideoCaptureError::kMacDeckLinkErrorQueryingInputInterface;
      return true;
    case media::mojom::VideoCaptureError::
        kMacDeckLinkErrorCreatingDisplayModeIterator:
      *output = media::VideoCaptureError::
          kMacDeckLinkErrorCreatingDisplayModeIterator;
      return true;
    case media::mojom::VideoCaptureError::kMacDeckLinkCouldNotFindADisplayMode:
      *output = media::VideoCaptureError::kMacDeckLinkCouldNotFindADisplayMode;
      return true;
    case media::mojom::VideoCaptureError::
        kMacDeckLinkCouldNotSelectTheVideoFormatWeLike:
      *output = media::VideoCaptureError::
          kMacDeckLinkCouldNotSelectTheVideoFormatWeLike;
      return true;
    case media::mojom::VideoCaptureError::kMacDeckLinkCouldNotStartCapturing:
      *output = media::VideoCaptureError::kMacDeckLinkCouldNotStartCapturing;
      return true;
    case media::mojom::VideoCaptureError::kMacDeckLinkUnsupportedPixelFormat:
      *output = media::VideoCaptureError::kMacDeckLinkUnsupportedPixelFormat;
      return true;
    case media::mojom::VideoCaptureError::
        kMacAvFoundationReceivedAVCaptureSessionRuntimeErrorNotification:
      *output = media::VideoCaptureError::
          kMacAvFoundationReceivedAVCaptureSessionRuntimeErrorNotification;
      return true;
     case media::mojom::VideoCaptureError::kAndroidApi2ErrorConfiguringCamera:
       *output = media::VideoCaptureError::kAndroidApi2ErrorConfiguringCamera;
       return true;
//flaw_line_below:
    case media::mojom::VideoCaptureError::kCrosHalV3DeviceDelegateFailedToFlush:
//flaw_line_below:
      *output = media::VideoCaptureError::kCrosHalV3DeviceDelegateFailedToFlush;
//flaw_line_below:
      return true;
   }
   NOTREACHED();
   return false;
}
"
8746,186482,,Remote,Not required,,CVE-2016-5214,https://www.cvedetails.com/cve/CVE-2016-5214/,CWE-19,Medium,,Partial,,2017-01-19,4.3,"Google Chrome prior to 55.0.2883.75 for Windows mishandled downloaded files, which allowed a remote attacker to prevent the downloaded file from receiving the Mark of the Web via a crafted HTML page.",2018-01-04,,0,https://github.com/chromium/chromium/commit/fff73016a86f9a5990d080dc76058f8528a423f9,fff73016a86f9a5990d080dc76058f8528a423f9,"Revert ""Enable camera blob stream when needed""

This reverts commit 10f4b93635e12f9fa0cba1641a10938ca38ed448.

Reason for revert:

Findit (https://goo.gl/kROfz5) identified CL at revision 601492 as the
culprit for failures in the build cycles as shown on:
https://findit-for-me.appspot.com/waterfall/culprit?key=ag9zfmZpbmRpdC1mb3ItbWVyRAsSDVdmU3VzcGVjdGVkQ0wiMWNocm9taXVtLzEwZjRiOTM2MzVlMTJmOWZhMGNiYTE2NDFhMTA5MzhjYTM4ZWQ0NDgM

Sample Failed Build: https://ci.chromium.org/buildbot/chromium.memory/Linux%20ChromiumOS%20MSan%20Tests/9190

Sample Failed Step: capture_unittests

Original change's description:
> Enable camera blob stream when needed
> 
> Since blob stream needs higher resolution, it causes higher cpu loading
> to require higher resolution and resize to smaller resolution.
> In hangout app, we don't need blob stream. Enabling blob stream when
> needed can save a lot of cpu usage.
> 
> BUG=b:114676133
> TEST=manually test in apprtc and CCA. make sure picture taking still
> works in CCA.
> 
> Change-Id: I9144461bc76627903d0b3b359ce9cf962ff3628c
> Reviewed-on: https://chromium-review.googlesource.com/c/1261242
> Commit-Queue: Heng-ruey Hsu <henryhsu@chromium.org>
> Reviewed-by: Ricky Liang <jcliang@chromium.org>
> Reviewed-by: Xiaohan Wang <xhwang@chromium.org>
> Reviewed-by: Robert Sesek <rsesek@chromium.org>
> Cr-Commit-Position: refs/heads/master@{#601492}

No-Presubmit: true
No-Tree-Checks: true
No-Try: true
BUG=b:114676133

Change-Id: If173ffe9259f7eca849b184806bd56e2a9fbaac4
Reviewed-on: https://chromium-review.googlesource.com/c/1292256
Cr-Commit-Position: refs/heads/master@{#601538}",3,media/capture/mojom/video_capture_types_mojom_traits.cc,"{""sha"": ""849014ef4908ef3ef91fc0ae60499c2704742b58"", ""filename"": ""media/capture/mojom/video_capture_types.mojom"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 2, ""changes"": 3, ""blob_url"": ""https://github.com/chromium/chromium/blob/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/mojom/video_capture_types.mojom"", ""raw_url"": ""https://github.com/chromium/chromium/raw/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/mojom/video_capture_types.mojom"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/media/capture/mojom/video_capture_types.mojom?ref=fff73016a86f9a5990d080dc76058f8528a423f9"", ""patch"": ""@@ -205,8 +205,7 @@ enum VideoCaptureError {\n   kMacDeckLinkCouldNotStartCapturing,\n   kMacDeckLinkUnsupportedPixelFormat,\n   kMacAvFoundationReceivedAVCaptureSessionRuntimeErrorNotification,\n-  kAndroidApi2ErrorConfiguringCamera,\n-  kCrosHalV3DeviceDelegateFailedToFlush\n+  kAndroidApi2ErrorConfiguringCamera\n };\n \n enum VideoCaptureFrameDropReason {""}<_**next**_>{""sha"": ""02e2f9757b9d66ad79679536c875fccad7408572"", ""filename"": ""media/capture/mojom/video_capture_types_mojom_traits.cc"", ""status"": ""modified"", ""additions"": 0, ""deletions"": 6, ""changes"": 6, ""blob_url"": ""https://github.com/chromium/chromium/blob/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/mojom/video_capture_types_mojom_traits.cc"", ""raw_url"": ""https://github.com/chromium/chromium/raw/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/mojom/video_capture_types_mojom_traits.cc"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/media/capture/mojom/video_capture_types_mojom_traits.cc?ref=fff73016a86f9a5990d080dc76058f8528a423f9"", ""patch"": ""@@ -658,9 +658,6 @@ EnumTraits<media::mojom::VideoCaptureError, media::VideoCaptureError>::ToMojom(\n     case media::VideoCaptureError::kAndroidApi2ErrorConfiguringCamera:\n       return media::mojom::VideoCaptureError::\n           kAndroidApi2ErrorConfiguringCamera;\n-    case media::VideoCaptureError::kCrosHalV3DeviceDelegateFailedToFlush:\n-      return media::mojom::VideoCaptureError::\n-          kCrosHalV3DeviceDelegateFailedToFlush;\n   }\n   NOTREACHED();\n   return media::mojom::VideoCaptureError::kNone;\n@@ -1179,9 +1176,6 @@ bool EnumTraits<media::mojom::VideoCaptureError, media::VideoCaptureError>::\n     case media::mojom::VideoCaptureError::kAndroidApi2ErrorConfiguringCamera:\n       *output = media::VideoCaptureError::kAndroidApi2ErrorConfiguringCamera;\n       return true;\n-    case media::mojom::VideoCaptureError::kCrosHalV3DeviceDelegateFailedToFlush:\n-      *output = media::VideoCaptureError::kCrosHalV3DeviceDelegateFailedToFlush;\n-      return true;\n   }\n   NOTREACHED();\n   return false;""}<_**next**_>{""sha"": ""ecc9f87f4a2161a083c714a10046ba4adfe51131"", ""filename"": ""media/capture/video/chromeos/camera_device_delegate.cc"", ""status"": ""modified"", ""additions"": 38, ""deletions"": 76, ""changes"": 114, ""blob_url"": ""https://github.com/chromium/chromium/blob/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video/chromeos/camera_device_delegate.cc"", ""raw_url"": ""https://github.com/chromium/chromium/raw/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video/chromeos/camera_device_delegate.cc"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/media/capture/video/chromeos/camera_device_delegate.cc?ref=fff73016a86f9a5990d080dc76058f8528a423f9"", ""patch"": ""@@ -133,12 +133,6 @@ class CameraDeviceDelegate::StreamCaptureInterfaceImpl final\n     }\n   }\n \n-  void Flush(base::OnceCallback<void(int32_t)> callback) final {\n-    if (camera_device_delegate_) {\n-      camera_device_delegate_->Flush(std::move(callback));\n-    }\n-  }\n-\n  private:\n   const base::WeakPtr<CameraDeviceDelegate> camera_device_delegate_;\n };\n@@ -195,7 +189,7 @@ void CameraDeviceDelegate::StopAndDeAllocate(\n     // The device delegate is in the process of opening the camera device.\n     return;\n   }\n-  stream_buffer_manager_->StopPreview(base::NullCallback());\n+  stream_buffer_manager_->StopPreview();\n   device_ops_->Close(\n       base::BindOnce(&CameraDeviceDelegate::OnClosed, GetWeakPtr()));\n }\n@@ -232,17 +226,18 @@ void CameraDeviceDelegate::GetPhotoState(\n     return;\n   }\n \n-  int32_t max_blob_width = 0, max_blob_height = 0;\n-  GetMaxBlobStreamResolution(static_metadata_, &max_blob_width,\n-                             &max_blob_height);\n-  photo_state->width->current = max_blob_width;\n-  photo_state->width->min = max_blob_width;\n-  photo_state->width->max = max_blob_width;\n-  photo_state->width->step = 0.0;\n-  photo_state->height->current = max_blob_height;\n-  photo_state->height->min = max_blob_height;\n-  photo_state->height->max = max_blob_height;\n-  photo_state->height->step = 0.0;\n+  auto stream_config =\n+      stream_buffer_manager_->GetStreamConfiguration(StreamType::kStillCapture);\n+  if (stream_config) {\n+    photo_state->width->current = stream_config->width;\n+    photo_state->width->min = stream_config->width;\n+    photo_state->width->max = stream_config->width;\n+    photo_state->width->step = 0.0;\n+    photo_state->height->current = stream_config->height;\n+    photo_state->height->min = stream_config->height;\n+    photo_state->height->max = stream_config->height;\n+    photo_state->height->step = 0.0;\n+  }\n   std::move(callback).Run(std::move(photo_state));\n }\n \n@@ -263,14 +258,7 @@ void CameraDeviceDelegate::SetPhotoOptions(\n     return;\n   }\n \n-  if (stream_buffer_manager_->GetStreamNumber() < kMaxConfiguredStreams) {\n-    stream_buffer_manager_->StopPreview(\n-        base::BindOnce(&CameraDeviceDelegate::OnFlushed, GetWeakPtr()));\n-    set_photo_option_callback_ = std::move(callback);\n-  } else {\n-    set_photo_option_callback_.Reset();\n-    std::move(callback).Run(true);\n-  }\n+  std::move(callback).Run(true);\n }\n \n void CameraDeviceDelegate::SetRotation(int rotation) {\n@@ -294,7 +282,7 @@ void CameraDeviceDelegate::OnMojoConnectionError() {\n   } else {\n     // The Mojo channel terminated unexpectedly.\n     if (stream_buffer_manager_) {\n-      stream_buffer_manager_->StopPreview(base::NullCallback());\n+      stream_buffer_manager_->StopPreview();\n     }\n     device_context_->SetState(CameraDeviceContext::State::kStopped);\n     device_context_->SetErrorState(\n@@ -307,19 +295,6 @@ void CameraDeviceDelegate::OnMojoConnectionError() {\n   }\n }\n \n-void CameraDeviceDelegate::OnFlushed(int32_t result) {\n-  DCHECK(ipc_task_runner_->BelongsToCurrentThread());\n-  if (result) {\n-    device_context_->SetErrorState(\n-        media::VideoCaptureError::kCrosHalV3DeviceDelegateFailedToFlush,\n-        FROM_HERE,\n-        std::string(\""Flush failed: \"") + base::safe_strerror(-result));\n-    return;\n-  }\n-  device_context_->SetState(CameraDeviceContext::State::kInitialized);\n-  ConfigureStreams(true);\n-}\n-\n void CameraDeviceDelegate::OnClosed(int32_t result) {\n   DCHECK(ipc_task_runner_->BelongsToCurrentThread());\n   DCHECK_EQ(device_context_->GetState(), CameraDeviceContext::State::kStopping);\n@@ -451,10 +426,10 @@ void CameraDeviceDelegate::OnInitialized(int32_t result) {\n     return;\n   }\n   device_context_->SetState(CameraDeviceContext::State::kInitialized);\n-  ConfigureStreams(false);\n+  ConfigureStreams();\n }\n \n-void CameraDeviceDelegate::ConfigureStreams(bool require_photo) {\n+void CameraDeviceDelegate::ConfigureStreams() {\n   DCHECK(ipc_task_runner_->BelongsToCurrentThread());\n   DCHECK_EQ(device_context_->GetState(),\n             CameraDeviceContext::State::kInitialized);\n@@ -475,34 +450,31 @@ void CameraDeviceDelegate::ConfigureStreams(bool require_photo) {\n   preview_stream->rotation =\n       cros::mojom::Camera3StreamRotation::CAMERA3_STREAM_ROTATION_0;\n \n-  cros::mojom::Camera3StreamConfigurationPtr stream_config =\n-      cros::mojom::Camera3StreamConfiguration::New();\n-  stream_config->streams.push_back(std::move(preview_stream));\n-\n   // Set up context for still capture stream. We set still capture stream to the\n   // JPEG stream configuration with maximum supported resolution.\n   // TODO(jcliang): Once we support SetPhotoOptions() the still capture stream\n   // should be configured dynamically per the photo options.\n-  if (require_photo) {\n-    int32_t max_blob_width = 0, max_blob_height = 0;\n-    GetMaxBlobStreamResolution(static_metadata_, &max_blob_width,\n-                               &max_blob_height);\n-\n-    cros::mojom::Camera3StreamPtr still_capture_stream =\n-        cros::mojom::Camera3Stream::New();\n-    still_capture_stream->id = static_cast<uint64_t>(StreamType::kStillCapture);\n-    still_capture_stream->stream_type =\n-        cros::mojom::Camera3StreamType::CAMERA3_STREAM_OUTPUT;\n-    still_capture_stream->width = max_blob_width;\n-    still_capture_stream->height = max_blob_height;\n-    still_capture_stream->format =\n-        cros::mojom::HalPixelFormat::HAL_PIXEL_FORMAT_BLOB;\n-    still_capture_stream->data_space = 0;\n-    still_capture_stream->rotation =\n-        cros::mojom::Camera3StreamRotation::CAMERA3_STREAM_ROTATION_0;\n-    stream_config->streams.push_back(std::move(still_capture_stream));\n-  }\n+  int32_t max_blob_width = 0, max_blob_height = 0;\n+  GetMaxBlobStreamResolution(static_metadata_, &max_blob_width,\n+                             &max_blob_height);\n \n+  cros::mojom::Camera3StreamPtr still_capture_stream =\n+      cros::mojom::Camera3Stream::New();\n+  still_capture_stream->id = static_cast<uint64_t>(StreamType::kStillCapture);\n+  still_capture_stream->stream_type =\n+      cros::mojom::Camera3StreamType::CAMERA3_STREAM_OUTPUT;\n+  still_capture_stream->width = max_blob_width;\n+  still_capture_stream->height = max_blob_height;\n+  still_capture_stream->format =\n+      cros::mojom::HalPixelFormat::HAL_PIXEL_FORMAT_BLOB;\n+  still_capture_stream->data_space = 0;\n+  still_capture_stream->rotation =\n+      cros::mojom::Camera3StreamRotation::CAMERA3_STREAM_ROTATION_0;\n+\n+  cros::mojom::Camera3StreamConfigurationPtr stream_config =\n+      cros::mojom::Camera3StreamConfiguration::New();\n+  stream_config->streams.push_back(std::move(preview_stream));\n+  stream_config->streams.push_back(std::move(still_capture_stream));\n   stream_config->operation_mode = cros::mojom::Camera3StreamConfigurationMode::\n       CAMERA3_STREAM_CONFIGURATION_NORMAL_MODE;\n   device_ops_->ConfigureStreams(\n@@ -530,8 +502,7 @@ void CameraDeviceDelegate::OnConfiguredStreams(\n     return;\n   }\n   if (!updated_config ||\n-      updated_config->streams.size() > kMaxConfiguredStreams ||\n-      updated_config->streams.size() < 1) {\n+      updated_config->streams.size() != kMaxConfiguredStreams) {\n     device_context_->SetErrorState(\n         media::VideoCaptureError::\n             kCrosHalV3DeviceDelegateWrongNumberOfStreamsConfigured,\n@@ -598,10 +569,6 @@ void CameraDeviceDelegate::OnConstructedDefaultPreviewRequestSettings(\n         base::BindOnce(&CameraDeviceDelegate::ConstructDefaultRequestSettings,\n                        GetWeakPtr(), StreamType::kStillCapture));\n   }\n-\n-  if (set_photo_option_callback_) {\n-    std::move(set_photo_option_callback_).Run(true);\n-  }\n }\n \n void CameraDeviceDelegate::OnConstructedDefaultStillCaptureRequestSettings(\n@@ -666,11 +633,6 @@ void CameraDeviceDelegate::ProcessCaptureRequest(\n   device_ops_->ProcessCaptureRequest(std::move(request), std::move(callback));\n }\n \n-void CameraDeviceDelegate::Flush(base::OnceCallback<void(int32_t)> callback) {\n-  DCHECK(ipc_task_runner_->BelongsToCurrentThread());\n-  device_ops_->Flush(std::move(callback));\n-}\n-\n bool CameraDeviceDelegate::SetPointsOfInterest(\n     const std::vector<mojom::Point2DPtr>& points_of_interest) {\n   if (points_of_interest.empty()) {""}<_**next**_>{""sha"": ""1f4c3966071593f821acdf6701fad6c6dc613e8f"", ""filename"": ""media/capture/video/chromeos/camera_device_delegate.h"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 10, ""changes"": 11, ""blob_url"": ""https://github.com/chromium/chromium/blob/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video/chromeos/camera_device_delegate.h"", ""raw_url"": ""https://github.com/chromium/chromium/raw/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video/chromeos/camera_device_delegate.h"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/media/capture/video/chromeos/camera_device_delegate.h?ref=fff73016a86f9a5990d080dc76058f8528a423f9"", ""patch"": ""@@ -60,9 +60,6 @@ class CAPTURE_EXPORT StreamCaptureInterface {\n   virtual void ProcessCaptureRequest(\n       cros::mojom::Camera3CaptureRequestPtr request,\n       base::OnceCallback<void(int32_t)> callback) = 0;\n-\n-  // Send flush to cancel all pending requests to the camera HAL.\n-  virtual void Flush(base::OnceCallback<void(int32_t)> callback) = 0;\n };\n \n // CameraDeviceDelegate is instantiated on the capture thread where\n@@ -102,9 +99,6 @@ class CAPTURE_EXPORT CameraDeviceDelegate final {\n   // Mojo connection error handler.\n   void OnMojoConnectionError();\n \n-  // Reconfigure streams for picture taking.\n-  void OnFlushed(int32_t result);\n-\n   // Callback method for the Close Mojo IPC call.  This method resets the Mojo\n   // connection and closes the camera device.\n   void OnClosed(int32_t result);\n@@ -130,7 +124,7 @@ class CAPTURE_EXPORT CameraDeviceDelegate final {\n   // indicates.  If there's no error OnConfiguredStreams notifies\n   // |client_| the capture has started by calling OnStarted, and proceeds to\n   // ConstructDefaultRequestSettings.\n-  void ConfigureStreams(bool require_photo);\n+  void ConfigureStreams();\n   void OnConfiguredStreams(\n       int32_t result,\n       cros::mojom::Camera3StreamConfigurationPtr updated_config);\n@@ -161,7 +155,6 @@ class CAPTURE_EXPORT CameraDeviceDelegate final {\n                       base::OnceCallback<void(int32_t)> callback);\n   void ProcessCaptureRequest(cros::mojom::Camera3CaptureRequestPtr request,\n                              base::OnceCallback<void(int32_t)> callback);\n-  void Flush(base::OnceCallback<void(int32_t)> callback);\n \n   bool SetPointsOfInterest(\n       const std::vector<mojom::Point2DPtr>& points_of_interest);\n@@ -194,8 +187,6 @@ class CAPTURE_EXPORT CameraDeviceDelegate final {\n \n   base::OnceClosure device_close_callback_;\n \n-  VideoCaptureDevice::SetPhotoOptionsCallback set_photo_option_callback_;\n-\n   base::WeakPtrFactory<CameraDeviceDelegate> weak_ptr_factory_;\n \n   DISALLOW_IMPLICIT_CONSTRUCTORS(CameraDeviceDelegate);""}<_**next**_>{""sha"": ""d2c0646ab8372f2d8a6996a3774f513a80f52648"", ""filename"": ""media/capture/video/chromeos/camera_device_delegate_unittest.cc"", ""status"": ""modified"", ""additions"": 18, ""deletions"": 27, ""changes"": 45, ""blob_url"": ""https://github.com/chromium/chromium/blob/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video/chromeos/camera_device_delegate_unittest.cc"", ""raw_url"": ""https://github.com/chromium/chromium/raw/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video/chromeos/camera_device_delegate_unittest.cc"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/media/capture/video/chromeos/camera_device_delegate_unittest.cc?ref=fff73016a86f9a5990d080dc76058f8528a423f9"", ""patch"": ""@@ -242,13 +242,11 @@ class CameraDeviceDelegateTest : public ::testing::Test {\n       base::OnceCallback<void(int32_t,\n                               cros::mojom::Camera3StreamConfigurationPtr)>&\n           callback) {\n-    ASSERT_GE(2u, config->streams.size());\n-    ASSERT_LT(0u, config->streams.size());\n+    ASSERT_EQ(2u, config->streams.size());\n     for (size_t i = 0; i < config->streams.size(); ++i) {\n       config->streams[i]->usage = 0;\n       config->streams[i]->max_buffers = 1;\n     }\n-    num_streams_ = config->streams.size();\n     std::move(callback).Run(0, std::move(config));\n   }\n \n@@ -334,16 +332,14 @@ class CameraDeviceDelegateTest : public ::testing::Test {\n         .Times(1)\n         .WillOnce(Invoke(&unittest_internal::MockGpuMemoryBufferManager::\n                              CreateFakeGpuMemoryBuffer));\n-    if (num_streams_ == 2) {\n-      EXPECT_CALL(\n-          mock_gpu_memory_buffer_manager_,\n-          CreateGpuMemoryBuffer(_, gfx::BufferFormat::R_8,\n-                                gfx::BufferUsage::CAMERA_AND_CPU_READ_WRITE,\n-                                gpu::kNullSurfaceHandle))\n-          .Times(1)\n-          .WillOnce(Invoke(&unittest_internal::MockGpuMemoryBufferManager::\n-                               CreateFakeGpuMemoryBuffer));\n-    }\n+    EXPECT_CALL(\n+        mock_gpu_memory_buffer_manager_,\n+        CreateGpuMemoryBuffer(_, gfx::BufferFormat::R_8,\n+                              gfx::BufferUsage::CAMERA_AND_CPU_READ_WRITE,\n+                              gpu::kNullSurfaceHandle))\n+        .Times(1)\n+        .WillOnce(Invoke(&unittest_internal::MockGpuMemoryBufferManager::\n+                             CreateFakeGpuMemoryBuffer));\n     EXPECT_CALL(\n         mock_gpu_memory_buffer_manager_,\n         CreateGpuMemoryBuffer(gfx::Size(kDefaultWidth, kDefaultHeight),\n@@ -353,16 +349,14 @@ class CameraDeviceDelegateTest : public ::testing::Test {\n         .Times(1)\n         .WillOnce(Invoke(&unittest_internal::MockGpuMemoryBufferManager::\n                              CreateFakeGpuMemoryBuffer));\n-    if (num_streams_ == 2) {\n-      EXPECT_CALL(mock_gpu_memory_buffer_manager_,\n-                  CreateGpuMemoryBuffer(\n-                      gfx::Size(kJpegMaxBufferSize, 1), gfx::BufferFormat::R_8,\n-                      gfx::BufferUsage::CAMERA_AND_CPU_READ_WRITE,\n-                      gpu::kNullSurfaceHandle))\n-          .Times(1)\n-          .WillOnce(Invoke(&unittest_internal::MockGpuMemoryBufferManager::\n-                               CreateFakeGpuMemoryBuffer));\n-    }\n+    EXPECT_CALL(mock_gpu_memory_buffer_manager_,\n+                CreateGpuMemoryBuffer(\n+                    gfx::Size(kJpegMaxBufferSize, 1), gfx::BufferFormat::R_8,\n+                    gfx::BufferUsage::CAMERA_AND_CPU_READ_WRITE,\n+                    gpu::kNullSurfaceHandle))\n+        .Times(1)\n+        .WillOnce(Invoke(&unittest_internal::MockGpuMemoryBufferManager::\n+                             CreateFakeGpuMemoryBuffer));\n   }\n \n   void SetUpExpectationUntilCapturing(\n@@ -428,7 +422,6 @@ class CameraDeviceDelegateTest : public ::testing::Test {\n     ASSERT_TRUE(camera_device_delegate_);\n     device_delegate_thread_.Stop();\n     camera_device_delegate_.reset();\n-    num_streams_ = 0;\n   }\n \n   void DoLoop() {\n@@ -468,8 +461,6 @@ class CameraDeviceDelegateTest : public ::testing::Test {\n \n   std::unique_ptr<CameraDeviceContext> device_context_;\n \n-  size_t num_streams_;\n-\n  private:\n   base::test::ScopedTaskEnvironment scoped_task_environment_;\n   base::Thread hal_delegate_thread_;\n@@ -612,7 +603,7 @@ TEST_F(CameraDeviceDelegateTest, FailToOpenDevice) {\n   };\n   EXPECT_CALL(*mock_client, OnError(_, _, _))\n       .Times(AtLeast(1))\n-      .WillRepeatedly(InvokeWithoutArgs(stop_on_error));\n+      .WillOnce(InvokeWithoutArgs(stop_on_error));\n \n   EXPECT_CALL(mock_camera_module_, DoGetCameraInfo(0, _))\n       .Times(1)""}<_**next**_>{""sha"": ""05e0da906502a6b44265bc01f33a5122a3cebb39"", ""filename"": ""media/capture/video/chromeos/stream_buffer_manager.cc"", ""status"": ""modified"", ""additions"": 3, ""deletions"": 11, ""changes"": 14, ""blob_url"": ""https://github.com/chromium/chromium/blob/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video/chromeos/stream_buffer_manager.cc"", ""raw_url"": ""https://github.com/chromium/chromium/raw/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video/chromeos/stream_buffer_manager.cc"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/media/capture/video/chromeos/stream_buffer_manager.cc?ref=fff73016a86f9a5990d080dc76058f8528a423f9"", ""patch"": ""@@ -187,13 +187,9 @@ void StreamBufferManager::StartPreview(\n   RegisterBuffer(StreamType::kPreview);\n }\n \n-void StreamBufferManager::StopPreview(\n-    base::OnceCallback<void(int32_t)> callback) {\n+void StreamBufferManager::StopPreview() {\n   DCHECK(ipc_task_runner_->BelongsToCurrentThread());\n   capturing_ = false;\n-  if (callback) {\n-    capture_interface_->Flush(std::move(callback));\n-  }\n }\n \n cros::mojom::Camera3StreamPtr StreamBufferManager::GetStreamConfiguration(\n@@ -227,10 +223,6 @@ void StreamBufferManager::TakePhoto(\n   RegisterBuffer(StreamType::kStillCapture);\n }\n \n-size_t StreamBufferManager::GetStreamNumber() {\n-  return stream_context_.size();\n-}\n-\n void StreamBufferManager::AddResultMetadataObserver(\n     ResultMetadataObserver* observer) {\n   DCHECK(ipc_task_runner_->BelongsToCurrentThread());\n@@ -424,6 +416,7 @@ void StreamBufferManager::OnRegisteredBuffer(StreamType stream_type,\n void StreamBufferManager::ProcessCaptureRequest() {\n   DCHECK(ipc_task_runner_->BelongsToCurrentThread());\n   DCHECK(stream_context_[StreamType::kPreview]);\n+  DCHECK(stream_context_[StreamType::kStillCapture]);\n \n   cros::mojom::Camera3CaptureRequestPtr request =\n       cros::mojom::Camera3CaptureRequest::New();\n@@ -446,8 +439,7 @@ void StreamBufferManager::ProcessCaptureRequest() {\n     request->output_buffers.push_back(std::move(buffer));\n   }\n \n-  if (stream_context_.count(StreamType::kStillCapture) &&\n-      !stream_context_[StreamType::kStillCapture]->registered_buffers.empty()) {\n+  if (!stream_context_[StreamType::kStillCapture]->registered_buffers.empty()) {\n     DCHECK(!still_capture_callbacks_currently_processing_.empty());\n     cros::mojom::Camera3StreamBufferPtr buffer =\n         cros::mojom::Camera3StreamBuffer::New();""}<_**next**_>{""sha"": ""1fa3f22573e3314a77fad39379daca6d18637dbd"", ""filename"": ""media/capture/video/chromeos/stream_buffer_manager.h"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 3, ""changes"": 4, ""blob_url"": ""https://github.com/chromium/chromium/blob/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video/chromeos/stream_buffer_manager.h"", ""raw_url"": ""https://github.com/chromium/chromium/raw/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video/chromeos/stream_buffer_manager.h"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/media/capture/video/chromeos/stream_buffer_manager.h?ref=fff73016a86f9a5990d080dc76058f8528a423f9"", ""patch"": ""@@ -116,15 +116,13 @@ class CAPTURE_EXPORT StreamBufferManager final\n \n   // Stops the capture loop.  After StopPreview is called |callback_ops_| is\n   // unbound, so no new capture request or result will be processed.\n-  void StopPreview(base::OnceCallback<void(int32_t)> callback);\n+  void StopPreview();\n \n   cros::mojom::Camera3StreamPtr GetStreamConfiguration(StreamType stream_type);\n \n   void TakePhoto(cros::mojom::CameraMetadataPtr settings,\n                  VideoCaptureDevice::TakePhotoCallback callback);\n \n-  size_t GetStreamNumber();\n-\n   // CaptureMetadataDispatcher implementations.\n   void AddResultMetadataObserver(ResultMetadataObserver* observer) override;\n   void RemoveResultMetadataObserver(ResultMetadataObserver* observer) override;""}<_**next**_>{""sha"": ""2fcbdfeb4065cd52fb78234eafcd6c99520bc811"", ""filename"": ""media/capture/video/chromeos/stream_buffer_manager_unittest.cc"", ""status"": ""modified"", ""additions"": 0, ""deletions"": 3, ""changes"": 3, ""blob_url"": ""https://github.com/chromium/chromium/blob/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video/chromeos/stream_buffer_manager_unittest.cc"", ""raw_url"": ""https://github.com/chromium/chromium/raw/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video/chromeos/stream_buffer_manager_unittest.cc"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/media/capture/video/chromeos/stream_buffer_manager_unittest.cc?ref=fff73016a86f9a5990d080dc76058f8528a423f9"", ""patch"": ""@@ -63,9 +63,6 @@ class MockStreamCaptureInterface : public StreamCaptureInterface {\n   MOCK_METHOD2(DoProcessCaptureRequest,\n                void(cros::mojom::Camera3CaptureRequestPtr& request,\n                     base::OnceCallback<void(int32_t)>& callback));\n-\n-  void Flush(base::OnceCallback<void(int32_t)> callback) { DoFlush(callback); }\n-  MOCK_METHOD1(DoFlush, void(base::OnceCallback<void(int32_t)>& callback));\n };\n \n const VideoCaptureFormat kDefaultCaptureFormat(gfx::Size(1280, 720),""}<_**next**_>{""sha"": ""599200ed423d1215a8ab81f0dc732138fb94b02a"", ""filename"": ""media/capture/video_capture_types.h"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 2, ""changes"": 3, ""blob_url"": ""https://github.com/chromium/chromium/blob/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video_capture_types.h"", ""raw_url"": ""https://github.com/chromium/chromium/raw/fff73016a86f9a5990d080dc76058f8528a423f9/media/capture/video_capture_types.h"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/media/capture/video_capture_types.h?ref=fff73016a86f9a5990d080dc76058f8528a423f9"", ""patch"": ""@@ -178,8 +178,7 @@ enum class VideoCaptureError {\n   kMacDeckLinkUnsupportedPixelFormat = 112,\n   kMacAvFoundationReceivedAVCaptureSessionRuntimeErrorNotification = 113,\n   kAndroidApi2ErrorConfiguringCamera = 114,\n-  kCrosHalV3DeviceDelegateFailedToFlush = 115,\n-  kMaxValue = 115\n+  kMaxValue = 114\n };\n \n // WARNING: Do not change the values assigned to the entries. They are used for""}","EnumTraits<media::mojom::VideoCaptureError, media::VideoCaptureError>::ToMojom(
    media::VideoCaptureError input) {
  switch (input) {
    case media::VideoCaptureError::kNone:
      return media::mojom::VideoCaptureError::kNone;
    case media::VideoCaptureError::
        kVideoCaptureControllerInvalidOrUnsupportedVideoCaptureParametersRequested:
      return media::mojom::VideoCaptureError::
          kVideoCaptureControllerInvalidOrUnsupportedVideoCaptureParametersRequested;
    case media::VideoCaptureError::kVideoCaptureControllerIsAlreadyInErrorState:
      return media::mojom::VideoCaptureError::
          kVideoCaptureControllerIsAlreadyInErrorState;
    case media::VideoCaptureError::kVideoCaptureManagerDeviceConnectionLost:
      return media::mojom::VideoCaptureError::
          kVideoCaptureManagerDeviceConnectionLost;
    case media::VideoCaptureError::
        kFrameSinkVideoCaptureDeviceAleradyEndedOnFatalError:
      return media::mojom::VideoCaptureError::
          kFrameSinkVideoCaptureDeviceAleradyEndedOnFatalError;
    case media::VideoCaptureError::
        kFrameSinkVideoCaptureDeviceEncounteredFatalError:
      return media::mojom::VideoCaptureError::
          kFrameSinkVideoCaptureDeviceEncounteredFatalError;
    case media::VideoCaptureError::kV4L2FailedToOpenV4L2DeviceDriverFile:
      return media::mojom::VideoCaptureError::
          kV4L2FailedToOpenV4L2DeviceDriverFile;
    case media::VideoCaptureError::kV4L2ThisIsNotAV4L2VideoCaptureDevice:
      return media::mojom::VideoCaptureError::
          kV4L2ThisIsNotAV4L2VideoCaptureDevice;
    case media::VideoCaptureError::kV4L2FailedToFindASupportedCameraFormat:
      return media::mojom::VideoCaptureError::
          kV4L2FailedToFindASupportedCameraFormat;
    case media::VideoCaptureError::kV4L2FailedToSetVideoCaptureFormat:
      return media::mojom::VideoCaptureError::
          kV4L2FailedToSetVideoCaptureFormat;
    case media::VideoCaptureError::kV4L2UnsupportedPixelFormat:
      return media::mojom::VideoCaptureError::kV4L2UnsupportedPixelFormat;
    case media::VideoCaptureError::kV4L2FailedToSetCameraFramerate:
      return media::mojom::VideoCaptureError::kV4L2FailedToSetCameraFramerate;
    case media::VideoCaptureError::kV4L2ErrorRequestingMmapBuffers:
      return media::mojom::VideoCaptureError::kV4L2ErrorRequestingMmapBuffers;
    case media::VideoCaptureError::kV4L2AllocateBufferFailed:
      return media::mojom::VideoCaptureError::kV4L2AllocateBufferFailed;
    case media::VideoCaptureError::kV4L2VidiocStreamonFailed:
      return media::mojom::VideoCaptureError::kV4L2VidiocStreamonFailed;
    case media::VideoCaptureError::kV4L2VidiocStreamoffFailed:
      return media::mojom::VideoCaptureError::kV4L2VidiocStreamoffFailed;
    case media::VideoCaptureError::kV4L2FailedToVidiocReqbufsWithCount0:
      return media::mojom::VideoCaptureError::
          kV4L2FailedToVidiocReqbufsWithCount0;
    case media::VideoCaptureError::kV4L2PollFailed:
      return media::mojom::VideoCaptureError::kV4L2PollFailed;
    case media::VideoCaptureError::
        kV4L2MultipleContinuousTimeoutsWhileReadPolling:
      return media::mojom::VideoCaptureError::
          kV4L2MultipleContinuousTimeoutsWhileReadPolling;
    case media::VideoCaptureError::kV4L2FailedToDequeueCaptureBuffer:
      return media::mojom::VideoCaptureError::kV4L2FailedToDequeueCaptureBuffer;
    case media::VideoCaptureError::kV4L2FailedToEnqueueCaptureBuffer:
      return media::mojom::VideoCaptureError::kV4L2FailedToEnqueueCaptureBuffer;
    case media::VideoCaptureError::
        kSingleClientVideoCaptureHostLostConnectionToDevice:
      return media::mojom::VideoCaptureError::
          kSingleClientVideoCaptureHostLostConnectionToDevice;
    case media::VideoCaptureError::kSingleClientVideoCaptureDeviceLaunchAborted:
      return media::mojom::VideoCaptureError::
          kSingleClientVideoCaptureDeviceLaunchAborted;
    case media::VideoCaptureError::
        kDesktopCaptureDeviceWebrtcDesktopCapturerHasFailed:
      return media::mojom::VideoCaptureError::
          kDesktopCaptureDeviceWebrtcDesktopCapturerHasFailed;
    case media::VideoCaptureError::kFileVideoCaptureDeviceCouldNotOpenVideoFile:
      return media::mojom::VideoCaptureError::
          kFileVideoCaptureDeviceCouldNotOpenVideoFile;
    case media::VideoCaptureError::
        kDeviceCaptureLinuxFailedToCreateVideoCaptureDelegate:
      return media::mojom::VideoCaptureError::
          kDeviceCaptureLinuxFailedToCreateVideoCaptureDelegate;
    case media::VideoCaptureError::
        kErrorFakeDeviceIntentionallyEmittingErrorEvent:
      return media::mojom::VideoCaptureError::
          kErrorFakeDeviceIntentionallyEmittingErrorEvent;
    case media::VideoCaptureError::kDeviceClientTooManyFramesDroppedY16:
      return media::mojom::VideoCaptureError::
          kDeviceClientTooManyFramesDroppedY16;
    case media::VideoCaptureError::
        kDeviceMediaToMojoAdapterEncounteredUnsupportedBufferType:
      return media::mojom::VideoCaptureError::
          kDeviceMediaToMojoAdapterEncounteredUnsupportedBufferType;
    case media::VideoCaptureError::
        kVideoCaptureManagerProcessDeviceStartQueueDeviceInfoNotFound:
      return media::mojom::VideoCaptureError::
          kVideoCaptureManagerProcessDeviceStartQueueDeviceInfoNotFound;
    case media::VideoCaptureError::
        kInProcessDeviceLauncherFailedToCreateDeviceInstance:
      return media::mojom::VideoCaptureError::
          kInProcessDeviceLauncherFailedToCreateDeviceInstance;
    case media::VideoCaptureError::
        kServiceDeviceLauncherLostConnectionToDeviceFactoryDuringDeviceStart:
      return media::mojom::VideoCaptureError::
          kServiceDeviceLauncherLostConnectionToDeviceFactoryDuringDeviceStart;
    case media::VideoCaptureError::
        kServiceDeviceLauncherServiceRespondedWithDeviceNotFound:
      return media::mojom::VideoCaptureError::
          kServiceDeviceLauncherServiceRespondedWithDeviceNotFound;
    case media::VideoCaptureError::
        kServiceDeviceLauncherConnectionLostWhileWaitingForCallback:
      return media::mojom::VideoCaptureError::
          kServiceDeviceLauncherConnectionLostWhileWaitingForCallback;
    case media::VideoCaptureError::kIntentionalErrorRaisedByUnitTest:
      return media::mojom::VideoCaptureError::kIntentionalErrorRaisedByUnitTest;
    case media::VideoCaptureError::kCrosHalV3FailedToStartDeviceThread:
      return media::mojom::VideoCaptureError::
          kCrosHalV3FailedToStartDeviceThread;
    case media::VideoCaptureError::kCrosHalV3DeviceDelegateMojoConnectionError:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateMojoConnectionError;
    case media::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToGetCameraInfo:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToGetCameraInfo;
    case media::VideoCaptureError::
        kCrosHalV3DeviceDelegateMissingSensorOrientationInfo:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateMissingSensorOrientationInfo;
    case media::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToOpenCameraDevice:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToOpenCameraDevice;
    case media::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToInitializeCameraDevice:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToInitializeCameraDevice;
    case media::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToConfigureStreams:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToConfigureStreams;
    case media::VideoCaptureError::
        kCrosHalV3DeviceDelegateWrongNumberOfStreamsConfigured:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateWrongNumberOfStreamsConfigured;
    case media::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToGetDefaultRequestSettings:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToGetDefaultRequestSettings;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerHalRequestedTooManyBuffers:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerHalRequestedTooManyBuffers;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToCreateGpuMemoryBuffer:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToCreateGpuMemoryBuffer;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToMapGpuMemoryBuffer:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToMapGpuMemoryBuffer;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerUnsupportedVideoPixelFormat:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerUnsupportedVideoPixelFormat;
    case media::VideoCaptureError::kCrosHalV3BufferManagerFailedToDupFd:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToDupFd;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToWrapGpuMemoryHandle:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToWrapGpuMemoryHandle;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToRegisterBuffer:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToRegisterBuffer;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerProcessCaptureRequestFailed:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerProcessCaptureRequestFailed;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerInvalidPendingResultId:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerInvalidPendingResultId;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerReceivedDuplicatedPartialMetadata:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerReceivedDuplicatedPartialMetadata;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerIncorrectNumberOfOutputBuffersReceived:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerIncorrectNumberOfOutputBuffersReceived;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerInvalidTypeOfOutputBuffersReceived:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerInvalidTypeOfOutputBuffersReceived;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerReceivedMultipleResultBuffersForFrame:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerReceivedMultipleResultBuffersForFrame;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerUnknownStreamInCamera3NotifyMsg:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerUnknownStreamInCamera3NotifyMsg;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerReceivedInvalidShutterTime:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerReceivedInvalidShutterTime;
    case media::VideoCaptureError::kCrosHalV3BufferManagerFatalDeviceError:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerFatalDeviceError;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerReceivedFrameIsOutOfOrder:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerReceivedFrameIsOutOfOrder;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToUnwrapReleaseFenceFd:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToUnwrapReleaseFenceFd;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerSyncWaitOnReleaseFenceTimedOut:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerSyncWaitOnReleaseFenceTimedOut;
    case media::VideoCaptureError::kCrosHalV3BufferManagerInvalidJpegBlob:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerInvalidJpegBlob;
    case media::VideoCaptureError::kAndroidFailedToAllocate:
      return media::mojom::VideoCaptureError::kAndroidFailedToAllocate;
    case media::VideoCaptureError::kAndroidFailedToStartCapture:
      return media::mojom::VideoCaptureError::kAndroidFailedToStartCapture;
    case media::VideoCaptureError::kAndroidFailedToStopCapture:
      return media::mojom::VideoCaptureError::kAndroidFailedToStopCapture;
    case media::VideoCaptureError::kAndroidApi1CameraErrorCallbackReceived:
      return media::mojom::VideoCaptureError::
          kAndroidApi1CameraErrorCallbackReceived;
    case media::VideoCaptureError::kAndroidApi2CameraDeviceErrorReceived:
      return media::mojom::VideoCaptureError::
          kAndroidApi2CameraDeviceErrorReceived;
    case media::VideoCaptureError::kAndroidApi2CaptureSessionConfigureFailed:
      return media::mojom::VideoCaptureError::
          kAndroidApi2CaptureSessionConfigureFailed;
    case media::VideoCaptureError::kAndroidApi2ImageReaderUnexpectedImageFormat:
      return media::mojom::VideoCaptureError::
          kAndroidApi2ImageReaderUnexpectedImageFormat;
    case media::VideoCaptureError::
        kAndroidApi2ImageReaderSizeDidNotMatchImageSize:
      return media::mojom::VideoCaptureError::
          kAndroidApi2ImageReaderSizeDidNotMatchImageSize;
    case media::VideoCaptureError::kAndroidApi2ErrorRestartingPreview:
      return media::mojom::VideoCaptureError::
          kAndroidApi2ErrorRestartingPreview;
    case media::VideoCaptureError::kAndroidScreenCaptureUnsupportedFormat:
      return media::mojom::VideoCaptureError::
          kAndroidScreenCaptureUnsupportedFormat;
    case media::VideoCaptureError::
        kAndroidScreenCaptureFailedToStartCaptureMachine:
      return media::mojom::VideoCaptureError::
          kAndroidScreenCaptureFailedToStartCaptureMachine;
    case media::VideoCaptureError::
        kAndroidScreenCaptureTheUserDeniedScreenCapture:
      return media::mojom::VideoCaptureError::
          kAndroidScreenCaptureTheUserDeniedScreenCapture;
    case media::VideoCaptureError::
        kAndroidScreenCaptureFailedToStartScreenCapture:
      return media::mojom::VideoCaptureError::
          kAndroidScreenCaptureFailedToStartScreenCapture;
    case media::VideoCaptureError::kWinDirectShowCantGetCaptureFormatSettings:
      return media::mojom::VideoCaptureError::
          kWinDirectShowCantGetCaptureFormatSettings;
    case media::VideoCaptureError::
        kWinDirectShowFailedToGetNumberOfCapabilities:
      return media::mojom::VideoCaptureError::
          kWinDirectShowFailedToGetNumberOfCapabilities;
    case media::VideoCaptureError::
        kWinDirectShowFailedToGetCaptureDeviceCapabilities:
      return media::mojom::VideoCaptureError::
          kWinDirectShowFailedToGetCaptureDeviceCapabilities;
    case media::VideoCaptureError::
        kWinDirectShowFailedToSetCaptureDeviceOutputFormat:
      return media::mojom::VideoCaptureError::
          kWinDirectShowFailedToSetCaptureDeviceOutputFormat;
    case media::VideoCaptureError::kWinDirectShowFailedToConnectTheCaptureGraph:
      return media::mojom::VideoCaptureError::
          kWinDirectShowFailedToConnectTheCaptureGraph;
    case media::VideoCaptureError::kWinDirectShowFailedToPauseTheCaptureDevice:
      return media::mojom::VideoCaptureError::
          kWinDirectShowFailedToPauseTheCaptureDevice;
    case media::VideoCaptureError::kWinDirectShowFailedToStartTheCaptureDevice:
      return media::mojom::VideoCaptureError::
          kWinDirectShowFailedToStartTheCaptureDevice;
    case media::VideoCaptureError::kWinDirectShowFailedToStopTheCaptureGraph:
      return media::mojom::VideoCaptureError::
          kWinDirectShowFailedToStopTheCaptureGraph;
    case media::VideoCaptureError::kWinMediaFoundationEngineIsNull:
      return media::mojom::VideoCaptureError::kWinMediaFoundationEngineIsNull;
    case media::VideoCaptureError::kWinMediaFoundationEngineGetSourceFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationEngineGetSourceFailed;
    case media::VideoCaptureError::
        kWinMediaFoundationFillPhotoCapabilitiesFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationFillPhotoCapabilitiesFailed;
    case media::VideoCaptureError::
        kWinMediaFoundationFillVideoCapabilitiesFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationFillVideoCapabilitiesFailed;
    case media::VideoCaptureError::kWinMediaFoundationNoVideoCapabilityFound:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationNoVideoCapabilityFound;
    case media::VideoCaptureError::
        kWinMediaFoundationGetAvailableDeviceMediaTypeFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationGetAvailableDeviceMediaTypeFailed;
    case media::VideoCaptureError::
        kWinMediaFoundationSetCurrentDeviceMediaTypeFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationSetCurrentDeviceMediaTypeFailed;
    case media::VideoCaptureError::kWinMediaFoundationEngineGetSinkFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationEngineGetSinkFailed;
    case media::VideoCaptureError::
        kWinMediaFoundationSinkQueryCapturePreviewInterfaceFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationSinkQueryCapturePreviewInterfaceFailed;
    case media::VideoCaptureError::
        kWinMediaFoundationSinkRemoveAllStreamsFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationSinkRemoveAllStreamsFailed;
    case media::VideoCaptureError::
        kWinMediaFoundationCreateSinkVideoMediaTypeFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationCreateSinkVideoMediaTypeFailed;
    case media::VideoCaptureError::
        kWinMediaFoundationConvertToVideoSinkMediaTypeFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationConvertToVideoSinkMediaTypeFailed;
    case media::VideoCaptureError::kWinMediaFoundationSinkAddStreamFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationSinkAddStreamFailed;
    case media::VideoCaptureError::
        kWinMediaFoundationSinkSetSampleCallbackFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationSinkSetSampleCallbackFailed;
    case media::VideoCaptureError::kWinMediaFoundationEngineStartPreviewFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationEngineStartPreviewFailed;
    case media::VideoCaptureError::kWinMediaFoundationGetMediaEventStatusFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationGetMediaEventStatusFailed;
    case media::VideoCaptureError::kMacSetCaptureDeviceFailed:
      return media::mojom::VideoCaptureError::kMacSetCaptureDeviceFailed;
    case media::VideoCaptureError::kMacCouldNotStartCaptureDevice:
      return media::mojom::VideoCaptureError::kMacCouldNotStartCaptureDevice;
    case media::VideoCaptureError::kMacReceivedFrameWithUnexpectedResolution:
      return media::mojom::VideoCaptureError::
          kMacReceivedFrameWithUnexpectedResolution;
    case media::VideoCaptureError::kMacUpdateCaptureResolutionFailed:
      return media::mojom::VideoCaptureError::kMacUpdateCaptureResolutionFailed;
    case media::VideoCaptureError::kMacDeckLinkDeviceIdNotFoundInTheSystem:
      return media::mojom::VideoCaptureError::
          kMacDeckLinkDeviceIdNotFoundInTheSystem;
    case media::VideoCaptureError::kMacDeckLinkErrorQueryingInputInterface:
      return media::mojom::VideoCaptureError::
          kMacDeckLinkErrorQueryingInputInterface;
    case media::VideoCaptureError::kMacDeckLinkErrorCreatingDisplayModeIterator:
      return media::mojom::VideoCaptureError::
          kMacDeckLinkErrorCreatingDisplayModeIterator;
    case media::VideoCaptureError::kMacDeckLinkCouldNotFindADisplayMode:
      return media::mojom::VideoCaptureError::
          kMacDeckLinkCouldNotFindADisplayMode;
    case media::VideoCaptureError::
        kMacDeckLinkCouldNotSelectTheVideoFormatWeLike:
      return media::mojom::VideoCaptureError::
          kMacDeckLinkCouldNotSelectTheVideoFormatWeLike;
    case media::VideoCaptureError::kMacDeckLinkCouldNotStartCapturing:
      return media::mojom::VideoCaptureError::
          kMacDeckLinkCouldNotStartCapturing;
    case media::VideoCaptureError::kMacDeckLinkUnsupportedPixelFormat:
      return media::mojom::VideoCaptureError::
          kMacDeckLinkUnsupportedPixelFormat;
    case media::VideoCaptureError::
        kMacAvFoundationReceivedAVCaptureSessionRuntimeErrorNotification:
      return media::mojom::VideoCaptureError::
          kMacAvFoundationReceivedAVCaptureSessionRuntimeErrorNotification;
     case media::VideoCaptureError::kAndroidApi2ErrorConfiguringCamera:
       return media::mojom::VideoCaptureError::
           kAndroidApi2ErrorConfiguringCamera;
   }
   NOTREACHED();
   return media::mojom::VideoCaptureError::kNone;
}
","EnumTraits<media::mojom::VideoCaptureError, media::VideoCaptureError>::ToMojom(
    media::VideoCaptureError input) {
  switch (input) {
    case media::VideoCaptureError::kNone:
      return media::mojom::VideoCaptureError::kNone;
    case media::VideoCaptureError::
        kVideoCaptureControllerInvalidOrUnsupportedVideoCaptureParametersRequested:
      return media::mojom::VideoCaptureError::
          kVideoCaptureControllerInvalidOrUnsupportedVideoCaptureParametersRequested;
    case media::VideoCaptureError::kVideoCaptureControllerIsAlreadyInErrorState:
      return media::mojom::VideoCaptureError::
          kVideoCaptureControllerIsAlreadyInErrorState;
    case media::VideoCaptureError::kVideoCaptureManagerDeviceConnectionLost:
      return media::mojom::VideoCaptureError::
          kVideoCaptureManagerDeviceConnectionLost;
    case media::VideoCaptureError::
        kFrameSinkVideoCaptureDeviceAleradyEndedOnFatalError:
      return media::mojom::VideoCaptureError::
          kFrameSinkVideoCaptureDeviceAleradyEndedOnFatalError;
    case media::VideoCaptureError::
        kFrameSinkVideoCaptureDeviceEncounteredFatalError:
      return media::mojom::VideoCaptureError::
          kFrameSinkVideoCaptureDeviceEncounteredFatalError;
    case media::VideoCaptureError::kV4L2FailedToOpenV4L2DeviceDriverFile:
      return media::mojom::VideoCaptureError::
          kV4L2FailedToOpenV4L2DeviceDriverFile;
    case media::VideoCaptureError::kV4L2ThisIsNotAV4L2VideoCaptureDevice:
      return media::mojom::VideoCaptureError::
          kV4L2ThisIsNotAV4L2VideoCaptureDevice;
    case media::VideoCaptureError::kV4L2FailedToFindASupportedCameraFormat:
      return media::mojom::VideoCaptureError::
          kV4L2FailedToFindASupportedCameraFormat;
    case media::VideoCaptureError::kV4L2FailedToSetVideoCaptureFormat:
      return media::mojom::VideoCaptureError::
          kV4L2FailedToSetVideoCaptureFormat;
    case media::VideoCaptureError::kV4L2UnsupportedPixelFormat:
      return media::mojom::VideoCaptureError::kV4L2UnsupportedPixelFormat;
    case media::VideoCaptureError::kV4L2FailedToSetCameraFramerate:
      return media::mojom::VideoCaptureError::kV4L2FailedToSetCameraFramerate;
    case media::VideoCaptureError::kV4L2ErrorRequestingMmapBuffers:
      return media::mojom::VideoCaptureError::kV4L2ErrorRequestingMmapBuffers;
    case media::VideoCaptureError::kV4L2AllocateBufferFailed:
      return media::mojom::VideoCaptureError::kV4L2AllocateBufferFailed;
    case media::VideoCaptureError::kV4L2VidiocStreamonFailed:
      return media::mojom::VideoCaptureError::kV4L2VidiocStreamonFailed;
    case media::VideoCaptureError::kV4L2VidiocStreamoffFailed:
      return media::mojom::VideoCaptureError::kV4L2VidiocStreamoffFailed;
    case media::VideoCaptureError::kV4L2FailedToVidiocReqbufsWithCount0:
      return media::mojom::VideoCaptureError::
          kV4L2FailedToVidiocReqbufsWithCount0;
    case media::VideoCaptureError::kV4L2PollFailed:
      return media::mojom::VideoCaptureError::kV4L2PollFailed;
    case media::VideoCaptureError::
        kV4L2MultipleContinuousTimeoutsWhileReadPolling:
      return media::mojom::VideoCaptureError::
          kV4L2MultipleContinuousTimeoutsWhileReadPolling;
    case media::VideoCaptureError::kV4L2FailedToDequeueCaptureBuffer:
      return media::mojom::VideoCaptureError::kV4L2FailedToDequeueCaptureBuffer;
    case media::VideoCaptureError::kV4L2FailedToEnqueueCaptureBuffer:
      return media::mojom::VideoCaptureError::kV4L2FailedToEnqueueCaptureBuffer;
    case media::VideoCaptureError::
        kSingleClientVideoCaptureHostLostConnectionToDevice:
      return media::mojom::VideoCaptureError::
          kSingleClientVideoCaptureHostLostConnectionToDevice;
    case media::VideoCaptureError::kSingleClientVideoCaptureDeviceLaunchAborted:
      return media::mojom::VideoCaptureError::
          kSingleClientVideoCaptureDeviceLaunchAborted;
    case media::VideoCaptureError::
        kDesktopCaptureDeviceWebrtcDesktopCapturerHasFailed:
      return media::mojom::VideoCaptureError::
          kDesktopCaptureDeviceWebrtcDesktopCapturerHasFailed;
    case media::VideoCaptureError::kFileVideoCaptureDeviceCouldNotOpenVideoFile:
      return media::mojom::VideoCaptureError::
          kFileVideoCaptureDeviceCouldNotOpenVideoFile;
    case media::VideoCaptureError::
        kDeviceCaptureLinuxFailedToCreateVideoCaptureDelegate:
      return media::mojom::VideoCaptureError::
          kDeviceCaptureLinuxFailedToCreateVideoCaptureDelegate;
    case media::VideoCaptureError::
        kErrorFakeDeviceIntentionallyEmittingErrorEvent:
      return media::mojom::VideoCaptureError::
          kErrorFakeDeviceIntentionallyEmittingErrorEvent;
    case media::VideoCaptureError::kDeviceClientTooManyFramesDroppedY16:
      return media::mojom::VideoCaptureError::
          kDeviceClientTooManyFramesDroppedY16;
    case media::VideoCaptureError::
        kDeviceMediaToMojoAdapterEncounteredUnsupportedBufferType:
      return media::mojom::VideoCaptureError::
          kDeviceMediaToMojoAdapterEncounteredUnsupportedBufferType;
    case media::VideoCaptureError::
        kVideoCaptureManagerProcessDeviceStartQueueDeviceInfoNotFound:
      return media::mojom::VideoCaptureError::
          kVideoCaptureManagerProcessDeviceStartQueueDeviceInfoNotFound;
    case media::VideoCaptureError::
        kInProcessDeviceLauncherFailedToCreateDeviceInstance:
      return media::mojom::VideoCaptureError::
          kInProcessDeviceLauncherFailedToCreateDeviceInstance;
    case media::VideoCaptureError::
        kServiceDeviceLauncherLostConnectionToDeviceFactoryDuringDeviceStart:
      return media::mojom::VideoCaptureError::
          kServiceDeviceLauncherLostConnectionToDeviceFactoryDuringDeviceStart;
    case media::VideoCaptureError::
        kServiceDeviceLauncherServiceRespondedWithDeviceNotFound:
      return media::mojom::VideoCaptureError::
          kServiceDeviceLauncherServiceRespondedWithDeviceNotFound;
    case media::VideoCaptureError::
        kServiceDeviceLauncherConnectionLostWhileWaitingForCallback:
      return media::mojom::VideoCaptureError::
          kServiceDeviceLauncherConnectionLostWhileWaitingForCallback;
    case media::VideoCaptureError::kIntentionalErrorRaisedByUnitTest:
      return media::mojom::VideoCaptureError::kIntentionalErrorRaisedByUnitTest;
    case media::VideoCaptureError::kCrosHalV3FailedToStartDeviceThread:
      return media::mojom::VideoCaptureError::
          kCrosHalV3FailedToStartDeviceThread;
    case media::VideoCaptureError::kCrosHalV3DeviceDelegateMojoConnectionError:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateMojoConnectionError;
    case media::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToGetCameraInfo:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToGetCameraInfo;
    case media::VideoCaptureError::
        kCrosHalV3DeviceDelegateMissingSensorOrientationInfo:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateMissingSensorOrientationInfo;
    case media::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToOpenCameraDevice:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToOpenCameraDevice;
    case media::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToInitializeCameraDevice:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToInitializeCameraDevice;
    case media::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToConfigureStreams:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToConfigureStreams;
    case media::VideoCaptureError::
        kCrosHalV3DeviceDelegateWrongNumberOfStreamsConfigured:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateWrongNumberOfStreamsConfigured;
    case media::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToGetDefaultRequestSettings:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToGetDefaultRequestSettings;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerHalRequestedTooManyBuffers:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerHalRequestedTooManyBuffers;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToCreateGpuMemoryBuffer:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToCreateGpuMemoryBuffer;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToMapGpuMemoryBuffer:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToMapGpuMemoryBuffer;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerUnsupportedVideoPixelFormat:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerUnsupportedVideoPixelFormat;
    case media::VideoCaptureError::kCrosHalV3BufferManagerFailedToDupFd:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToDupFd;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToWrapGpuMemoryHandle:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToWrapGpuMemoryHandle;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToRegisterBuffer:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToRegisterBuffer;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerProcessCaptureRequestFailed:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerProcessCaptureRequestFailed;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerInvalidPendingResultId:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerInvalidPendingResultId;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerReceivedDuplicatedPartialMetadata:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerReceivedDuplicatedPartialMetadata;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerIncorrectNumberOfOutputBuffersReceived:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerIncorrectNumberOfOutputBuffersReceived;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerInvalidTypeOfOutputBuffersReceived:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerInvalidTypeOfOutputBuffersReceived;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerReceivedMultipleResultBuffersForFrame:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerReceivedMultipleResultBuffersForFrame;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerUnknownStreamInCamera3NotifyMsg:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerUnknownStreamInCamera3NotifyMsg;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerReceivedInvalidShutterTime:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerReceivedInvalidShutterTime;
    case media::VideoCaptureError::kCrosHalV3BufferManagerFatalDeviceError:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerFatalDeviceError;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerReceivedFrameIsOutOfOrder:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerReceivedFrameIsOutOfOrder;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToUnwrapReleaseFenceFd:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToUnwrapReleaseFenceFd;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerSyncWaitOnReleaseFenceTimedOut:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerSyncWaitOnReleaseFenceTimedOut;
    case media::VideoCaptureError::kCrosHalV3BufferManagerInvalidJpegBlob:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerInvalidJpegBlob;
    case media::VideoCaptureError::kAndroidFailedToAllocate:
      return media::mojom::VideoCaptureError::kAndroidFailedToAllocate;
    case media::VideoCaptureError::kAndroidFailedToStartCapture:
      return media::mojom::VideoCaptureError::kAndroidFailedToStartCapture;
    case media::VideoCaptureError::kAndroidFailedToStopCapture:
      return media::mojom::VideoCaptureError::kAndroidFailedToStopCapture;
    case media::VideoCaptureError::kAndroidApi1CameraErrorCallbackReceived:
      return media::mojom::VideoCaptureError::
          kAndroidApi1CameraErrorCallbackReceived;
    case media::VideoCaptureError::kAndroidApi2CameraDeviceErrorReceived:
      return media::mojom::VideoCaptureError::
          kAndroidApi2CameraDeviceErrorReceived;
    case media::VideoCaptureError::kAndroidApi2CaptureSessionConfigureFailed:
      return media::mojom::VideoCaptureError::
          kAndroidApi2CaptureSessionConfigureFailed;
    case media::VideoCaptureError::kAndroidApi2ImageReaderUnexpectedImageFormat:
      return media::mojom::VideoCaptureError::
          kAndroidApi2ImageReaderUnexpectedImageFormat;
    case media::VideoCaptureError::
        kAndroidApi2ImageReaderSizeDidNotMatchImageSize:
      return media::mojom::VideoCaptureError::
          kAndroidApi2ImageReaderSizeDidNotMatchImageSize;
    case media::VideoCaptureError::kAndroidApi2ErrorRestartingPreview:
      return media::mojom::VideoCaptureError::
          kAndroidApi2ErrorRestartingPreview;
    case media::VideoCaptureError::kAndroidScreenCaptureUnsupportedFormat:
      return media::mojom::VideoCaptureError::
          kAndroidScreenCaptureUnsupportedFormat;
    case media::VideoCaptureError::
        kAndroidScreenCaptureFailedToStartCaptureMachine:
      return media::mojom::VideoCaptureError::
          kAndroidScreenCaptureFailedToStartCaptureMachine;
    case media::VideoCaptureError::
        kAndroidScreenCaptureTheUserDeniedScreenCapture:
      return media::mojom::VideoCaptureError::
          kAndroidScreenCaptureTheUserDeniedScreenCapture;
    case media::VideoCaptureError::
        kAndroidScreenCaptureFailedToStartScreenCapture:
      return media::mojom::VideoCaptureError::
          kAndroidScreenCaptureFailedToStartScreenCapture;
    case media::VideoCaptureError::kWinDirectShowCantGetCaptureFormatSettings:
      return media::mojom::VideoCaptureError::
          kWinDirectShowCantGetCaptureFormatSettings;
    case media::VideoCaptureError::
        kWinDirectShowFailedToGetNumberOfCapabilities:
      return media::mojom::VideoCaptureError::
          kWinDirectShowFailedToGetNumberOfCapabilities;
    case media::VideoCaptureError::
        kWinDirectShowFailedToGetCaptureDeviceCapabilities:
      return media::mojom::VideoCaptureError::
          kWinDirectShowFailedToGetCaptureDeviceCapabilities;
    case media::VideoCaptureError::
        kWinDirectShowFailedToSetCaptureDeviceOutputFormat:
      return media::mojom::VideoCaptureError::
          kWinDirectShowFailedToSetCaptureDeviceOutputFormat;
    case media::VideoCaptureError::kWinDirectShowFailedToConnectTheCaptureGraph:
      return media::mojom::VideoCaptureError::
          kWinDirectShowFailedToConnectTheCaptureGraph;
    case media::VideoCaptureError::kWinDirectShowFailedToPauseTheCaptureDevice:
      return media::mojom::VideoCaptureError::
          kWinDirectShowFailedToPauseTheCaptureDevice;
    case media::VideoCaptureError::kWinDirectShowFailedToStartTheCaptureDevice:
      return media::mojom::VideoCaptureError::
          kWinDirectShowFailedToStartTheCaptureDevice;
    case media::VideoCaptureError::kWinDirectShowFailedToStopTheCaptureGraph:
      return media::mojom::VideoCaptureError::
          kWinDirectShowFailedToStopTheCaptureGraph;
    case media::VideoCaptureError::kWinMediaFoundationEngineIsNull:
      return media::mojom::VideoCaptureError::kWinMediaFoundationEngineIsNull;
    case media::VideoCaptureError::kWinMediaFoundationEngineGetSourceFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationEngineGetSourceFailed;
    case media::VideoCaptureError::
        kWinMediaFoundationFillPhotoCapabilitiesFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationFillPhotoCapabilitiesFailed;
    case media::VideoCaptureError::
        kWinMediaFoundationFillVideoCapabilitiesFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationFillVideoCapabilitiesFailed;
    case media::VideoCaptureError::kWinMediaFoundationNoVideoCapabilityFound:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationNoVideoCapabilityFound;
    case media::VideoCaptureError::
        kWinMediaFoundationGetAvailableDeviceMediaTypeFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationGetAvailableDeviceMediaTypeFailed;
    case media::VideoCaptureError::
        kWinMediaFoundationSetCurrentDeviceMediaTypeFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationSetCurrentDeviceMediaTypeFailed;
    case media::VideoCaptureError::kWinMediaFoundationEngineGetSinkFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationEngineGetSinkFailed;
    case media::VideoCaptureError::
        kWinMediaFoundationSinkQueryCapturePreviewInterfaceFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationSinkQueryCapturePreviewInterfaceFailed;
    case media::VideoCaptureError::
        kWinMediaFoundationSinkRemoveAllStreamsFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationSinkRemoveAllStreamsFailed;
    case media::VideoCaptureError::
        kWinMediaFoundationCreateSinkVideoMediaTypeFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationCreateSinkVideoMediaTypeFailed;
    case media::VideoCaptureError::
        kWinMediaFoundationConvertToVideoSinkMediaTypeFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationConvertToVideoSinkMediaTypeFailed;
    case media::VideoCaptureError::kWinMediaFoundationSinkAddStreamFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationSinkAddStreamFailed;
    case media::VideoCaptureError::
        kWinMediaFoundationSinkSetSampleCallbackFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationSinkSetSampleCallbackFailed;
    case media::VideoCaptureError::kWinMediaFoundationEngineStartPreviewFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationEngineStartPreviewFailed;
    case media::VideoCaptureError::kWinMediaFoundationGetMediaEventStatusFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationGetMediaEventStatusFailed;
    case media::VideoCaptureError::kMacSetCaptureDeviceFailed:
      return media::mojom::VideoCaptureError::kMacSetCaptureDeviceFailed;
    case media::VideoCaptureError::kMacCouldNotStartCaptureDevice:
      return media::mojom::VideoCaptureError::kMacCouldNotStartCaptureDevice;
    case media::VideoCaptureError::kMacReceivedFrameWithUnexpectedResolution:
      return media::mojom::VideoCaptureError::
          kMacReceivedFrameWithUnexpectedResolution;
    case media::VideoCaptureError::kMacUpdateCaptureResolutionFailed:
      return media::mojom::VideoCaptureError::kMacUpdateCaptureResolutionFailed;
    case media::VideoCaptureError::kMacDeckLinkDeviceIdNotFoundInTheSystem:
      return media::mojom::VideoCaptureError::
          kMacDeckLinkDeviceIdNotFoundInTheSystem;
    case media::VideoCaptureError::kMacDeckLinkErrorQueryingInputInterface:
      return media::mojom::VideoCaptureError::
          kMacDeckLinkErrorQueryingInputInterface;
    case media::VideoCaptureError::kMacDeckLinkErrorCreatingDisplayModeIterator:
      return media::mojom::VideoCaptureError::
          kMacDeckLinkErrorCreatingDisplayModeIterator;
    case media::VideoCaptureError::kMacDeckLinkCouldNotFindADisplayMode:
      return media::mojom::VideoCaptureError::
          kMacDeckLinkCouldNotFindADisplayMode;
    case media::VideoCaptureError::
        kMacDeckLinkCouldNotSelectTheVideoFormatWeLike:
      return media::mojom::VideoCaptureError::
          kMacDeckLinkCouldNotSelectTheVideoFormatWeLike;
    case media::VideoCaptureError::kMacDeckLinkCouldNotStartCapturing:
      return media::mojom::VideoCaptureError::
          kMacDeckLinkCouldNotStartCapturing;
    case media::VideoCaptureError::kMacDeckLinkUnsupportedPixelFormat:
      return media::mojom::VideoCaptureError::
          kMacDeckLinkUnsupportedPixelFormat;
    case media::VideoCaptureError::
        kMacAvFoundationReceivedAVCaptureSessionRuntimeErrorNotification:
      return media::mojom::VideoCaptureError::
          kMacAvFoundationReceivedAVCaptureSessionRuntimeErrorNotification;
     case media::VideoCaptureError::kAndroidApi2ErrorConfiguringCamera:
       return media::mojom::VideoCaptureError::
           kAndroidApi2ErrorConfiguringCamera;
    case media::VideoCaptureError::kCrosHalV3DeviceDelegateFailedToFlush:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToFlush;
   }
   NOTREACHED();
   return media::mojom::VideoCaptureError::kNone;
}
",C,,"    case media::VideoCaptureError::kCrosHalV3DeviceDelegateFailedToFlush:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToFlush;
",,"@@ -658,9 +658,6 @@ EnumTraits<media::mojom::VideoCaptureError, media::VideoCaptureError>::ToMojom(
     case media::VideoCaptureError::kAndroidApi2ErrorConfiguringCamera:
       return media::mojom::VideoCaptureError::
           kAndroidApi2ErrorConfiguringCamera;
-    case media::VideoCaptureError::kCrosHalV3DeviceDelegateFailedToFlush:
-      return media::mojom::VideoCaptureError::
-          kCrosHalV3DeviceDelegateFailedToFlush;
   }
   NOTREACHED();
   return media::mojom::VideoCaptureError::kNone;
@@ -1179,9 +1176,6 @@ bool EnumTraits<media::mojom::VideoCaptureError, media::VideoCaptureError>::
     case media::mojom::VideoCaptureError::kAndroidApi2ErrorConfiguringCamera:
       *output = media::VideoCaptureError::kAndroidApi2ErrorConfiguringCamera;
       return true;
-    case media::mojom::VideoCaptureError::kCrosHalV3DeviceDelegateFailedToFlush:
-      *output = media::VideoCaptureError::kCrosHalV3DeviceDelegateFailedToFlush;
-      return true;
   }
   NOTREACHED();
   return false;",Chrome,fff73016a86f9a5990d080dc76058f8528a423f9,3b62417ecd317d4ff62f2396a3f10d8cc310e146,1,"EnumTraits<media::mojom::VideoCaptureError, media::VideoCaptureError>::ToMojom(
    media::VideoCaptureError input) {
  switch (input) {
    case media::VideoCaptureError::kNone:
      return media::mojom::VideoCaptureError::kNone;
    case media::VideoCaptureError::
        kVideoCaptureControllerInvalidOrUnsupportedVideoCaptureParametersRequested:
      return media::mojom::VideoCaptureError::
          kVideoCaptureControllerInvalidOrUnsupportedVideoCaptureParametersRequested;
    case media::VideoCaptureError::kVideoCaptureControllerIsAlreadyInErrorState:
      return media::mojom::VideoCaptureError::
          kVideoCaptureControllerIsAlreadyInErrorState;
    case media::VideoCaptureError::kVideoCaptureManagerDeviceConnectionLost:
      return media::mojom::VideoCaptureError::
          kVideoCaptureManagerDeviceConnectionLost;
    case media::VideoCaptureError::
        kFrameSinkVideoCaptureDeviceAleradyEndedOnFatalError:
      return media::mojom::VideoCaptureError::
          kFrameSinkVideoCaptureDeviceAleradyEndedOnFatalError;
    case media::VideoCaptureError::
        kFrameSinkVideoCaptureDeviceEncounteredFatalError:
      return media::mojom::VideoCaptureError::
          kFrameSinkVideoCaptureDeviceEncounteredFatalError;
    case media::VideoCaptureError::kV4L2FailedToOpenV4L2DeviceDriverFile:
      return media::mojom::VideoCaptureError::
          kV4L2FailedToOpenV4L2DeviceDriverFile;
    case media::VideoCaptureError::kV4L2ThisIsNotAV4L2VideoCaptureDevice:
      return media::mojom::VideoCaptureError::
          kV4L2ThisIsNotAV4L2VideoCaptureDevice;
    case media::VideoCaptureError::kV4L2FailedToFindASupportedCameraFormat:
      return media::mojom::VideoCaptureError::
          kV4L2FailedToFindASupportedCameraFormat;
    case media::VideoCaptureError::kV4L2FailedToSetVideoCaptureFormat:
      return media::mojom::VideoCaptureError::
          kV4L2FailedToSetVideoCaptureFormat;
    case media::VideoCaptureError::kV4L2UnsupportedPixelFormat:
      return media::mojom::VideoCaptureError::kV4L2UnsupportedPixelFormat;
    case media::VideoCaptureError::kV4L2FailedToSetCameraFramerate:
      return media::mojom::VideoCaptureError::kV4L2FailedToSetCameraFramerate;
    case media::VideoCaptureError::kV4L2ErrorRequestingMmapBuffers:
      return media::mojom::VideoCaptureError::kV4L2ErrorRequestingMmapBuffers;
    case media::VideoCaptureError::kV4L2AllocateBufferFailed:
      return media::mojom::VideoCaptureError::kV4L2AllocateBufferFailed;
    case media::VideoCaptureError::kV4L2VidiocStreamonFailed:
      return media::mojom::VideoCaptureError::kV4L2VidiocStreamonFailed;
    case media::VideoCaptureError::kV4L2VidiocStreamoffFailed:
      return media::mojom::VideoCaptureError::kV4L2VidiocStreamoffFailed;
    case media::VideoCaptureError::kV4L2FailedToVidiocReqbufsWithCount0:
      return media::mojom::VideoCaptureError::
          kV4L2FailedToVidiocReqbufsWithCount0;
    case media::VideoCaptureError::kV4L2PollFailed:
      return media::mojom::VideoCaptureError::kV4L2PollFailed;
    case media::VideoCaptureError::
        kV4L2MultipleContinuousTimeoutsWhileReadPolling:
      return media::mojom::VideoCaptureError::
          kV4L2MultipleContinuousTimeoutsWhileReadPolling;
    case media::VideoCaptureError::kV4L2FailedToDequeueCaptureBuffer:
      return media::mojom::VideoCaptureError::kV4L2FailedToDequeueCaptureBuffer;
    case media::VideoCaptureError::kV4L2FailedToEnqueueCaptureBuffer:
      return media::mojom::VideoCaptureError::kV4L2FailedToEnqueueCaptureBuffer;
    case media::VideoCaptureError::
        kSingleClientVideoCaptureHostLostConnectionToDevice:
      return media::mojom::VideoCaptureError::
          kSingleClientVideoCaptureHostLostConnectionToDevice;
    case media::VideoCaptureError::kSingleClientVideoCaptureDeviceLaunchAborted:
      return media::mojom::VideoCaptureError::
          kSingleClientVideoCaptureDeviceLaunchAborted;
    case media::VideoCaptureError::
        kDesktopCaptureDeviceWebrtcDesktopCapturerHasFailed:
      return media::mojom::VideoCaptureError::
          kDesktopCaptureDeviceWebrtcDesktopCapturerHasFailed;
    case media::VideoCaptureError::kFileVideoCaptureDeviceCouldNotOpenVideoFile:
      return media::mojom::VideoCaptureError::
          kFileVideoCaptureDeviceCouldNotOpenVideoFile;
    case media::VideoCaptureError::
        kDeviceCaptureLinuxFailedToCreateVideoCaptureDelegate:
      return media::mojom::VideoCaptureError::
          kDeviceCaptureLinuxFailedToCreateVideoCaptureDelegate;
    case media::VideoCaptureError::
        kErrorFakeDeviceIntentionallyEmittingErrorEvent:
      return media::mojom::VideoCaptureError::
          kErrorFakeDeviceIntentionallyEmittingErrorEvent;
    case media::VideoCaptureError::kDeviceClientTooManyFramesDroppedY16:
      return media::mojom::VideoCaptureError::
          kDeviceClientTooManyFramesDroppedY16;
    case media::VideoCaptureError::
        kDeviceMediaToMojoAdapterEncounteredUnsupportedBufferType:
      return media::mojom::VideoCaptureError::
          kDeviceMediaToMojoAdapterEncounteredUnsupportedBufferType;
    case media::VideoCaptureError::
        kVideoCaptureManagerProcessDeviceStartQueueDeviceInfoNotFound:
      return media::mojom::VideoCaptureError::
          kVideoCaptureManagerProcessDeviceStartQueueDeviceInfoNotFound;
    case media::VideoCaptureError::
        kInProcessDeviceLauncherFailedToCreateDeviceInstance:
      return media::mojom::VideoCaptureError::
          kInProcessDeviceLauncherFailedToCreateDeviceInstance;
    case media::VideoCaptureError::
        kServiceDeviceLauncherLostConnectionToDeviceFactoryDuringDeviceStart:
      return media::mojom::VideoCaptureError::
          kServiceDeviceLauncherLostConnectionToDeviceFactoryDuringDeviceStart;
    case media::VideoCaptureError::
        kServiceDeviceLauncherServiceRespondedWithDeviceNotFound:
      return media::mojom::VideoCaptureError::
          kServiceDeviceLauncherServiceRespondedWithDeviceNotFound;
    case media::VideoCaptureError::
        kServiceDeviceLauncherConnectionLostWhileWaitingForCallback:
      return media::mojom::VideoCaptureError::
          kServiceDeviceLauncherConnectionLostWhileWaitingForCallback;
    case media::VideoCaptureError::kIntentionalErrorRaisedByUnitTest:
      return media::mojom::VideoCaptureError::kIntentionalErrorRaisedByUnitTest;
    case media::VideoCaptureError::kCrosHalV3FailedToStartDeviceThread:
      return media::mojom::VideoCaptureError::
          kCrosHalV3FailedToStartDeviceThread;
    case media::VideoCaptureError::kCrosHalV3DeviceDelegateMojoConnectionError:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateMojoConnectionError;
    case media::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToGetCameraInfo:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToGetCameraInfo;
    case media::VideoCaptureError::
        kCrosHalV3DeviceDelegateMissingSensorOrientationInfo:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateMissingSensorOrientationInfo;
    case media::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToOpenCameraDevice:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToOpenCameraDevice;
    case media::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToInitializeCameraDevice:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToInitializeCameraDevice;
    case media::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToConfigureStreams:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToConfigureStreams;
    case media::VideoCaptureError::
        kCrosHalV3DeviceDelegateWrongNumberOfStreamsConfigured:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateWrongNumberOfStreamsConfigured;
    case media::VideoCaptureError::
        kCrosHalV3DeviceDelegateFailedToGetDefaultRequestSettings:
      return media::mojom::VideoCaptureError::
          kCrosHalV3DeviceDelegateFailedToGetDefaultRequestSettings;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerHalRequestedTooManyBuffers:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerHalRequestedTooManyBuffers;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToCreateGpuMemoryBuffer:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToCreateGpuMemoryBuffer;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToMapGpuMemoryBuffer:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToMapGpuMemoryBuffer;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerUnsupportedVideoPixelFormat:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerUnsupportedVideoPixelFormat;
    case media::VideoCaptureError::kCrosHalV3BufferManagerFailedToDupFd:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToDupFd;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToWrapGpuMemoryHandle:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToWrapGpuMemoryHandle;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToRegisterBuffer:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToRegisterBuffer;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerProcessCaptureRequestFailed:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerProcessCaptureRequestFailed;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerInvalidPendingResultId:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerInvalidPendingResultId;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerReceivedDuplicatedPartialMetadata:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerReceivedDuplicatedPartialMetadata;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerIncorrectNumberOfOutputBuffersReceived:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerIncorrectNumberOfOutputBuffersReceived;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerInvalidTypeOfOutputBuffersReceived:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerInvalidTypeOfOutputBuffersReceived;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerReceivedMultipleResultBuffersForFrame:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerReceivedMultipleResultBuffersForFrame;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerUnknownStreamInCamera3NotifyMsg:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerUnknownStreamInCamera3NotifyMsg;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerReceivedInvalidShutterTime:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerReceivedInvalidShutterTime;
    case media::VideoCaptureError::kCrosHalV3BufferManagerFatalDeviceError:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerFatalDeviceError;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerReceivedFrameIsOutOfOrder:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerReceivedFrameIsOutOfOrder;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerFailedToUnwrapReleaseFenceFd:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerFailedToUnwrapReleaseFenceFd;
    case media::VideoCaptureError::
        kCrosHalV3BufferManagerSyncWaitOnReleaseFenceTimedOut:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerSyncWaitOnReleaseFenceTimedOut;
    case media::VideoCaptureError::kCrosHalV3BufferManagerInvalidJpegBlob:
      return media::mojom::VideoCaptureError::
          kCrosHalV3BufferManagerInvalidJpegBlob;
    case media::VideoCaptureError::kAndroidFailedToAllocate:
      return media::mojom::VideoCaptureError::kAndroidFailedToAllocate;
    case media::VideoCaptureError::kAndroidFailedToStartCapture:
      return media::mojom::VideoCaptureError::kAndroidFailedToStartCapture;
    case media::VideoCaptureError::kAndroidFailedToStopCapture:
      return media::mojom::VideoCaptureError::kAndroidFailedToStopCapture;
    case media::VideoCaptureError::kAndroidApi1CameraErrorCallbackReceived:
      return media::mojom::VideoCaptureError::
          kAndroidApi1CameraErrorCallbackReceived;
    case media::VideoCaptureError::kAndroidApi2CameraDeviceErrorReceived:
      return media::mojom::VideoCaptureError::
          kAndroidApi2CameraDeviceErrorReceived;
    case media::VideoCaptureError::kAndroidApi2CaptureSessionConfigureFailed:
      return media::mojom::VideoCaptureError::
          kAndroidApi2CaptureSessionConfigureFailed;
    case media::VideoCaptureError::kAndroidApi2ImageReaderUnexpectedImageFormat:
      return media::mojom::VideoCaptureError::
          kAndroidApi2ImageReaderUnexpectedImageFormat;
    case media::VideoCaptureError::
        kAndroidApi2ImageReaderSizeDidNotMatchImageSize:
      return media::mojom::VideoCaptureError::
          kAndroidApi2ImageReaderSizeDidNotMatchImageSize;
    case media::VideoCaptureError::kAndroidApi2ErrorRestartingPreview:
      return media::mojom::VideoCaptureError::
          kAndroidApi2ErrorRestartingPreview;
    case media::VideoCaptureError::kAndroidScreenCaptureUnsupportedFormat:
      return media::mojom::VideoCaptureError::
          kAndroidScreenCaptureUnsupportedFormat;
    case media::VideoCaptureError::
        kAndroidScreenCaptureFailedToStartCaptureMachine:
      return media::mojom::VideoCaptureError::
          kAndroidScreenCaptureFailedToStartCaptureMachine;
    case media::VideoCaptureError::
        kAndroidScreenCaptureTheUserDeniedScreenCapture:
      return media::mojom::VideoCaptureError::
          kAndroidScreenCaptureTheUserDeniedScreenCapture;
    case media::VideoCaptureError::
        kAndroidScreenCaptureFailedToStartScreenCapture:
      return media::mojom::VideoCaptureError::
          kAndroidScreenCaptureFailedToStartScreenCapture;
    case media::VideoCaptureError::kWinDirectShowCantGetCaptureFormatSettings:
      return media::mojom::VideoCaptureError::
          kWinDirectShowCantGetCaptureFormatSettings;
    case media::VideoCaptureError::
        kWinDirectShowFailedToGetNumberOfCapabilities:
      return media::mojom::VideoCaptureError::
          kWinDirectShowFailedToGetNumberOfCapabilities;
    case media::VideoCaptureError::
        kWinDirectShowFailedToGetCaptureDeviceCapabilities:
      return media::mojom::VideoCaptureError::
          kWinDirectShowFailedToGetCaptureDeviceCapabilities;
    case media::VideoCaptureError::
        kWinDirectShowFailedToSetCaptureDeviceOutputFormat:
      return media::mojom::VideoCaptureError::
          kWinDirectShowFailedToSetCaptureDeviceOutputFormat;
    case media::VideoCaptureError::kWinDirectShowFailedToConnectTheCaptureGraph:
      return media::mojom::VideoCaptureError::
          kWinDirectShowFailedToConnectTheCaptureGraph;
    case media::VideoCaptureError::kWinDirectShowFailedToPauseTheCaptureDevice:
      return media::mojom::VideoCaptureError::
          kWinDirectShowFailedToPauseTheCaptureDevice;
    case media::VideoCaptureError::kWinDirectShowFailedToStartTheCaptureDevice:
      return media::mojom::VideoCaptureError::
          kWinDirectShowFailedToStartTheCaptureDevice;
    case media::VideoCaptureError::kWinDirectShowFailedToStopTheCaptureGraph:
      return media::mojom::VideoCaptureError::
          kWinDirectShowFailedToStopTheCaptureGraph;
    case media::VideoCaptureError::kWinMediaFoundationEngineIsNull:
      return media::mojom::VideoCaptureError::kWinMediaFoundationEngineIsNull;
    case media::VideoCaptureError::kWinMediaFoundationEngineGetSourceFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationEngineGetSourceFailed;
    case media::VideoCaptureError::
        kWinMediaFoundationFillPhotoCapabilitiesFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationFillPhotoCapabilitiesFailed;
    case media::VideoCaptureError::
        kWinMediaFoundationFillVideoCapabilitiesFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationFillVideoCapabilitiesFailed;
    case media::VideoCaptureError::kWinMediaFoundationNoVideoCapabilityFound:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationNoVideoCapabilityFound;
    case media::VideoCaptureError::
        kWinMediaFoundationGetAvailableDeviceMediaTypeFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationGetAvailableDeviceMediaTypeFailed;
    case media::VideoCaptureError::
        kWinMediaFoundationSetCurrentDeviceMediaTypeFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationSetCurrentDeviceMediaTypeFailed;
    case media::VideoCaptureError::kWinMediaFoundationEngineGetSinkFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationEngineGetSinkFailed;
    case media::VideoCaptureError::
        kWinMediaFoundationSinkQueryCapturePreviewInterfaceFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationSinkQueryCapturePreviewInterfaceFailed;
    case media::VideoCaptureError::
        kWinMediaFoundationSinkRemoveAllStreamsFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationSinkRemoveAllStreamsFailed;
    case media::VideoCaptureError::
        kWinMediaFoundationCreateSinkVideoMediaTypeFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationCreateSinkVideoMediaTypeFailed;
    case media::VideoCaptureError::
        kWinMediaFoundationConvertToVideoSinkMediaTypeFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationConvertToVideoSinkMediaTypeFailed;
    case media::VideoCaptureError::kWinMediaFoundationSinkAddStreamFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationSinkAddStreamFailed;
    case media::VideoCaptureError::
        kWinMediaFoundationSinkSetSampleCallbackFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationSinkSetSampleCallbackFailed;
    case media::VideoCaptureError::kWinMediaFoundationEngineStartPreviewFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationEngineStartPreviewFailed;
    case media::VideoCaptureError::kWinMediaFoundationGetMediaEventStatusFailed:
      return media::mojom::VideoCaptureError::
          kWinMediaFoundationGetMediaEventStatusFailed;
    case media::VideoCaptureError::kMacSetCaptureDeviceFailed:
      return media::mojom::VideoCaptureError::kMacSetCaptureDeviceFailed;
    case media::VideoCaptureError::kMacCouldNotStartCaptureDevice:
      return media::mojom::VideoCaptureError::kMacCouldNotStartCaptureDevice;
    case media::VideoCaptureError::kMacReceivedFrameWithUnexpectedResolution:
      return media::mojom::VideoCaptureError::
          kMacReceivedFrameWithUnexpectedResolution;
    case media::VideoCaptureError::kMacUpdateCaptureResolutionFailed:
      return media::mojom::VideoCaptureError::kMacUpdateCaptureResolutionFailed;
    case media::VideoCaptureError::kMacDeckLinkDeviceIdNotFoundInTheSystem:
      return media::mojom::VideoCaptureError::
          kMacDeckLinkDeviceIdNotFoundInTheSystem;
    case media::VideoCaptureError::kMacDeckLinkErrorQueryingInputInterface:
      return media::mojom::VideoCaptureError::
          kMacDeckLinkErrorQueryingInputInterface;
    case media::VideoCaptureError::kMacDeckLinkErrorCreatingDisplayModeIterator:
      return media::mojom::VideoCaptureError::
          kMacDeckLinkErrorCreatingDisplayModeIterator;
    case media::VideoCaptureError::kMacDeckLinkCouldNotFindADisplayMode:
      return media::mojom::VideoCaptureError::
          kMacDeckLinkCouldNotFindADisplayMode;
    case media::VideoCaptureError::
        kMacDeckLinkCouldNotSelectTheVideoFormatWeLike:
      return media::mojom::VideoCaptureError::
          kMacDeckLinkCouldNotSelectTheVideoFormatWeLike;
    case media::VideoCaptureError::kMacDeckLinkCouldNotStartCapturing:
      return media::mojom::VideoCaptureError::
          kMacDeckLinkCouldNotStartCapturing;
    case media::VideoCaptureError::kMacDeckLinkUnsupportedPixelFormat:
      return media::mojom::VideoCaptureError::
          kMacDeckLinkUnsupportedPixelFormat;
    case media::VideoCaptureError::
        kMacAvFoundationReceivedAVCaptureSessionRuntimeErrorNotification:
      return media::mojom::VideoCaptureError::
          kMacAvFoundationReceivedAVCaptureSessionRuntimeErrorNotification;
     case media::VideoCaptureError::kAndroidApi2ErrorConfiguringCamera:
       return media::mojom::VideoCaptureError::
           kAndroidApi2ErrorConfiguringCamera;
//flaw_line_below:
    case media::VideoCaptureError::kCrosHalV3DeviceDelegateFailedToFlush:
//flaw_line_below:
      return media::mojom::VideoCaptureError::
//flaw_line_below:
          kCrosHalV3DeviceDelegateFailedToFlush;
   }
   NOTREACHED();
   return media::mojom::VideoCaptureError::kNone;
}
"
8778,186514,,Remote,Not required,,CVE-2016-5225,https://www.cvedetails.com/cve/CVE-2016-5225/,CWE-19,Medium,,Partial,,2017-01-19,4.3,"Blink in Google Chrome prior to 55.0.2883.75 for Mac, Windows and Linux, and 55.0.2883.84 for Android incorrectly handled form actions, which allowed a remote attacker to bypass Content Security Policy via a crafted HTML page.",2018-01-04,Bypass ,5,https://github.com/chromium/chromium/commit/4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0,4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0,"Enforce form-action CSP even when form.target is present.

BUG=630332

Review-Url: https://codereview.chromium.org/2464123004
Cr-Commit-Position: refs/heads/master@{#429922}",3,third_party/WebKit/Source/core/html/HTMLFormElement.cpp,"{""sha"": ""7b22df1678c243254c0861227ada90d0d291a7c6"", ""filename"": ""third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-blocked-when-target-blank-expected.txt"", ""status"": ""added"", ""additions"": 13, ""deletions"": 0, ""changes"": 13, ""blob_url"": ""https://github.com/chromium/chromium/blob/4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0/third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-blocked-when-target-blank-expected.txt"", ""raw_url"": ""https://github.com/chromium/chromium/raw/4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0/third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-blocked-when-target-blank-expected.txt"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-blocked-when-target-blank-expected.txt?ref=4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0"", ""patch"": ""@@ -0,0 +1,13 @@\n+CONSOLE MESSAGE: line 15: submit event fired.\n+CONSOLE ERROR: line 19: Refused to send form data to 'http://127.0.0.1:8000/navigation/resources/form-target.pl' because it violates the following Content Security Policy directive: \""form-action 'none'\"".\n+\n+CONSOLE MESSAGE: line 24: securitypolicyviolation event fired.\n+CONSOLE MESSAGE: line 25: securitypolicyviolation_event.documentURI=http://127.0.0.1:8000/security/contentSecurityPolicy/1.1/form-action-blocked-when-target-blank.html\n+CONSOLE MESSAGE: line 26: securitypolicyviolation_event.blockedURI=http://127.0.0.1:8000/navigation/resources/form-target.pl\n+CONSOLE MESSAGE: line 27: securitypolicyviolation_event.violatedDirective=form-action\n+  \n+Tests that blocking form actions works correctly. If this test passes, you will see a console error, and will not see a page indicating a form was POSTed.\n+\n+============== Back Forward List ==============\n+curr->  http://127.0.0.1:8000/security/contentSecurityPolicy/1.1/form-action-blocked-when-target-blank.html\n+===============================================""}<_**next**_>{""sha"": ""09103f5b1998e37db283dc7e0ddd65e98cab7ef4"", ""filename"": ""third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-blocked-when-target-blank.html"", ""status"": ""added"", ""additions"": 43, ""deletions"": 0, ""changes"": 43, ""blob_url"": ""https://github.com/chromium/chromium/blob/4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0/third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-blocked-when-target-blank.html"", ""raw_url"": ""https://github.com/chromium/chromium/raw/4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0/third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-blocked-when-target-blank.html"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-blocked-when-target-blank.html?ref=4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0"", ""patch"": ""@@ -0,0 +1,43 @@\n+<!DOCTYPE html>\n+<html>\n+<head>\n+<meta http-equiv=\""Content-Security-Policy\"" content=\""form-action 'none'\"">\n+<script>\n+    if (window.testRunner) {\n+        testRunner.dumpAsText();\n+        testRunner.waitUntilDone();\n+        testRunner.clearBackForwardList();\n+        testRunner.dumpBackForwardList();\n+    }\n+\n+    window.addEventListener('load', function() {\n+        document.getElementById('theform').addEventListener('submit', function(e) {\n+            console.log('submit event fired.');\n+        });\n+\n+        setTimeout(function() {\n+            document.getElementById('submit').click();\n+        }, 0);\n+    });\n+\n+    document.addEventListener('securitypolicyviolation', function(e) {\n+        console.log('securitypolicyviolation event fired.');\n+        console.log('securitypolicyviolation_event.documentURI=' + e.documentURI);\n+        console.log('securitypolicyviolation_event.blockedURI=' + e.blockedURI);\n+        console.log('securitypolicyviolation_event.violatedDirective=' + e.violatedDirective);\n+        setTimeout(function() {\n+            testRunner.notifyDone();\n+        }, 0);\n+    });\n+</script>\n+</head>\n+<body>\n+    <form action='/navigation/resources/form-target.pl' id='theform'\n+          method='post' target=\""_blank\"">\n+        <input type='text' name='fieldname' value='fieldvalue'>\n+        <input type='submit' id='submit' value='submit'>\n+    </form>\n+\n+    <p>Tests that blocking form actions works correctly. If this test passes, you will see a console error, and will not see a page indicating a form was POSTed.</p>\n+</body>\n+</html>""}<_**next**_>{""sha"": ""957bce5a723faa41fc0fdc7e63df512af9713125"", ""filename"": ""third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-blocked-when-target-cross-site-window-expected.txt"", ""status"": ""added"", ""additions"": 9, ""deletions"": 0, ""changes"": 9, ""blob_url"": ""https://github.com/chromium/chromium/blob/4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0/third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-blocked-when-target-cross-site-window-expected.txt"", ""raw_url"": ""https://github.com/chromium/chromium/raw/4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0/third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-blocked-when-target-cross-site-window-expected.txt"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-blocked-when-target-cross-site-window-expected.txt?ref=4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0"", ""patch"": ""@@ -0,0 +1,9 @@\n+CONSOLE MESSAGE: line 19: submit event fired.\n+CONSOLE ERROR: line 23: Refused to send form data to 'http://127.0.0.1:8000/navigation/resources/form-target.pl' because it violates the following Content Security Policy directive: \""form-action 'none'\"".\n+\n+CONSOLE MESSAGE: line 28: securitypolicyviolation event fired.\n+CONSOLE MESSAGE: line 29: securitypolicyviolation_event.documentURI=http://127.0.0.1:8000/security/contentSecurityPolicy/1.1/form-action-blocked-when-target-cross-site-window.html\n+CONSOLE MESSAGE: line 30: securitypolicyviolation_event.blockedURI=http://127.0.0.1:8000/navigation/resources/form-target.pl\n+CONSOLE MESSAGE: line 31: securitypolicyviolation_event.violatedDirective=form-action\n+  \n+Tests that blocking form actions works correctly. If this test passes, you will see a console error, and will not see a page indicating a form was POSTed.""}<_**next**_>{""sha"": ""1b2dfe864fc8a1e7c62859fbeb70e6abed963f9e"", ""filename"": ""third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-blocked-when-target-cross-site-window.html"", ""status"": ""added"", ""additions"": 47, ""deletions"": 0, ""changes"": 47, ""blob_url"": ""https://github.com/chromium/chromium/blob/4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0/third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-blocked-when-target-cross-site-window.html"", ""raw_url"": ""https://github.com/chromium/chromium/raw/4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0/third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-blocked-when-target-cross-site-window.html"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-blocked-when-target-cross-site-window.html?ref=4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0"", ""patch"": ""@@ -0,0 +1,47 @@\n+<!DOCTYPE html>\n+<html>\n+<head>\n+<meta http-equiv=\""Content-Security-Policy\"" content=\""form-action 'none'\"">\n+<script>\n+    if (window.testRunner) {\n+        testRunner.dumpAsText();\n+        testRunner.waitUntilDone();\n+        testRunner.setCanOpenWindows();\n+    }\n+\n+    // Open a new window with the name matching form.target attribute below.\n+    window.open(\n+        'http://localhost:8080/security/resources/empty.html',\n+        'namedCrossSiteWindow')\n+\n+    window.addEventListener('load', function() {\n+        document.getElementById('theform').addEventListener('submit', function(e) {\n+            console.log('submit event fired.');\n+        });\n+\n+        setTimeout(function() {\n+            document.getElementById('submit').click();\n+        }, 0);\n+    });\n+\n+    document.addEventListener('securitypolicyviolation', function(e) {\n+        console.log('securitypolicyviolation event fired.');\n+        console.log('securitypolicyviolation_event.documentURI=' + e.documentURI);\n+        console.log('securitypolicyviolation_event.blockedURI=' + e.blockedURI);\n+        console.log('securitypolicyviolation_event.violatedDirective=' + e.violatedDirective);\n+        setTimeout(function() {\n+            testRunner.notifyDone();\n+        }, 0);\n+    });\n+</script>\n+</head>\n+<body>\n+    <form action='/navigation/resources/form-target.pl' id='theform'\n+          method='post' target=\""namedCrossSiteWindow\"">\n+        <input type='text' name='fieldname' value='fieldvalue'>\n+        <input type='submit' id='submit' value='submit'>\n+    </form>\n+\n+    <p>Tests that blocking form actions works correctly. If this test passes, you will see a console error, and will not see a page indicating a form was POSTed.</p>\n+</body>\n+</html>""}<_**next**_>{""sha"": ""9e95b5d927f352e51d6925bc3620a776f35d3787"", ""filename"": ""third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-src-blocked-expected.txt"", ""status"": ""modified"", ""additions"": 6, ""deletions"": 1, ""changes"": 7, ""blob_url"": ""https://github.com/chromium/chromium/blob/4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0/third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-src-blocked-expected.txt"", ""raw_url"": ""https://github.com/chromium/chromium/raw/4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0/third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-src-blocked-expected.txt"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-src-blocked-expected.txt?ref=4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0"", ""patch"": ""@@ -1,5 +1,10 @@\n-CONSOLE ERROR: Refused to send form data to 'http://127.0.0.1:8000/navigation/resources/form-target.pl' because it violates the following Content Security Policy directive: \""form-action 'none'\"".\n+CONSOLE MESSAGE: line 15: submit event fired.\n+CONSOLE ERROR: line 19: Refused to send form data to 'http://127.0.0.1:8000/navigation/resources/form-target.pl' because it violates the following Content Security Policy directive: \""form-action 'none'\"".\n \n+CONSOLE MESSAGE: line 24: securitypolicyviolation event fired.\n+CONSOLE MESSAGE: line 25: securitypolicyviolation_event.documentURI=http://127.0.0.1:8000/security/contentSecurityPolicy/1.1/form-action-src-blocked.html\n+CONSOLE MESSAGE: line 26: securitypolicyviolation_event.blockedURI=http://127.0.0.1:8000/navigation/resources/form-target.pl\n+CONSOLE MESSAGE: line 27: securitypolicyviolation_event.violatedDirective=form-action\n   \n Tests that blocking form actions works correctly. If this test passes, you will see a console error, and will not see a page indicating a form was POSTed.\n ""}<_**next**_>{""sha"": ""b5bc0a3f413e1e946148975be530dccdfaf946d0"", ""filename"": ""third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-src-blocked.html"", ""status"": ""modified"", ""additions"": 15, ""deletions"": 3, ""changes"": 18, ""blob_url"": ""https://github.com/chromium/chromium/blob/4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0/third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-src-blocked.html"", ""raw_url"": ""https://github.com/chromium/chromium/raw/4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0/third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-src-blocked.html"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-src-blocked.html?ref=4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0"", ""patch"": ""@@ -9,14 +9,26 @@\n         testRunner.clearBackForwardList();\n         testRunner.dumpBackForwardList();\n     }\n+\n     window.addEventListener('load', function() {\n+        document.getElementById('theform').addEventListener('submit', function(e) {\n+            console.log('submit event fired.');\n+        });\n+\n         setTimeout(function() {\n             document.getElementById('submit').click();\n         }, 0);\n     });\n-    setTimeout(function () {\n-        testRunner.notifyDone();\n-    }, 1000);\n+\n+    document.addEventListener('securitypolicyviolation', function(e) {\n+        console.log('securitypolicyviolation event fired.');\n+        console.log('securitypolicyviolation_event.documentURI=' + e.documentURI);\n+        console.log('securitypolicyviolation_event.blockedURI=' + e.blockedURI);\n+        console.log('securitypolicyviolation_event.violatedDirective=' + e.violatedDirective);\n+        setTimeout(function() {\n+            testRunner.notifyDone();\n+        }, 0);\n+    });\n </script>\n </head>\n <body>""}<_**next**_>{""sha"": ""5f482cf28e871163391b21a85761662b42fb5c6a"", ""filename"": ""third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-src-get-blocked-expected.txt"", ""status"": ""modified"", ""additions"": 1, ""deletions"": 1, ""changes"": 2, ""blob_url"": ""https://github.com/chromium/chromium/blob/4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0/third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-src-get-blocked-expected.txt"", ""raw_url"": ""https://github.com/chromium/chromium/raw/4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0/third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-src-get-blocked-expected.txt"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/third_party/WebKit/LayoutTests/http/tests/security/contentSecurityPolicy/1.1/form-action-src-get-blocked-expected.txt?ref=4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0"", ""patch"": ""@@ -1,4 +1,4 @@\n-CONSOLE ERROR: Refused to send form data to 'http://127.0.0.1:8000/navigation/resources/form-target.pl?fieldname=fieldvalue' because it violates the following Content Security Policy directive: \""form-action 'none'\"".\n+CONSOLE ERROR: line 16: Refused to send form data to 'http://127.0.0.1:8000/navigation/resources/form-target.pl' because it violates the following Content Security Policy directive: \""form-action 'none'\"".\n \n   \n Tests that blocking form actions works correctly. If this test passes, you will see a console error, and will not see a page indicating a form was POSTed.""}<_**next**_>{""sha"": ""746f318784c9fbb967c94848593369c6cba6ce64"", ""filename"": ""third_party/WebKit/Source/core/html/HTMLFormElement.cpp"", ""status"": ""modified"", ""additions"": 5, ""deletions"": 3, ""changes"": 8, ""blob_url"": ""https://github.com/chromium/chromium/blob/4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0/third_party/WebKit/Source/core/html/HTMLFormElement.cpp"", ""raw_url"": ""https://github.com/chromium/chromium/raw/4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0/third_party/WebKit/Source/core/html/HTMLFormElement.cpp"", ""contents_url"": ""https://api.github.com/repos/chromium/chromium/contents/third_party/WebKit/Source/core/html/HTMLFormElement.cpp?ref=4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0"", ""patch"": ""@@ -416,10 +416,12 @@ void HTMLFormElement::scheduleFormSubmission(FormSubmission* submission) {\n     return;\n   }\n \n+  if (!document().contentSecurityPolicy()->allowFormAction(\n+          submission->action())) {\n+    return;\n+  }\n+\n   if (protocolIsJavaScript(submission->action())) {\n-    if (!document().contentSecurityPolicy()->allowFormAction(\n-            submission->action()))\n-      return;\n     document().frame()->script().executeScriptIfJavaScriptURL(\n         submission->action(), this);\n     return;""}","void HTMLFormElement::scheduleFormSubmission(FormSubmission* submission) {
  DCHECK(submission->method() == FormSubmission::PostMethod ||
         submission->method() == FormSubmission::GetMethod);
  DCHECK(submission->data());
  DCHECK(submission->form());
  if (submission->action().isEmpty())
    return;
  if (document().isSandboxed(SandboxForms)) {
    document().addConsoleMessage(ConsoleMessage::create(
        SecurityMessageSource, ErrorMessageLevel,
        ""Blocked form submission to '"" + submission->action().elidedString() +
            ""' because the form's frame is sandboxed and the 'allow-forms' ""
            ""permission is not set.""));
     return;
   }
 
  if (!document().contentSecurityPolicy()->allowFormAction(
          submission->action())) {
    return;
  }

   if (protocolIsJavaScript(submission->action())) {
     document().frame()->script().executeScriptIfJavaScriptURL(
         submission->action(), this);
     return;
  }

  Frame* targetFrame = document().frame()->findFrameForNavigation(
      submission->target(), *document().frame());
  if (!targetFrame) {
    if (!LocalDOMWindow::allowPopUp(*document().frame()) &&
        !UserGestureIndicator::utilizeUserGesture())
      return;
    targetFrame = document().frame();
  } else {
    submission->clearTarget();
  }
  if (!targetFrame->host())
    return;

  UseCounter::count(document(), UseCounter::FormsSubmitted);
  if (MixedContentChecker::isMixedFormAction(document().frame(),
                                             submission->action()))
    UseCounter::count(document().frame(),
                      UseCounter::MixedContentFormsSubmitted);

  if (targetFrame->isLocalFrame()) {
    toLocalFrame(targetFrame)
        ->navigationScheduler()
        .scheduleFormSubmission(&document(), submission);
  } else {
    FrameLoadRequest frameLoadRequest =
        submission->createFrameLoadRequest(&document());
    toRemoteFrame(targetFrame)->navigate(frameLoadRequest);
  }
}
","void HTMLFormElement::scheduleFormSubmission(FormSubmission* submission) {
  DCHECK(submission->method() == FormSubmission::PostMethod ||
         submission->method() == FormSubmission::GetMethod);
  DCHECK(submission->data());
  DCHECK(submission->form());
  if (submission->action().isEmpty())
    return;
  if (document().isSandboxed(SandboxForms)) {
    document().addConsoleMessage(ConsoleMessage::create(
        SecurityMessageSource, ErrorMessageLevel,
        ""Blocked form submission to '"" + submission->action().elidedString() +
            ""' because the form's frame is sandboxed and the 'allow-forms' ""
            ""permission is not set.""));
     return;
   }
 
   if (protocolIsJavaScript(submission->action())) {
    if (!document().contentSecurityPolicy()->allowFormAction(
            submission->action()))
      return;
     document().frame()->script().executeScriptIfJavaScriptURL(
         submission->action(), this);
     return;
  }

  Frame* targetFrame = document().frame()->findFrameForNavigation(
      submission->target(), *document().frame());
  if (!targetFrame) {
    if (!LocalDOMWindow::allowPopUp(*document().frame()) &&
        !UserGestureIndicator::utilizeUserGesture())
      return;
    targetFrame = document().frame();
  } else {
    submission->clearTarget();
  }
  if (!targetFrame->host())
    return;

  UseCounter::count(document(), UseCounter::FormsSubmitted);
  if (MixedContentChecker::isMixedFormAction(document().frame(),
                                             submission->action()))
    UseCounter::count(document().frame(),
                      UseCounter::MixedContentFormsSubmitted);

  if (targetFrame->isLocalFrame()) {
    toLocalFrame(targetFrame)
        ->navigationScheduler()
        .scheduleFormSubmission(&document(), submission);
  } else {
    FrameLoadRequest frameLoadRequest =
        submission->createFrameLoadRequest(&document());
    toRemoteFrame(targetFrame)->navigate(frameLoadRequest);
  }
}
",C,"  if (!document().contentSecurityPolicy()->allowFormAction(
          submission->action())) {
    return;
  }

","    if (!document().contentSecurityPolicy()->allowFormAction(
            submission->action()))
      return;
",,"@@ -416,10 +416,12 @@ void HTMLFormElement::scheduleFormSubmission(FormSubmission* submission) {
     return;
   }
 
+  if (!document().contentSecurityPolicy()->allowFormAction(
+          submission->action())) {
+    return;
+  }
+
   if (protocolIsJavaScript(submission->action())) {
-    if (!document().contentSecurityPolicy()->allowFormAction(
-            submission->action()))
-      return;
     document().frame()->script().executeScriptIfJavaScriptURL(
         submission->action(), this);
     return;",Chrome,4ac4aff49c4c539bce6d8a0d8800c01324bb6bc0,2ad79b35d6c1a054c1f38681deff659cd2f3b00d,1,"void HTMLFormElement::scheduleFormSubmission(FormSubmission* submission) {
  DCHECK(submission->method() == FormSubmission::PostMethod ||
         submission->method() == FormSubmission::GetMethod);
  DCHECK(submission->data());
  DCHECK(submission->form());
  if (submission->action().isEmpty())
    return;
  if (document().isSandboxed(SandboxForms)) {
    // FIXME: This message should be moved off the console once a solution to
    // https://bugs.webkit.org/show_bug.cgi?id=103274 exists.
    document().addConsoleMessage(ConsoleMessage::create(
        SecurityMessageSource, ErrorMessageLevel,
        ""Blocked form submission to '"" + submission->action().elidedString() +
            ""' because the form's frame is sandboxed and the 'allow-forms' ""
            ""permission is not set.""));
     return;
   }
 
//fix_flaw_line_below:
//  if (!document().contentSecurityPolicy()->allowFormAction(
//fix_flaw_line_below:
//          submission->action())) {
//fix_flaw_line_below:
//    return;
//fix_flaw_line_below:
//  }
//fix_flaw_line_below:
//
   if (protocolIsJavaScript(submission->action())) {
//flaw_line_below:
    if (!document().contentSecurityPolicy()->allowFormAction(
//flaw_line_below:
            submission->action()))
//flaw_line_below:
      return;
     document().frame()->script().executeScriptIfJavaScriptURL(
         submission->action(), this);
     return;
  }

  Frame* targetFrame = document().frame()->findFrameForNavigation(
      submission->target(), *document().frame());
  if (!targetFrame) {
    if (!LocalDOMWindow::allowPopUp(*document().frame()) &&
        !UserGestureIndicator::utilizeUserGesture())
      return;
    targetFrame = document().frame();
  } else {
    submission->clearTarget();
  }
  if (!targetFrame->host())
    return;

  UseCounter::count(document(), UseCounter::FormsSubmitted);
  if (MixedContentChecker::isMixedFormAction(document().frame(),
                                             submission->action()))
    UseCounter::count(document().frame(),
                      UseCounter::MixedContentFormsSubmitted);

  // TODO(lukasza): Investigate if the code below can uniformly handle remote
  // and local frames (i.e. by calling virtual Frame::navigate from a timer).
  // See also https://goo.gl/95d2KA.
  if (targetFrame->isLocalFrame()) {
    toLocalFrame(targetFrame)
        ->navigationScheduler()
        .scheduleFormSubmission(&document(), submission);
  } else {
    FrameLoadRequest frameLoadRequest =
        submission->createFrameLoadRequest(&document());
    toRemoteFrame(targetFrame)->navigate(frameLoadRequest);
  }
}
"
10251,187987,,Local,Not required,Complete,CVE-2016-0808,https://www.cvedetails.com/cve/CVE-2016-0808/,CWE-19,Low,,,,2016-02-06,4.9,"Integer overflow in the getCoverageFormat12 function in CmapCoverage.cpp in the Minikin library in Android 5.x before 5.1.1 LMY49G and 6.x before 2016-02-01 allows attackers to cause a denial of service (continuous rebooting) via an application that triggers loading of a crafted TTF font, aka internal bug 25645298.",2016-03-14,DoS Overflow ,3,https://android.googlesource.com/platform/frameworks/minikin/+/ed4c8d79153baab7f26562afb8930652dfbf853b,ed4c8d79153baab7f26562afb8930652dfbf853b,"Avoid integer overflows in parsing fonts

A malformed TTF can cause size calculations to overflow. This patch
checks the maximum reasonable value so that the total size fits in 32
bits. It also adds some explicit casting to avoid possible technical
undefined behavior when parsing sized unsigned values.

Bug: 25645298
Change-Id: Id4716132041a6f4f1fbb73ec4e445391cf7d9616
(cherry picked from commit 183c9ec2800baa2ce099ee260c6cbc6121cf1274)
",1,libs/minikin/CmapCoverage.cpp,"{""filename"": ""libs/minikin/CmapCoverage.cpp"", ""raw_url"": ""https://android.googlesource.com/platform/frameworks/minikin/+/ed4c8d79153baab7f26562afb8930652dfbf853b/libs/minikin/CmapCoverage.cpp"", ""patch"": ""@@ -29,11 +29,12 @@\n\n \n // These could perhaps be optimized to use __builtin_bswap16 and friends.\n static uint32_t readU16(const uint8_t* data, size_t offset) {\n-    return data[offset] << 8 | data[offset + 1];\n+    return ((uint32_t)data[offset]) << 8 | ((uint32_t)data[offset + 1]);\n }\n \n static uint32_t readU32(const uint8_t* data, size_t offset) {\n-    return data[offset] << 24 | data[offset + 1] << 16 | data[offset + 2] << 8 | data[offset + 3];\n+    return ((uint32_t)data[offset]) << 24 | ((uint32_t)data[offset + 1]) << 16 |\n+        ((uint32_t)data[offset + 2]) << 8 | ((uint32_t)data[offset + 3]);\n }\n \n static void addRange(vector<uint32_t> &coverage, uint32_t start, uint32_t end) {\n@@ -101,11 +102,13 @@\n\n     const size_t kGroupSize = 12;\n     const size_t kStartCharCodeOffset = 0;\n     const size_t kEndCharCodeOffset = 4;\n+    const size_t kMaxNGroups = 0xfffffff0 / kGroupSize;  // protection against overflow\n+    // For all values < kMaxNGroups, kFirstGroupOffset + nGroups * kGroupSize fits in 32 bits.\n     if (kFirstGroupOffset > size) {\n         return false;\n     }\n     uint32_t nGroups = readU32(data, kNGroupsOffset);\n-    if (kFirstGroupOffset + nGroups * kGroupSize > size) {\n+    if (nGroups >= kMaxNGroups || kFirstGroupOffset + nGroups * kGroupSize > size) {\n         return false;\n     }\n     for (uint32_t i = 0; i < nGroups; i++) {\n""}","static bool getCoverageFormat12(vector<uint32_t>& coverage, const uint8_t* data, size_t size) {
 const size_t kNGroupsOffset = 12;
 const size_t kFirstGroupOffset = 16;

     const size_t kGroupSize = 12;
     const size_t kStartCharCodeOffset = 0;
     const size_t kEndCharCodeOffset = 4;
    const size_t kMaxNGroups = 0xfffffff0 / kGroupSize;  // protection against overflow
    // For all values < kMaxNGroups, kFirstGroupOffset + nGroups * kGroupSize fits in 32 bits.
     if (kFirstGroupOffset > size) {
         return false;
     }
     uint32_t nGroups = readU32(data, kNGroupsOffset);
    if (nGroups >= kMaxNGroups || kFirstGroupOffset + nGroups * kGroupSize > size) {
         return false;
     }
     for (uint32_t i = 0; i < nGroups; i++) {
 uint32_t groupOffset = kFirstGroupOffset + i * kGroupSize;
 uint32_t start = readU32(data, groupOffset + kStartCharCodeOffset);
 uint32_t end = readU32(data, groupOffset + kEndCharCodeOffset);
        addRange(coverage, start, end + 1); // file is inclusive, vector is exclusive
 }
 return true;
}
","static bool getCoverageFormat12(vector<uint32_t>& coverage, const uint8_t* data, size_t size) {
 const size_t kNGroupsOffset = 12;
 const size_t kFirstGroupOffset = 16;

     const size_t kGroupSize = 12;
     const size_t kStartCharCodeOffset = 0;
     const size_t kEndCharCodeOffset = 4;
     if (kFirstGroupOffset > size) {
         return false;
     }
     uint32_t nGroups = readU32(data, kNGroupsOffset);
    if (kFirstGroupOffset + nGroups * kGroupSize > size) {
         return false;
     }
     for (uint32_t i = 0; i < nGroups; i++) {
 uint32_t groupOffset = kFirstGroupOffset + i * kGroupSize;
 uint32_t start = readU32(data, groupOffset + kStartCharCodeOffset);
 uint32_t end = readU32(data, groupOffset + kEndCharCodeOffset);
        addRange(coverage, start, end + 1); // file is inclusive, vector is exclusive
 }
 return true;
}
",C,"    const size_t kMaxNGroups = 0xfffffff0 / kGroupSize;  // protection against overflow
    // For all values < kMaxNGroups, kFirstGroupOffset + nGroups * kGroupSize fits in 32 bits.
    if (nGroups >= kMaxNGroups || kFirstGroupOffset + nGroups * kGroupSize > size) {
","    if (kFirstGroupOffset + nGroups * kGroupSize > size) {
",,"@@ -29,11 +29,12 @@

 
 // These could perhaps be optimized to use __builtin_bswap16 and friends.
 static uint32_t readU16(const uint8_t* data, size_t offset) {
-    return data[offset] << 8 | data[offset + 1];
+    return ((uint32_t)data[offset]) << 8 | ((uint32_t)data[offset + 1]);
 }
 
 static uint32_t readU32(const uint8_t* data, size_t offset) {
-    return data[offset] << 24 | data[offset + 1] << 16 | data[offset + 2] << 8 | data[offset + 3];
+    return ((uint32_t)data[offset]) << 24 | ((uint32_t)data[offset + 1]) << 16 |
+        ((uint32_t)data[offset + 2]) << 8 | ((uint32_t)data[offset + 3]);
 }
 
 static void addRange(vector<uint32_t> &coverage, uint32_t start, uint32_t end) {
@@ -101,11 +102,13 @@

     const size_t kGroupSize = 12;
     const size_t kStartCharCodeOffset = 0;
     const size_t kEndCharCodeOffset = 4;
+    const size_t kMaxNGroups = 0xfffffff0 / kGroupSize;  // protection against overflow
+    // For all values < kMaxNGroups, kFirstGroupOffset + nGroups * kGroupSize fits in 32 bits.
     if (kFirstGroupOffset > size) {
         return false;
     }
     uint32_t nGroups = readU32(data, kNGroupsOffset);
-    if (kFirstGroupOffset + nGroups * kGroupSize > size) {
+    if (nGroups >= kMaxNGroups || kFirstGroupOffset + nGroups * kGroupSize > size) {
         return false;
     }
     for (uint32_t i = 0; i < nGroups; i++) {
",Android,https://android.googlesource.com/platform/frameworks/minikin/+/ed4c8d79153baab7f26562afb8930652dfbf853b/,https://android.googlesource.com/platform/frameworks/minikin/+/ed4c8d79153baab7f26562afb8930652dfbf853b%5E/,1,"static bool getCoverageFormat12(vector<uint32_t>& coverage, const uint8_t* data, size_t size) {
 const size_t kNGroupsOffset = 12;
 const size_t kFirstGroupOffset = 16;

     const size_t kGroupSize = 12;
     const size_t kStartCharCodeOffset = 0;
     const size_t kEndCharCodeOffset = 4;
//fix_flaw_line_below:
//    const size_t kMaxNGroups = 0xfffffff0 / kGroupSize;  // protection against overflow
//fix_flaw_line_below:
//    // For all values < kMaxNGroups, kFirstGroupOffset + nGroups * kGroupSize fits in 32 bits.
     if (kFirstGroupOffset > size) {
         return false;
     }
     uint32_t nGroups = readU32(data, kNGroupsOffset);
//flaw_line_below:
    if (kFirstGroupOffset + nGroups * kGroupSize > size) {
//fix_flaw_line_below:
//    if (nGroups >= kMaxNGroups || kFirstGroupOffset + nGroups * kGroupSize > size) {
         return false;
     }
     for (uint32_t i = 0; i < nGroups; i++) {
 uint32_t groupOffset = kFirstGroupOffset + i * kGroupSize;
 uint32_t start = readU32(data, groupOffset + kStartCharCodeOffset);
 uint32_t end = readU32(data, groupOffset + kEndCharCodeOffset);
        addRange(coverage, start, end + 1); // file is inclusive, vector is exclusive
 }
 return true;
}
"
10252,187988,,Local,Not required,Complete,CVE-2016-0808,https://www.cvedetails.com/cve/CVE-2016-0808/,CWE-19,Low,,,,2016-02-06,4.9,"Integer overflow in the getCoverageFormat12 function in CmapCoverage.cpp in the Minikin library in Android 5.x before 5.1.1 LMY49G and 6.x before 2016-02-01 allows attackers to cause a denial of service (continuous rebooting) via an application that triggers loading of a crafted TTF font, aka internal bug 25645298.",2016-03-14,DoS Overflow ,1,https://android.googlesource.com/platform/frameworks/minikin/+/ed4c8d79153baab7f26562afb8930652dfbf853b,ed4c8d79153baab7f26562afb8930652dfbf853b,"Avoid integer overflows in parsing fonts

A malformed TTF can cause size calculations to overflow. This patch
checks the maximum reasonable value so that the total size fits in 32
bits. It also adds some explicit casting to avoid possible technical
undefined behavior when parsing sized unsigned values.

Bug: 25645298
Change-Id: Id4716132041a6f4f1fbb73ec4e445391cf7d9616
(cherry picked from commit 183c9ec2800baa2ce099ee260c6cbc6121cf1274)
",1,libs/minikin/CmapCoverage.cpp,"{""filename"": ""libs/minikin/CmapCoverage.cpp"", ""raw_url"": ""https://android.googlesource.com/platform/frameworks/minikin/+/ed4c8d79153baab7f26562afb8930652dfbf853b/libs/minikin/CmapCoverage.cpp"", ""patch"": ""@@ -29,11 +29,12 @@\n\n \n // These could perhaps be optimized to use __builtin_bswap16 and friends.\n static uint32_t readU16(const uint8_t* data, size_t offset) {\n-    return data[offset] << 8 | data[offset + 1];\n+    return ((uint32_t)data[offset]) << 8 | ((uint32_t)data[offset + 1]);\n }\n \n static uint32_t readU32(const uint8_t* data, size_t offset) {\n-    return data[offset] << 24 | data[offset + 1] << 16 | data[offset + 2] << 8 | data[offset + 3];\n+    return ((uint32_t)data[offset]) << 24 | ((uint32_t)data[offset + 1]) << 16 |\n+        ((uint32_t)data[offset + 2]) << 8 | ((uint32_t)data[offset + 3]);\n }\n \n static void addRange(vector<uint32_t> &coverage, uint32_t start, uint32_t end) {\n@@ -101,11 +102,13 @@\n\n     const size_t kGroupSize = 12;\n     const size_t kStartCharCodeOffset = 0;\n     const size_t kEndCharCodeOffset = 4;\n+    const size_t kMaxNGroups = 0xfffffff0 / kGroupSize;  // protection against overflow\n+    // For all values < kMaxNGroups, kFirstGroupOffset + nGroups * kGroupSize fits in 32 bits.\n     if (kFirstGroupOffset > size) {\n         return false;\n     }\n     uint32_t nGroups = readU32(data, kNGroupsOffset);\n-    if (kFirstGroupOffset + nGroups * kGroupSize > size) {\n+    if (nGroups >= kMaxNGroups || kFirstGroupOffset + nGroups * kGroupSize > size) {\n         return false;\n     }\n     for (uint32_t i = 0; i < nGroups; i++) {\n""}"," static uint32_t readU16(const uint8_t* data, size_t offset) {
    return ((uint32_t)data[offset]) << 8 | ((uint32_t)data[offset + 1]);
 }
"," static uint32_t readU16(const uint8_t* data, size_t offset) {
    return data[offset] << 8 | data[offset + 1];
 }
",C,"    return ((uint32_t)data[offset]) << 8 | ((uint32_t)data[offset + 1]);
","    return data[offset] << 8 | data[offset + 1];
",,"@@ -29,11 +29,12 @@

 
 // These could perhaps be optimized to use __builtin_bswap16 and friends.
 static uint32_t readU16(const uint8_t* data, size_t offset) {
-    return data[offset] << 8 | data[offset + 1];
+    return ((uint32_t)data[offset]) << 8 | ((uint32_t)data[offset + 1]);
 }
 
 static uint32_t readU32(const uint8_t* data, size_t offset) {
-    return data[offset] << 24 | data[offset + 1] << 16 | data[offset + 2] << 8 | data[offset + 3];
+    return ((uint32_t)data[offset]) << 24 | ((uint32_t)data[offset + 1]) << 16 |
+        ((uint32_t)data[offset + 2]) << 8 | ((uint32_t)data[offset + 3]);
 }
 
 static void addRange(vector<uint32_t> &coverage, uint32_t start, uint32_t end) {
@@ -101,11 +102,13 @@

     const size_t kGroupSize = 12;
     const size_t kStartCharCodeOffset = 0;
     const size_t kEndCharCodeOffset = 4;
+    const size_t kMaxNGroups = 0xfffffff0 / kGroupSize;  // protection against overflow
+    // For all values < kMaxNGroups, kFirstGroupOffset + nGroups * kGroupSize fits in 32 bits.
     if (kFirstGroupOffset > size) {
         return false;
     }
     uint32_t nGroups = readU32(data, kNGroupsOffset);
-    if (kFirstGroupOffset + nGroups * kGroupSize > size) {
+    if (nGroups >= kMaxNGroups || kFirstGroupOffset + nGroups * kGroupSize > size) {
         return false;
     }
     for (uint32_t i = 0; i < nGroups; i++) {
",Android,https://android.googlesource.com/platform/frameworks/minikin/+/ed4c8d79153baab7f26562afb8930652dfbf853b/,https://android.googlesource.com/platform/frameworks/minikin/+/ed4c8d79153baab7f26562afb8930652dfbf853b%5E/,1," static uint32_t readU16(const uint8_t* data, size_t offset) {
//flaw_line_below:
    return data[offset] << 8 | data[offset + 1];
//fix_flaw_line_below:
//    return ((uint32_t)data[offset]) << 8 | ((uint32_t)data[offset + 1]);
 }
"
10253,187989,,Local,Not required,Complete,CVE-2016-0808,https://www.cvedetails.com/cve/CVE-2016-0808/,CWE-19,Low,,,,2016-02-06,4.9,"Integer overflow in the getCoverageFormat12 function in CmapCoverage.cpp in the Minikin library in Android 5.x before 5.1.1 LMY49G and 6.x before 2016-02-01 allows attackers to cause a denial of service (continuous rebooting) via an application that triggers loading of a crafted TTF font, aka internal bug 25645298.",2016-03-14,DoS Overflow ,2,https://android.googlesource.com/platform/frameworks/minikin/+/ed4c8d79153baab7f26562afb8930652dfbf853b,ed4c8d79153baab7f26562afb8930652dfbf853b,"Avoid integer overflows in parsing fonts

A malformed TTF can cause size calculations to overflow. This patch
checks the maximum reasonable value so that the total size fits in 32
bits. It also adds some explicit casting to avoid possible technical
undefined behavior when parsing sized unsigned values.

Bug: 25645298
Change-Id: Id4716132041a6f4f1fbb73ec4e445391cf7d9616
(cherry picked from commit 183c9ec2800baa2ce099ee260c6cbc6121cf1274)
",1,libs/minikin/CmapCoverage.cpp,"{""filename"": ""libs/minikin/CmapCoverage.cpp"", ""raw_url"": ""https://android.googlesource.com/platform/frameworks/minikin/+/ed4c8d79153baab7f26562afb8930652dfbf853b/libs/minikin/CmapCoverage.cpp"", ""patch"": ""@@ -29,11 +29,12 @@\n\n \n // These could perhaps be optimized to use __builtin_bswap16 and friends.\n static uint32_t readU16(const uint8_t* data, size_t offset) {\n-    return data[offset] << 8 | data[offset + 1];\n+    return ((uint32_t)data[offset]) << 8 | ((uint32_t)data[offset + 1]);\n }\n \n static uint32_t readU32(const uint8_t* data, size_t offset) {\n-    return data[offset] << 24 | data[offset + 1] << 16 | data[offset + 2] << 8 | data[offset + 3];\n+    return ((uint32_t)data[offset]) << 24 | ((uint32_t)data[offset + 1]) << 16 |\n+        ((uint32_t)data[offset + 2]) << 8 | ((uint32_t)data[offset + 3]);\n }\n \n static void addRange(vector<uint32_t> &coverage, uint32_t start, uint32_t end) {\n@@ -101,11 +102,13 @@\n\n     const size_t kGroupSize = 12;\n     const size_t kStartCharCodeOffset = 0;\n     const size_t kEndCharCodeOffset = 4;\n+    const size_t kMaxNGroups = 0xfffffff0 / kGroupSize;  // protection against overflow\n+    // For all values < kMaxNGroups, kFirstGroupOffset + nGroups * kGroupSize fits in 32 bits.\n     if (kFirstGroupOffset > size) {\n         return false;\n     }\n     uint32_t nGroups = readU32(data, kNGroupsOffset);\n-    if (kFirstGroupOffset + nGroups * kGroupSize > size) {\n+    if (nGroups >= kMaxNGroups || kFirstGroupOffset + nGroups * kGroupSize > size) {\n         return false;\n     }\n     for (uint32_t i = 0; i < nGroups; i++) {\n""}"," static uint32_t readU32(const uint8_t* data, size_t offset) {
    return ((uint32_t)data[offset]) << 24 | ((uint32_t)data[offset + 1]) << 16 |
        ((uint32_t)data[offset + 2]) << 8 | ((uint32_t)data[offset + 3]);
 }
"," static uint32_t readU32(const uint8_t* data, size_t offset) {
    return data[offset] << 24 | data[offset + 1] << 16 | data[offset + 2] << 8 | data[offset + 3];
 }
",C,"    return ((uint32_t)data[offset]) << 24 | ((uint32_t)data[offset + 1]) << 16 |
        ((uint32_t)data[offset + 2]) << 8 | ((uint32_t)data[offset + 3]);
","    return data[offset] << 24 | data[offset + 1] << 16 | data[offset + 2] << 8 | data[offset + 3];
",,"@@ -29,11 +29,12 @@

 
 // These could perhaps be optimized to use __builtin_bswap16 and friends.
 static uint32_t readU16(const uint8_t* data, size_t offset) {
-    return data[offset] << 8 | data[offset + 1];
+    return ((uint32_t)data[offset]) << 8 | ((uint32_t)data[offset + 1]);
 }
 
 static uint32_t readU32(const uint8_t* data, size_t offset) {
-    return data[offset] << 24 | data[offset + 1] << 16 | data[offset + 2] << 8 | data[offset + 3];
+    return ((uint32_t)data[offset]) << 24 | ((uint32_t)data[offset + 1]) << 16 |
+        ((uint32_t)data[offset + 2]) << 8 | ((uint32_t)data[offset + 3]);
 }
 
 static void addRange(vector<uint32_t> &coverage, uint32_t start, uint32_t end) {
@@ -101,11 +102,13 @@

     const size_t kGroupSize = 12;
     const size_t kStartCharCodeOffset = 0;
     const size_t kEndCharCodeOffset = 4;
+    const size_t kMaxNGroups = 0xfffffff0 / kGroupSize;  // protection against overflow
+    // For all values < kMaxNGroups, kFirstGroupOffset + nGroups * kGroupSize fits in 32 bits.
     if (kFirstGroupOffset > size) {
         return false;
     }
     uint32_t nGroups = readU32(data, kNGroupsOffset);
-    if (kFirstGroupOffset + nGroups * kGroupSize > size) {
+    if (nGroups >= kMaxNGroups || kFirstGroupOffset + nGroups * kGroupSize > size) {
         return false;
     }
     for (uint32_t i = 0; i < nGroups; i++) {
",Android,https://android.googlesource.com/platform/frameworks/minikin/+/ed4c8d79153baab7f26562afb8930652dfbf853b/,https://android.googlesource.com/platform/frameworks/minikin/+/ed4c8d79153baab7f26562afb8930652dfbf853b%5E/,1," static uint32_t readU32(const uint8_t* data, size_t offset) {
//flaw_line_below:
    return data[offset] << 24 | data[offset + 1] << 16 | data[offset + 2] << 8 | data[offset + 3];
//fix_flaw_line_below:
//    return ((uint32_t)data[offset]) << 24 | ((uint32_t)data[offset + 1]) << 16 |
//fix_flaw_line_below:
//        ((uint32_t)data[offset + 2]) << 8 | ((uint32_t)data[offset + 3]);
 }
"
